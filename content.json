{"meta":{"title":"Yao Lirong's Blog","subtitle":null,"description":"å§šç«‹åµ˜ (Yao Lirong)'s Personal Website","author":"Yao Lirong","url":"https://yao-lirong.github.io/blog","root":"/blog/"},"pages":[{"title":"è‚¥è‚ æŠ±æ­‰ï¼Œå‡ºé”™äº†","date":"2025-04-23T16:14:56.051Z","updated":"2021-09-24T03:43:52.000Z","comments":true,"path":"404.html","permalink":"https://yao-lirong.github.io/blog/404.html","excerpt":"","text":""},{"title":"Hello, World","date":"2019-06-27T04:00:00.000Z","updated":"2021-09-24T03:35:56.000Z","comments":true,"path":"about/index.html","permalink":"https://yao-lirong.github.io/blog/about/index.html","excerpt":"","text":"Cornell CS â€™2023 Credits Favicon - Concentric Rinds by M.C. Escher Homepage - Encounter by M.C. Escher About Me page - Day and Night by M.C. Escher"}],"posts":[{"title":"Matryoshka Representation Learning, Adaptive Retrieval and Binary Vector Search","slug":"2024-12-25-Matryoshka-Representation-Learning,-Adaptive-Retrieval-and-Binary-Vector-Search","date":"2024-12-25T05:00:00.000Z","updated":"2025-09-15T17:52:19.640Z","comments":true,"path":"2024-12-25-Matryoshka-Representation-Learning,-Adaptive-Retrieval-and-Binary-Vector-Search/","permalink":"https://yao-lirong.github.io/blog/2024-12-25-Matryoshka-Representation-Learning,-Adaptive-Retrieval-and-Binary-Vector-Search/","excerpt":"Introduces ways to make retrieval quicker","text":"Intro to Matryoshka Representation Learning In Matryoshka Representation Learning (MRL), we want to construct an encoding ed with dimension d such that its truncations of different lengths (ed/16, ed/8, ed/4, ed/2â€‹) are each (somewhat) valid representations. Suppose youâ€™re training on a classification problem with the classic encoder + classifier head architecture. At train time: classic setting: you just use the vector ed as input to the classifier head MRL: construct multiple classifier heads (in our case 5) and put one on top of encoding of each length (ed/16, â€¦, ed) and average the loss of each classifier head. So we build heads of size [d, num_class], [d/2, num_class], ... [d/16, num_class] Note these classifier heads share weights. Application: Adaptive Retrieval Online retrieval is one of the tasks where latency matters the most. Given a user query q, it is slow to compute KNN from a dataset of size 1M (106) indexes if each index has dimension 3072. With MRL, we can decompose the process into two stages: Shortlist: First retrieve 2K indexes where the distance is computed using only 1024-d vector (the first 1024 elements of the 3072 vector) Rerank: Find KNN among these 2K indexes where the distance is computed using the full length 3072 vector The FLOP is therefore reduced from 3072 Ã— 106 to 1024 Ã— 106 + 3072 Ã— 2K. Ce Gao tested full length 3072-dim vector vs adaptive retrieval using Matryoshka 1024-dim. The accuracy dropped from 99% to 89% with Requests Per Second (RPS) raises from 300 to 1000. Find more details of Matryoshka Representation Learning and its applications in this wonderful blog post. Read from section What is MRL? (Really this Time) Binary Vector Search Ce Gao suggested another way to reduce memory and FLOP use. He proposes to turn the length d FP32 vector into a length d binary vector, where original positive value is set to 1 and original negative value is set to 0. Without using adaptive retrieval, the accuracy dropped from 99% to 83%, but the latency (RPS = 3000) and memory has a significant improvement because previously one single vector / encoding consists of d 32-bit number, whereas now it only consists of d 1-bit number. If you adapt the Adaptive Retrieval setup mentioned earlier: Shortlist: retrieve 2K indexes using full-length but binary vector Rerank: find KNN among 2K indexes using full-length, FP32 vector you get a precision drop from 99% only to 96% with an RPS of 1700. P.S. I discovered this method on Simon Willisonâ€™s blog.","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"YouTube Recommendation Algorithms (2016)","slug":"2024-10-15-YouTube-Recommendation-Algorithms-(2016)","date":"2024-10-15T04:00:00.000Z","updated":"2025-09-03T01:42:46.382Z","comments":true,"path":"2024-10-15-YouTube-Recommendation-Algorithms-(2016)/","permalink":"https://yao-lirong.github.io/blog/2024-10-15-YouTube-Recommendation-Algorithms-(2016)/","excerpt":"This is a detailed reading of Googleâ€™s paper Deep Neural Networks for YouTube Recommendations","text":"This is a detailed reading of Googleâ€™s paper Deep Neural Networks for YouTube Recommendations Candidate Generation Problem Setup We pose recommendation as an extreme multi-class classification problem where we predict which video will be watched next. Specifically, we classify a specific video watch wt at time t among millions of videos i (classes) from a video corpus V based on a user U and context C. And $u \\in \\R^d$ represents a high-dimensional â€œembeddingâ€ of the user-context pair and the $v_j \\in \\R^d$ represent embeddings of each candidate video. P(wt = i âˆ£ U, C) = Softmax(V, u)i Input what we didnâ€™t use: explicit feedback (thumbs up/down, in-product surveys) because thereâ€™s too few of them in the tail of videos. embedded video watches: representation of each video: in my understanding, YouTube didnâ€™t extract information from their videos, and fed the extracted info into the embedder. Instead, they directly fed the video ids into the embedder. To my understanding, â€œInspired by continuous bag of words language modelsâ€ means they fed the video ids into the embedder, just like NLP feeds BoW representation into embedder. It doesnâ€™t mean YouTube decomposes a video into word count like BoW. I reached this conclusion from the last sentence of 4.1 Feature Representation - Embedding Categorical Features, where 1000000*32 / (2048*2048) = 7 The overwhelming majority of model parameters are in these high-cardinality embedding spaces - for example, one million IDs embedded in a 32 dimensional space have 7 times more parameters than fully connected layers 2048 units wide. representation of watch history: watch history is a variable-length list of videos. YouTube used average-pooling to transform them into a fixed-length vector. why order-independent pooling? embedded search tokens: each query is tokenized into unigrams and bigrams. each token is embedded. All these embedded tokens from all queries are then pooled and fed into the model as a summarized dense search history. geographic embeddings: The userâ€™s geographic region and device are embedded and concatenated. Simple binary and continuous features: such as the userâ€™s gender, logged-in state and age are input directly into the network as real values normalized to [0, 1]. example (sample) age: ML model often has bias towards past samples because thereâ€™s more data about them. Itâ€™s common to promote video freshness during re-rank phase, but YouTube also try to reduce this bias as early as in candidate generation phase. We define the example age to be the time between training and obtaining this sample. e.g. t days earlier, after having watched video v, user searched word w and clicked on another video y. We use this sample in training, so its sample age is t. By introducing this feature, our model no longer reflects the average watch likelihood in the training window of several weeks, but the likelihood at a specific time step. At serving time, this feature is set to zero (or slightly negative) to reflect that the model is making predictions at the very end of the training window. æ€»ç»“æŸçŸ¥ä¹è®¨è®ºä¸‹çš„å†…å®¹: example age å’Œæ¶ˆé™¤ç¬¬ä¸€ç§ ad position bias åšæ³•ç±»ä¼¼ çº¯feedåº”ç”¨ä¸­å‰ç½®å†…å®¹ç‚¹å‡»ç‡è¢«é«˜ä¼°ï¼šæ–°é—»å®¢æˆ·ç«¯ï¼Œpositioné å‰çš„æ˜¯è™šé«˜çš„ï¼Œè¿™éƒ¨åˆ†å« position biasï¼Œè¾“å…¥ç»™æ¨¡å‹çš„æ—¶å€™ä¹Ÿè¦è¾“å…¥å®ƒä»¬çš„ä½ç½®ï¼Œåœ¨çº¿ä¸Šé¢„ä¼°æ—¶ç½®0 æœç´¢åå‘åº”ç”¨ä¸­å‰ç½®å†…å®¹ç‚¹å‡»ç‡è¢«ä½ä¼°ï¼šæ‰‹ç™¾ï¼Œæ‰‹æ·˜ï¼Œç¾å›¢ç­‰ï¼Œéƒ½ä¼šåœ¨é¦–é¡µé»˜è®¤å±•ç¤ºfeedï¼Œä½†å¾ˆå¤šç›®çš„æ˜ç¡®çš„ç”¨æˆ·å‹æ ¹ä¸ä¼šç”¨è¿™äº›æ¨èåŠŸèƒ½ï¼Œå¯¼è‡´è¿™éƒ¨åˆ†å±•ç¤ºçš„å†…å®¹ç‚¹å‡»ç‡æ˜¯è¢«ä½ä¼°äº†ã€‚å®é™…æ“ä½œä¸­å¤§å®¶å¯èƒ½åªé’ˆå¯¹æœ‰feedäº’åŠ¨çš„ç”¨æˆ·è¿›è¡Œé‡‡æ ·ï¼ŒæŠ›å¼ƒäº†å®Œå…¨è¿‡è·¯å‹ç”¨æˆ·çš„è¡Œä¸ºï¼Œä¹Ÿç®—æ˜¯ä¿®æ­£biasäº† Data Gathering Details Class Balance: generate a fixed number of training examples per user, effectively weighting our users equally in the loss function Permutation-Invariant Pooling: in pooling, YouTube chose average pooling among sum, max, etc, because average performed the best. The important thing is, they decided to abandon sequence information whatsoever. Their explanation is below and I donâ€™t quite buy it because theyâ€™re definitely better way to solve this problem than discarding the info altogether. In addition, they did publish another paper on sequence-based recommendation system later. I think at this paperâ€™s publishing time, they either didnâ€™t want to publicize it or have not tested that in detail. Consider the user has just issued a search query for â€œtaylor swiftâ€. Since our problem is posed as predicting the next watched video, a classifier given this information will predict that the most likely videos to be watched are those which appear on the corresponding search results page for â€œtaylor swiftâ€. Unsurprisingly, reproducing the userâ€™s last search page as homepage recommendations performs very poorly. By discarding sequence information and representing search queries with an unordered bag of tokens, the classifier is no longer directly aware of the origin of the label. Next-Watch Heldout: at the time, many collaborative filtering systems implicitly choose the labels and context by holding out a random item and predicting it from other items in the userâ€™s history. They decided to always hold out and predict userâ€™s next watch and achieved much better results. This is now already the standard. In fact it appeared in my college class CS4780 by Killian. Training: In these experiments, a vocabulary of 1M videos and 1M search tokens were embedded with 256 floats each in a maximum bag size of 50 recent watches and 50 recent searches. The softmax layer outputs a multinomial distribution over the same 1M video classes with a dimension of 256 (which can be thought of as a separate output video embedding). negative sampling: for the same user, in addition to his watched videos, we also sample some unwatched videos to generalize the model. Importance Weighting: we do not take softmax over all the 1M videos. Instead, we sample ~5000 of them, compute their probability, re-weight them based on importance (watch time, click rate?) and only compute loss over these samples. loss: this is a multi-class classification problem, so we use cross-entropy loss naturally Inference / Serving: kNN: In serving, we need an algorithm sublinear to number of classes (videos to recommend). Say the last layer of the network has hidden dimension d and we have N videos to predict. Decoding hidden dimension back into per-video logits and take a softmax takes O(dN). Sorting takes O(Nlog N). The total time is O(dN + Nlog N). On the other hand, naive kNN takes O(dN) time in total and some heuristic version like Ball tree can take O(dlog N)â€‹â€‹. distance is based on dot product how do we get video embedding? (where is decoder?) youtube-candidate-generation-architecture All classification models have to include a decoder (FC layer) at the end of the network but before the softmax layer to decode the hidden vector back to per-video logits in video ID space to make prediction. If we have 1M videos and hidden vector is of dimension 256, the decoder is a matrix of size [256, 1M]. However, the graph presented in the paper is very confusing because the authors omit drawing the decoder and made it an implicit part of the softmax layer. Anyway, we know we do have that decoder, so itâ€™s natural to use the vectors in the decoder as our video embedding. The i-th videoâ€™s embedding is simply decoder[:, i]. weight sharing / weight tying: this is a concept I encountered in nanoGPT and has become clear here. At the beginning of the network, we have a video encoder from video ID space to hidden space; at the end of the network, we have a video decoder from hidden space back to video ID space. It is possible to share weights (use the same weights) in encoder and decoder to save space (recall this part costs the most parameter). This is just mentioned by people in comment section and is not implemented by Google. Ranking Problem Setup We pose ranking as predicting the expected watch time of a video. Ranking by click-through rate often promotes deceptive videos that the user does not complete (â€œclickbaitâ€) whereas watch time better captures engagement Input (Feature Engineering) userâ€™s previous interaction with the item itself and other similar items: e.g. userâ€™s past history with the channel that uploaded the video being scored (how many videos has the user watched from this channel? When was the last time the user watched a video on this topic?) propagate information from candidate generation into ranking in the form of features: e.g. which sources nominated this video candidate? What scores did they assign? frequency of past video impressions: If a user was recently recommended a video but did not watch it then the model will naturally demote this impression on the next page load. Input Details embedding space should increase approximately proportional to the logarithm of the number of unique values of data space very large space (video id &amp; query token) is truncated by click-through-rate. So we only recommend videos above a certain CTR. Note these filtered out videos can still be searched out. Out-of-vocabulary values (new / truncated videos) are mapped to the zero embedding. Continuous features are always normalized to [0, 1) In addition to the raw normalized feature x, we also input $\\sqrt x$ and x2â€‹, giving the network more expressive power by allowing it to easily form super- and sub-linear functions of the feature. Feeding powers of continuous features was found to improve offline accuracy. Training We use Logistic Regression to predict expected watch time (EWT) of a video, but LR only predicts 0 or 1. How can we use it to predict EWT? We use weighted logistic regression, where the positive (clicked) impressions are weighted by the observed watch time on the video. Negative (unclicked) impressions all receive unit weight. In training, we use the weighted cross entropy loss: WeightedCrossEntropy = âˆ’âˆ‘i[Tiyilog pi + (1 âˆ’ yi)log (1 âˆ’ pi)] ### Serving In serving, we directly output eÎ¸x as the predicted watch time. Why is this the watch time? Recall in Logistic Regression, we have a binary classification problem, so we can define P(Yi = 1|Xi) = p, P(Yi = 0|Xi) = 1 âˆ’ p and $$ p = \\frac{1}{1 + e^{-\\theta^T x}} $$ In statistics, we define odds as: $$ \\texttt{odds} = \\frac{p}{1-p} = \\frac{1}{e^{-\\theta^Tx}} = e^{\\theta^Tx} $$ If we take a log at both sides, we have the log odds, or logits $$ \\ln(\\texttt{odds}) = \\ln(\\frac{p}{1-p}) = \\theta^Tx $$ Now letâ€™s look at the our weighted logistic regression problem: Positive impressions are weighted by watch time Ti. Negative impressions receive unit weight. We have a total N videos, and k of them are positive (clicked). We have k = pN and the expected watch time of all videos is $\\mathbb E[T] = \\frac{\\sum_i^k T_i}{N}$. Now look at our weighted odds: $$ \\begin{align} \\texttt{wghted odds} &amp;= \\frac{\\text{weighted pos prob}}{\\text{weighted neg prob}}\\\\ &amp;= \\frac{\\sum_i^k T_i}{N-k} = \\frac{\\sum_i^k T_i}{N-pN} = \\frac{\\sum_i^k T_i}{N(1-p)} = \\frac{\\sum_i^k T_i}{N}\\frac{1}{1-p}\\\\ &amp; = \\mathbb E[T](1+p) \\approx \\mathbb E[T] \\hspace{20px}\\text{($p$ is small)} \\end{align} $$ Therefore, at serving time, we can directly output eÎ¸x because it is the expected watch time. Evaluation Metric Since weâ€™re essentially predicting a videoâ€™s watch time, we â€œwrongly-predicted videoâ€™s watch timeâ€ as our evaluation metric. In the paper, author called it â€œweighted, per-user lossâ€. Specifically, for each user, we feed the model both positive (clicked) and negative (unclicked) impressions shown to him on a single page. We first predict their respective watch time with our model. â€œmispredicted watch timeâ€ is the positive videoâ€™s watch time when the negative impression receives a longer predicted watch time than the positive impression. This userâ€™s loss is total mispredicted watch time / total watch time of ground-truth (positive) impressions. Takeaway example age expected watch time KNN - quick serving feature engineering what is surrogate problem? https://www.youtube.com/watch?v=WK_Nr4tUtl8 Comment RNNè¿™ä¸ªæ–¹æ³•åœ¨17å¹´å·²ç»ç”±Alex Beutelåšä¸Šçº¿äº†ï¼Œå…¶å®åœ¨16å¹´åˆå°±æƒ³åšï¼Œåªæ˜¯æ•ˆæœè¿˜æ²¡æœ‰å®Œå…¨å‡ºæ¥ï¼Œåæ¥Alexå‘ç°äº†åŸå…ˆåšæ³•çš„ä¸€äº›å¼±ç‚¹ï¼Œå¾ˆå¿«æ”¹è¿›ä¹‹åå°±ä¸Šçº¿äº†ï¼Œä½œä¸ºé‡è¦çš„candidates generationæ¥æºï¼›æ’åºç›®æ ‡åªå†™äº†EWTï¼Œä¸€æ˜¯Googleçš„æŠ€æœ¯ä¿å¯†è¦æ±‚ï¼Œæ¯•ç«Ÿè¿˜æ˜¯è¦åšåˆ°HR-safeçš„ï¼Œè®ºæ–‡åªèƒ½ç‚¹åˆ°å³æ­¢ï¼ŒäºŒæ˜¯ç›¸å¯¹æœ‰æ•ˆå¹¶ä¸”èƒ½å¤Ÿæ¯”åˆ†å¼€é¢„æµ‹ctrå’Œstaytimeèƒ½èŠ‚çœserving latenc â€“ ä¸¥æ— under é‡è¯»Youtubeæ·±åº¦å­¦ä¹ æ¨èç³»ç»Ÿè®ºæ–‡ï¼Œå­—å­—ç ç‘ï¼ŒæƒŠä¸ºç¥æ–‡","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"Running MobileBert on Android with TensorFlow Lite","slug":"2024-09-22-Running-MobileBert-on-Android-with-TensorFlow-Lite","date":"2024-09-22T04:00:00.000Z","updated":"2025-09-03T01:42:46.391Z","comments":true,"path":"2024-09-22-Running-MobileBert-on-Android-with-TensorFlow-Lite/","permalink":"https://yao-lirong.github.io/blog/2024-09-22-Running-MobileBert-on-Android-with-TensorFlow-Lite/","excerpt":"So Google, fxxk you.","text":"So Google, fxxk you. Prerequsities This picture very well explains how TFLite works and also why TensorFlow 2 has both a tf and a keras. TFLite Workflow Detours This section is mostly rant, but it is meaningful in preventing you from taking any of the wrong path. Skip to the next section for a tutorial on what to do. We first found the Googleâ€™s official release http://google-research/mobilebert/, but the tutorial was unclear: Why do I need data_dir and output_dir to export TFLite? How do I even read in the pre-trained weights? the code itself was pretty messy: why did they have export function and training function all at this same file run_squad.py and the only way to tell the program whether to train/export is checking whether export_dir is None rather than passing a flag? In figuring out what each part does in this code, I looked up TensorFlow 1â€™s doc and good lord they were broken. Google doesnâ€™t even host it anywhere: you have to go to a GitHub repo to read them in .md format. At this moment I decided I will not touch anything written by TensorFlow 1â€™s API. (I actually went through this pain back at my first ML intern in Haier, but not again) Sidenote before this: I didnâ€™t know you can release modelâ€™s on Kaggle (thought everyone releases on Hugging Face) and Google moved their own TensorFlow Hub to Kaggle So my supervisor found me a more readable Google release on Kaggle with some high-level API and doesnâ€™t require you to read the painful source code. The above link has a redirect to TensorFlow 2 implementation with an official TFLite release. How neat. However, the official TFLite release doesnâ€™t have signature - TensorFlowâ€™s specification of input and output (remember when you pass inputs to a model you need to give name to them e.g. token_ids = ..., mask = ...) which is required for Xiaomi Service Framework to run a TFLite. P.S. Yes signature is not required to specify when exporting, but for godâ€™s sake all your tutorial teaches people to use it and your own released ditched it? WTF Google. is broken (as expected?). When I tried to run it on my PC, I got the following error indices_has_only_positive_elements was not true.gather index out of boundsNode number 2 (GATHER) failed to invoke.gather index out of boundsNode number 2 (GATHER) failed to invoke. Someone encountered a similar bug while running the example code provided by TensorFlow and the Google SWE found a bug in their example. At this moment I decided not to trust this TFLite file anymore and just convert it on my own. So letâ€™s use this official TensorFlow 2 implementation and convert it to TFLite. It was all good and running on my PC, but Its output format was really weird It output consists of 'mobile_bert_encoder', 'mobile_bert_encoder_1', 'mobile_bert_encoder_2', ..., 'mobile_bert_encoder_51' Each of these has shape (1, 4, 128, 128) for a seq_length = 128, hidden_dim = 512 model. I figured 4 being the number of heads and the other 128 is hidden_dim for each head. They output attention scores, not the final encoded vector: my input was 5 tokens and they output is output[0, 0, 0, :] = array([0.198, 0.138, 0.244, 0.148, 0.270, 0. , 0. , .... They sum to 1 and any other positions at output are 0 , so attention score was my best guess. It doesnâ€™t run on Android phone: tflite engine load failed due to java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Op builtin_code out of range: 153. Are you using old TFLite binary with newer model? A Stack Overflow answer suggests the TensorFlow used to export TFLite running on my PC doesnâ€™t match the version of TFLite run time on this Android phone. It can also be caused by me messing up with the whole environment while installing Optimum to export TFLite last night, but I didnâ€™t bother to look because I finally found the solution And comes the savior, the king, the go-to solution in MLOps - Huggingface. Reminded by a discussion I read by chance, I came to realize TFMobileBertModel.from_pretrained actually returns the Keras model (and the without TF version returns a PyTorch model). That means I can just use Hugging Face API to read it in, then use the native TensorFlow 2 API to export to TFLite. And everything works like a charm now. The final output signature is just Hugging Faceâ€™s familiar ['last_hidden_state', 'pooler_output'] Converting TensorFlow Model to TFLite Conversion is pretty straight forward. You can just follow this official guide: For Mobile &amp; Edge: Convert TensorFlow models. Though I actually followed my predecessorâ€™s note (which actually comes from another TF tutorial). He also told me to caution that calling tf.disable_eager_execution() can lead to absence of signature, so do not call tf.disable_eager_execution() to disable eager mode. 1234567891011121314151617181920212223from transformers import MobileBertTokenizerFast, TFMobileBertModel# Convert Modelif be_sane: bert_model = TFMobileBertModel.from_pretrained(kerasH5_model_path) if keras_file else \\ TFMobileBertModel.from_pretrained(pytorch_model_path, from_pt = True) converter = tf.lite.TFLiteConverter.from_keras_model(bert_model)else: # be crazy or already knows the messy TensorFlow.SavedModel format converter = tf.lite.TFLiteConverter.from_saved_model(model_path)tflite_model = converter.convert()# Save Modeltflite_output_path = &#x27;/model.tflite&#x27;with open(tflite_output_path, &#x27;wb&#x27;) as f: f.write(tflite_model)# Check Signature# Empty signature means error in the export process and the file cannot be used by Xiaomi Service Frameworkinterpreter = tf.lite.Interpreter(model_path=tflite_output_path)interpreter = tf.lite.Interpreter(model_content=tflite_model)interpreter.allocate_tensors()signatures = interpreter.get_signature_list()print(&quot;tflite model signatures:&quot;, signatures) 1234&#123;&#x27;serving_default&#x27;: &#123;&#x27;inputs&#x27;: [&#x27;attention_mask&#x27;,&#x27;input_ids&#x27;,&#x27;token_type_ids&#x27;],&#x27;outputs&#x27;: [&#x27;last_hidden_state&#x27;, &#x27;pooler_output&#x27;]&#125;&#125; In addition, summarizing from the detours I took, Do not use Hugging Faceâ€™s Optimum for (at least vanilla) conversion because it just calls the above command (see code) Do not even bother to look at Googleâ€™s original code converting MobileBert to TFLite because nobody knows what theyâ€™re writing. Running TFLite (on PC) Running TFLite on Android phone is the other departmentâ€™s task. I just want to run the TFLite file on PC to test everythingâ€™s good. To do that, I strictly followed TensorFlowâ€™s official guide: TensorFlow Lite inference: Load and run a model in Python.Our converted models have the signatures, you can just follow the â€œwith a defined SignatureDefâ€ guide. 12345678tokenizer = MobileBertTokenizerFast(f&quot;&#123;model_path&#125;/vocab.txt&quot;)t_output = tokenizer(&quot;è¶Šè¿‡é•¿åŸï¼Œèµ°å‘ä¸–ç•Œ&quot;, return_tensors=&quot;tf&quot;)ii, tt, am = t_output[&#x27;input_ids&#x27;], t_output[&#x27;token_type_ids&#x27;], t_output[&#x27;attention_mask&#x27;]# `get_signature_runner()` with empty input gives the &quot;serving_default&quot; runner# `runner` input parameter is specified by `serving_default[&#x27;inputs&#x27;]`runner = interpreter.get_signature_runner() output = runner(input_ids = ii, token_type_ids = tt, attention_mask = am)assert output.keys == [&#x27;last_hidden_state&#x27;, &#x27;pooler_output&#x27;] On the other hand, for a model without signatures, you need to use the more primitive API input_details and output_details. They specify the following properties, where index is (probably) the index of this tensor in the compute graph. To pass input values and get output values, you need to access them by this index. 12345678interpreter.allocate_tensors()input_details = interpreter.get_input_details()output_details = interpreter.get_output_details()interpreter.set_tensor(input_details[0][&#x27;index&#x27;], input_data)interpreter.invoke()output_data = interpreter.get_tensor(output_details[0][&#x27;index&#x27;])print(output_data) The following is the input_details of the non-signature Google packed MobileBert. 123456789101112interpreter.get_input_details()[&#123;&#x27;name&#x27;: &#x27;model_attention_mask:0&#x27;, &#x27;index&#x27;: 0, &#x27;shape&#x27;: array([ 1, 512], dtype=int32), &#x27;shape_signature&#x27;: array([ 1, 512], dtype=int32), &#x27;dtype&#x27;: numpy.int64, &#x27;quantization&#x27;: (0.0, 0), &#x27;quantization_parameters&#x27;: &#123;&#x27;scales&#x27;: array([], dtype=float32), &#x27;zero_points&#x27;: array([], dtype=int32), &#x27;quantized_dimension&#x27;: 0&#125;, &#x27;sparsity_parameters&#x27;: &#123;&#125;&#125;, &#123;...&#125;] Numerical Accuracy Our original torch/TensorFlow encoder and the converted TFLite encoder, when both running on PC using Python, has a 1.2% difference in their output (last_hidden_state or pooled_output). We do not know where this discrepancy comes from. Converting Tokenizer to TFLite We exported and ran the encoder, but thatâ€™s not enough. We canâ€™t ask the user to type in token_ids every time. Therefore, we need to integrate the preprocessor (tokenizer) into our TFLite file. To do that, we first tried integrating Googleâ€™s official Keras tokenizer implementation into our BERT model and convert them together into a TFLite (yeah I didnâ€™t learn the lesson). This failed in the converting step for reasons that would become clear later. And we switched gears to follow some other guide and first try to convert a standalone tokenizer to TFLite. Tokenizer is a part of the TensorFlow Text library. I followed the official guide: Converting TensorFlow Text operators to TensorFlow Lite with text.FastBertTokenizer. Note when you follow it, do it carefully and closely. I encountered a few problems along the way: When you change the text.WhitespaceTokenizer in guide to our text.FastBertTokenizer, remember to specify a text.FastBertTokenizer(vocab=vocab_lst). We need not the path to the vocab but the actual list e.g. [ \"[PAD]\", \"[unused0]\", \"[unused1]\", ...] describes the vocab where [PAD] maps to token id 0, [unused0] to token id 1, and so on. text.FastBertTokenizer (or the standard version) does not add [CLS] token for you. Google says this is to make sure â€œyou are able to manipulate the tokens and determine how to construct your segments separatelyâ€ (GitHub issue). How considerate you are, dear Google. I spent one and a half day figuring out how to add these tokens when the modelâ€™s input length needs to be fixed, otherwise it triggers TensorFlowâ€™s compute graph to throw â€œcanâ€™t get variable-length inputâ€ error. I finally found a solution in Googleâ€™s mediapipeâ€™s implementation. Could not translate MLIR to FlatBuffer when running tflite_model = converter.convert(): as mentioned, you must follow the guide very carefully. The guide specifies a TensorFlow Text version. If not this version, the conversion would fail 1pip install -U &quot;tensorflow-text==2.11.*&quot; Encountered unresolved custom op: FastBertNormalize when running converted interpreter / signature: as stated in the Inference section of the guide, tokenizers are custom operations and need to be specified when running inference. (I canâ€™t find doc for InterpreterWithCustomOps anywhere but it does have an argument model_path) 123interp = interpreter.InterpreterWithCustomOps( model_content=tflite_model,# or model_path=TFLITE_FILE_PATH custom_op_registerers=tf_text.tflite_registrar.SELECT_TFTEXT_OPS) TensorFlow Text custom ops are not found on Android: the above inference guide writes while the example below shows inference in Python, the steps are similar in other languages with some minor API translations which is a total lie. Android does not support these operations as the custom text op list only mentions python support. At the end, I did manage to 1 merge the above tokenizer and HuggingFace model, 2 export a TFLite model that reads in a text and outputs the last hidden state. However, I seem to have lost that piece of the code. Donâ€™t worry though. Because thanks to Googleâ€™s shitty framework, it only works with very few tokenizer implementations anyway. The work-for-all solution is to build your own tokenizer in Java. P.S. While debugging the FlatBuffer error, I came across the TensorFlow authoring tool that can explicitly specify a functionâ€™s input output format and detect op unsupported by TFLite. However, the tools is pretty broken for me. Debugging this tool would probably take longer than finding the problem yourself online / ask on a forum. Writing Your Own Tokenizer Whatâ€™s weird is TensorFlow does have an official BERT on Android example. Reading it again, I found their tokenizer is actually implemented by C++ (see this example). The repo containing the tokenizer code is called tflite-support. Finding this libraryâ€™s doc, it becomes clear that the text-related operations are currently not supported. TFLite-Support Current use-case coverage Google seems to have used JNI to call the C++ implementation of tokenizer (see code). Therefore, weâ€™d better write our own tokenizer. Luckily Hugging Face also has a Bert on Android example - tflite-android-transformers and writes more accessible code. We directly copied their tokenizer implementation. However, when switching to Chinese vocabulary, the tokenizer goes glitchy. See the following example where we tokenize the sentenceã€Œè¶Šè¿‡é•¿åŸ ï¼Œèµ°å‘ä¸–ç•Œã€ 1234567891011# Our Java tokenizer gives the following tokens, which detokenizes to the following stringtokenizer.decode([101, 6632, 19871, 20327, 14871, 8024, 6624, 14460, 13743, 17575, 102])&#x27;[CLS] è¶Šè¿‡é•¿åŸ ï¼Œ èµ°å‘ä¸–ç•Œ [SEP]&#x27;# On the other hand, official Hugging Face python BertTokenizer givestokenizer.decode([101, 6632, 6814, 7270, 1814, 8024, 6624, 1403, 686, 4518, 102])&#x27;[CLS] è¶Š è¿‡ é•¿ åŸ ï¼Œ èµ° å‘ ä¸– ç•Œ [SEP]&#x27;# Inspecting the first difference, our Java tokenizer seems to have used sentencepiece tokenizer.decode([19871])&#x27;##è¿‡&#x27; It turns out BERT in its original implementation (code) does not use sentence-piece tokenizer on Chinese characters. Instead, it uses character level tokenizer. Therefore, we need to first insert a whitespace to every character to ensure sentence-piece isnâ€™t applied. Note Hugging Face tokenizer follows BERT original python code very closely so you can easily find where to insert that piece of code. Bert original implementation in Python, with Chinese logic 1234567def tokenize(self, text): &quot;&quot;&quot;Tokenizes a piece of text.&quot;&quot;&quot; text = convert_to_unicode(text) text = self._clean_text(text) # Chinese Logic text = self._tokenize_chinese_chars(text) orig_tokens = whitespace_tokenize(text) Hugging Face tokenizer in Java, without Chinese logic 12345public final class BasicTokenizer &#123; public List&lt;String&gt; tokenize(String text) &#123; String cleanedText = cleanText(text); // Insert Here List&lt;String&gt; origTokens = whitespaceTokenize(cleanedText); Building a Classifier The final task is actually to build a classifier of 28 online store commodity classes. As I mentioned in the Detours section, I do not know and donâ€™t wanna bother to know how to define or change a signature. Therefore, I again turn to Hugging Face for its MobileBertForSequenceClassification. The default classification head only has 1 layer, I changed its structure to give it more expressive power. 12345678910model = MobileBertForSequenceClassification.from_pretrained( model_path, num_labels=len(labels), problem_type=&quot;multi_label_classification&quot;, id2label=id2label, label2id=label2id)model.classifier = nn.Sequential(OrderedDict([ (&#x27;fc1&#x27;, nn.Linear(768, 1024)), (&#x27;relu1&#x27;, nn.LeakyReLU()), (&#x27;fc2&#x27;, nn.Linear(1024, num_labels))]))# Fine-tune ...torch.save(model.state_dict(), model_path) However, this throws error when you try to read such a fine-tuned model back in. MobileBertForSequenceClassification is set to have one-layer classification head, so it cannot read in your self-defined classifierâ€™s weights. 12345torch_model = CustomMobileBertForSequenceClassification.from_pretrained( model_path, problem_type=&quot;multi_label_classification&quot;, num_labels=len(labels), id2label=id2label, label2id=label2id)&gt; Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at ./ckpts/ and are newly initialized: [&#x27;classifier.bias&#x27;, &#x27;classifier.weight&#x27;] To solve this, you can Save encoder weight and classifier weight separately, then load them separately Create a custom class corresponding to your weights and initialize an instance of that class instead 2 is clearly the more sensible way. You should read the very clearly written MobileBertForSequenceClassification to understand what exactly needs to be changed. It turns out all we have to do is to extend the original class and change its __init__ part, so it has a 2-layer classification head. 1234567891011121314151617181920212223242526from transformers import MobileBertForSequenceClassification, TFMobileBertForSequenceClassificationclass CustomMobileBertForSequenceClassification(MobileBertForSequenceClassification): def __init__(self, config): super().__init__(config) self.classifier = nn.Sequential(OrderedDict([ (&#x27;fc1&#x27;, nn.Linear(768, 1024)), (&#x27;relu1&#x27;, nn.LeakyReLU()), (&#x27;fc2&#x27;, nn.Linear(1024, 28)) ])) self.post_init()class TFCustomMobileBertForSequenceClassification(TFMobileBertForSequenceClassification): def __init__(self, config, *inputs, **kwargs): super().__init__(config, *inputs, **kwargs) self.classifier = keras.Sequential([ keras.layers.Dense(1024, input_dim=768, name=&#x27;fc1&#x27;), keras.layers.LeakyReLU(alpha=0.01, name = &#x27;relu1&#x27;), # Keras defaults alpha to 0.3 keras.layers.Dense(28, name=&#x27;fc2&#x27;) ])torch_model = CustomMobileBertForSequenceClassification.from_pretrained( model_path, problem_type=&quot;multi_label_classification&quot;, num_labels=len(labels), id2label=id2label, label2id=label2id)tf_model = TFCustomMobileBertForSequenceClassification.from_pretrained( ..., from_pt=True) However, you may find these two models output different values on the same input. A closer look at weights unveil that Hugging Face didnâ€™t convert classifierâ€™s weights from our Torch model to TensorFlow model correctly. We have to set them manually instead. 12tf_model.classifier.get_layer(&quot;fc1&quot;).set_weights([torch_model.classifier.fc1.weight.transpose(1, 0).detach(), torch_model.classifier.fc1.bias.detach()])tf_model.classifier.get_layer(&quot;fc2&quot;).set_weights([torch_model.classifier.fc2.weight.transpose(1, 0).detach(), torch_model.classifier.fc2.bias.detach()]) And now we are finally ready to go. Quantization I followed this official doc: Post-training quantization. Because of time limit, I didnâ€™t try Quantization Aware Training (QAT). 1234567891011vanilla_converter = tf.lite.TFLiteConverter.from_keras_model(bert_model)tflite_model = vanilla_converter.convert()quant8_converter = tf.lite.TFLiteConverter.from_keras_model(bert_model)quant8_converter.optimizations = [tf.lite.Optimize.DEFAULT]tflite_quant8_model = quant8_converter.convert()quant16_converter = tf.lite.TFLiteConverter.from_keras_model(bert_model)quant16_converter.optimizations = [tf.lite.Optimize.DEFAULT]quant16_converter.target_spec.supported_types = [tf.float16]tflite_quant16_model = quant16_converter.convert() Below I report several key metrics for this Chinese-MobileBERT + a 2-layer classification head of [768*1024, 1024*class_num]. This was tested on a Xiaomi 12X with snapdragon 870. The baseline model is my colleagueâ€™s BERT-Large implementation with accuracy 88.50% and size 1230MB. My modelâ€™s accuracy was bad at first: 75.01% with hyper-parameter weight_decay = 0.01, learning_rate = 1e-4, but we searched out a good hyper-parameter of weight_decay = 2e-4,learning_rate = 2e-5 giving 86.01%. We had 28 classes, 38000 training data in total, and trained for 5 epochs where the validation accuracy roughly flattens. Quantization Logit Difference Accuracy Accuracy (after hyper-param search) Model Size (MB) Inference Time(ms) Power Usage(ma) CPU(%) Memory(MB) float32 (No quant) 0 75.01% 86.094% 101.4 1003.3 89.98 108.02 267.11 float16 0.015% 75.01% 86.073% 51 838 64.15 108.77 377.11 int8 4.251% 63.49% 85.947% 25.9 573.8 60.09 110.83 233.19 If look at the not fine-tuned, vanilla transformer encoder only, the last_hidden_state has a difference: Quantization Logit Difference Model Size (MB) float32 (No quant) 0 97 float16 0.1% 48.1 int8 19.8% 24.9 Small Language Models BERT is the go-to option for classification task. But when it comes to small BERT, we had several options: mobileBERT distilledBERT tinyBERT As the post is about, we used mobileBERT at last because itâ€™s by Google Brain and Google probably knows their thing best. On the other hand, if youâ€™re looking for small generative model, which people mostly call SLM (Small Language Model) as opposed to LLM, I found these options but didnâ€™t try them myself. openELM: Apple, 1.1B Phi-2: Microsoft, 2.7B Post Script If you want to build an app utilizing edge transformer, I would recommend to read the source code of Hugging Faceâ€™s toy app. It doesnâ€™t have a README or tutorial, nor have I gone through it personally, but everything from TensorFlow sucks (including MediaPipe unfortunately) When checking back on this tutorial at date 2024/12/28, I found Google released AI Edge Torch, the official tool converting PyTorch models into a .tflite format. So you may probably want to try this first, but again, donâ€™t trust anything from TensorFlow team.","categories":[],"tags":[]},{"title":"Variational Inference","slug":"2024-09-09-Variational-Inference","date":"2024-09-09T04:00:00.000Z","updated":"2025-09-03T01:42:46.391Z","comments":true,"path":"2024-09-09-Variational-Inference/","permalink":"https://yao-lirong.github.io/blog/2024-09-09-Variational-Inference/","excerpt":"","text":"Probabilistic Latent Variable Models The two general forms of probabilistic models are: p(x): a typical probabilistic distribution. In this model, we call x the query. p(y âˆ£ x): a conditional probabilistic distribution. In this model, we cal x the evidence and y the query. Latent variable models are models that have variables other than the query and the evidence. p(x) = âˆ‘zp(x âˆ£ z) p(z)â€‹ A classic latent variable model of p(x) is the mixture model, where p(x) is actually a mixture of several different probabilistic model. For example, in the following graph, z is a discrete variable representing which class a datapoint belongs to and is represented by different colors here. p(x âˆ£ z) is each classâ€™s probability distribution, where in this case can each be modeled by a Gaussian. And p(x)â€‹ when we observe it, is just a bunch of uncolored datapoints and is hard to fit a distribution on it. However, we can see itâ€™s roughly spread in 3 clusters so we introduce the latent variable representing class and we can now well fit a Gaussian mixture model on it (a mixture of 3 Gaussians) Gaussian Mixture Model p(y âˆ£ x) = âˆ‘zp(y âˆ£ x, z) p(z) or p(y âˆ£ x) = âˆ‘zp(y âˆ£ z) p(z âˆ£ x): the conditional probability is a bit more free. You can decompose and model it using zâ€‹ as you like. An example of latent conditional model is the mixture density network, which we use in RLâ€™s imitation learning to deal with multi-modal situations each requiring a different distribution. Latent Variable Models in General When we use latent variable models, it means we want to decompose a complicated distribution into several simple / easy distributions. By complicated, we mean itâ€™s not possible to write it in a well-defined distribution. By simple / easy, we mean we can write it as a well-defined parametrized distribution, where the parameters can be complex, but the distribution itself is easy to write (a Gaussian of just mean and sigma, or as a Bernoulli with just one variable, etc.) p(x) = âˆ«p(x âˆ£ z)p(z)dz p(z) is an â€œeasyâ€ prior we choose. For example a Gaussian, a categorical distribution, etc. p(x âˆ£ z) should also be an easy distribution, like a Gaussian: $ p(x z) = ({nn}(z), {nn}(z))$ even though the mapping from z to the actual parameters of Gaussian can be complex, where in this case we have to model the mapping through a neural network and this mapping is the learnable part. p(x) is complicated, not possible to write out as any well-defined distribution. Therefore, we decompose it into the two parts above that are easy to parametrize as a probability distribution and learn the parameters inside the distribution. Generative models are not equal to latent variable models. We usually model generative models as latent variable ones because generative models are usually complex probability distributions and we can make it easier by introducing one or more latent variable. How to Train a Latent Variable Model Given dataset ğ’Ÿ = {x1, x2, â€¦, xN}, to fit a typical probabilistic model pÎ¸(x), we use the maximum likelihood estimation: $$ \\theta \\leftarrow \\underset{\\theta}{arg\\!\\max} \\frac 1 N \\sum_i \\log p_\\theta(x_i) $$ In the latent variable model set up, we can substitute the definition in and an MLE would look like $$ \\theta \\leftarrow \\underset{\\theta}{arg\\!\\max} \\frac 1 N \\sum_i \\log \\left( \\int p_\\theta(x_i \\mid z) p(z) dz \\right) $$ pÎ¸(x âˆ£ z) and p(z) are distributions of our choices, but this integral is still intractable when z is continuous. So now itâ€™s time to do some math tricks. Variational Inference Variational Approximation First, we construct an easy / simple probability distribution qi(z) to approximate p(z|xi) - the posterior distribution specific to datapoint xi. By easy we again mean it is easy to parametrize (a Gaussian, a Bernoulli, etc.) We will show that by introducing this qi(z), we can actually construct a lower bound of log p(xi). Whatâ€™s good with this lower bound? Later on, we will also prove this bound is sufficiently tight, so as we push up the value of this lower bound, we push up the value of p(xi) which is exactly what we want. $$ \\begin{align} \\log p(x_{i}) &amp;= \\log\\int_{z}p(x_{i}|z)p(z)\\\\ &amp;= \\log\\int_{z}p(x_{i}|z)p(z) \\frac{q_i(z)}{q_i(z)} \\\\ &amp;= \\log \\mathbb E_{z\\sim q_{i}(z)} \\left[\\frac{p(x_{i}|z)p(z)} {q_{i}(z)}\\right] \\\\ &amp;\\geq \\mathbb E_{z\\sim q_{i}(z)} \\left[\\log\\frac{p(x_{i}|z)p(z)}{q_{i}(z)}\\right] &amp;\\text{\\# Jensen's Inequality} \\\\ &amp;= \\mathbb E_{z\\sim q_{i}(z)} \\left[\\log p(x_{i}|z)+\\log p(z) \\right] - \\mathbb E_{z\\sim q_{i}(z)} \\left[ \\log {q_{i}(z)}\\right]\\\\ &amp;= \\mathbb E_{z\\sim q_{i}(z)} \\left[\\log p(x_{i}|z)+\\log p(z) \\right] + \\mathcal H_{z\\sim q_{i}(z)} (q_i) = \\mathcal L_i(p, q_i) \\end{align} $$ Recall p(x) is a difficult probability distribution, so we decompose it into two easy distributions p(x|z) and p(z), and use an easy distribution qi(z) to approximate the posterior p(z|xi). Now the good thing is: everything here is tractable: for the first term, we can fix a qi(z) of our choice (recall qi is a distribution we constructed), sample some z, and evaluate the expression. For the second term, we notice it is just the entropy of a distribution and for simple distributions (we constructed qi to be simple), it has a closed form (even if it doesnâ€™t, you can simply sample and evaluate) We call the final lower bound we derived here the variance lower bound or evidence lower bound (ELBO). $$ \\begin{align} \\log p(x_{i}) &amp;\\geq \\mathcal L_i(p, q_i) \\\\ &amp;= \\mathbb E_{z\\sim q_{i}(z)} \\left[\\log p(x_{i}|z)+\\log p(z) \\right] + \\mathcal H_{z\\sim q_{i}(z)} (q_i) \\end{align} $$ ### Effect of Pushing Up ELBO (Intuitively) Assume our p(â‹…)â€‹ is a fixed value, what does pushing up ELBO mean? Here, we give out an intuitive explanation. First, we look at the first term with the two log combined. $$ \\begin{align} &amp;\\mathbb E_{z\\sim q_{i}(z)} \\left[\\log p(x_{i}|z)+\\log p(z) \\right] \\\\ = &amp;\\mathbb E_{z\\sim q_{i}(z)} \\left[\\log p(x_{i},z) \\right] \\end{align} $$ To maximize this value, we just have to find a distribution of z, inside which we have the largest value of p(xi, z). Therefore, we want z to distribute mostly under the peak of p(xi, z), Since qi(z) is the distribution we currently have for z, we want qi(z) to sit mostly under the peak of p(xi, z). In the following graph, the y-axis is p(xi, z), the distribution we try to maximize, and the x-axis is our latent variable z. There is also a hidden axis - the probability mass (distribution) of z. We project this hidden axis to the y-axis in this graph. To maximize this first term, we spread zâ€™s mass as much under the peak of p(xi, z) as possible, which makes the green part of this graph. maximize ELBO Now we take the second term entropy into consideration. â„’i(p, qi) = ğ”¼z âˆ¼ qi(z)[log p(xi, z)] + â„‹z âˆ¼ qi(z)(qi) From our entropy post, we know entropy measures the expected code length of communicating the event described by a random variable. So the more random this variable is, the more code words itâ€™s required to communicate it. Therefore, the more spread out / uniform the distribution is, the higher the entropy. If weâ€™re maxing the entropy, we donâ€™t want the distribution to be skinny. See the following graph. entropy-example When we consider both entropy and the first term, we should achieve this probability distribution depicted in brown. If we donâ€™t have the entropy, z will want to sit under the most likely point, but since we added entropy, z now tries to cover it. In conclusion, (equal sign â€œ=â€ reads â€œin effectâ€) maximize evidence lower bound = cover most of the p(xi|z) distribution = maximize approximation between qi and p(xi|z). maximize ELBO Effect of Pushing Up ELBO (Analytically) Can we measure how good our approximation is? That is, can we measure the distance between p(xi|z) and qi? In fact, we have a nice, analytical way to look at it using KL divergence. For two arbitrary distribution p, q of x, the KL divergence of q from p (the distance from q to p, note KL divergence is not symmetric) is $$ \\begin{align} D_{\\mathrm{KL}}(q|p) &amp;=E_{x\\sim q(x)}\\left[\\log{\\frac{q(x)}{p(x)}}\\right]\\\\ &amp;=E_{x \\sim q(x)}[\\log q(x)]-E_{x \\sim q(x)}[\\log p(x)]\\\\ &amp;=-E_{x \\sim q(x)}[\\log p(x)]-H(q) \\end{align} $$ Doesnâ€™t this look similar to our evidence lower bound? Borrowing that explanation, minimizing KL divergence = cover most of the p(z) distribution = maximize approximation between q and p. KL-divergence Having understood the definition of KL divergence, letâ€™s use it to measure the distance between qi(z) and p(z|xi) - the distribution we want qi to approximate: $$ \\begin{align} D_{KL}(q_{i}(z)\\|p(z \\mid x_{i})) &amp;= E_{z\\sim q_{i}(z)}\\left[\\log{\\frac{q_{i}(z)}{p(z|x_{i})}}\\right]\\\\ &amp;= E_{z\\sim q_{i}(z)}\\left[\\log{\\frac{q_{i}(z)p(x_{i})}{p(x_{i},z)}}\\right]\\\\ &amp;= -E_{z\\sim q_{i}(z)}\\left[\\log p(x_{i}|z)+\\log p(z)\\right] + E_{z\\sim q_{i}(z)}\\log q_i(z) + E_{z\\sim q_{i}(z)}\\log p(x_{i})\\\\ &amp;= -E_{z\\sim q_{i}(z)}\\left[\\log p(x_{i}|z)+\\log p(z)\\right] + \\mathcal H(q_i) + E_{z\\sim q_{i}(z)}\\log p(x_{i})\\\\ &amp;= -\\mathcal L(p, q_i) + \\log p(x_i)\\\\ \\log p(x_i) &amp;= \\mathcal L(p, q_i) + D_{KL}(q_{i}(x_{i})\\|p(z \\mid x_{i})) \\end{align} $$ Therefore, having a good approximation of qi to p(xi|z) = driving KL divergence, which is always a non-negative number, to 0 = the evidence lower bound is a tight bound or even equal to log p(xi)â€‹ - the ultimate thing we want to optimize. Looking at our optimization objective â„’ here: â„’(p, qi) = log p(xi) âˆ’ DKL(qi(xi)âˆ¥p(z âˆ£ xi)) When we optimize w.r.t. q: note the first term log p(xi) is independent of q, so its value stays the same. We are in effect optimizing against the KL divergence only, making the distance between our approximation qi and p(z|xi) smaller. The best / extreme case is we have DKL = 0, so â„’ = log p(xi). When we optimize w.r.t. p: Recall our ultimate goal is to make log p(xi) bigger, so we make a better model in theory. Only in theory because we donâ€™t know whether the bound is tight or not. The Learning Algorithm? Therefore, when we optimize â„’(p, qi)â€‹ w.r.t. qâ€‹, we make the bound tighter (make â„’â€‹ a better approximation of log p(xi)â€‹ ); when we optimize â„’(p, qi)â€‹ w.r.t. pâ€‹, we make a better model in general. By alternating these two steps, we have the actual learning algorithm. Letâ€™s review: which parts are learnable in these two distributions? In our latent variable model setup, we decompose the complicated distribution p(x) into two easy distributions p(x|z) and p(z), where the mapping from z to actual parameters of this p(x|z) distribution needs to be modeled by a complex network. Therefore, the only distribution in the p part with learnable parameters is p(x|z). We denote it with pÎ¸(x|z). In our ELBO setup, we also introduced a simple qi(z) for each datapoint xi to approximate the posterior p(z|xi). To optimize w.r.t. q, we optimize the parameters of each distribution. If qi(z) = ğ’©(Î¼i, Ïƒi), we optimize each Î¼i, Ïƒi. (we can optimize the entropy value for sure, but Iâ€™m not entirely sure how you would take gradient of the expectation term Ez âˆ¼ qi(z)[log p(z)]) Therefore, we have our learning algorithm: $$ \\begin{align} &amp;\\text{for each $x_i$ in $\\{x_1, \\dots, x_N\\}$: }\\\\ &amp;\\hspace{4mm} \\text{sample $z \\sim q_i(z)$}\\\\ &amp;\\hspace{4mm} \\text{optimize against $p$:}\\\\ &amp;\\hspace{4mm} \\hspace{4mm} \\nabla_\\theta \\mathcal L (p_\\theta, q_i) = \\nabla_\\theta \\log p_\\theta(x_i|z) \\\\ &amp;\\hspace{4mm} \\hspace{4mm} \\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta \\mathcal L (p, q_i) \\\\ &amp;\\hspace{4mm} \\text{optimize against $q$:}\\\\ &amp;\\hspace{4mm} \\hspace{4mm} \\nabla_{\\mu_i, \\sigma_i} \\mathcal L (p_\\theta, q_i) = \\nabla_{\\mu_i, \\sigma_i} \\left[\\mathbb E_{z\\sim q_{i}(z)} \\left[\\log p(x_{i}|z)+\\log p(z) \\right] + \\mathcal H_{z\\sim q_{i}(z)} (q_i) \\right] \\\\ &amp;\\hspace{4mm} \\hspace{4mm} (\\mu_i, \\sigma_i) \\leftarrow (\\mu_i, \\sigma_i) + \\alpha \\nabla_{\\mu_i, \\sigma_i} \\mathcal L (p, q_i) \\\\ \\end{align} $$ Thereâ€™s a problem with optimizing qi though. Note we have a separate q for each data point i, which means if we have N data points, we will have to store N Ã— (|Î¼i| + |Ïƒi|) parameters assuming we chose qi to be Gaussian. In machine learning, the number of data points N is usually in millions, making this model unwieldily big. Itâ€™s true in inference time we do not use q at all (weâ€™ll see why this is true in the last chapter about VAE), but in training time, we still need them so itâ€™s necessary to keep all these parameters. Therefore, instead of having a separate qi(â‹…) to approximate each data pointâ€™s P(â‹…|xi) specifically, we use a learnable model qÏ•(â‹…|xi) to approximate p(â‹…|xi) This learnable network will take in a datapoint xi, predicts the corresponding Î¼i, Ïƒi. We can then sample zâ€‹ from this predicted network. Amortized By adapting q to be a learnable network qÏ•â€‹ instead, model size does not depend on the number of datapoints anymore. Therefore, it is amortized. The variational lower bound becomes: â„’(pÎ¸(xi|z), qÏ•(z|xi)) = ğ”¼z âˆ¼ qÏ•(z|xi)[log pÎ¸(xi|z) + log p(z)] + â„‹(qÏ•(z|xi)) The learning algorithm naturally becomes: $$ $$ Gradient Over Expectation (Policy Gradient) The question now boils down to how do we calculate this gradient âˆ‡Ï•â„’(pÎ¸, qÏ•). The second term entropy is easy. We purposefully chose q to be a simple distribution, so there is usually a close form of its entropy and we just have to look it up. The meat is in the first part. How do we take gradient w.r.t. parameter Ï• in the expectation termâ€™s distribution qÏ• ? Note the term inside expectation is independent of Ï•, so we can rewrite it as R(xi, z) = log pÎ¸(xi|z) + log p(z) and call the whole thing J. J(Ï•) = âˆ‡Ï•ğ”¼z âˆ¼ qÏ•(z|xi)[R(xi, z)] We chose these namings purposefully because we encountered something similar back in the policy gradient part of reinforcement learning LINK???. Say we have a trajectory Ï„, sampled from the state transition function with learnable policy Ï€Î¸, the final expected value we can get from starting state s0 can be written as the following, where R(Ï„) is a reward function returning the reward of this trajectory. J(Î¸) = VÏ€Î¸(s0) = ğ”¼Ï„ âˆ¼ Ps0Ï€Î¸[R(Ï„)] We can take the gradient of this value function V w.r.t our policy Ï€Î¸, so this is called policy gradient. If youâ€™re unfamiliar with RL setup, you just have to know we can derive the following gradient and we can approximate it by sampling M trajectories. $$ $$ Pugging in our $q$ and $\\phi$, $$ $$ Reparametrization Trick We have our full learning algorithm and itâ€™s ready to go now. However, there is a tiny improvement we can do. We defined our qÏ• to be a normal distribution ğ’©(Î¼Ï•, ÏƒÏ•) Observe that all normal distributions can be written as a function of the unit normal distribution. Therefore, a sample z is in effect: z âˆ¼ ğ’©(Î¼Ï•, ÏƒÏ•) â‡” z = Î¼Ï• + ÏµÏƒÏ•, Ïµ âˆ¼ ğ’©(0, 1) Letâ€™s rewrite our expectation term to now sample an Ïµ from the unit normal distribution instead. By decomposing z into these two parts, we separate the stochastic part and changed z from a sample of some stochastic distribution into a deterministic function z(Ï•, Ïµ) parametrized by Ï• and random variable Ïµ that is independent of Ï•. Ïµ takes the stochastic part alone. Our learnable parameter Ï• now only parametrizes deterministic quantity. âˆ‡Ï•J(Ï•) = âˆ‡Ï•ğ”¼Ïµ âˆ¼ ğ’©(0, 1)[R(xi, Î¼Ï• + ÏµÏƒÏ•)] Aside from these theoretical benefits, mathematically, we do not have to take gradient w.r.t an expectation of parametrized distribution anymore. Instead, the gradient can go straight into the expectation term now like how we usually interchange gradient and expectation (think about discrete case, expectation is just a big sum so we can do it). âˆ‡Ï•J(Ï•) = ğ”¼Ïµ âˆ¼ ğ’©(0, 1)[âˆ‡Ï•R(xi, Î¼Ï• + ÏµÏƒÏ•)] Further, to approximate this expectation, we just sample some Ïµ from this normal distribution. $$ \\nabla_\\phi J(\\phi) \\approx \\frac 1 M \\sum_j^M \\nabla_\\phi R(x_i, \\mu_\\phi + \\epsilon_j \\sigma_\\phi) $$ With reparametrization, we achieve a lower variance than policy gradient because we are using the derivative of R. (Unfortunately the lecturer didnâ€™t provide a quantitative analysis on this and I donâ€™t know how to prove it) On the other hand, previously, we only took derivative w.r.t. the probability distribution. Why didnâ€™t we use derivative of R back in RL with policy gradient? Itâ€™s not we donâ€™t want to but we canâ€™t: we canâ€™t use reparametrization in RL because in RL we usually cannot take derivative w.r.t. reward R. Method Formula Approximation Benefit Deficit Policy Gradient âˆ‡Ï•ğ”¼z âˆ¼ qÏ•(z âˆ£ xi)[R(xi, z)] $\\frac 1 M \\sum_j^M \\nabla_\\phi[\\log q_\\phi(z_j \\mid x_i)] R(x_i,z_j)$ works with both discrete and continuous latent variable z High variance, requires multiple samples &amp; small learning rates Reparametrization ğ”¼Ïµ âˆ¼ ğ’©(0, 1)[âˆ‡Ï•R(xi, Î¼Ï• + ÏµÏƒÏ•)] $\\frac 1 M \\sum_j^M \\nabla_\\phi R(x_i, \\mu_\\phi + \\epsilon_j \\sigma_\\phi)$ low variance, simple to implement (weâ€™ll see soon) only works with continuous variable z and have to model it with a Gaussian In fact, you can forget about the policy gradient method and simply take it for granted that you cannot back propagate a sampled value âˆ‡Ï•ğ”¼z âˆ¼ qÏ•(z|xi), so you have to find some way to make our zâ€‹ deterministic, which is what weâ€™re doing here with our reparametrization trick. reparametrization-trick Left is without the â€œreparameterization trickâ€, and right is with it. Red shows sampling operations that are non-differentiable. Blue shows loss layers. We forward the network by going up and back propagate it by going down. The forward behavior of these networks is identical, but back propagation can be applied only to the right network. Figure copied from Carl Doersch: Tutorial on Variational Autoencoders Looking at â„’ Directly $$ \\begin{align} \\mathcal L_i = \\mathcal L \\left( p_\\theta(x_i | z), q_\\phi(z | x_i) \\right) &amp;= \\mathbb E_{z\\sim q_\\phi(z | x_i)} \\left[\\log p_\\theta(x_{i}|z)+\\log p(z) \\right] + \\mathcal H (q_\\phi(z|x_i))\\\\ &amp;= \\mathbb E_{z\\sim q_\\phi(z | x_i)} \\left[\\log p_\\theta(x_{i}|z) \\right] + \\mathbb E_{z\\sim q_\\phi(z | x_i)} \\left[\\log p(z) \\right] + \\mathcal H (q_\\phi(z|x_i))\\\\ &amp;= \\mathbb E_{z\\sim q_\\phi(z | x_i)} \\left[\\log p_\\theta(x_{i}|z)\\right] - D_{KL}(q_\\phi(z | x_i)\\|p(z)) \\\\ &amp;= \\mathbb E_{\\epsilon \\sim \\mathcal N(0,1)} \\left[\\log p_\\theta(x_{i}| \\mu_\\phi + \\epsilon \\sigma_\\phi)\\right] - D_{KL}(q_\\phi(z | x_i)\\|p(z)) \\\\ &amp;\\approx \\frac 1 M \\sum_j^M \\log p_\\theta(x_{i}| \\mu_\\phi + \\epsilon_j \\sigma_\\phi) - D_{KL}(q_\\phi(z | x_i)\\|p(z)) \\\\ \\end{align} $$ For the first term, we can just evaluate it. For the second KL term, since we chose both distributions to be easy (in this case Gaussian), there often is a nice analytical form for it. Therefore, we can go ahead to maximize the variational lower bound â„’â€‹. We can also draw out the following computational graph for the log term and conclude we can back propagate this graph without any problem. On the other hand, if we didnâ€™t do the reparametrization trick, we will get stuck at z: you cannot back propagate z - a sampled value instead of a variable. And we will have to seek help from policy gradient. With reparametrization, we decompose z into two variables Î¼Ï•, ÏƒÏ• we can back propagate through and one stochastic value Ïµ we do not care about. computational-graph Variational Autoencoder Setup and Interpretation What we have gone though constitutes the full pipeline of a variational autoencoder. In a variation autoencoder, we have observed variable x and latent variable z encoder qÏ•(z|x) = ğ’©(Î¼Ï•(x), ÏƒÏ•(x)) decoder pÎ¸(x|z) = ğ’©(Î¼Î¸(z), ÏƒÎ¸(z)) In training, given an observed sample xi, we encode it to latent variable zi using qÏ•, then tries to decode it back with decoder pÎ¸. We maximize the variational lower bound during the process. For all N samples, the training objective looks like: (where the Ïµ is a sampled value) $$ \\max_{\\phi,\\theta} \\frac 1 N \\sum_i^N \\log p_\\theta\\left(x_{i}| \\mu_\\phi(x_i) + \\epsilon \\sigma_\\phi(x_i)\\right) - D_{KL}(q_\\phi(z | x_i)\\|p(z)) \\\\ $$ In inference (generation), we sample a z from our prior p(z), then decode it using pÎ¸: z âˆ¼ p(z), x âˆ¼ pÎ¸(x|z) Why does the variational autoencoder work? We talked about many benefits of maximizing this variational lower bound in previous chapter. Letâ€™s look at it again in this decoder-encoder setup,. â„’i = ğ”¼z âˆ¼ qÏ•(z|xi)[log pÎ¸(xi|z)] âˆ’ DKL(qÏ•(z|xi)âˆ¥p(z)) The first log pÎ¸ term maximizes the probability of our observed image x given a sample z, so the model makes decoder pÎ¸ to reconstruct image xâ€‹ as accurate as possible. The second KL term restricts the encoding of an image to be close to the actual prior, which makes sure at inference / generate time, we can directly sample from the prior. Comparison with Auto-Encoder vae-and-ae The VAEâ€™s decoder is trained to convert random points in the embedding space (generated by perturbing the input encodings) to sensible outputs. By contrast, the decoder for the deterministic autoencoder only ever gets as inputs the exact encodings of the training set, so it does not know what to do with random inputs that are outside what it was trained on. So a standard autoencoder cannot create new samples. The reason the VAE is better at sample is that it embeds images into Gaussians in latent space, whereas the AE embeds images into points, which are like delta functions. The advantage of using a latent distribution is that it encourages local smoothness, since a given image may map to multiple nearby places, depending on the stochastic sampling. By contrast, in an AE, the latent space is typically not smooth, so images from different classes often end up next to each other. Figure copied from Probabilistic Machine Learning: An Introduction - Figure 20.26 We can leverage the smoothness of the latent space to perform image interpolation in latent space. Reference Most content of this blog post comes from Berkeley CS 285 (Sergey Levine): Lecture 18, Variational Inference, which I think organized his lecture based on An Introduction to Variational Autoencoders (2.1-2.7, and 2.9.1), or more in-depth on the authorâ€™s PhD thesis Variational Inference and Deep Learning: A New Synthesis I found this wonderful tutorial in Probabilistic Machine Learning: Advanced Topics Some graph come from Probabilistic Machine Learning: An Introduction itself and Carl Doersch: Tutorial on Variational Autoencoders, which is referenced in the previous book. Note though the Probabilistic Machine Learning book itself is a horrible book with extremely confusing explanations.","categories":[],"tags":[]},{"title":"Hyper-Parameter Tuning with Optuna","slug":"2024-08-23-Hyper-Parameter-Tuning-with-Optuna","date":"2024-08-23T04:00:00.000Z","updated":"2025-09-03T01:42:46.391Z","comments":true,"path":"2024-08-23-Hyper-Parameter-Tuning-with-Optuna/","permalink":"https://yao-lirong.github.io/blog/2024-08-23-Hyper-Parameter-Tuning-with-Optuna/","excerpt":"After self-implementing a grid-search but having a horrible time writing pyplot visualizing the result, I finally decided to find an existing tool to do the HP tuning for me.","text":"After self-implementing a grid-search but having a horrible time writing pyplot visualizing the result, I finally decided to find an existing tool to do the HP tuning for me. There are two popular HP tuning framework RayTune: almost industry standard Optuna: user friendly, requires minimal modification to original code Thereâ€™s also skorch integrating scikit-learn and pytorch, so you can use sklearn GridSearchCV. For our simple task, we will go with Optuna. Getting Started To get Optuna running, you just need to add 4 lines in your training logic and a few more lines to start its search. In training logic: 12345678910111213141516171819202122232425def train_model(image_datasets, lr, weight_decay, num_epochs, trial : optuna.trial.Trial=None): optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay) for epoch in range(num_epochs): model.train() for inputs, labels in dataloaders[&quot;train&quot;]: # Training Logic model.eval() for inputs, labels in dataloaders[&quot;val&quot;]: running_loss += loss.item() * inputs.size(0) # Eval Logic epoch_loss = running_loss / dataset_sizes[&quot;val&quot;] if epoch_acc &gt; best_acc or (epoch_acc == best_acc and epoch_loss &lt; best_loss): best_acc, best_loss = epoch_acc, epoch_loss &quot;&quot;&quot; OPTUNA CODE GOES HERE: For each epoch, you should report value of a user-defined factor. Optuna uses this factor alone to determine whether to prune out this trial at current epoch step. Your objective value returned has nothing to do with pruning. Read for more at: https://optuna.readthedocs.io/en/v3.6.1/reference/generated/optuna.trial.Trial.html#optuna.trial.Trial.report &quot;&quot;&quot; if trial is not None: trial.report(epoch_loss, epoch) if trial.should_prune(): raise optuna.exceptions.TrialPruned() return best_loss The following code shows how to set the search space and start the search. 12345678910111213141516171819202122232425def optuna_objective(trial : optuna.trial.Trial): &quot;&quot;&quot; Define a custom objective function we want to optimize on. This function returns value of the criteria you want to finally evaluate your model on. i.e. how you compare different models. The best model should have the best value of this objective. If you say the best model should have highest training accuracy at the last epoch, then return training accuracy at the last epoch here. In our example, we think the best model should have the best `best_loss`, where a model&#x27;s `best_loss` is this model&#x27;s lowest validation loss across all epochs. &quot;&quot;&quot; image_datasets = prepare_data() lr = trial.suggest_float(&quot;lr&quot;, 1e-6, 1e-1, log=True) weight_decay = trial.suggest_float(&quot;weight_decay&quot;, 1e-6, 1e-1, log=True) loss = train_model(image_datasets, lr, weight_decay, 15, trial) return lossif __name__ == &quot;__main__&quot;: &quot;&quot;&quot; Create a study called `plant_144` where we minimize the objective passed in. Start the search. The search ends when we finish 10 trials or spend 3 hours. &quot;&quot;&quot; study = optuna.create_study( direction=&quot;minimize&quot;, study_name=&quot;plant_144&quot;) study.optimize(optuna_objective, n_trials=10, timeout=3*60*60) print(&quot; Objective Value: &quot;, study.best_trial.value) print(&quot; Params: &quot;) for key, value in study.best_trial.params.items(): print(f&quot; &#123;key&#125;: &#123;value&#125;&quot;) The above example was adapted from Optunaâ€™s PyTorch starting example. For more reporting printout statements, check the original example. Saving Study and Board Visualization In addition to printing out all the info to the console and losing them from memory after this python script finishes, we can save them in the form of an RDB (Relational Database, or just database as most databases are RDB). To do this, we pass a database URL to the storage argument 1234study = optuna.create_study( direction=&quot;minimize&quot;, study_name=&quot;plant_144&quot;, storage=&quot;sqlite:///db.sqlite3&quot;) You can now Ctrl+C stop this search at anytime and resume it by running the same code again. Database exposes itself as a server in machines. Therefore, to access it (even in local machine), we use Database URL. Just like to access a webpage online, we use an HTTPS url. In our example here, the history will be stored in a file called db.sqlite3 under current directory. This file is a general database and can store study other than the one called plant_144. You can store another study inside it. 1234study = optuna.create_study( direction=&quot;maximize&quot;, study_name=&quot;plant_8&quot;, storage=&quot;sqlite:///db.sqlite3&quot;) For me this code just worked without having to install SQLite DB. This is probably because it comes with my Ubuntu but I have no idea. Check official tutorial Saving/Resuming Study for more on saving and loading. You can now visualize the search history, each parameterâ€™s importance, etc. with optuna-dashboard 1optuna-dashboard sqlite:///db.sqlite3 optuna-dashboard Multi-GPU Parallelism Support romanâ€™s Stack Overflow answer provides a very simple way to do multi-GPU tuning by utilizing Optunaâ€™s resume feature. To do so, create a study by following the previous code. Then modify your code now to resume instead of starting a new study. 123if __name__ == &#x27;__main__&#x27;: study = optuna.load_study(study_name=&#x27;plant_144&#x27;, storage=&#x27;sqlite:///db.sqlite3&#x27;) study.optimize(objective, n_trials=100) and simply start â€œresumeâ€ this study on different available GPUs 12CUDA_VISIBLE_DEVICES=3 nohup python optuna.py &gt; log3.txt 2&gt;&amp;1 &amp;CUDA_VISIBLE_DEVICES=5 nohup python optuna.py &gt; log5.txt 2&gt;&amp;1 &amp; The history from both processes will be stored under the study called plant_144 in file db.sqlite3. For more information on parallelizing on multiple gpu, check official guide: Easy Parallelization Some Complaints In its visualization, Optuna doesnâ€™t provide an option to filter out the â€œbadâ€ trial runs, making the scale of all graph ridiculous and usually of no information.","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"KV Cache","slug":"2024-07-02-KV-Cache","date":"2024-07-02T04:00:00.000Z","updated":"2025-09-02T23:51:12.123Z","comments":true,"path":"2024-07-02-KV-Cache/","permalink":"https://yao-lirong.github.io/blog/2024-07-02-KV-Cache/","excerpt":"Before this, see 2024/06/17 Conducting Multi-Round Conversation with Transformers for why we need cache. But we have query, key, value three matrices. Why do you only cache past keys and values? How about past queries?","text":"Before this, see 2024/06/17 Conducting Multi-Round Conversation with Transformers for why we need cache. But we have query, key, value three matrices. Why do you only cache past keys and values? How about past queries? Attention Mechanism in Detail Recall the attention process in transformer can be written in the following matrix form: $$ Z = \\text{Attention}(Q,K,V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V $$ If we look a particular output at position i, it can be written as: $$ z_i =( {} ) \\begin&#123;bmatrix&#125; v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end&#123;bmatrix&#125; $$ A simple example can be found in the famous Illustrated Transformer self attention output From the formula and the example, we can see that key and values are always a pair in calculation. In fact, this is aligned with the very concept of soft dictionary behind attention: we get a query from somewhere and look at all the keys in the dictionaries to find, for each key, how much it relates to this query and output the weighted average of each keyâ€™s value based on the relatedness. Generative Transformer (Decoder Based) Autoregressive Decoder Letâ€™s consider a causal language model, aka a transformerâ€™s autoregressive generative decoder. At inference time, we only care about the output at the last position because the model is autoregressive and the outputs at all the previous positions are exactly the same as our input. (See the above graph from blogpost Transformers-based Encoder-Decoder Models) Therefore, if the current sequence has length s, we only care about zs. All the other outputs z1â€¦s âˆ’ 1 are useless. Inference code in Karpathyâ€™s nanoGPT corroborated this in its inference time implementation: 1234if targets is None: # inference-time mini-optimization: only forward the lm_head on the very last position logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim loss = None Now revisit the formula to calculate the output zs: $$ z_s =( {} ) \\begin&#123;bmatrix&#125; v_1 \\\\ v_2 \\\\ \\vdots \\\\ v_s \\end&#123;bmatrix&#125; $$ It should be clear that to save computation, we only need to cache the kv values in the previous positions and itâ€™s useless to cache the q value. To give a more detailed example, letâ€™s consider the whole process to generate a sequence of tokens with length n: t1, â€¦, tn. We can see the previous queries are never used in the computation. $$ $$ Time Complexity Boost People complain about the slow inference time of generative transformer model, where it has a quadratic sequence length term O(s2). This quadratic term is caused by QKT matrix multiplication in attention where both matrices have shape s Ã— d. Recall running time of matmul AB where $A \\in \\R^{m \\times p}, B \\in \\R^{p \\times n}$ is O(mpn), so this matmul of query and key matrix has time complexity O(s2d). However, by observing that we only need the output at the very last position in generative model and utilizing KV-cache, we reduce our matrix $Q \\in \\R^{s \\times d}$ to a single vector of $q \\in \\R^{1 \\times d}$ and effectively reduce the time complexity of this operation to O(sd). Therefore, we can eliminate the quadratic term from our inference time and only need linear time s instead. What about Encoder Based Transformer Model? Encoder Based transformer models do not have the issue of repeatedly computing the same past tokensâ€™ attention scores so do not need a KV-cache. Code Implementation Facebookâ€™s cross-lingual language model (XLM) gives a fantastic example of how to implement KV-Cache (or transformers in general, it provides abundant comments of tensor shape at each step). At inference time, do not recompute elements (where slen or a more descriptive naming can be cached_sequence_length is how many previous positions have been cached): link 12345678if cache is not None: _slen = slen - cache[&#x27;slen&#x27;] x = x[:, -_slen:] positions = positions[:, -_slen:] if langs is not None: langs = langs[:, -_slen:] mask = mask[:, -_slen:] attn_mask = attn_mask[:, -_slen:] Retrieve, use and update cache: link1 link2 1234567if self.layer_id in cache: k_, v_ = cache[self.layer_id] k = torch.cat([k_, k], dim=2) # (bs, n_heads, klen, dim_per_head) v = torch.cat([v_, v], dim=2) # (bs, n_heads, klen, dim_per_head)cache[self.layer_id] = (k, v)...cache[&#x27;slen&#x27;] += tensor.size(1) XLM can serve multiple purposes including as a generative causal language model, masked language model, or a translation language model. We use KV-Cache only with causal language model in generate() function, see code. XLM has a Memory module that implements Product-Key Memory Layers whose mechanism rings very familiar to me but I canâ€™t recall where Iâ€™ve encountered something similar before. Anyway, you can ignore those Memory implementations and focus on the attention part if use it as a source to learn cache or the basics of attention. More Code Examples This Medium post KV caching explained leads way to where to find Hugging Faceâ€™s implementation in general, which can be too modular and abstract nowadays. Itâ€™s hidden in the forward function in XXXForCausalLM. Take LlamaForCausalLM as an example, in its forward function, we still need to go down the abstraction to LlamaModel -&gt; LlamaDecoderLayer -&gt; LlamaAttention and we can see the past_key_value there implementing the Cache class. I didnâ€™t read into how Hugging Face did it. This Zhihu post explaining KV-Cache leads way to Hugging Faceâ€™s GPT-2. The original GPT-2 code is in fact more straightforward, but youâ€™d better just read XLM. It simply has more comments and the naming is more self-explanatory. PS I initially didnâ€™t find where Hugging Face implemented KV-Cache in current version (transformer 4.40) but only this Cache class and failed to find where itâ€™s used. So I followed the recommendation under this Zhihu post to go to transformer 2.5.0 instead. A quick search like â€œkvâ€ or â€œcacheâ€ led me to modeling_xlm.py. I was surprised to find early Hugging Face model code was more of a rename of original implementation instead of a refactor they do now. I then read this KV caching explained post. Its graph isnâ€™t super straightforward but it introduces how KV-cache reduces time complexity and where to find Hugging Faceâ€™s implementation.","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"Conducting Multi-Round Conversation with Transformers","slug":"2024-06-17-Conducting-Multi-Round-Conversation-with-Transformers","date":"2024-06-17T04:00:00.000Z","updated":"2025-09-02T23:51:12.124Z","comments":true,"path":"2024-06-17-Conducting-Multi-Round-Conversation-with-Transformers/","permalink":"https://yao-lirong.github.io/blog/2024-06-17-Conducting-Multi-Round-Conversation-with-Transformers/","excerpt":"I was using LLaVA to query in an image how many characters there are. For higher accuracy, I decided to employ Chain of Thought, but struggled to implement it. CoT is conducted through a multiple round conversation. It is easily done in a graphical chat interface but how is it done internally with code?","text":"I was using LLaVA to query in an image how many characters there are. For higher accuracy, I decided to employ Chain of Thought, but struggled to implement it. CoT is conducted through a multiple round conversation. It is easily done in a graphical chat interface but how is it done internally with code? Token Level Before diving into instruct / chat model, letâ€™s go to the lowest level and think how transformers do generation. Transformer is an autoregressive model: it uses its own output as input for the next round. Looking at nanoGPTâ€™s generate function: 12345678910111213def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None): &quot;&quot;&quot; Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete the sequence max_new_tokens times, feeding the predictions back into the model each time. &quot;&quot;&quot; for _ in range(max_new_tokens): idx_cond = idx if idx.size(1) &lt;= self.config.block_size else idx[:, -self.config.block_size:] logits, _ = self(idx_cond) logits = logits[:, -1, :] / temperature probs = F.softmax(logits, dim=-1) idx_next = torch.multinomial(probs, num_samples=1) idx = torch.cat((idx, idx_next), dim=1) return idx If we ignore the details, this for loop is effectively doing: 123456789token0 = tokenizer(text)output1 = model(token0)token1 = get_resposne(output1) output2 = model(token0 + token1)token2 = get_resposne(output2)output3 = model(token0 + token1 + token2)... By writing it out like this, itâ€™s clear that each turn of generation, we feed the previous step input into the model as something new, though exactly the same. Therefore, when we call model(token0 + token1), we forgot about all the attention we calculated in model(token0) even though the attention for token0 part is actually completely the same. This is why people complain transformer inference is slow and this is where the inference speed-up techniques like KV-cache comes in. This also reveals that the very popular graph demonstrating the theory behind transformerâ€™s inference lied (at least to me). When calculate yi + 1, we do not re-use y0â€¦yi or the attention or the activations in the middle. We just re-feed them back into the model as something completely new. Autoregressive Decoder Conversation Level Chat model is also just a text continuation model except it follows a chat template distinguishing which texts are inputted by the user and which are generated by the assistant. In the lowest abstraction level - the token level, for each turn, the model outputs one token and uses that as part of the input in next turnâ€™s generation. One abstraction level higher to this conversation level, to do multiple-round conversation, a chat model similarly outputs one response to one userâ€™s input and uses that response as a part of the input for next turnâ€™s generation. Therefore, to conduct conversation with a chat model, we just append the modelâ€™s response at each turn to its corresponding input. 123456input1 = tokenizer(text1)output1 = model(input1)# output1 contains input1 and model&#x27;s response 1response1 = get_resposne(output1) input2 = tokenizer(text2)output2 = model(input1 + response1 + input2) And yes, this means to get output2, we feed input1 + response1 both as new to the model, but this shouldnâ€™t be a concern anymore since we feed each token as new anyway. get_response The question now comes to how we should implement get_response to extract the assistantâ€™s response from the text-continuation modelâ€™s output. Find the indicator (prefix) of the start of assistantâ€™s message: Note when the model doesnâ€™t follow the instruction and failed to generate such a prefix, this method fails. 123456prefix = &quot;\\[/INST\\]&quot; # escape special characters for regexwith torch.no_grad(): output = model.generate(**inputs, max_new_tokens = 300)detoked_output = processor.decode(output[0], skip_special_tokens=True)answer_idx = [m.end() for m in re.finditer(prefix, detoked_output)][-1]answer = detoked_output[answer_idx:] recommended - Get the substring that is after the input (prompt): Hugging Face uses this approach in their TextGenerationPipeline. Thereâ€™s a clean_up_tokenization_spaces variable in decode function which defaults to False. (For what it does, see this discussion) Hugging Face set it to True in both call, but I tried set both to False or one to True the other to False, either can give correct results. That said, itâ€™s still best to follow what Hugging Face wrote. After all they know their codes best. 12345678910with torch.no_grad(): output = model.generate(**inputs, max_new_tokens = 300)detoked_output = processor.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)cutoff = len(text_processor.decode( inputs[&quot;input_ids&quot;][0], skip_special_tokens=True, clean_up_tokenization_spaces=True, ))answer = detoked_output[cutoff:] Detours when Taking the Recommended Approach I had some trouble with this recommended approach at first: 12345678chat = [ &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;&lt;image&gt;\\nHow many animated characters are there in this image?&quot;&#125;]prompt = text_processor.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)inputs = processor(prompt, image, return_tensors=&quot;pt&quot;).to(device)...detoked_output = processor.decode(output[0], skip_special_tokens=True)cutoff = len(prompt) And cutoff is actually many indexes after the real starting point of assistantâ€™s response. That is because when we apply_chat_template, we added some special tokens &lt;s&gt; &lt;\\s&gt; to indicate the start and end of one turn of conversation with the assistant, but when we detokenize the output, we skip_special_tokens to get the response only and caused this discrepancy. I thought at first that this discrepancy comes from LLaVA replaced &lt;image&gt; token with the image embeddings (or pixel_values as Hugging Face calls it) because &lt;image&gt; also disappeared in the detoked_output. However, after reading LLaVAâ€™s paper: Visual Instruction Tuning Figure 1: LLaVA network architecture, I realized LLaVA actually puts the image in front of the text input instead of inserting it in the middle. LLaVA architecture And &lt;image&gt; disappeared because itâ€™s also a special token. However it was not inside the tokenizer.all_special_tokens. Reading the source code of tokenizer, Iâ€™m actually not sure how it was added as a special token so was not able to debug why itâ€™s not in all_special_tokens. For this specific behavior, I submitted an issue on Hugging Face forum. You can find chat template definition in tokenizer_config.json -&gt; \"chat_template\". Also in this file, \"added_tokens_decoder\" attribute defines &lt;image&gt; as a special token. The Complete Code I referenced Hugging Face conversation pipeline for the general structure and the response extractor 12345678910111213141516171819202122232425queries = [ &quot;&lt;image&gt;\\nHow many animated characters are there in this image?&quot;, &quot;Answer with a single number in decimal format. Give no explanations.&quot;]def generate_response(image): chat = [] for query in queries: chat.append(&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: query&#125;) prompt = text_processor.apply_chat_template(chat, tokenize=False, add_generation_prompt=True) inputs = processor(prompt, image, return_tensors=&quot;pt&quot;).to(device) with torch.no_grad(): output = model.generate(**inputs, max_new_tokens = 300) output = processor.decode(output[0], skip_special_tokens=True) input_ids = inputs[&quot;input_ids&quot;] cutoff = len(text_processor.decode( input_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True, )) answer = output[cutoff:] chat.append(&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: answer&#125;) return answer PS As written at the start of this blogpost, it all began from me trying to do multi-round conversation with a transformer. A web search took me to these discussions (link 1, link 2). Itâ€™s obvious this accepted approach of appending output to previous message causes great waste of computing resources, which made me realize how transform works internally at the lowest level is itself a waste of resources.","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"GPT-4o Release","slug":"2024-05-14-GPT-4o-Release","date":"2024-05-14T04:00:00.000Z","updated":"2025-09-02T23:51:12.133Z","comments":true,"path":"2024-05-14-GPT-4o-Release/","permalink":"https://yao-lirong.github.io/blog/2024-05-14-GPT-4o-Release/","excerpt":"One day before Google I/O, OpenAI made a Spring Update Release, introducing multi-modal end-to-end model GPT4-o","text":"One day before Google I/O, OpenAI made a Spring Update Release, introducing multi-modal end-to-end model GPT4-o Capabilities and Features In their release live, we see Real-time responsiveness in audio mode, ability to be interruptted Detect tone and mood in your speech, including how hard you breath Real-time responsiveness in vision mode: no need to take a picture, just hold your phoneâ€™s camera there and it can screenshot(?) for you Right after the live, OpenAI updated their blog, showing more demos: Two GPT-4os harmonizing: on the same device same session. They can sing and harmonize. They can follow userâ€™s instruction to sing faster, sing slower, or sing in a higher voice. Lullaby: user can give instruction by speech to tell GPT-4o to go lighter, louder, â€¦ Taking faster: user can give instruction by speech to tell GPT-4o to speak faster, slower Failure cases: it sometimes go wild and speak in another language fail in translation tasks fail in teaching intonation in Chinese Technicality GPT-4o is a single new model end-to-end across text, vision, and audio, meaning that all inputs and outputs are processed by the same neural network. Previously, ChatGPT Voice Mode is a pipeline of three separate models: audio-text transcription, GPT-3.5/GPT-4 text model, text-to-audio conversion model Designed a new tokenizer with greater compression: Hindi has 2.9x fewer tokens, Russian 1.7x, Korean 1.7x, Chinese 1.4x, Japanese 1.4x, and European languages, including English, has 1.1x fewer tokens. New tokenizer means fully new pre-trained model (brought up in this reddit thread) It is super fast, responding to audio inputs with an average of 320 milliseconds, while original ChatGPT Voice Mode has latencies of 2.8 seconds (GPT-3.5) and 5.4 seconds (GPT-4) on average. At the same time, GPT-4o â€œachieves GPT-4 Turbo-level performance on text, reasoning, and coding intelligence.â€ What did they do to speed up inference? Is it Quantization, MoE or something else? (brought up in this reddit thread) Whatâ€™s the model size? Nothing is reported. Inspecting the New Tokenizer When I used reddit on the day GPT-4o released, this post came to me suggesting Chinese tokens in OpenAIâ€™s new tokenizer are greatly contaminated. The new tokenizer o200k_base is actually twice as large as the last cl100k_base and has already been loaded to GitHub in this commit.","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"CLIP","slug":"2024-04-22-CLIP","date":"2024-04-22T04:00:00.000Z","updated":"2025-09-03T01:42:46.384Z","comments":true,"path":"2024-04-22-CLIP/","permalink":"https://yao-lirong.github.io/blog/2024-04-22-CLIP/","excerpt":"CLIP investigates whether it is possible to transfer the success of task-agnostic web-scale pre-training in NLP to another domain (CV).","text":"CLIP investigates whether it is possible to transfer the success of task-agnostic web-scale pre-training in NLP to another domain (CV). This line of work represents the current pragmatic middle ground between learning from a limited amount of supervised â€œgold-labelsâ€ and learning from practically unlimited amounts of raw text. 2 Approach 2.1 Advantage of Natural Language Supervision easy to scale: natural language data amount is huge, much easier to obtain than crowd-sourced labeling flexible zero-shot transfer: connects image representation to language; different from unsupervised or self-supervised model that is limited to image domain. 2.2 Constructing Dataset To explore effects of web-scale pre-training, we first build a web-scale dataset. Construct a query list of size 500,000 that contains words occurred &gt;= 100 times in Wikipedia Search for images of these queries, construct a dataset of 400M (image, text) pair Class balance (yeah thatâ€™s the word describing â€œmake each class have the same number of samples so itâ€™s fairâ€) by including 20,000 pairs per query 2.3 What to Predict? What is the Loss? Previous methods with natural language supervision attempt is about predicting a bag of words (BoW) / phrase n-gram representation of labels. The authors explore different approaches. This work is all about large scale pre-training and scaling. Training efficiency is the key to scaling natural language supervision. Authors selected final pre-training method based on efficiency. They compared three approaches: Transformer language model (captioning model): train a transformer to predict the caption of an image. So this is a generative task and uses transformerâ€™s loss function. It learns 3 times slower than the baseline - approach 2. A model predicts BoW encoding of the caption: this was used as a simple baseline and authors found approach 1 couldnâ€™t even beat this baseline. This approach still tries to predict the exact words of the text label, but the order of how words appear no longer matters. This is not much easier due to the wide variety of descriptions, comments, and related text that co-occur with images. A contrastive model predicts which text as a whole is paired with which image: In this way, we decrease the output space to only the number of classes we have. We learn 4 times faster than the baseline - approach 2. Accuracy vs #(images processed) See Figure 2 for a detailed comparison on accuracy vs. #(images fed) of these three models. This illustrates how fast / slow a training method learns. Approach Output Space Answer Space: In ideal scenario, what do we choose from? Transformer Language Model All English sentences (permutation of all English words) 500K queries BoW prediction model Word count bucket of all English sentences (combination of all English words) 500K queries Contrastive pairing model Sentences describing class and labels batch_size pre-selected queries (32768 in CLIP) Itâ€™s worth noting that CLIP uses a very large minibatch size of 215 = 32768 2.4 Model Architecture and Scaling Summary of CLIP Image encoder has two architectures: ResNet-50 and ViT 1234567891011121314151617181920# image_encoder - ResNet or Vision Transformer# text_encoder - CBOW or Text Transformer# I[n, h, w, c] - minibatch of aligned images# T[n, l] - minibatch of aligned texts# W_i[d_i, d_e] - learned proj of image to embed# W_t[d_t, d_e] - learned proj of text to embed# t - learned temperature parameter# extract feature representations of each modalityI_f = image_encoder(I) #[n, d_i]T_f = text_encoder(T) #[n, d_t]# joint multimodal embedding [n, d_e]I_e = l2_normalize(np.dot(I_f, W_i), axis=1)T_e = l2_normalize(np.dot(T_f, W_t), axis=1)# scaled pairwise cosine similarities [n, n]logits = np.dot(I_e, T_e.T) * np.exp(t)# symmetric loss functionlabels = np.arange(n)loss_i = cross_entropy_loss(logits, labels, axis=0)loss_t = cross_entropy_loss(logits, labels, axis=1)loss = (loss_i + loss_t)/2 Note: d_e represents multi-modal embedding space. the temperature parameter Ï„ is directly optimized as a log-parameterized multiplicative scalar to avoid turning as a hyper-parameter. implementation in original release The authors train CLIP from scratch without initializing the image encoder with ImageNet weights or the text encoder with pre-trained weights. This section also describes how to scale the text encoder and how to scale both kinds of image encoder. 3 Experiments Authors conducted experiments on 36 different datasets. 3.1 Zero-Shot Transfer Authors wanted to experiment on zero-shot transfer ability because of the ability demonstrated in language models. The following is the most exciting sentence to me in this paper. I think it explains a lot of large-scale design choices by OpenAI team. Did this paper inspire Ilya to go all the way down the path of scaling? Our focus on studying zero-shot transfer as an evaluation of task learning is inspired by work demonstrating task learning in the field of NLP. To our knowledge Liu et al. (2018) first identified task learning as an â€œunexpected side-effectâ€ when a language model trained to generate Wikipedia articles learned to reliably transliterate names between languages. Authors explain in detail how we do zero-shot classification and give an interpretation to the pipeline. I wrote the previous â€œoutput spaceâ€ and â€œanswer spaceâ€ thing based on this interpretation. The cosine similarity of these embeddings is then calculated, scaled by a temperature parameter Ï„ , and normalized into a probability distribution via a softmax. Note that this prediction layer is a multinomial logistic regression classifier with L2-normalized inputs, L2-normalized weights, no bias, and temperature scaling. When interpreted this way, the image encoder is the computer vision backbone which computes a feature representation for the image and the text encoder is a hypernetwork which generates the weights of a linear classifier based on the text specifying the visual concepts that the classes represent. Continuing with this interpretation, every step of CLIP pre-training can be viewed as optimizing the performance of a randomly created proxy to a computer vision dataset which contains 1 example per class and has 32,768 total classes defined via natural language descriptions. prompt engineering and ensembling Text in our training data is usually a sentence, but text in test data is just a one word label. To bridge this gap, we use some prompt template. default: A photo of a &#123;label&#125; on several fine-grained image classification datasets, itâ€™s helpful to specify the category: A photo of a &#123;label&#125;, a type of pet or a satellite photo of a &#123;label&#125; ensembling several different prompts improve performance: use different context prompts such as A photo of a big &#123;label&#125; and A photo of a small &#123;label&#125;. Authors construct the ensemble over the embedding space instead of probability space. In this way, they cache a single set of averaged text embedding so compute cost doesnâ€™t increase in amortized time. scaling law Zero-shot CLIP scales wrt model compute Scaling law is the law that empirically shows that performance is predictable as a function of important quantities such as training compute and dataset size. On 36 different datasets, ResNet CLIPâ€™s average zero-shot error is well modeled by a log-log linear scaling trend. However, performance on individual evaluations is much more varied despite the smooth overall trend. Authors did not report ViT CLIP scaling results. 3.2 Representation Learning To use CLIP as a representation of the image, there are two common approaches: Fitting a linear classifier on a representation extracted from the model End-to-end fine-tuning of the model. Fine-tuning increases flexibility, and prior work has convincingly demonstrated that fine-tuning outperforms linear classification on most image classification datasets. However, OpenAI chooses to use linear classifier to measure CLIP performance for the following reasons: the more official reason: we chose it because itâ€™s weak and therefore better shows how dataset-agnostic CLIP is Our work is focused on developing a high-performing task and dataset-agnostic pre-training approach. Fine-tuning, because it adapts representations to each dataset during the fine-tuning phase, can compensate for and potentially mask failures to learn general and robust representations during the pre-training phase. Linear classifiers, because of their limited flexibility, instead highlight these failures and provide clear feedback during development the more practical reason: Fine-tuning opens up a much larger design and hyper-parameter space, which makes it difficult to fairly evaluate and computationally expensive. By comparison, linear classifiers require minimal hyper-parameter tuning and have standardized implementations and evaluation procedures. bonus reason: Linear classifier has the added benefit of being very similar to the approach used for its zero-shot classifiers which enables extensive comparisons and analysis approach: Appendix A.3 provides a full guideline of training such a linear classifier, including details on hyper-parameter search, solver method, and train-valid-test split. Notably, the input to the Logistic Regression is the image embedding (output of the image encoder I_f), not the multi-modal embedding (image embedding that went through the multi-modal linear projection) results: when comparing to other models of similar compute requirement, small CLIP have wins and loses. However, CLIP scales very well and the largest model achieves both SOTA score and compute efficiency. ViT vs ResNet: The authors found CLIP ViT is about 3x more compute efficient than CLIP ResNet. This is aligned with ViT paperâ€™s finding Out-of-Domain Performance and Natural Distribution Shift: Researchers often find models exceeding human on ImageNet test set can still make simple mistakes on other test data and score much lower than human. A common explanation is these models are adept at finding patterns within dataset, so improve in-distribution performance. However many of these patterns are spurious and do not hold for other distributions and result in large drops in performance on other datasets. Most of the studies that reach the above explanation limited their evaluation model to those trained on ImageNet. Therefore, the authors want to know to what degree are these failures attributable to deep learning, ImageNet, or some combination of the two? They explore this by evaluating ImageNet models on natural distribution shifted dataset. Natural distribution shift means testing trained models on data that is different in e.g. image style, image blurriness, geographic location, and camera operation (Hendrycks et al. The many faces of robustness). â€œNaturalâ€ is used to make a distinction from synthetic distribution shift made through style-transferred or adversarially generated. Authors found CLIP perform much better on these natural distribution shifted dataset. However, this doesnâ€™t necessarily mean supervised learning on ImageNet causes a robustness gap. Other details of CLIP, such as its large and diverse pre-training dataset or use of natural language supervision could also produce robust models. Therefore, OpenAI measured how the performance of CLIP models change after adapting to the ImageNet distribution via an L2 regularized logistic regression classifier fit to CLIP features on the ImageNet training set. This improved accuracy on ImageNet by 9.2% to 85.4%, but average accuracy under distribution shift slightly decreases. To me this doesnâ€™t say much. If you fine-tune (or fit a linear classifier) to a specific dataset, of course youâ€™d expect its behavior to be bad on some other dataset. But on the contrary, these natural-distribution-shifted dataset is not that different from ImageNet. Yes, there are some animations / sketches, but most are just some more pictures of that class. And CLIP with an ImageNet linear head cannot get them right. I guess what the authors want to say is that ImageNet is not just A arbitrary dataset, but has almost become a machine learning benchmark dataset. It is supposed to be general because all models train on it and these models will be deployed to all sorts of scenario. The authors didnâ€™t go far to attack the generality of ImageNet or even draw any conclusion on why fitting an ImageNet classification head hurts natural distribution shift performance. The authors just prompt to caution that though prior work has also pre-trained models on distributions other than ImageNet, it is common to study and release models only after they have been fine-tuned to ImageNet. And it would be wise to also study the models pre-trained on distributions other than ImageNet. Results: Taken together, these results suggest that the recent shift towards large-scale task and dataset agnostic pre-training combined with a reorientation towards zero-shot and few-shot benchmarking on broad evaluation suites promotes the development of more robust systems and provides a more accurate assessment of performance. 5 Data Overlap Analysis A concern with pre-training on a very large internet dataset is unintentional overlap with downstream evals. One option to prevent this is to identify and remove all duplicates before training a model. While this guarantees reporting true hold-out performance, it requires knowing all possible data which a model might be evaluated on ahead of time. This has the downside of limiting the scope of benchmarking and analysis. Therefore, OpenAI instead built a duplicate detector, document how much overlap occurs, and run experiments on dataset with and without these overlaps to measure how performance changes due to these overlaps. So instead of simply removing them, they record performance of before and after removing them. They found that there is a median overlap of 2.2% and an average overlap of 3.2%. Due to this small amount of overlap, overall accuracy is rarely shifted by more than 0.1% with only 7 datasets above this threshold. It would be useful if OpenAI also releases their duplicate detector model. Appendix C discusses it in more details but it doesnâ€™t seem like OpenAI ever released it. 6 Limitations Performance: CLIP cannot beat dataset-specific trained &amp; designed models: CLIP zero-shot performs better than a pre-trained ResNet-50 feature + a linear classifier, but on most datasets, CLIP is well below the SOTA for that specific dataset. zero-shot CLIP still generalizes poorly to data that is truly out-of-distribution for it: CLIP simply has a super large domain, not really a general model. For example, MNIST digits are not at all in its web-scraped huge dataset, so CLIP does surprisingly bad on this super simple dataset. CLIP is limited to â€œchoosingâ€: CLIP cannot just take in a picture and spit out its class. You need to give CLIP a range to choose from. CLIP is based on â€œchoosingâ€, not â€œgeneratingâ€ (image captioning model) Training Methodology: In training time, CLIP repeatedly queried performance on full validation sets to guide optimization. These validation sets often have thousands of examples, which is unrealistic for true zero-shot scenarios. On the contrary, LLM in training time doesnâ€™t do this (?) Training dataset comes from Internet. Its image-text pairs are unfiltered and uncurated and result in CLIP models learning many social biases. Supervision with Natural Language: Many complex tasks and visual concepts can be difficult to specify just through text. Actual training examples are undeniably useful but CLIP does not optimize for few-shot performance directly. In our work, we fall back to fitting linear classifiers on top of CLIPâ€™s features. This results in a counter-intuitive drop in performance when transitioning from a zero-shot to a few-shot setting. 7 Broader Impacts In this section, the authors mainly introduces the bias exists in CLIP and what kind of surveillance it can be used for. Nothing too interesting, but they discussed how tweaking the category system can improve modelâ€™s performance. This reminds me of what I did in Xiaomiâ€™s oversea app store tagging project, where I added new category and modified existing categoryâ€™s definition to improve the cos-similarity based zero-shot classification model performance. Given that we observed that people under 20 were the most likely to be classified in both the crime-related and non-human animal categories, we carried out classification for the images with the same classes but with an additional category â€˜childâ€™ added to the categories. We found that this drastically reduced the number of images of people under 20 classified in either crime-related categories or non-human animal categories (Table 7). This points to how class design has the potential to be a key factor determining both the model performance and the unwanted biases or behavior the model may exhibit The authors then go on to conclude that Decisions about things like class design are a key determiner not only of model performance, but also of how and in what contexts model biases manifest Takeaways Data is still the king in ML. It is possible to transfer the success of task-agnostic web-scale pre-training in NLP to CV. The key to scaling &amp; training efficiency is how compact your output space is (word permutation - &gt; word combination -&gt; batch_size) We can use prompt ensembling to improve CLIPâ€™s performance. To use CLIP as the feature extractor and put a linear classifier on top of it, we use the image embedding (image encoderâ€™s output), not he multi-modal embedding (image embedding went through the multi-modal linear projection); On the other hand, for zero-shot classification, you use multi-modal embedding, the same as the training process except now you only have one image and calculate the cos similarity with all class names. Decisions about things like class design are a key determiner not only of model performance, but also of how and in what contexts model biases manifest","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"Gradient Scaling","slug":"2024-04-08-Gradient-Scaling","date":"2024-04-08T04:00:00.000Z","updated":"2025-09-02T23:51:12.133Z","comments":true,"path":"2024-04-08-Gradient-Scaling/","permalink":"https://yao-lirong.github.io/blog/2024-04-08-Gradient-Scaling/","excerpt":"Loss Scaling / Gradient Scaling was mentioned in Mixed-Precision Training as one of the 3 techniques, but there are many points to be careful with when in practice.","text":"Loss Scaling / Gradient Scaling was mentioned in Mixed-Precision Training as one of the 3 techniques, but there are many points to be careful with when in practice. Overview: Typical Use Case Hereâ€™s an overview of how to use amp.GradScaler adapted from PyTorch official doc. Background If the forward pass for a particular op has float16 inputs, under Automatic Mixed Precision package - torch.amp, the backward pass for that op will produce gradients of the same data type - float16 . Gradient values with small magnitudes may not be representable in float16. These values will flush to zero (â€œunderflowâ€), so the update for the corresponding parameters will be lost. Code scaler.scale(loss).backward(): To prevent underflow, â€œgradient scalingâ€™ multiplies the networkâ€™s loss(es) by a scale factor and invokes a backward pass on the scaled loss(es). In this way, the gradients on all parameters are scaled by this same factor and we donâ€™t have to worry about them flush to zero. scaler.scale(loss) multiplies a given loss by scalerâ€™s current scale factor. We then call backward on this scaled loss. scaler.step(optimizer): After back-propagation, all learnable parameters get their gradients, which are scaled to prevent underflow. Before applying whatever learning algorithm (Adam, SGD, â€¦) on them, we have to unscale them so the amount to be updated is correct. scaler.step(optimizer) 1. unscales gradients, 2. calls optimizer.step(), and does the previous two points safely: Internally invokes unscale_(optimizer) (unless unscale_() was explicitly called for optimizer earlier in the iteration). As part of the unscale_(), gradients are checked for infs/NaNs to prevent overflow/underflow (For why overflow can happen, check point 3 scaler.update) If no inf/NaN gradients are found, invokes optimizer.step() using the unscaled gradients. Otherwise, optimizer.step() is skipped to avoid corrupting the params. scaler.update(): It would be great if we could just multiply all gradients by a super big number so absolutely no underflow happens, but doing so can cause overflow. The scaler estimates a good scaling factor for each iteration, so neither underflow nor overflow happens. scaler.update() updates scalerâ€™s scale factor for next iteration. 1234567891011scaler = torch.cuda.amp.GradScaler()for epoch in epochs: for input, target in data: optimizer.zero_grad() with autocast(device_type=&#x27;cuda&#x27;, dtype=torch.float16): output = model(input) loss = loss_fn(output, target) scaler.scale(loss).backward() scaler.step(optimizer) scaler.update() Working with Unscaled Gradients - Gradient clipping gradient clipping manipulates a set of gradients such that their global norm torch.nn.utils.clip_grad_norm_() or maximum magnitude torch.nn.utils.clip_grad_value_() is &lt;= some user-imposed threshold. The â€œgradientsâ€ here of course refer to the original, unscaled gradients. Therefore, you need to call scaler.unscale_(optimizer) before clipping. 123456789101112131415161718192021scaler = GradScaler()for epoch in epochs: for input, target in data: optimizer.zero_grad() with autocast(device_type=&#x27;cuda&#x27;, dtype=torch.float16): output = model(input) loss = loss_fn(output, target) scaler.scale(loss).backward() # Unscales the gradients of optimizer&#x27;s assigned params in-place scaler.unscale_(optimizer) # Since the gradients of optimizer&#x27;s assigned params are unscaled, clips as usual: torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm) # optimizer&#x27;s gradients are already unscaled, so scaler.step does not unscale them, # although it still skips optimizer.step() if the gradients contain infs or NaNs. scaler.step(optimizer) scaler.update() Working with Scaled Gradients - Gradient accumulation Gradient accumulation adds gradients over an effective batch of size batch_per_step * gradient_accumulation_steps (* num_procs if distributed). Operations related to scaled gradients should occur at effective batch granularity. The following happens at the end of each effective batch: inf/NaN checking step skipping if inf/NaN grads are found parameter update scale update Within an effective batch, all grads you accumulate should all be scaled and the scale factor should remain unchanged. 123456789101112131415161718scaler = GradScaler()for epoch in epochs: for micro_step in range(gradient_accumulation_steps): input, target = get_data(epoch, micro_step) with autocast(device_type=&#x27;cuda&#x27;, dtype=torch.float16): output = model(input) loss = loss_fn(output, target) loss = loss / gradient_accumulation_steps # Accumulates scaled gradients. scaler.scale(loss).backward() # If you need to work with unscaled gradients, # after all (scaled) grads for the upcoming step have been accumulated # may unscale_ here if desired (e.g., to allow clipping unscaled gradients) scaler.step(optimizer) scaler.update() optimizer.zero_grad() These examples may seem too vanilla, check out nanoGPTâ€™s mixed precision training loop for a lively combination of gradient accumulation and gradient clipping. Working with Scaled Gradients - Gradient penalty What? Why? https://discuss.pytorch.org/t/whats-the-use-of-scaled-grad-params-in-this-example-of-gradient-penalty-with-scaled-gradients/199741/3 Epilogue This wiki page from Deepgram provides a detailed view of what gradient scaling is about, but I donâ€™t know why it just reads like AI-generated content. Maybe because it gives too many unnecessary details.","categories":[],"tags":[]},{"title":"Decoupled Weight Decay Regularization (SGDW & AdamW)","slug":"2024-03-13-Decoupled-Weight-Decay-Regularization-(SGDW-&-AdamW)","date":"2024-03-13T04:00:00.000Z","updated":"2025-09-02T23:51:12.124Z","comments":true,"path":"2024-03-13-Decoupled-Weight-Decay-Regularization-(SGDW-&-AdamW)/","permalink":"https://yao-lirong.github.io/blog/2024-03-13-Decoupled-Weight-Decay-Regularization-(SGDW-&-AdamW)/","excerpt":"The paper Decoupled Weight Decay Regularization mainly introduces AdamW, which is the SOTA optimizer since then. It investigates why Adam with L2 regularization sometimes performs worse than SGD with L2 regularization. It demonstrates weight decay and L2 regularization, two things people usually draw an equal sign, are not the same. And it shows weight decay is the ultimate go-to choice.","text":"The paper Decoupled Weight Decay Regularization mainly introduces AdamW, which is the SOTA optimizer since then. It investigates why Adam with L2 regularization sometimes performs worse than SGD with L2 regularization. It demonstrates weight decay and L2 regularization, two things people usually draw an equal sign, are not the same. And it shows weight decay is the ultimate go-to choice. Weight decay and L2 regularization are equivalent in SGD when set L2 regularizer $\\lambda' = \\frac \\lambda \\alpha$, which is our common practice. The situation is more complicated with adaptive gradient algorithms like Adam. Adam performs much better with weight decay and the authors propose the new SOTA optimizer AdamW (Adam with decoupled weight decay). All the conclusions and main finding can be found in the first 2 pages of the paper and mostly in the Introduction section. I did not read the math. This blogpost from Fast.ai demonstrates how the two methods are different in code, a bit easier to understand than the paper which doesnâ€™t provide a comparision. Weight Decay in Transformers AdamW is the go-to optimizer for LLM these days. Researchers chose it because LLMs are hard to train and rarely overfit, and Adam is the best choice when convergence speed is considered (reference). People have also found AdamW usually performs best with big weight decay coefficient like 0.05 or 0.1 (zhihu question, ViT paper: Training &amp; Fine-tuning section) When we apply weight decay in transformers, we apply it to all layers except LayerNorm and bias layers. In nanoGPT, Karpathy filtered them out using: 12345678# create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.# i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don&#x27;t.decay_params = [p for n, p in param_dict.items() if p.dim() &gt;= 2]nodecay_params = [p for n, p in param_dict.items() if p.dim() &lt; 2]optim_groups = [ &#123;&#x27;params&#x27;: decay_params, &#x27;weight_decay&#x27;: weight_decay&#125;, &#123;&#x27;params&#x27;: nodecay_params, &#x27;weight_decay&#x27;: 0.0&#125;] One caveat is that, in earlier versions, Karpathy did NOT weight decay embeddings: 12345blacklist_weight_modules = (torch.nn.LayerNorm, LayerNorm, torch.nn.Embedding)...elif pn.endswith(&#x27;weight&#x27;) and isinstance(m, blacklist_weight_modules): # weights of blacklist modules will NOT be weight decayed no_decay.add(fpn) I couldnâ€™t find any instruction on whether you should decay embeddings or not when training a transformer, but Hugging Faceâ€™s transformer implementation also decays embeddings, in line with Karpathyâ€™s latest implementation. 123# get_parameter_names(model, name) excludes layers with `name`decay_parameters = get_parameter_names(model, ALL_LAYERNORM_LAYERS)decay_parameters = [name for name in decay_parameters if &quot;bias&quot; not in name]","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"Mixed-Precision Training","slug":"2024-03-01-Mixed-Precision-Training","date":"2024-03-01T05:00:00.000Z","updated":"2025-09-02T23:51:12.127Z","comments":true,"path":"2024-03-01-Mixed-Precision-Training/","permalink":"https://yao-lirong.github.io/blog/2024-03-01-Mixed-Precision-Training/","excerpt":"Mixed-precision training was introduced in Nvidia and Baiduâ€™s research. The blogpost from Nvidia gave a nice summary of how itâ€™s done and why it works. Nvidia also gave a more in-depth coverage of the same points in their tutorial on training with mixed precision.","text":"Mixed-precision training was introduced in Nvidia and Baiduâ€™s research. The blogpost from Nvidia gave a nice summary of how itâ€™s done and why it works. Nvidia also gave a more in-depth coverage of the same points in their tutorial on training with mixed precision. I decided to learn this as I was reading nanoGPTâ€™s code: 12torch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmultorch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn Benefits Decrease the required amount of memory: FP32 -&gt; FP16 Shorten the training or inference time: memory bandwith: half-precision halves the number of bytes need to be accessed, thus reducing time-spent in memory-limited operations arithmetic bandwidth: half-precision arithmatic is inherintely faster than single-precision 3 Techniques in Original Paper Accumulation into FP32: then convert to FP16 for storage Loss Scaling (Gradient Scaling): There are four types of tensors encountered when training DNNs: activations, activation gradients, weights, and weight gradients. In experience activations, weights, and weight gradients can be represented with half precision. However, for some networks activation gradients are too small to be represented in half-precision range (underflow) Therefore, we need to scale up the activation gradients. This can be done by simply multiply the training loss with the scale factor. This adds just a single multiplication and by the chain rule it ensures that all the gradients are scaled up at no additional cost. FP32 Master Copy of Weights: Weight gradient magnitudes are smaller than corresponding weights, especially after multiplication with the learning rate. So sometimes no update takes place. The remedy is to store the weights in single precision, but do computation in half precision. Update this master copy of weights after each computation. More Recent Update In NVIDIA Ampere GPU architecture, Nvidia introduced TensorFloat32 (TF32) with FP32 range (8bit) and FP16 precision (10bit). With the additional sign bit, it is a novel 19 bit representation of floats. On an A100, it brings 8x speed up compared to FP32, while FP16/BF16 brings 16x speedup. Therefore, mixed-precision training with a native 16-bit format (FP16/BF16) is still the fastest option. TF32 is only exposed as a Tensor Core operation mode, not a type. Internally, all storage in memory and other operations remain completely in FP32, only convolutions and matrix-multiplications convert their inputs to TF32 right before multiplication. Therefore, it does not provide the memory benifits or the native arithmetic speed up brought by 16-bit format. Its benefit is that it brings Tensor Core acceleration to single-precision DL workloads, without needing any changes to model scripts. It needs to be noted that TF32 gives less accurate computation results. Therefore, PyTorch decided to set toggle torch.backends.matmul.allow_tf32 = False by default starting from 1.12. Read more about PyTorchâ€™s official comparison of speed and numerical stability. Best Practices PyTorch gave some official best practices tips to developers. Please do check them out here.","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"Parameter and FLOP Count in Transformer Model","slug":"2024-02-22-Parameter-and-FLOP-Count-in-Transformer-Model","date":"2024-02-22T05:00:00.000Z","updated":"2025-09-02T23:34:26.325Z","comments":true,"path":"2024-02-22-Parameter-and-FLOP-Count-in-Transformer-Model/","permalink":"https://yao-lirong.github.io/blog/2024-02-22-Parameter-and-FLOP-Count-in-Transformer-Model/","excerpt":"We borrow the results of decoder-only transformer models from OpenAIâ€™s paper Scaling Laws for Neural Language Models Section 2.1","text":"We borrow the results of decoder-only transformer models from OpenAIâ€™s paper Scaling Laws for Neural Language Models Section 2.1 We use the following notations: L = number of layers of transformer blocks (N in Attention is All You Need) dmodel = dimension of the input &amp; output of a transformer block, also the output of the text encoder and input of the decoder dff = dimension of the feed-forward networkâ€™s bottleneck. We defined the feed-forward network as fc1 = fc(d_model, d_ff), fc2 = fc(d_ff, d_model) dattn = dimension of the multi-head attention output (In Attention is All You Need, we have h number of heads. Queries and keys have dimension dk. Values have dimension dv. In practice, we usually have dk = dv. dattn we have here is defined as dk Ã— h) Part Parameters Explanation Embed $n_{vocab}\\times d_{model} \\\\ +n_{ctx} \\times d_{model}$ One word embedding matrix (mapping each token to corresponding embedding ) and one positional embedding matrix Attention: Q K V Matrix L3dmodeldattn WQ has shape (dmodel, dattn). Thereâ€™re also WK and WV Attention: Multi-head Projection $L d_{attn} d_{model} $ After we concat the output from all heads, thereâ€™s one projection from all-head output to the final output. This is that matrix. It was defined as WO in Attention is All You Need 3.2.2. Feedforward Network L2dmodeldff Explained in the definition of dff above. Total (Non-Embedding) 2Ldmodel(2dattn + dff) If we have the standard dattn = dmodel = dff/4, we can get N = 12Ldmodel2 Put this into practice, letâ€™s calculate a rough estimate of number of parameters the vanilla transformer has. The vanilla transformer base, per the paper Attention is All You Need Table 3, L = 6, dmodel = 512, dff = 2048, dattn = h Ã— dk = 8 Ã— 64 = 512, nvocab = 37000. I didnâ€™t find info about nctx, but is probably 512. Note that different from OpenAIâ€™s favorite decoder-only transformer, the vanilla transformer has an encoder-decoder architecture and the decoder block has an additional attention block. Therefore, the encoder has a total 2Ldmodel(2dattn + dff) parameters, the decoder has a total 2Ldmodel(4dattn + dff) params, and the embedding part has a total nvocab Ã— dmodel + nctx Ã— dmodel params. The final result is âˆ¼ 63 Ã— 106. I tried hard to figure out where went off from the paperâ€™s 65 Ã— 106 but had no luck. Adding the parameters of LayerNorm still didnâ€™t even out the numbers. But itâ€™s close enough so Iâ€™ll call it a day.","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"Memory Pinning and Transfer Data between Host (CPU) and Device (GPU)","slug":"2024-02-09-Memory-Pinning-and-Transfer-Data-between-Host-(CPU)-and-Device-(GPU)","date":"2024-02-09T05:00:00.000Z","updated":"2025-09-02T23:51:12.127Z","comments":true,"path":"2024-02-09-Memory-Pinning-and-Transfer-Data-between-Host-(CPU)-and-Device-(GPU)/","permalink":"https://yao-lirong.github.io/blog/2024-02-09-Memory-Pinning-and-Transfer-Data-between-Host-(CPU)-and-Device-(GPU)/","excerpt":"PyTorch official documentation explains this concept very briefly and we go into more detail here.","text":"PyTorch official documentation explains this concept very briefly and we go into more detail here. What is memory pinning and why we use it First, letâ€™s go back to our OS class and remind what â€œpaged memoryâ€ means. Process always wants contiguous memory. The OS uses memory paging to enable logically contiguous memory that is not physically contiguous. When a process requests memory, OS allocates page frames to the process. These page frames look contiguous to the process, but are actually not so in physical memory. The OS then maps the processâ€™s logical pages to the physical page frames. This Nvidia blog on data transfer explains what this has to do with GPU: The GPU cannot access data directly from pageable host memory (logically contiguous), so when a data transfer from pageable host memory to device memory is invoked, the CUDA driver must first allocate a temporary page-locked, or â€œpinnedâ€, physically contiguous host array, copy the host data to the pinned array, and then transfer the data from the pinned array to device memory. pinned memory Therefore, we can avoid the cost of the transfer between pageable and pinned host arrays by directly allocating our host arrays in pinned memory. To my understanding, â€œdirectly allocating in pinned memoryâ€ corresponds to whatâ€™s described in DataLoaderâ€™s documentation as: 1loader = DataLoader(dataset, pin_memory=True) pin_memory() and non_blocking=True On the other hand, while reading nanoGPTâ€™s code, I saw the following code: 123if device_type == &#x27;cuda&#x27;: # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True) x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True) pin_memory is familiar to us while non_blocking is something new. It tells the program that it can perform other operations on this data while it being trasferred from host to device. (so donâ€™t block till transfer is done to start the operation) This async copy usually speeds things up. This Stack Overflow answer gives a detaild example of the async part. Here in the code, we are explicitly calling pin_memory() on something already initialized, which really confused me. Since according to the above quoted Nvidia blog, â€œwhen a data transfer from pageable host memory to cuda device memory is invoked, the CUDA driver must first allocate a pinned host array, copy the host data to the pinned array, and then transfer the data from the pinned array to device memory.â€ That is to say: even without such an explicit pin_memory() call, CUDA will do it for us. I found this exchange on PyTorchâ€™s forum and also asked this question myself, but didnâ€™t receive a super clear answer. But inferring from what @ptrblck said, I think it is correct to say that the following two commands are equal in speed (with the first pinning memory implicitly and the second does it explicitly) t.to(\"cuda\", non_blocking=False) t.pin_memory().to(\"cuda\", non_blocking=False) and explicit memory pinning call is only useful when used together with to(device, non_blocking=True) Someone in this Zhihu discussion also argues paged memory can be exchanged into disk swap when physical memory is not enough. Explicitly pinning memory avoids this problem and saves the time of finding these pages in disk for every query (pinning brings them all out into physical memory). The poster did not give a reference though.","categories":[],"tags":[]},{"title":"Switching Personal Homepage Theme to al-folio","slug":"2024-01-27-Switching-Personal-Webpage-Theme-to-al-folio","date":"2024-01-27T05:00:00.000Z","updated":"2024-01-28T09:22:54.542Z","comments":true,"path":"2024-01-27-Switching-Personal-Webpage-Theme-to-al-folio/","permalink":"https://yao-lirong.github.io/blog/2024-01-27-Switching-Personal-Webpage-Theme-to-al-folio/","excerpt":"Since long before have I realized I do need a more official and more academic homepage in addition to a personal blog site, but I didnâ€™t find time to do it until I started working. Now after this switch, I have my personal homepage of al-folio in Jekyll and at the same time my blog of archer in Hexo.","text":"Since long before have I realized I do need a more official and more academic homepage in addition to a personal blog site, but I didnâ€™t find time to do it until I started working. Now after this switch, I have my personal homepage of al-folio in Jekyll and at the same time my blog of archer in Hexo. Migrating Hexo Blog to Sub-Directory I want to keep this archer theme for my blog while creating a new personal homepage. Therefore, I have to move this repo out of the GitHub page repo and into some other blog repo. That is, this blog will now be served as a GitHub project page, like my ARC 40. What needs to be done was surprisingly simple: Create a GitHub repo to store your webpages: This repo will contain the exact same information as my previous Yao-Lirong/Yao-Lirong.github.io. I created Yao-Lirong/blog. Change your Hexo _config.yml. You can reference the official guide on deploying, but they didnâ€™t mention how to one-command deploy a project page. 123456789101112# URL## If your site is put in a subdirectory, set url as &#x27;http://yoursite.com/child&#x27; and root as &#x27;/child/&#x27;url: https://yao-lirong.github.io/blogroot: /blog/# Deployment## Docs: https://hexo.io/docs/one-command-deploymentdeploy: type: git repo: https://github.com/Yao-Lirong/blog branch: master message: Updated at &#123;&#123; now(&#x27;YYYY-MM-DD HH:mm&#x27;) &#125;&#125; hexo clean &amp;&amp; hexo deploy Configuring al-folio Local Install Since this migration was a long process, when I was working on al-folio, my archer page was still up and I have to first try out al-folio locally to not break my current GitHub page. To do this, the only feasible way is to use docker as suggested in their install instruction. Donâ€™t bother to try other ways. You wonâ€™t have any luck running them. 1234git clone --depth 1 https://github.com/alshedivat/al-folio.gitcd al-folio/docker compose pulldocker compose up Personalization _pages/*.md will be shown on the navigation bar. I deleted most of them and only kept _pages/about.md, cv.md, projects.md _news/ directory contains what will be shown on the homepage â€œnewsâ€ section. Do change those _sass/_themes.scss has a variable --global-theme-color controlling the theme of this site. I had 12--global-theme-color: #&#123;$cyan-color&#125;;--global-hover-color: #&#123;$light-cyan-color&#125;; In _config.yaml, we see that projects is listed under collections. This means we can build the following file structure, where we have _pages/projects.md to be displayed on the navigation bar as an entry point and projects/p1.md for a specific project. Find more about collections in README 123456_pages/â”œâ”€ projects.md - mywebsite.com/projects/projects/â”œâ”€ p1.md - mywebsite.com/projects/p1â”œâ”€ p2.md - mywebsite.com/projects/p2â”œâ”€ .... Integrating Hexo Blog into New Homepage Delete any blog-related feature that came along with al-folio: reference Delete all the example posts: rm -rf ./_posts/ Delete the template generating mywebsite.com/blog page: rm -rf ./blog/ Comment out the following entries under Jekyll Archives section and Blog section in _config.yml to make sure absolutely nothing is generated under mywebsite.com/blog address: (I was about to comment out everything, but it turns out this would break some content generation features, so after some experiments I found you only need to comment out the followings:) 1234567891011121314151617181920212223242526# -----------------------------------------------# Blog# -----------------------------------------------permalink: /blog/:year/:title/related_blog_posts: enabled: true max_related: 5# -----------------------------------------------# Jekyll Archives# -----------------------------------------------jekyll-archives: enabled: [year, tags, categories] # enables year, tag and category archives (remove if you need to disable one of them). layouts: year: archive-year tag: archive-tag category: archive-category permalinks: year: &quot;/blog/:year/&quot; tag: &quot;/blog/tag/:name/&quot; category: &quot;/blog/category/:name/&quot;display_tags: [&quot;formatting&quot;, &quot;images&quot;, &quot;links&quot;, &quot;math&quot;, &quot;code&quot;] # these tags will be displayed on the front page of your blogdisplay_categories: [&quot;blockquotes&quot;] # these categories will be displayed on the front page of your blog Set the blog entry on the navigation bar link to my actual blog address: set _config.yml blog_nav_title: to empty, so the al-folioâ€™s blog entry will not show on the navigation bar, reference 1, reference 2 Find in _includes/header.html the if statement &#123;% if site.blog_nav_title %&#125; go to the end of this if statement and add something: reference 123456789101112131415&#123;% if site.blog_nav_title %&#125;&lt;!-- Blog --&gt;&lt;!-- Empty here because blog_nav_title attribute is empty --&gt;&lt;li class=&quot;nav-item &#123;% if page.url contains &#x27;blog&#x27; %&#125;active&#123;% endif %&#125;&quot;&gt; &lt;a class=&quot;nav-link&quot; href=&quot;&#123;&#123; &#x27;/blog/&#x27; | relative_url &#125;&#125;&quot;&gt;&#123;&#123; site.blog_nav_title &#125;&#125; &#123;%- if page.url contains &#x27;blog&#x27; -%&#125; &lt;span class=&quot;sr-only&quot;&gt;(current)&lt;/span&gt; &#123;%- endif -%&#125; &lt;/a&gt;&lt;/li&gt;&#123;%- endif %&#125;&lt;!-- Actual Blog Takes Place Here --&gt;&lt;li class=&quot;nav-item&quot;&gt; &lt;a class=&quot;nav-link&quot; href=&quot;https://yao-lirong.github.io/blog/&quot;&gt;blog&lt;/a&gt;&lt;/li&gt; One thing really good about al-folio is that it allows including external blog posts. You can do this by adding the RSS feed in _config.yml: reference 123external_sources: - name: blog rss_url: https://yao-lirong.github.io/blog/atom.xml These external posts can also be displayed on your homepage if you set latest_posts: true in the front matter of _pages/about.md TBD how about sitemap? GA4 tags check do a photowall?","categories":[],"tags":[]},{"title":"Visual Information Theory","slug":"2024-01-21-Visual-Information-Theory","date":"2024-01-21T05:00:00.000Z","updated":"2025-09-02T23:24:43.202Z","comments":true,"path":"2024-01-21-Visual-Information-Theory/","permalink":"https://yao-lirong.github.io/blog/2024-01-21-Visual-Information-Theory/","excerpt":"This blog post is adapted from ex-OpenAI researcher, Anthropic co-founder Christopher Olahâ€™s wonderful work. I removed parts that are generally commonsense to a CS kid and added some of my own notes &amp; explanations.","text":"This blog post is adapted from ex-OpenAI researcher, Anthropic co-founder Christopher Olahâ€™s wonderful work. I removed parts that are generally commonsense to a CS kid and added some of my own notes &amp; explanations. Visualizing Probability Distribution The author did a really cool job visualizing probability distribution here, but doesnâ€™t provide any more knowledge than basic probability theory, so removed this part. Code I want to communicate with my friend Bob, so we establish a code, mapping each possible word we may say to sequences of bits. fixed length code However, Bob is a dog lover, with very high probability, he talks about dogs. Bobâ€™s word frequency Incorporating the code we defined above into this graph, we get the following diagram, with the vertical axis to visualize the probability of each word, p(x), and the horizontal axis to visualize the length of the corresponding codeword, L(x). Notice the total area is the expected length of a codeword we send. Expected length of fixed-length code Variable-Length Code Perhaps we could be very clever and make a variable-length code where codewords for common words are made especially short. The challenge is that thereâ€™s competition between codewords â€“ making some shorter forces us to make others longer. To minimize the message length, we especially want the commonly used ones to be. So the resulting code has shorter codewords for common words (like â€œdogâ€) and longer codewords for less common words (like â€œbirdâ€). Variable length code Looking at this code format with word frequency, on average, the length of a codeword is now 1.75 bits! Expected length of variable-length code It turns out that this code is the best possible code. There is no code which, for this word frequency distribution, will give us an average codeword length of less than 1.75 bits. There is simply a fundamental limit. Communicating what word was said, what event from this distribution occurred, requires us to communicate at least 1.75 bits on average. No matter how clever our code, itâ€™s impossible to get the average message length to be less. We call this fundamental limit the entropy of the distribution â€“ weâ€™ll discuss it in much more detail shortly. The Space of Codewords To make our codewords uniquely decodable, we want them to follow the prefix property: no codeword should be the prefix of another codeword. i.e. If we see a particular codeword, there shouldnâ€™t be some longer version that is also a codeword. Codes that obey this property are also called prefix codes. One useful way to think about this is that every codeword requires a sacrifice from the space of possible codewords. If we take the codeword 01, we lose the ability to use any codewords itâ€™s a prefix of. We canâ€™t use 010 or 011010110 anymore because of ambiguity â€“ theyâ€™re lost to us. The following graph shows we in effect lost $\\frac {1} {2^{L(01)}} = \\frac {1} {2^2} = \\frac {1} {4}$ of our codeword space. Code space sacrificed Since a quarter of all codewords start with 01, weâ€™ve sacrificed a quarter of all possible codewords. Thatâ€™s the price we pay in exchange for having one codeword thatâ€™s only 2 bits long! In turn this sacrifice means that all the other codewords need to be a bit longer. Thereâ€™s always this sort of trade off between the lengths of the different codewords. A short codeword requires you to sacrifice more of the space of possible codewords, preventing other codewords from being short. What we need to figure out is what the right trade off to make is! Cost of Codeword You can think of this like having a limited budget to spend on getting short codewords. In fact, we have a budget = 1 to spend, where 1 is the area of the whole codeword space. We pay for one codeword by sacrificing a fraction of possible codewords. We define the cost c of having a code word x with length L as $\\frac 1 {2^{L(x)}}$. The cost of buying a codeword of length 0 is 1, all possible codewords â€“ if you want to have a codeword of length 0, you canâ€™t have any other codeword. $x = \\emptyset, c = \\frac 1 {2^{L(\\emptyset)}} = \\frac 1 {2^0}$ The cost of a codeword of length 1, like â€œ0â€, is 1/2 because half of possible codewords start with â€œ0â€. $x = 0, c = \\frac 1 {2^{L(\"0\")}} = \\frac 1 {2^1}$ The cost of a codeword of length 2, like â€œ01â€, is 1/4 because a quarter of all possible codewords start with â€œ01â€ $x = 0, c = \\frac 1 {2^{L(\"01\")}} = \\frac 1 {2^2}$ â€¦ (ignore the gray area in the following graph, the function we plot is $\\frac 1 {2^L}$ and cost is the height) Code cost To make the calculation simpler, instead of base 2, we imagine we have the natural number e. It now is no longer a binary code, but a â€œnaturalâ€ code with the cost becomes $\\frac 1 {e^L}$. It is both the height and the gray area: $\\frac 1 {e^L} = \\int^\\infty_L \\frac 1 {e^L} \\; dL$ Optimal Encoding Recall the expected length of the codeword we pictured above, if we look at each codewordâ€™s contribution to this expected length, each codeword makes the average message length longer by its probability times the length of the codeword. For example, if we need to send a codeword that is 4 bits long 50% of the time, our average message length is 2 bits longer than it would be if we werenâ€™t sending that codeword. We can picture this as a rectangle. Contribution to expected length Now, we have two values related to the length of a codeword and we picture them together in the following graph: The amount we pay decides the length of the codeword: gray part decides the width of the purple rectangle The length of the codeword controls how much it adds to the average message length: width of the rec decides the area of the rec (height is fixed for a given word because height represents the word frequency) Contribution and cost Short codewords reduce the average message length but are expensive, while long codewords increase the average message length but are cheap. short vs long Whatâ€™s the best way to use our limited budget? Just like one wants to invest more in tools that one uses regularly, we want to spend more on frequently used codewords. Thereâ€™s one particularly natural way to do this: distribute our budget in proportion to how common an event is - c(x) = p(x). The following graph shows such encoding system. Additionally, thatâ€™s exactly what we did in our codes with Bob: â€œdogâ€ appears $\\frac 1 2$ of the time, so we give it codeword â€œ0â€ with the cost $c = \\frac 1 {2^{L(\"0\")}} = \\frac 1 {2^1}$; â€œbirdâ€ appears $\\frac 1 8$ of the time, so we give it codeword â€œ111â€ with the cost $c = \\frac 1 {2^{L(\"111\")}} = \\frac 1 {2^3}$; If an event only happens 1% of the time, we only spend 1% of our budget. Contribution and cost line up The author then proved it is the optimal thing to do. Honestly I didnâ€™t understand the proof, but this code system weâ€™re talking about here is no more than a general version of Huffman Encoding. So I guess itâ€™s fine as long as you understand how to prove the greedy Huffman Encoding is optimal. Calculating Entropy In the Cost of Codeword section, we defined the cost c of having a code word x with length L as $\\frac 1 {2^{L(x)}}$. By inverting this definition, given c, we can infer the length $L(x) = \\log_2 \\frac 1 c$ Furthermore, in the Optimal Encoding section, we proved the optimal cost to spend on each word is c(x) = p(x), so the length of the optimal encoding system is $L(x) = \\log_2 \\frac 1 {p(x)}$ Earlier, we said: given a probability distribution of what we want to communicate, there is a fundamental limit of expected code length we need to send no matter how smart our code is. This limit, the expected code length using the best possible code, is called the entropy of p: H(p). $$ H(p) = \\mathbb{E}_{p(x)} [L(x)] = \\sum_x p(x) \\log_2 \\frac 1 {p(x)} $$ People usually write entropy in the following way, which makes it much less intuitive. H(p) = âˆ’âˆ‘xp(x)log2p(x) The entropy, which by definition is the shortest possible code, has clear implications for compression. In addition, it describes how uncertain I am and gives a way to quantify information: If I knew for sure what was going to happen, I wouldnâ€™t have to send a message at all! p(x) = 1 âŸ¹ H(x) = 0 If thereâ€™s two things that could happen with 50% probability, I only need to send 1 bit. âˆ€xi, p(xi) = 0.5 âŸ¹ H(x) = 1 If thereâ€™s 64 different things that could happen with equal probability, Iâ€™d have to send 6 bits. $\\forall x_i, p(x_i) = \\frac 1 {64} \\implies H(x) = 6$ The more concentrated the probability, the more I can craft a clever code with short average messages. The more diffuse the probability, the longer my messages have to be. Cross Entropy Imagine now a cat-lover Alice talks about animals with the following word frequency: Alice loves cats When Alice sends a message to Bob using Bobâ€™s codes, her messages were longer than they needed to be. Bobâ€™s code was optimized to his probability distribution. Alice has a different probability distribution, and the code is suboptimal for it: the expected codeword length when Bob uses his own code is 1.75 bits, while when Alice uses his code itâ€™s 2.25. It would be worse if the two werenâ€™t so similar! The expected length of communicating an event from distribution q(x) with the optimal code for another distribution p(x) is called the cross-entropy. Formally, we define cross-entropy as: (people usually write H(q, p) instead) $$ H_p(q) = \\mathbb E_{q} \\log_2\\left(\\frac{1}{p(x)}\\right)= \\sum_x q(x)\\log_2\\left(\\frac{1}{p(x)}\\right) $$ To lower the cost of Alice sending message, I asked both of them to now use Aliceâ€™s coding, but this made it suboptimal for Bob and surprisingly, itâ€™s worse for Bob to use Aliceâ€™s code than for Alice to use his! Cross-entropy isnâ€™t symmetric. Bob using his own code (H(p) = 1.75 bits) Alice using Bobâ€™s code (Hp(q) = 2.25 bits) Alice using her own code (H(q) = 1.75 bits) Bob using Aliceâ€™s code (Hq(p) = 2.375 bits) In the following diagram, if the messages are coming from the same distribution the plots are beside each other, and if they use the same codes they are on top of each other. This allows you to kind of visually slide the distributions and codes together. 4 cases of cross entropy So why one is bigger than the other? This is because When Bob uses Aliceâ€™s code Hq(p), Bob says â€œdogâ€ with high probability but â€œdogâ€ is a word Alice happens to say the least so assigned longest length to. On the other hand for Hp(q), Bob didnâ€™t dislike â€œcatsâ€ that much, so didnâ€™t assign it with too big a word length. KL Divergence Cross-entropy gives us a way to express how different two probability distributions are. When using qâ€™s codewords for pâ€™s distribution, the more different the distributions p and q are, the bigger the difference is between cross-entropy of p with respect to q and the entropy of p. In math, Dq(p) = Hq(p) âˆ’ H(p) is bigger. H_q(p) Similarly when using pâ€™s codewords for qâ€™s distribution. H_p(q) The really interesting thing is the difference Dq(p). That difference is how much longer our messages are because we used a code optimized for a different distribution q. If the distributions are the same, this difference will be zero. As the difference grows, it will get bigger. This difference is the Kullbackâ€“Leibler divergence, or just the KL divergence. The really neat thing about KL divergence is that itâ€™s like a distance between two distributions. It measures how different they are! (If you take that idea seriously, you end up with information geometry) People usually write it as DLK(p||q), but our more intuitive way writes: Dq(p) = Hq(p) âˆ’ H(p) If you expand the definition of KL divergence, you get: $$ \\begin{align} D_q(p) &amp;= \\sum_x p(x)\\log_2\\left(\\frac{p(x)}{q(x)} \\right) \\\\ &amp;= \\sum_x p(x) \\left[ \\log_2\\left(\\frac{1}{q(x)} \\right) - \\log_2\\left(\\frac{1}{p(x)} \\right)\\right]\\\\ &amp;= \\sum_x p(x) \\left[ L_q(x) - L_p(x)\\right] \\end{align} $$ And we see the $\\log_2\\left(\\frac{p(x)}{q(x)} \\right)$ is simply the difference between how many bits a code optimized for q and a code optimized for p would use to represent x. The expression as a whole is the expected difference in how many bits the two codes would use Multiple Variables and Joint Entropy Letâ€™s return to our weather and clothing example from earlier. My mother, like many parents, worries that I donâ€™t dress appropriately for the weather. So, she often wants to know both the weather and what clothing Iâ€™m wearing. How many bits do I have to send her to communicate this? To send both pieces of information, we can flatten the probability distribution (calculate the joint probability) flattened probability Now we can figure out the optimal codewords for events of these probabilities and compute the average message length: joint word length Everything is the exact same as our normal definition, except with two variables instead of one. We call this the joint entropy of X and Y, defined as $$ H(X,Y) = \\mathbb E_{p(x,y)} \\log_2\\left(\\frac{1}{p(x,y)}\\right) = \\sum_{x,y} p(x,y) \\log_2\\left(\\frac{1}{p(x,y)}\\right) $$ Itâ€™s in fact more intuitive not to flatten it, but Instead to keep the 2 dimensional square and add word length as a 3rd dimension height. Now the entropy is the volume. 3D code length Conditional Entropy Suppose my mom already knows the weather. She can check it on the news. Now how much information do I need to provide? I actually need to send less, because the weather strongly implies what clothing Iâ€™ll wear! Conditional code length separated When itâ€™s sunny, I can use a special sunny-optimized code, and when itâ€™s raining I can use a raining optimized code. In both cases, I send less information than if I used a generic code for both. For example in case of raining, I send code length of 4 when I wear t-shirt and code length of 4/3 when I wear coat. $$ H(X \\mid \\text{Y = raining}) = \\frac 1 4 \\log_2 \\frac 1 4 + \\frac 3 4 \\log_2 \\frac 3 4 = 0.81 $$ (Donâ€™t worry for now why the entropy, representing length of an optimal codeword, can be fractional, we will explain it later) With a similar calculation, we show H(X âˆ£ Y = sunny) = 0.81. To get the average amount of information I need to send my mother, I just put these two cases together: $$ \\begin{align} H(X \\mid Y) &amp;= P(\\text{Y = rainy})\\,H(X \\mid \\text{Y = rainy})+ P(\\text{Y = sunny})\\,H(X \\mid \\text{Y = sunny}) \\\\ &amp;= \\frac 1 4 \\times 0.81 + \\frac 3 4 \\times 0.81 = 0.81 \\end{align} $$ Conditional code length together We call this the conditional entropy: $$ \\begin{align} H(X|Y) &amp;= \\sum_y p(y) H(X \\mid Y=y) \\\\ &amp;= \\sum_y p(y) \\sum_x p(x|y) \\log_2\\left(\\frac{1}{p(x|y)}\\right) \\\\ &amp;= \\sum_{x,y} p(x,y) \\log_2\\left(\\frac{1}{p(x|y)}\\right) \\end{align} $$ Mutual Information In the previous section, we observed that knowing one variable can mean that communicating another variable requires less information. One nice way to think about this is to imagine amounts of information as bars. These bars overlap if thereâ€™s shared information between them: some of the information in X and Y is shared between them, so H(X) and H(Y) are overlapping bars. And since H(X, Y) is the information in both, itâ€™s the union of the bars H(X) and H(Y). Multi-variate bar 1 We rank the information needed to communicate these 3 kinds of things in descending order: Both X and Y: joint entropy H(X, Y) X alone: marginal entropy H(X) X when Y is known: conditional entropy H(X|Y) Ranking information contained In the bar perspective, H(X|Y) is the information we need to send to communicate X to someone who already knows Y - it is the information in X which isnâ€™t also in Y. Visually, that means H(X|Y) is the part of H(X) bar which doesnâ€™t overlap with H(Y). Multi-variate bar 2 From this, we get another identity: the information in X and Y is the information in Y plus the information in X which is not in Y. (sounds like set, doesnâ€™t it?) H(X, Y) = H(Y) + H(X|Y) To wrap up, we have information in each variable: H(X) and H(Y) union of the information in both: H(X, Y) information in one but not the other: H(X|Y) and H(Y|X) We can further define mutual information: information both in X and Y, or in set terms, the intersection of information: I(X, Y) = H(X) + H(Y) âˆ’ H(X, Y) If you expand the definition of mutual information out, you get: $$ I(X,Y) = \\sum_{x,y} p(x,y) \\log_2\\left(\\frac{p(x,y)}{p(x)p(y)} \\right) $$ That looks suspiciously like KL divergence! Well, it is KL divergence. Itâ€™s the KL divergence of P(X, Y) and its naive approximation P(X)P(Y). That is, itâ€™s the number of bits you save representing X and Y if you understand the relationship between them instead of assuming theyâ€™re independent. and the variation of information. The variation of information is the information which isnâ€™t shared between the variables. It gives a metric of distance between different variables. The variation of information between two variables is zero if knowing the value of one tells you the value of the other and increases as they become more independent. V(X, Y) = H(X, Y) âˆ’ I(X, Y) How does this relate to KL divergence, which also gave us a notion of distance? Well, KL divergence gives us a distance between two distributions over the same variable or set of variables. In contrast, variation of information gives us distance between two jointly distributed variables. KL divergence is between distributions, variation of information within a distribution. In summary, we put them all in a single diagram: Multi-variate bar 3 Fractional Bits A careful reader may have noticed that in previous calculations, we had fractional length of message. Isnâ€™t that weird? How should we interpret such a message? How is it done in real life? The answer is: you can think of them as expected length of a message. If half the time one sends a single bit, and half the time one sends two bits, on average one sends one and a half bits. Thereâ€™s nothing strange about averages being fractional. Thatâ€™s a quick but vague answer. Letâ€™s look at an example: consider a probability distribution where one event a happens 71% of the time and another event b occurs 29% of the time. Fractional bit single The optimal code would use 0.5 bits to represent a, and 1.7 bits to represent b. Well, if we want to send a single one of these codewords, it simply isnâ€™t possible. Weâ€™re forced to round to a whole number of bits, and send on average 1 bit. â€¦ But if weâ€™re sending multiple messages at once, it turns out that we can do better. Letâ€™s consider communicating two events from this distribution. If we send them independently, using the code we established for a single event, weâ€™d need to send two bits. Can we do better? Fractional bit double Half the time, we need to communicate aa, 21% of the time we need to send ab or ba, and 8% of the time we need to communicate bb. Again, the ideal code involves fractional numbers of bits. Fractional bit double code length If we round the codeword lengths, weâ€™ll get something like this: Fractional bit double code length rounded This codes give us an average message length of 1.8 bits. Thatâ€™s less than the 2 bits when we send them independently. Another way of thinking of this is that weâ€™re sending 1.8/2 = 0.9 bits on average for each event. If we were to send more events at once, it would become smaller still. As n tends to infinity, the overhead due to rounding our code would vanish, and the number of bits per codeword would approach the entropy. Further, notice that the ideal codeword length for a was 0.5 bits, and the ideal codeword length for aa was 1 bit. Ideal codeword lengths add, even when theyâ€™re fractional! So, if we communicate a lot of events at once, the lengths will add. Conclusion Entropy is optimal length .. KL divergence .. Entropy over multiple variables can be interpreted as sets of information","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"Quantization","slug":"2023-12-01-Quantization","date":"2023-12-01T05:00:00.000Z","updated":"2025-09-02T23:51:12.130Z","comments":true,"path":"2023-12-01-Quantization/","permalink":"https://yao-lirong.github.io/blog/2023-12-01-Quantization/","excerpt":"","text":"K-bit Inference Scaling Laws This paper and its Appendix serves as a good summary of SOTA quantization techniques and their results. Why should we quantize? The overall computation latency â€“ the time it takes from start to finish of a computation â€“ is mainly determined by two factors: (1) how long does it take to load the data from main memory into caches and registers, (2) how long does it take to perform the computation. Therefore, reducing the time spent loading data from main memory is often the best way to accelerate overall computation latency. Such reductions can be achieved mainly through caching and lower precision numbers. Note though, to do computation, we dequantize the weight in the cache and perform a 16-bit floating point multiplication with the 16-bit input. Thatâ€™s because no CPU / GPU supports these weird data type computation. In this work, the author used blocking, a zero-shot quantization method, for 3, 4, 5, 6, 7, and 8 bits. By plotting out perplexity vs total bits of the model, they found that lowering the bit precision generally improves scaling. However, this trend stops across all models at 3-bit precision, where performance degrades. Therefore, 4-bit precision is optimal for almost all models at all scales, with few exceptions. BLOOM and BLOOMZ show almost the same quantization behavior, indicating that fine-tuning an existing model does not change its quantization properties. Data types: The quantile quantization and float data types provide better scaling than integer and dynamic exponent quantization. The author concluded that quantile quantization is the best. zero-shot quantization: directly quantize a model without any additional information. Can be used immediately, which makes them easy to use, but zero-shot quantization methods often fail at lower precisions. one-shot quantizationL need a mini-batch of data for quantization. more accurate, such as GPTQ, which optimizes the rounding during quantization via a mini-batch of data. But they are also more complex and may require hours of optimization before a model can be used. LLM.int8() In this quantization paper, the author discovered an emergent outlier feature in tranformers that totally wreck quantization. They also plotted a scaling law for this emergent outlier feature. By doing so, he proposed the LLM.int8() no-performance-degradation quantization method. I didnâ€™t read the paper, but looked at the authorâ€™s blog post instead. How Quantization works First, how do we quantize a number? Imagine the following example: you have a data type I5 with values [0, 1, 2, 3, 4, 5] and a data type I3 with values [0, 2, 4]. We want to quantize I5 vector [3, 1, 2, 3] to I3: map from original domain to unit domain [-1, 1] find absolute maximum 3 = max(abs([3, 1, 2, 3])), divide the vector by 3 to get [1.0, 0.33, 0.66, 1.0] map from unit domain [-1, 1] to quantized domain Multiply by the range of the target data type I3, which is 4: [1.0, 0.33, 0.66, 1.0] -&gt; [4.0, 1.33, 2.66, 4.0] round to the nearest representable number in this quantized domain [4.0, 1.33, 2.66, 4.0] -&gt; [4, 0, 2, 4] To dequantize, we reverse this process: map from quantized domain to unit domain [-1, 1] Divide the vector by range 4 to get [1.0, 0.0, 0.5, 1.0] map from unit domain [-1, 1] to original domain Multiply by the stored absolute maximum 3: [1.0, 0.0, 0.5, 1.0] -&gt; [3.0, 0.0, 1.5, 3.0] round to the nearest representable number in the original domain [3.0, 0.0, 1.5, 3.0] -&gt; [3, 0, 2, 3] We see that our dequantization and quantization led to one error at the second element. Emergent Outlier Features Since we are using the absolute, it is obvious that if we have an outlier, there will be more errors. So the authors go on to discover the distribution of outliers. They call such outliers emergent outlier features. The authors explain such outlier features as to select only a single feature. At the same time, the other small value part brings the unimportant values down. The authors also found this very interesting emergent phenomenom, which I directly quote below: However, this full â€œcoordinationâ€ through a single dimension only happens after the phase shift. Before the phase shift, in transformers with less than 6.7B parameters some layers disagree which dimension to use for these large features (no prominent outliers). â€¦ The phase shift happens around 6.7B, where 100% of layers use the same dimension for outliers. At this point, a couple of things happen rapidly: Transformers become more stable. If you treat the outlier features separately, I believe you can probably run and even train transformers in less than 8-bit precision without degradation in performance. Note the model perplexity rather than mere model size determines the phase shift. GGML MLabonne did a great explanation to how GGML did quantization. GGML quantizes weights in a rather naive way. Basically, it groups blocks of values and rounds them to a lower precision. Some techniques, like Q4_K_M and Q5_K_M, implement a higher precision for critical layers. In this case, every weight is stored in 4-bit precision, with the exception of half of the attention.wv and feed_forward.w2 tensors. Experimentally, this mixed precision proves to be a good tradeoff between accuracy and resource usage. If we look into the ggml-quants.h file, we can see how the blocks are defined. For example, the block_q4_0 structure is defined as: 12345#define QK4_0 32typedef struct &#123; ggml_fp16_t d; // delta uint8_t qs[QK4_0 / 2]; // nibbles / quants&#125; block_q4_0; In GGML, weights are processed in blocks, each consisting of 32 values. For each block, a scale factor (delta) is derived from the largest weight value. All weights in the block are then scaled, quantized, and packed efficiently for storage (nibbles). Oobabooga, the author of text generation webui, did an in-depth survey of inference time, model size, vRAM usage on different types of quantization formats (GPTQ, GGUF, EXL2, â€¦)","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"Fine-Tuning LLMs: Prompt Tuning, Adapter, LoRA","slug":"2023-11-20-Fine-Tuning-LLMs-Prompt-Tuning,-Adapter,-LoRA","date":"2023-11-20T05:00:00.000Z","updated":"2025-09-03T01:42:46.391Z","comments":true,"path":"2023-11-20-Fine-Tuning-LLMs-Prompt-Tuning,-Adapter,-LoRA/","permalink":"https://yao-lirong.github.io/blog/2023-11-20-Fine-Tuning-LLMs-Prompt-Tuning,-Adapter,-LoRA/","excerpt":"This article A Guid to Parameter-efficient Fine-tuning (PEFT) made a very good summary with nice drawings. There are some differences between its explanation with the original paper but the basic architecture is all good.","text":"This article A Guid to Parameter-efficient Fine-tuning (PEFT) made a very good summary with nice drawings. There are some differences between its explanation with the original paper but the basic architecture is all good. Prompt Tuning Prefix tuning, prompt tuning, and p-tuning all prepend some vectors as prefixes / soft prompts to the vector inputs to transformers. Their goal is to find a context that steers the language model toward generating text that solves a particular task. Adapter Before Adapter, when performing vanilla fine-tuning, a modification is made to the top layer of the network because the label spaces and losses for the upstream and downstream tasks differ. Now, Adapter modules perform more general architectural modifications to re-purpose a pretrained network for a downstream task: it injects new layers into the original network. In standard fine-tuning, the new top-layer and the original weights are co-trained. In contrast, in Adapter tuning, the parameters of the original network are frozen and therefore may be shared by many tasks. Adapter Architecture Left: We add the adapter module twice to each Transformer layer: after the projection following multiheaded attention and after the two feed-forward layers. Right: The adapter consists of a bottleneck which contains few parameters relative to the attention and feedforward layers in the original model. The adapter also contains a skip-connection. During adapter tuning, the green layers are trained on the downstream data, this includes the adapter, the layer normalization parameters, and the final classification layer Therefore, we can denote the Adapter layer as: y = B(Ïƒ(Ax)) + x Define bottleneck dimension r (to be consistent with LoRA, in the original Adapter paper, this was m), so $A \\in \\R^{r \\times d}, B \\in \\R^{d \\times r}$. Including biases, we add a total 2dr + d + r parameters with r â‰ª d. In initialization, we initialize the adapters to a near-identity function, so original network is unaffected when training starts. Adapter achieves similar results with only 1% needed parameters as compared to full fine-tuning. LoRA: Low-Rank Adaptation of LLM Before LoRA, SOTA techniques have some drawbacks: Adapter Layers Introduce Inference Latency: Adapter layers have few parameters, but â€œlarge neural networks rely on hardware parallelism to keep the latency low, and adapter layers have to be processed sequentially. This makes a difference in the online inference setting where the batch size is typically as small as one.â€ I actually donâ€™t understand how to parallelize an LLM inference even if without Adapter Directly Optimizing the Prompt is Hard: Prompt tuning and prefix tuning both require adding a prefix (to either the input vector or to the hidden vector in middle). In this way, it â€œreduces the sequence length available to process a downstream task, which we suspect makes tuning the prompt less performant compared to other methods.â€ Its performance changes non-monotonically in trainable parameters, too. So itâ€™s hard to optimize. LoRAâ€™s architecture is simply a matrix multiplication - Adapter without non-linearity or skip connection. So instead of y = B(Ïƒ(Ax)) + x, we do Î”y = BAx. There is one fundamental difference though: Adapter is an extra layer added into the original network, but LoRA is a layer added along side with the original network. Thatâ€™s why I have a delta in LoRAâ€™s formula. In fact, LoRA was specifically designed for low-rank matrix multiplication decomposition, note for any pretrained weight $W_0 \\in \\R^{d \\times k}$ with y = W0x and we want to update this weight matrix in fine-tuning: W = W0 + Î”W, we define Î”W = BA, so W = W0 + BA. This simple design yields a unimaginable good result: note matrix BA is also of dimension $\\R^{d \\times k}$. Therefore, we can directly add this result matrix to the original matrix and inferencing with LoRA, when we add this matrix in, gives us no additional inference latency. Similar to Adapter, LoRA uses a random Gaussian initialization for A and zero for B, so Î”Wx = BAx is zero at the beginning of training and W = W0 + Î”W yields the same result (identity) as before. Thanks to the matrix decomposition nature, we can apply LoRA to any matrix multiplication in principle. However, we found that in transformers, imagine if we have 8 ranks to distribute, when r(Wq) = r(Wv) = 4 or r(Wq) = r(Wk) = r(Wv) = r(Wo) = 2 gives best result. The author also found that the fine-tune matrix actually has a very low rank, so in practice even if we set r = 1 can give good enough results. Go to Section 7 for more interesting experiments they conducted. In diffusion models, we use LoRA on the stable diffusionâ€™s cross attention layer.","categories":[],"tags":[]},{"title":"Graph Networks & GraphCast","slug":"2023-11-16-Graph-Networks-&-GraphCast","date":"2023-11-16T05:00:00.000Z","updated":"2025-09-03T01:42:46.384Z","comments":true,"path":"2023-11-16-Graph-Networks-&-GraphCast/","permalink":"https://yao-lirong.github.io/blog/2023-11-16-Graph-Networks-&-GraphCast/","excerpt":"","text":"Graph Networks This is a very detailed and clear intro to Graph Networks by Deepmind. Graph Definition (Box 3 &amp; 3.2.1) We define a graph to have node, edge, and global attributes. Global attribute, u, for example can be the gravitational field in a three body problem setting. Global attribute is there to give a chance to any local node / edge to know whatâ€™s happening in a global perspective (mostly places far awy from it). If we exclude the global u (which aggregates information from across the nodes and edges), the information that a node has access to after m steps of propagation is determined by the set of nodes and edges that are at most m hops away (Figure 7). This can be interpreted as breaking down a complex computation into smaller elementary steps. Graph Update (3.2.2 &amp; 3.2.3 &amp; 4.2) Graph Network Algorithm The whole GN consists of the following 6 functions: $$ \\begin{array}{l} {\\mathbf{e}_{k}^{\\prime}=\\phi^{e}\\left(\\mathbf{e}_{k},\\mathbf{v}_{r_{k}},\\mathbf{v}_{s_{k}},\\mathbf{u}\\right)}\\\\ {\\mathbf{v}_{i}^{\\prime}=\\phi^{v}\\left({{\\bar{\\mathbf{e}}}}_{i}^{\\prime},\\mathbf{v}_{i},\\mathbf{u}\\right)}\\\\ {\\mathbf{u}^{\\prime}=\\phi^{u}\\left({\\bar{\\mathbf{e}}}^{\\prime},{\\bar{\\mathbf{v}}}^{\\prime},\\mathbf{u}\\right)} \\end{array} \\begin{array}{l} {\\bar{{\\mathbf{e}}}_{i}^{\\prime}=\\rho^{e\\to v}\\left(E_{i}^{\\prime}\\right)}\\\\ {\\bar{{\\mathbf{e}}}^{\\prime}=\\rho^{e\\to u}\\left(E^{\\prime}\\right)}\\\\ {\\bar{{\\mathbf{v}}}^{\\prime}=\\rho^{v\\to u}\\left(V^{\\prime}\\right)} \\end{array} $$ Ï•e is an edge specific function and is applied to every edge, same for node and global. Ï• can be any function, people usually use Neural Networks. On the other hand, Ï takes in a set as input, so needs to be an aggregate function invariant to permutations, like sum, mean, max, min, etc. These functions are not affected by the order they are sent in. Composing Multi Graph Block Architecture (4.3) A GN is simply three aggregate functions and three update functions for node, edge, global respectively. It always takes in a graph comprised of edge, node, and global attributes as input, and returning a graph comprised of edge, node, and global attribute. The GN operates on any graph without caring about size of the graph, so it is extremely easy to stack multiple GN block together. Figure 6 shows 3 commons ways of stacking GN blocks. Graph Networks Advantage (3.2.4) First, graphs can express arbitrary relationships among entities, so the way input interacts is not limited to a fixed model architecture. Graphs represent entities and their relations as sets, which are invariant to permutations. However, we can still impose ordering by encoding the indices in the node or edge attribute. A GNâ€™s per-edge and per-node functions are reused across all edges and nodes, respectively. Therefore, GN can easily operate on graphs of any size. Limitations (5.2) Notions like recursion, control flow, and conditional iteration are not straightforward to represent with graphs. GraphCast GraphCast by Deepmind is a perfect example to understand encode-process-decode GN structure and it is clearly written. Note the model architecture is inside the supplementary material. The following notes mostly come from Section3 GraphCast model. They defined two space for this task. One on the grid space based on earthâ€™s latitude and logitude, where the atmospheric information comes from. The other on a â€œmesh spaceâ€ based on a regular sphere, where the actual processing happens. The design was made on the observation that â€œUsing the latitude-longitude grid is not an advisable representation due to its spatial inhomogeneity, and high resolution at the poles which demands disproportionate compute resources.â€ Mesh Space As for the mesh space, it is not only 1 mesh space, but 7 mesh space layered together. The first mesh space (M0) is a regular icosahefron (12 nodes and 20 faces). The second (M1) is the first layer divided 6 times. The third (M2) is the second divided 6 times and so forth. The M0 layer is the base and the coarsest one. Among all layers, It has the fewest points and the greatest distance between each point. On the other hand, M6 layer has the finest resolution, most points, and each point is only a few units away from each other. When we update a particular point on the net, we look at each layer: M0, M1, â€¦, M6. For each layer Mi, we look at this pointâ€™s neighbor on this mesh and use these edges to update this pointâ€™s value. On M0, the neighbors are far away, so you get information from away. On M6, the neighbors are very close, so you get information from close points. This is exactly what depicted on paperâ€™s Fig1 e) - every point has input from different distance. Whatâ€™s most important is that since the finer resolution layer is obtained by dividing the coarser layer, every point and edge on the coarser layer can be directly found on the finer layer. Therefore, in memory we only have to store a single layer M6. You might ask what if a point on M6 is not originally on M0? Will it still have neighbors on M0 properly defined? Yes (I think), because you can think of the mesh construction process in reverse: if you start with an arbitrary point on the finest mesh and make the resolution coarser, you will always be able to get back to some regular icosahefron with the same strcuture as the M0 we started with (though not the exact same one because this point you started with might indeed not be on the M0 we built the multi-mesh upon). The encoder is a graph mapping grid nodes to mesh nodes. The processer happens on mesh nodes only. The decoder maps mesh nodes back to the grid nodes.","categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"}]},{"title":"First Time Debugging with ChatGPT","slug":"2023-04-04-First-Time-Debugging-with-ChatGPT","date":"2023-04-04T04:00:00.000Z","updated":"2025-09-03T01:42:46.391Z","comments":true,"path":"2023-04-04-First-Time-Debugging-with-ChatGPT/","permalink":"https://yao-lirong.github.io/blog/2023-04-04-First-Time-Debugging-with-ChatGPT/","excerpt":"I was trying out the sampling in MMM music generation model today and encountered the problem described in this issue I proposed. I have no experience writing C in python with ctypes, so I figured why not ask the magic conch shell ChatGPT?","text":"I was trying out the sampling in MMM music generation model today and encountered the problem described in this issue I proposed. I have no experience writing C in python with ctypes, so I figured why not ask the magic conch shell ChatGPT? Iâ€™ve asked him several â€œhow to write â€¦â€ questions since its release, but this was the first time I actually ask him to help me understand a snippet of code so I can proceed to debugging. It did pretty good in my first question, as it should do as the SOTA LLM model. q0 a0 What strikes me is the context-aware ability it showed in my second question. It is well known it can do so from all the demos, but seeing it actually work with a real example of your own is really a different story. Here, I just asked an absolutely arbitrary question and it knew what I was referring to q1 a1 It became mostly clear to me where the bug was, but to make sure q2 a2 q3 a3 At last, I conveniently asked it how to fix this bug q4 a4","categories":[],"tags":[{"name":"Journal","slug":"Journal","permalink":"https://yao-lirong.github.io/blog/tags/Journal/"}]},{"title":"2022 Web Journal","slug":"2022-12-31-2022-ç½‘ç»œæ—¥å¿—","date":"2022-12-31T05:00:00.000Z","updated":"2024-01-07T06:45:42.749Z","comments":true,"path":"2022-12-31-2022-ç½‘ç»œæ—¥å¿—/","permalink":"https://yao-lirong.github.io/blog/2022-12-31-2022-%E7%BD%91%E7%BB%9C%E6%97%A5%E5%BF%97/","excerpt":"","text":"â€œçŸ³è€äººâ€åå¡Œ å› å¸¸å¹´é£åŒ–ã€æµ·æ°´ä¾µèš€ï¼ŒåŠ ä¸Šå½“å¤©çš„é£é›¨é›·å‡»ï¼Œå±±ä¸œçœé’å²›å¸‚è‘—ååœ°æ ‡â€œçŸ³è€äººâ€æµ·èš€æŸ±åå¡Œï¼Œå®˜æ–¹ç§°å·²é‡‡å–ä¸´æ—¶æ€§ä¿æŠ¤æªæ–½ï¼Œä¿®å¤æ–¹æ¡ˆæ­£åœ¨è®ºè¯ã€‚ Tech - Tools VSCode Users can now type @lang:languageId in the Settings editor search box to view and edit all settings that can be configured for the language with ID languageId. This way, users can view language-specific settings, also known as language overrides. Keyboard shortcuts: ctrl + pgup and ctrl + pgdn to navigate between opened tabs ctrl + \\ go to pairing bracket (self-defined) Enable switching between terminal and editor 12&#123; &quot;key&quot;: &quot;ctrl+`&quot;, &quot;command&quot;: &quot;workbench.action.terminal.focus&quot;&#125;,&#123; &quot;key&quot;: &quot;ctrl+`&quot;, &quot;command&quot;: &quot;workbench.action.focusActiveEditorGroup&quot;, &quot;when&quot;: &quot;terminalFocus&quot;&#125; To jump by function with ctrl + uparrow and ctrl + downarrow, install extension â€œGo to Next/Previous Memberâ€ and change its setting to 12 &quot;gotoNextPreviousMember.symbolKinds&quot;: [&quot;interface&quot;, &quot;class&quot;, &quot;function&quot;, &quot;event&quot;, &quot;method&quot;, &quot;module&quot;, &quot;object&quot;, &quot;struct&quot;] Others A powerful spell that manipulates file names in shell: we want to extract the task ids from html files, which have this format like zz688732.html. Based on the task id, we construct filenames for output files, which have the format zult_688732.out. Finally, we move all these output files to directory results. 1ls zz*.html | grep 688 | sed -E &#x27;s/zz([0-9]+)\\.html/zult_\\1.out/&#x27; | xargs -n 1 -I &#x27;&#123;&#125;&#x27; mv &#x27;&#123;&#125;&#x27; ./results/ Find Out What Framework a Website Uses Markdown æ ‘å½¢ç›®å½•å¯è§†åŒ–ç”Ÿæˆå™¨ Draw your Latex Symbol: draw the symbol you are looking for into the square area above and the program will find all corresponding LaTeX commands. OneMark - Markdown in Onenote nbconvert: jupyter notebook built-in converter. It can convert ipynb file to html/markdown/LaTeX format and so on. 1jupyter nbconvert --to markdown lecture2.ipynb Solve Firefox reports â€œSecure Connection Failedâ€ when accessing YouTube: Kaspersky doing its job I guess Tech - Knowledge ä¸­æ–‡æ¡£æ¡ˆç¼–å†™æ’é›·æŒ‡å—: è®²è§£äº†å¼•å·ï¼Œç©ºæ ¼ï¼Œå…¨è§’åŠè§’ç¬¦å·ç­‰ä½¿ç”¨è§„èŒƒ Browser in the Browser Phishing Attack: The author introduces how to simulate a pop-up login window to maliciously acquire userâ€™s password. When use GitHub, use https to track remote branch. SSH works weird when you have multiple accounts on your local machine. Basic and extended regular expression: In short, ERE syntax is the regex that we are more familiar with, where where + ? () have special meanings. Hiding a photo inside another photo: by changing the least significant bit of every pixel point of the original photo to the photo we want to hide. When we reconstruct, simply extract all these least significant bits and put them back into a picture. This naive approach only works with square photos for now as it canâ€™t store metadata. It also becomes incomprehensible if go through compression like jpeg. Tech - Advances Microsoft Azure Text-to-Speech Engine: really amazing stuff, indistinguishable from real human voice The BRAIN Initiative: almost a whole brain simulation effort? Get Codex to Produce the Code You Want with Prompt Engineering: Software 3.0 is to design the prompt? FDA gives safety nod to â€˜no killâ€™ meat, bringing it closer to sale in the U.S.: Scientists â€œgrowâ€ meat: they extract cells from an animal, place them in tanks, feed them the nutrients, let them divide and reproduce, and end up with meat. Ruanyifeng 259 Glorious To View åº·å¥ˆå°”å¤©ä¸‹ç¬¬ä¸€ Glorious to View Where do Famous Cornell Alumni Live? Brain Collection Preserves Figures in History: Now on Uris 2nd floor. The most fascinating one is the Edward Rulloffâ€™ brain - a notorious murderer but claimed to have the 2nd largest brain ever found in human history Some very familiar melodies: Alma Mater, The Evening Song Virtual Tour to Cornell Teaching Dairy Barn, found in this CALS page Alright, so where does â€œCornell Note Takingâ€ come from? Hereâ€™s a post from Cornell Learning Strategy Center on â€œCornell Note Takingâ€ - it was really a thing. Cosmos, Johnson Museum of Art: my favorite view on campus Cornell Sesquicentennial Grove: never realized these benches have a name 1865 Society Wallpaper, Cornell Logo Digital Downloads, Schedule at Tour at Cornellâ€™s Particle Accelerator Haunted Stories at Cornell - A Halloween Video: talks about Morrill Hall dissection for Zoology, pumpkin mystery, sleeping founders at Sage Chapel, and other interesting ghost stories. #1 Subreddit Can somehow explain how meal plans arenâ€™t an absolute scam? Cornell kids doing the math :cloud_with_lightning: lightning strike on hill, context here ç”µæ¥ï¼ Daily Crime Log: try check this when youâ€™re really bored Dexter responded to a reddit post: both sides had a point To Do the Greatest Good 3D-printing robot enables sustainable construction: Random story reminds me of von Neumannâ€™s plan of using self-reproducing automata to colonize moon Smart thermostats inadvertently strain electric power grids Request a Purchase The following are the books I requested Cornell to purchase. æˆ¿æ€çªçš„åˆæˆ€æ¨‚åœ’ å æ˜Ÿæœ¯æ€äººé­”æ³• é¦–æ— Â·ä½œå´‡ä¹‹ç‰© ä¸‰å²”å£ Talks ä¸€å¸­ YiXi ææ¶µï¼šå°‘å¹´çš„ä½  7:00ï¼šã€Œé—®é¢˜å°‘å¹´ã€çš„ç¤¾ä¼šå·¥ä½œ æˆ‘è®¤ä¸ºé™ä½åˆ‘äº‹è´£ä»»å¹´é¾„è¡¨è¾¾äº†ä¸€ç§éœ€è¦ï¼Œè¿™ç§éœ€è¦æ˜¯ç‹¬ç«‹çš„å°‘å¹´å¸æ³•ä½“ç³»çš„éœ€è¦ï¼Œè€Œå¹¶ä¸ä»…ä»…æ˜¯çœŸçš„é™ä½å°±èƒ½è§£å†³çš„ã€‚æˆ‘ä»¬æŠŠåˆ‘äº‹è´£ä»»å¹´é¾„é™ä½åˆ°10å²åˆæ€ä¹ˆæ ·å‘¢ï¼Ÿä¸ä¼šæœ‰9å²çš„æœªæˆå¹´äººå®æ–½è¿æ³•çŠ¯ç½ªè¡Œä¸ºå—ï¼Ÿ èƒ¡ç«‹å¾·ï¼ˆDavid Huï¼‰ï¼šæµªè²»ç§‘å­¸å®¶ï¼šç±»ä¼¼åŸæ¥è®¢é˜…çš„å°å“¥ç™½å°¼æ‚å¿—é‡Œé¢å„ç§ä¹±ä¸ƒå…«ç³Ÿçš„ç ”ç©¶ï¼Œä½†å®é™…ä¸Šè¿™å¯èƒ½æ‰æ˜¯çœŸæ­£çš„ã€Œç”Ÿç‰©å­¦å®¶ã€ ç°åœ¨å¤§å¤šæ•°çš„ç”Ÿç‰©å­¦å®¶éƒ½åœ¨ç ”ç©¶ç»†èƒå’ŒåŸºå› ï¼ŒçœŸæ­£ç ”ç©¶åŠ¨ç‰©çš„äººè¶Šæ¥è¶Šå°‘äº† ä½•è¢œçš®ï¼šå°å€ä¿å®‰ï¼Œææ‡¼å’Œè¢«ææ‡¼çš„ï¼šä¸­å›½çš„å°åŒºä¸ºä»€ä¹ˆéœ€è¦ä¿å®‰ï¼Œä¿å®‰åˆ°åº•åœ¨å¹²ä»€ä¹ˆï¼Œä»¥åŠä»–ä»¬æ˜¯ä»€ä¹ˆæ ·çš„äºº æˆ‘ä»¬è¯´èµ·ææƒ§æ„Ÿï¼Œéƒ½ä¼šè®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªéå¸¸æ¶ˆæçš„ã€è´Ÿé¢çš„ã€è¢«åŠ¨çš„æƒ…ç»ªï¼Œå¤§å®¶éƒ½é¿ä¹‹ä¸åŠï¼Œä½†æ˜¯ä»ç†è®ºä¸Šè®²å®ƒå…¶å®ä¹Ÿå¯èƒ½æ˜¯ä¸€ç§æƒåˆ©ï¼Œå®ƒç”šè‡³æœ‰æ—¶å€™æ˜¯æœ‰åˆ©äºæŸäº›ç¾¤ä½“å†…éƒ¨çš„å›¢ç»“çš„ã€‚ å¾·å›½ç¤¾ä¼šå­¦å®¶è´å…‹å°±è¯´ï¼Œåœ¨ä¸€ä¸ªå¯¹ä¸Šå¸ã€é˜¶çº§ã€å›½å®¶å’Œè¿›æ­¥çš„ä¿¡ä»»å’Œä¿¡ä»°å·²åŸºæœ¬æ¶ˆå¤±çš„å¹´ä»£ï¼Œå…±åŒææƒ§å·²ç»è¢«è¯æ˜æ˜¯äººç±»ä»…å‰©çš„èƒ½é€šè¿‡çŸ›ç›¾æ¥åˆ¶é€ æ–°è”ç³»çš„èµ„æºäº†ã€‚ å¤§å®¶éƒ½çŸ¥é“ä¸­äº§é˜¶çº§å½¢æˆçš„æ—¶é—´å¾ˆçŸ­ï¼Œä»–ä»¬ä¹‹é—´å…±äº«çš„ä¸œè¥¿å¾ˆå°‘ï¼Œææƒ§æ„Ÿæ˜¯å°‘æ•°ä»–ä»¬èƒ½å¤Ÿå…±äº«çš„ä¸œè¥¿ä¹‹ä¸€ï¼Œç”šè‡³å¯ä»¥ç§°ä¹‹ä¸ºæ–‡åŒ–èµ„æœ¬ã€‚ä¸šä¸»ä¸å¤ªä¼šè¯´æˆ‘æƒ³è¦æ›´å¤šä¿å®‰æ˜¯å› ä¸ºæˆ‘æƒ³æŠ¬é«˜æˆ¿ä»·ï¼Œæˆ‘æƒ³ä½“ç°æˆ‘çš„èº«ä»½åœ°ä½ï¼Œä¸šä¸»åªä¼šè¯´æˆ‘æƒ³æ›´å¤šä¿å®‰æ˜¯å› ä¸ºæˆ‘è§‰å¾—ä¸å®‰å…¨ã€‚ ä»–ä»¬å…¶å®æ˜¯æŠŠè‡ªå·±æ”¾åœ¨äº†ä¸€ä¸ªè„†å¼±çš„ææƒ§çš„æ‹…å¿§çš„è§’è‰²å½“ä¸­ï¼Œå»åˆç†åŒ–è¿™æ ·ä¸€ç§ç‚«è€€æ€§æ¶ˆè´¹çš„éœ€æ±‚ã€‚ä½†è¿™ç§éœ€æ±‚å¹¶ä¸æ˜¯çœŸæ­£æºè‡ªäºå¯¹å°æ¦‚ç‡çŠ¯ç½ªçš„ä¸€ä¸ªææƒ§ï¼Œå¾ˆå¤§ç¨‹åº¦ä¸Šå®ƒæ˜¯æºäºåœ¨ä»Šå¤©è¿™æ ·ä¸€ä¸ªé«˜é€Ÿå‘å±•çš„æ—¶ä»£ï¼Œä»–å¯¹è‡ªèº«çš„ç»æµçŠ¶å†µå’Œç¤¾ä¼šåœ°ä½çš„æ²¡æœ‰å®‰å…¨æ„Ÿã€‚ æˆ‘å¦‚æœè·Ÿä¸šä¸»åä¸‹æ¥èŠææƒ§çš„è¯ï¼Œæˆ‘ä»¬å¯ä»¥èŠå¾ˆé•¿æ—¶é—´ï¼Œä»–ä»¬ä¼šè·Ÿæˆ‘è®²ï¼Œä»–ä»¬ä¼šå¾ˆå®³æ€•ç©ºæ°”æ±¡æŸ“ã€é£Ÿå“å®‰å…¨ã€ç¤¾åŒºçŠ¯ç½ªã€å°å­©æ‹å–ã€è½¬åŸºå› ç­‰ç­‰ã€‚å¦‚æœæˆ‘å»é—®ä¸€ä¸ªä¿å®‰ï¼Œä½ å®³æ€•ä»€ä¹ˆï¼Ÿæˆ‘é€šå¸¸æ˜¯å¾—ä¸åˆ°ç­”æ¡ˆçš„ã€‚ ä¿å®‰ä»¬ä¼¼ä¹ä»æ¥æ²¡æœ‰å‡†å¤‡å¥½è¦è¢«é—®è¿™æ ·ä¸€ä¸ªé—®é¢˜ï¼Œä¹Ÿå°±æ˜¯é»˜è®¤äº†ä»–ä»¬æ˜¯æ²¡æœ‰èµ„æ ¼ææƒ§çš„ã€‚ä½†æ˜¯æ¯ä¸ªäººéƒ½æœ‰ææƒ§ï¼Œææƒ§æ˜¯äººæ€§çš„ä¸€éƒ¨åˆ†ï¼Œå¦‚æœä½ å¦è®¤äº†ä¸€ä¸ªäººçš„ææƒ§ï¼Œå°±ç›¸å½“äºå¦è®¤äº†è¿™ä¸ªäººçš„äººæ€§ã€‚ å£°ä¸œå‡»è¥¿ èƒ½å½±å“ä¸€äº¿äººçš„ 1 ç§’åˆæ€æ ·ï¼Ÿ å¾ˆæœ‰æ´è§çš„èµ„æ·±å†…å®¹åˆ›ä½œè€…è°ˆè¯ã€‚è™½ç„¶ä»æŠ€æœ¯è‡ªç”±è§’åº¦æˆ‘ä¸å–œæ¬¢ä»–çš„å¤§éƒ¨åˆ†è§‚ç‚¹ï¼Œä½†æ˜¯æœ‰ä¸€ç‚¹éå¸¸å¯å–ï¼Œå°±æ˜¯ä»–æå‡ºæˆ‘ä»¬ç°åœ¨å•çº¯çš„ã€Œæµé‡ã€ï¼Œå³è§‚çœ‹æ—¶é•¿æ¥è¡¡é‡å†…å®¹ä»·å€¼å¤ªç‰‡é¢ï¼›éœ€è¦ç”¨ç«‹ä½“çš„ è§‚çœ‹é‡ Ã— è§‚çœ‹æ—¶é•¿ çš„è®¡é‡å•ä½å–ä»£ ç¾¤ä¼—åŸºç¡€å’Œé€šå¾€å¤ºå† ä¹‹è·¯ è®²ä¸­å›½å¥³è¶³æˆ–è€…æ›´å¹¿æ³›åˆ°è¶³çƒä»¥åŠæ•´ä¸ªå¤§ä½“è‚²çš„é—®é¢˜ã€‚15:38 å·¦å³è°ˆåˆ°æˆ‘ä»¬ç°åœ¨çš„ä½“è‚²å‘å±•æ˜¯ä¸€ä¸ªæ¶æ€§çš„å†…å¾ªç¯ï¼šè®­ç»ƒå¾ˆå¤šä½“è‚²ç”Ÿï¼Œä½†æ˜¯æœ€åèƒ½é å®ƒåƒé¥­çš„åªæœ‰ä¸€å°éƒ¨åˆ†äººï¼Œäºæ˜¯å¤§å¤šæ•°äººæŠ•å…¥äº†äººç”Ÿçš„é»„é‡‘æ—¶é—´æ— æ³•è¿›å…¥å›½å®¶é˜Ÿæˆä¸ºèŒä¸šè¿åŠ¨å‘˜ï¼Œåªèƒ½æœ€ç»ˆå»åšæ•™ç»ƒæˆ–è€…ä½“è‚²ç®¡ç†çš„ç›¸å…³èŒä¸šï¼Œè½¬å‹æ˜¯å¾ˆéš¾çš„ï¼Œæœ€ç»ˆå†ç”±è¿™äº›äººåŸ¹å…»æ–°çš„ä½“è‚²ç”Ÿã€‚å¯è§å¦‚æœé€‰æ‹©èµ°ä½“è‚²ï¼Œä½ çš„äººç”Ÿé“è·¯å¹¶ä¸æ˜¯è¶Šèµ°è¶Šå®½ï¼Œè€Œæ˜¯è¶Šèµ°è¶Šçª„çš„ã€‚ æˆ‘ä»¬ä¹ ä»¥ä¸ºå¸¸çš„å’Œå¹³ä¸ºä½•éš¾ä»¥é™ä¸´é˜¿å¯Œæ±—ï¼Ÿ åå‘å›½å®¶é€šè¿‡æ´åŠ©å‘å±•ï¼Œé¦–å…ˆéƒ½æ˜¯å¤–éƒ¨ä¸–ç•Œï¼ˆå‘è¾¾å›½å®¶ï¼‰æ‹‰åŠ¨ä¸€ä¸ªåŸå¸‚ï¼Œä½†æœ€ç»ˆç»“æœä¸å°½ç›¸åŒï¼š1.åŸå¸‚æˆåŠŸæ‹‰åŠ¨ä¹¡æ‘ï¼šå¦‚éŸ©å›½åŸå¸‚äººå£å æ€»äººå£ä¸€åŠï¼Œå¸¸å‘ç”Ÿåœ¨è§„æ¨¡å°çš„å›½å®¶ 2. ä¹¡æ‘æ‹‰å¹³åŸå¸‚ï¼šå¦‚å›½åœŸé¢ç§¯ç›¸æ¯”æ¥è¯´å·¨å¤§çš„è¶Šå—ã€Œè¥¿è´¡æ—¶åˆ»ã€ï¼ŒåŸå¸‚æ›´åƒæ˜¯ä¸€å—æ‚¬æµ®åœ¨è½åä¹¡æ‘ä¹‹ä¸Šçš„å…ˆè¿›é£åœ°ï¼Œæ²¡æœ‰åŠ›é‡æ‹‰åŠ¨ä¹¡æ‘ï¼Œæœ€ååŒ—è¶Šå°†å—è¶Šæ‹‰äº†ä¸‹æ¥ ä¼¯å†…æ–¯å’Œæ“çºµå¤§ä¼—æƒ…ç»ªçš„æ‰‹ We are the World æ˜å¤©ä¼šæ›´å¥½ â€œåŒå±‚â€å§é“ºåŠ¨è½¦ç»„æ˜¥è¿é¦–ç§€: å¤ªç‚«äº† å’±çš„é“è·¯æ–‡åŒ–åœ¨èµ„æºå…è®¸çš„æƒ…å†µä¸‹è¦æ˜¯èƒ½æ‰“æ—¥æœ¬å°±å¤ªå¥½äº† ã€Šå’¬æ–‡åš¼å­—ã€‹å†å¹´åå¤§æµè¡Œè¯­: çªç„¶æƒ³èµ·æ¥ã€Œè‡³äºä½ ä¿¡ä¸ä¿¡ï¼Œæˆ‘åæ­£ä¿¡äº†ã€‚ã€è¿™å¥åè¨€ï¼ŒæŸ¥äº†ä¸€ä¸‹åå’¬æ–‡åš¼å­—åŸæ¥ä¹Ÿæ˜¯æƒå¨ä¸”å¯“æ•™äºä¹çš„ä¸€æœ¬å°æœˆåˆŠï¼Œä»å†å¹´åå¤§æµè¡Œè¯­å¯ä»¥è¿½å¿†ä¸‹å¾€æ˜”ã€‚åŸé“¾æ¥å·²404ã€‚archive Doomsday Clock æœ«æ—¥æ—¶é’Ÿ è‘¡è„é‡‡æ‘˜å’Œæ¨±èŠ±ç››å¼€æ—¥æœŸè¯æ˜å…¨çƒå˜æš– African penguins endangered by shipping noise in Algoa Bay ä¸­æ–‡ç‰ˆ:å› èˆªè¿æ´»åŠ¨å™ªéŸ³ éæ´²ä¼é¹…æ¿’ä¸´ç­ç» â€œHunger Stoneâ€ Emerges With Grim Warning, last time a hunger stone emerges was just 4 years ago back in 2018 Critics and Fans Have Never Disagreed More About Movies: especially in those featuring Black people and women as the main characters. Woops :hushed: Cyberpunk 2077 å¤ªèµ›åšäº† Goodbye V, And Never Stop Fighting ä¸­å›½ç½‘æ°‘è§„æ¨¡è¶…10äº¿ å®é™…æ˜¯2021å¹´çš„æ–°é—»ï¼Œç¬¬ä¸€æ¬¡çœ‹åˆ°çš„æ—¶å€™æƒ³å¾—ä¸æ˜¯å¢é•¿å¾—å¥½å¿«ï¼Œè€Œæ˜¯è¿˜æœ‰4äº¿äººä¸ä½¿ç”¨äº’è”ç½‘ï¼Œä»–ä»¬åœ¨è¿™ä¸ªå»å“ªéƒ½è¦å¥åº·ç çš„æ—¶å€™æ€ä¹ˆç”Ÿå­˜å‘¢ï¼Ÿ Microsoft is testing ads in the Windows 11 File Explorer GitHub suspends accounts of Russian devs at sanctioned companies, original blog post mentioned here In parallel with our efforts to make sure GitHub is available to developers in all countries, we are continuing to ensure free open source services are available to all, including developers in Russia æ‚„æ‚„æ‹æ‘„è¡Œäººï¼Œç®—æ³•æŒ‡æŒ¥å‘˜å·¥ï¼šä¾¿åˆ©èœ‚çš„â€œç³»ç»Ÿâ€æ˜¯å¦è¶Šç•Œ Backup Archive è¿™æ˜¯ä¸€åœºé¢‡å…·ç§‘å¹»æ„å‘³çš„è¯•éªŒï¼Œä¸€å®¶åä¸ºä¾¿åˆ©èœ‚çš„è¿é”ç»è¥ä¾¿åˆ©åº—æ­£åœ¨ç ”å‘ä¸€å¥—ç®—æ³•ï¼Œä»é€‰å€ã€è®¢è´§ã€ç‰©æµã€é™ˆåˆ—ï¼Œç”šè‡³æ‰“æ‰«å«ç”Ÿï¼Œéƒ½äº¤ç»™â€œç³»ç»Ÿâ€å†³ç­–ã€‚ â€œç³»ç»Ÿâ€æ˜¯ä¾¿åˆ©èœ‚çš„å¤§è„‘ï¼Œé€šè¿‡ä¸€å°ç”µè„‘å‘åº—å‘˜ä»¬å‘å·æ–½ä»¤ï¼Œæ¯ä¸ªä»»åŠ¡éƒ½é™„æœ‰æä¸ºç»†è‡´çš„æ ‡å‡†æ“ä½œè§„èŒƒã€‚åº—é‡Œæœ‰æ‘„åƒå¤´å…¨æ–¹ä½æ— æ­»è§’è¦†ç›–ï¼Œå®ƒä»¬æ˜¯ç³»ç»Ÿçš„çœ¼ç›ï¼Œå®æ—¶ç›‘ç£ç€åº—å‘˜ä»¬ã€‚é€šè¿‡äººå·¥å’ŒAIè‡ªåŠ¨è¯†åˆ«åº—å†…çš„ç”»é¢ï¼Œä¸€æ—¦ä¸ç¬¦åˆè¦æ±‚ï¼Œä¾¿ä¼šè‡ªåŠ¨æŠ¥è­¦ã€‚ é¡¾å®¢ä»¬çš„ä¸€ä¸¾ä¸€åŠ¨ä¹Ÿä¼šè¢«æ”¶é›†èµ·æ¥ï¼Œæˆä¸ºç³»ç»Ÿçš„å†³ç­–ä¾æ®ã€‚è®©äººä¸å®‰çš„æ˜¯ï¼Œè¿™æ ·çš„æ‘„åƒå¤´ä»åº—å†…å»¶ä¼¸åˆ°äº†åº—å¤–ã€‚ä¸ºäº†å»ºç«‹ä¸€å¥—æ™ºèƒ½åŒ–çš„é€‰å€ç®—æ³•ï¼Œä¾¿åˆ©èœ‚æ­£åœ¨æ‚„æ‚„è¿›è¡Œä¸€åœºå¤§è§„æ¨¡çš„å…¬å…±å›¾åƒé‡‡é›†ã€‚ è‡ª2017å¹´èµ·ï¼Œåœ¨é•¿è¾¾äº”å¹´çš„æ—¶é—´é‡Œï¼Œä¾¿åˆ©èœ‚æ‹›å‹Ÿå¤§é‡ä¿¡æ¯é‡‡é›†å‘˜å°†æ‘„åƒå¤´æ‚„æ‚„åœ°æ”¾åœ¨äº†å¤šä¸ªåŸå¸‚çš„å±…æ°‘æ¥¼ã€å†™å­—æ¥¼ï¼Œç”šè‡³å›½å®¶æœºå…³çš„é—¨å£ï¼Œå®Œæ•´æ•æ‰ä¸‹å½“å¤©å‡ºå…¥çš„æ¯ä¸€ä¸ªäººã€‚æ¯ä¸€ä¸ªä¾¿åˆ©èœ‚çš„ç›®æ ‡åº—é“ºé™„è¿‘ï¼Œéƒ½ä¼šé­åˆ°ä¸€è½®å½•åƒã€‚ä¾¿åˆ©èœ‚åå°è‡³å°‘ç´¯ç§¯äº†æ•°åä¸‡æ¡æ‹æ‘„æ•°æ®ã€‚ ç§‘æŠ€çˆ±å¥½è€…å‘¨åˆŠï¼ˆç¬¬ 199 æœŸï¼‰ï¼šä¿„ç½—æ–¯çš„ HTTPS è¯ä¹¦é—®é¢˜ å¤«é£è€…ï¼Œå¤©åœ°ä¹‹æ°”ï¼Œæº¥ç•…è€Œè‡³ï¼Œä¸æ‹©è´µè´±é«˜ä¸‹è€ŒåŠ ç„‰ã€‚ å®ƒçš„æ„æ€æ˜¯ï¼Œå¤©åœ°é—´çš„é£ï¼Œæ— å·®åˆ«åœ°å¹æ‹‚ï¼Œä¸ä¼šå› ä¸ºè´µè´±é«˜ä¸‹ï¼Œè€Œæœ‰æ‰€ä¸åŒã€‚ æˆ‘ä¸€ç›´è®¤ä¸ºï¼Œäº’è”ç½‘æ˜¯ä¸­ç«‹çš„æŠ€æœ¯åŸºç¡€è®¾ç½®ï¼Œåº”è¯¥åƒé£ä¸€æ ·ï¼Œæ— å·®åˆ«åœ°å¹æ‹‚åˆ°æ¯ä¸ªäººï¼Œä¸åº”è¯¥åŒºåˆ†ç©·äººã€å¯Œäººã€åäººã€å¥½äººï¼Œäººäººéƒ½æœ‰æƒä½¿ç”¨äº’è”ç½‘ã€‚ ä¸€æ—¦å› ä¸ºæ”¿æ²»åŸå› åŠé”€ HTTPS è¯ä¹¦ï¼Œæˆ–è€…è®©ä¿„ç½—æ–¯æ–­ç½‘ï¼Œäº’è”ç½‘çš„ä¸­ç«‹æ€§å°±è¡ç„¶æ— å­˜ï¼Œä¸å†æ˜¯äººäººéƒ½å¯ä»¥ä½¿ç”¨çš„æŠ€æœ¯åŸºç¡€è®¾æ–½äº†ã€‚è¿™ç­‰äºæŠŠâ€äº’è”ç½‘æ­¦å™¨åŒ–â€ï¼Œåªè¦ä½ æ˜¯æˆ‘çœ¼ä¸­çš„æ¶æ£ï¼Œæˆ‘å°±ä¸åŒæ„ä½ ä½¿ç”¨äº’è”ç½‘ã€‚ å¼€äº†è¿™ç§å±é™©çš„å…ˆä¾‹ï¼ŒæŠŠäº’è”ç½‘å½“ä½œæ­¦å™¨ï¼Œäº’è”ç½‘ä»æ­¤å°±å˜æˆäº†å›½é˜²è®¾æ–½ã€‚å›½ä¸å›½ä¹‹é—´éƒ½æè‡ªå·±çš„è¯ä¹¦ã€è‡ªå·±çš„åŸŸåã€è‡ªå·±çš„å›½é™…ç½‘å…³ï¼Œä¸¥æ ¼åŒºåˆ†ç½‘ç»œå›½å¢ƒçº¿ã€‚äº’è”ç½‘åˆ›ç«‹æ—¶çš„å¼€æ”¾ã€è‡ªç”±ã€ç»Ÿä¸€ã€é€ ç¦äººç±»çš„æ¢¦æƒ³ï¼Œç°é£çƒŸç­ã€‚ Why Vivaldi will never create ThinkCoin When you strip away the hype, these virtual currencies have very real repercussions for people, society, and the environment. By creating our own cryptocurrency or supporting cryptocurrency-related features in the browser, we would be helping our users to participate in what is at best a gamble and at worst a scam. It would be unethical, plain and simple. Noisy: Random DNS, HTTP/S traffic noise generator - Y Combinator first he warned us: make sure you always use the -c flag if youâ€™re pinging something on the internet. This is to specify the count of pings sent out. If you didnâ€™t it would ping forever and generate too much traffic, and this useless noise would make you a â€œbad netizenâ€. He explained this and everything to us so kindly and with such sincerity it was like watching Fred Rodgers speak. Now we have to randomly barf noise onto the network to maybe have a better chance at some privacy. How did we let the internet become this awful? Musk Buying Twitter Is Not About Freedom of Speech Yes, Twitter will wind up with different rules, results and outcomesâ€”and it may be the better or worse for it. Along the way, some people will cheer, and others will jeer. But framing the discussion as a â€œfree speechâ€ issue is entirely disingenuous. This is simply a billionaire attempting to etch his world view into an algorithmâ€”even if he brands himself a swashbuckling digital freedom fighter. ç‹å±€ä¸“è®¿å›´æ£‹å›½æ‰‹æŸ¯æ´: å¶ç„¶YouTubeæ¨é€çš„è§†é¢‘ï¼Œ20åˆ†é’Ÿå……æ»¡ç€ç»æœ›çš„æ„Ÿè§‰ã€‚é˜è¿°è‡ªå·±æ‚²è§‚çš„åŸå› æ—¶ä»–è¯´æœºå™¨å­¦ä¸€ä¸ªæœˆå¯èƒ½æ•¢ä¸Šä¸€ä¸ªäººå­¦åå¹´ï¼Œå…¶å®è¿™å¯¹äºå¾ˆå¤šäººåœ¨å¹³å¸¸çš„å­¦ä¹ å·¥ä½œä¸­å¯èƒ½éƒ½æœ‰ä¸€æ ·çš„æ„Ÿè§‰ï¼šå¤©æ‰å­¦åŠå¹´é¡¶ä½ å››äº”å¹´ã€‚æŸ¯æ´åœ¨ä»¥å‰çš„å­¦ä¹ ä¸­å¿…ç„¶ä¹Ÿé‡åˆ°è¿‡è¿™ç§æƒ…å†µï¼Œæ€»å‘ç°æœ‰æ¯”è‡ªå·±èªæ˜æˆ–è€…åŠªåŠ›çš„ï¼Œä½†è‡ªå·±å†åŠªåŠ›è¶…è¿‡ä»–ä»¬å°±è¡Œäº†ï¼Œæ¯•ç«Ÿé¡¶å°–çš„äººæ™ºåŠ›å·®åˆ«éƒ½ä¸å¤§ã€‚ä½†è¿™æ¬¡æ›´åƒå­™æ‚Ÿç©ºå’Œå¦‚æ¥ä½›ä¸€æ ·ï¼Œä¸Šé¢æœ‰ä¸€ä¸ªè¢«ç”Ÿç‰©è§„å¾‹ä¸¥æ ¼è§„å®šçš„ä¸å¯è¶…è¶Šçš„å­˜åœ¨ï¼Œä¸€ä¸ªç­‹æ–—åä¸‡å…«åƒé‡Œä¹Ÿç¿»ä¸å‡ºå¦‚æ¥çš„äº”æŒ‡ï¼Œå°±ç®—ä½ å†æ€ä¹ˆç²¾è¿›è‡ªå·±ï¼Œå³ä½¿åˆ°ç™¾ä¸‡é‡Œåƒä¸‡é‡Œä¹Ÿä¸å¯èƒ½ï¼Œè¿™æ‰æ˜¯æœ€ç»æœ›çš„äº‹ã€‚ æˆ‘ä»¬èŒä¸šæ£‹æ‰‹æ˜¯éå¸¸å¤§çš„éœ‡æ’¼çš„ã€‚å› ä¸ºé‚£ä¸ªä¸‹æ³•ä»æ¥æ²¡æœ‰å‡ºç°è¿‡ï¼Œè¿‡å»è§‰å¾—è¿™æ˜¯è¦è¢«è€å¸ˆæ•™è®­çš„ã€‚æœ‰çš„ä¸‹æ³•æˆ‘ä»¬æƒ³éƒ½æ²¡æ•¢å»æƒ³è¿‡ï¼Œæ˜¯å®ƒè‡ªå·±åˆ›é€ çš„æ£‹ã€‚è¿™ç§æ„Ÿè§‰å…¶å®æ˜¯å¯¹æ–¹æ˜¯ä¸€ä¸ªç‰¹åˆ«é«˜å¤§çš„å·¨äººï¼Œå“ªæ€•ä½ è£…å†å¤šçš„æ­¦å™¨ï¼Œèš‚èšå“ªèƒ½æ’¼åŠ¨å¤§è±¡ï¼ŒçœŸçš„æ˜¯åŠ¨ä¸äº†ã€‚æˆ‘å½“æ—¶è§‰å¾—ï¼Œäººç±»çœŸæ˜¯å¯æ‚²å•Šï¼Œå°±è¿™æ ·è¢«è‡ªå·±åˆ›é€ çš„ä¸œè¥¿å‡»è´¥äº†ã€‚æ€ä¹ˆéƒ½èµ¢ä¸äº†è¿™ä¸ªä¸œè¥¿çš„å­˜åœ¨ã€‚ Is Social Media Training Us to Please a Machine? Though most of the article is cliche, this idea itself is very interesting. Content generators were used to please editors or reviewers, but now they have to please an algorithm. ä¸­æ–‡ç‰ˆï¼šç¤¾äº¤åª’ä½“æ˜¯å¦åœ¨è®­ç»ƒæˆ‘ä»¬å–æ‚¦æœºå™¨ï¼Ÿ å¹³å°ï¼šç°ä»£ç¤¾ä¼šçš„é¥è¿œå·«æœ¯: ã€Œå¹³å°ã€ï¼Œç®—æ³•é»‘ç®±ï¼Œæ— å½¢çš„å¤§æ‰‹ã€‚å¾ˆæœ‰æ„æ€çš„ä¸€ä¸ªå°æ—¶è°ˆè¯ï¼Œä¸ä¸Šæ–‡çš„å–æ‚¦ç®—æ³•æœ‰äº›ç›¸å…³ Did the Pandemic Normalize Employee-Monitoring Software? è®ºæ–‡å·¥å‚ç‹‚é€ å‡ 800 å¤šç¯‡ææ–™å­¦è®ºæ–‡: å‰‘æ¡¥æ™¶ä½“å­¦æ•°æ®ä¸­å¿ƒ çš„ç»“æ„æ•°æ®åº“å‘ç°ï¼Œè¿‘ 1000 ä¸ªæ™¶ä½“æ•°æ®ç»“æ„æ¡ç›®ï¼ˆæ¶‰åŠ810ç¯‡æ–‡ç« ï¼‰æ¶‰å«Œæ¥è‡ªä¸­å›½çš„è®ºæ–‡å·¥å‚ã€‚å› ä¸ºä¸­å›½åŒ»é™¢è¦æ±‚ï¼ŒåŒ»ç”Ÿåªæœ‰å‘è¡¨è®ºæ–‡æ‰èƒ½è¯„èŒç§°ï¼Œç»“æœå°±äº§ç”Ÿäº†è¿™äº›ä¸å­˜åœ¨çš„å°åˆ†å­ç»“æ„ã€‚ æ·±åœ³æŸå…¬å¸åœ¨æ¯ä¸ªå·¥ä½éƒ½è£…ä¸Šäº†ç›‘æ§ Give Up GitHub: The Time Has Come! Software Freedom Conservancy in response to GitHub announcing Copilot, which trained on FOSS softwareâ€™s code, as a commercial for-profit product. The ever-expanding job of preserving the internetâ€™s backpages: Internet Archive is on the brink of surpassing 100 petabytes and itâ€™s only getting harder to archive a webpage. Bypass paywall at archive.today Chinese Company Pirated VSCode: a very interesting one to read Wizz Air Charges Extra for Users with Ad-Blockers Danish Political Party Led by an AI Tim Cook says â€˜buy your mom an iPhoneâ€™ if you want RCS support in iMessage: ä½•ä¸é£Ÿè‚‰ç³œï¼Ÿ The people making money from just surfing the internet: Browser extension that sells your data directly to retail brands instead of Google. It gives you money in return. Northeastern University installed heat sensors under graduate student workersâ€™ desks: Northeaster be really have some thought here Generation Digital æ··è¿¹äºäº’è”ç½‘ è™šæ‹Ÿèº«ä»½ç”Ÿæˆ Generate a Random Name - éšæœºèº«ä»½ç”Ÿæˆ Fake Address, Random Address Generator - éšæœºèº«ä»½ç”Ÿæˆ Behind the Name - Random Name Generator Easy Random Name Picker - Random Name Generator ElfQrin - Fake Identity ID Random Name Generator Random User Generator åœ¨çº¿èº«ä»½è¯å·ç ç”Ÿæˆå™¨ ä¸­å›½å¤§é™†å†…åœ°å§“åã€èº«ä»½è¯å·ã€é“¶è¡Œå¡å·ç”Ÿæˆå™¨ åœ¨çº¿èº«ä»½è¯å·ç ç”Ÿæˆå™¨ airob0t/idcardgenerator èº«ä»½è¯å›¾ç‰‡ç”Ÿæˆå·¥å…· gh0stkey/RGPerson - éšæœºèº«ä»½ç”Ÿæˆè„šæœ¬ naozibuhao/idcard - èº«ä»½è¯ç”Ÿæˆå™¨ Just Delete Me - å‡èº«ä»½ç”Ÿæˆå™¨(è¿™ä¸ªç½‘ç«™çš„å›¾æ ‡,å¥½åƒåœ¨å“ªé‡Œçœ‹è¿‡ğŸ¤”) Fake Person/Name Generator | User Identity, Account and Profile Generator faker.js Fake Person/Name Generator Full Contact Information Generator My Fake Information Generator and Validator User Information Generator Articles å›¾ç‰‡ç”Ÿæˆ ä¼ªé€ äººåƒ Artbreeder Comixify This Waifu Does Not Exist - Gwern è™šæ‹ŸçŒ«å’ª Which Face is Real? SPADE Project Page Selfie2Anime Reflect.tech Gallery of AI Generated Faces | Generated.photos ãƒ”ã‚¯ã‚»ãƒ«ãƒŸãƒ¼ | ãƒ‰ãƒƒãƒˆçµµã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ PaddleGAN äººåƒç”Ÿæˆã€ç¼–è¾‘ã€èåˆã€åŠ¨ä½œè¿ç§» å›½äº§æµæ°“è½¯ä»¶å¿…é¡»ä½¿ç”¨æ—¶çš„è§£å†³æ–¹æ¡ˆ: Windows 7 Ultimate SP1 7601ï¼ˆè€æ¯›å­ã®lopatkin æ”¹è£…çš„ Windows 7 SP1 ä¼ä¸šç‰ˆç®€ä½“ä¸­æ–‡ç²¾ç®€ç‰ˆï¼‰ å®è£… TIM+å¾®ä¿¡åæ¶ˆè€— 1G å†…å­˜ï¼Œåˆ†é… 1.5G æ›¿ä»£ Typora: Typoraäºä»Šå¹´ä¸ƒæœˆå¼€å§‹å¼ºåˆ¶æ‰€æœ‰ç”¨æˆ·æ”¶è´¹ï¼Œè™½ç„¶æƒ³åˆ°äº†ç¦æ­¢è”ç½‘è¿™ç§æ–¹æ³•ä½†æ˜¯æ— æ•ˆï¼Œåæ¥æ‰çŸ¥é“æ˜¯å®ƒæ—©å‰åœ¨æ³¨å†Œè¡¨é‡Œå®‰äº†ä¸€ä¸ªæ—¥æœŸï¼Œæ‰€ä»¥ä¸ç®¡æˆ‘åˆ æ‰ Appdata\\Roaming é‡Œçš„æ•°æ®æˆ–è€…æ˜¯ç¦ç½‘éƒ½æ²¡ç”¨ã€‚äºæ˜¯å¼€å§‹æ‰¾æ›¿ä»£çš„ markdown editor: marktext: å‡ ä¹å®Œç¾çš„æ›¿ä»£å“ï¼Œä½†æ˜¯å¯¹äº front matter å’Œä¸€äº›å…¶ä»–è¯­æ³•çš„ç¼–è¾‘å¾ˆå¥‡æ€ªï¼Œæ— æ³•åšåˆ°æ‰€è§å³æ‰€å¾—ã€‚å¼€å‘è€…å¯¹äºè¿™ä¸ªé¡¹ç›®å‡ ä¹æ˜¯æ”¾å…»çš„çŠ¶æ€ï¼Œopen issueä¸Šåƒï¼Œæ‰€ä»¥æˆ‘è§‰å¾—è¿™é—®é¢˜æ°¸è¿œä¹Ÿè§£å†³ä¸äº†äº†ï¼Œä¸è¿‡ä¹Ÿæ˜¯å¤§ FOSS è½¯ä»¶çš„é€šç—…ã€‚è¿˜æœ‰ä¸€ä¸ªå°é—®é¢˜æ˜¯è¿™è½¯ä»¶åˆæ˜¯ electron æ¶æ„çš„ï¼Œå¤ªæ¶å¿ƒäººäº†ã€‚ abricotine: æ›´è½»é‡çš„æ›¿ä»£å“ï¼Œå°±æ˜¯æ¸²æŸ“é£æ ¼æ¯”è¾ƒç®€é™‹ä¸å¤ªå–œæ¬¢ Zettlr: æ¯”èµ·ç¼–è¾‘æ›´ä¾§é‡äºç¬”è®°æ•´ç†ï¼Œæœ€å¤§å¥½å¤„æ˜¯å¯ä»¥è‡ªå®šä¹‰æ–°å»ºæ–‡ä»¶çš„æ–‡ä»¶åä¿å­˜æ ¼å¼ã€‚å› ä¸ºæ˜¯ç¬”è®°æ•´ç†è½¯ä»¶æ‰€ä»¥ä¹Ÿæ›´é‡ä¸€ç‚¹ï¼Œä½“ç§¯æ¯” marktext å°ï¼Œå†…å­˜å ç”¨ä¸‰ä¸ªæœ€å¤§ã€‚ æœ€ç»ˆç»•äº†ä¸€åœˆç”¨çš„è¿˜æ˜¯ Typora çš„å­¦ä¹ ç‰ˆï¼Œå…¶å®ä¸æƒ³è¿™æ ·åšçš„ï¼Œä¸»è¦æ˜¯ç”µè„‘ä¸Šå¤§éƒ¨åˆ† md æ–‡ä»¶å·²ç»ä¿å­˜ä¸º Typora é»˜è®¤çš„ %date-%title.md çš„æ ¼å¼ï¼Œå†æ›´æ”¹å¤ªéº»çƒ¦ã€‚ Download Abema TV Videos InControl: Easily manage Windows 10 and 11 out-of-control updating and upgrading Windows 11 Classic Context Menu v1.1 Privacy Redirect: A web extension that redirects Twitter, YouTube, Instagram, Google Maps, Reddit, Google Search &amp; Google Translate requests to privacy friendly alternative frontends Copy Files: use teracopy for stability, use fastcopy for speed. Also teracopy can directly replaces windows copy hotkeys &amp; drag drop, so use teracopy in general. Quote How to Stop Worrying and Learn to Love the Internet, from Douglas Adams, also collected in The Salmon of Doubt everything thatâ€™s already in the world when youâ€™re born is just normal anything that gets invented between then and before you turn thirty is incredibly exciting and creative and with any luck you can make a career out of it anything that gets invented after youâ€™re thirty is against the natural order of things and the beginning of the end of civilization as we know it until itâ€™s been around for about ten years when it gradually turns out to be alright really. David Hilbertâ€™s Radio Address For us there is no ignorabimus. Wir mÃ¼ssen wissen, Wir werden wissen. Are you optimistic about the free software movement? - Richard Stallman I am a pessimist by nature. Many people can only keep on fighting when they expect to win. Iâ€™m not like that, I always expect to lose. I fight anyway, and sometimes I win. Remarks by President Biden Before Meeting with the White House Competition Council - Joe Biden, 46th President of the United States No, itâ€™s a great asset. More inflation. What a stupid son of a bitch. A meeting with Enrico Fermi â€œThere are two ways of doing calculations in theoretical physicsâ€, he said. â€œOne way, and this is the way I prefer, is to have a clear physical picture of the process that you are calculating. The other way is to have a precise and self-consistent mathematical formalism. You have neither.â€ In desperation I asked Fermi whether he was not impressed by the agreement between our calculated numbers and his measured numbers. He replied, â€œHow many arbitrary parameters did you use for your calculations?â€ I thought for a moment about our cut-off procedures and said, â€œFour.â€ He said, â€œI remember my friend Johnny von Neumann used to say, with four parameters I can fit an elephant, and with five I can make him wiggle his trunk.â€ Your Map is Wrong, Mark Zuckerberg on Web 2.0 Summit (2010/11) Your map is wrong. The biggest part of the map has to be uncharted territory. This map makes it seem like itâ€™s zero-sum, but itâ€™s not. Weâ€™re building value, not just taking it away from someone else. the not yet lizard Zuck A friend who had just finished his PhD Donâ€™t squander your ignorance. Once you learn something, you end up taking it for granted and it becomes so much harder to overcome your tacit knowledge and ask simple, but important, questions. Why Craigslist Still Looks the Same After 25+ Years: Solidot Because that serves people better. Iâ€™ve learned that people want stuff that is simple and fast and gets the job done. People donâ€™t need fancy stuff. Sometimes you just want to get through the day. For me as an engineer, simple is beautiful. Functional is beautiful. Prospect è§‚å¤©ä¸‹ Why Chicago Is Lighting Its Railroads on Fire Emergent City Flyby with Colossus: just some arbitrary dots when see in still, but it becomes cities when see in motion. Ascent, worldâ€™s tallest timber building å˜Ÿå˜Ÿå®è´ é™ˆæ€¡é¦¨ Archive: æˆ‘å„ç§ Archive ä¹Ÿçœ‹è¿‡ä¸€äº›ï¼Œä½†æ˜¯è¿™ä¹ˆå®Œæ•´ç²¾ç¾çš„çœŸæ˜¯å¤´ä¸€æ¬¡è§ã€‚æœ€éš¾èƒ½å¯è´µçš„æ˜¯æœ¬ç½‘ç«™çš„å…³äºé¡µå’Œ GitHub ä¸­ Readme å†™å¾—ç‰¹åˆ«è¯¦ç»†ï¼Œä½œè€…ä¸€å®šä¹Ÿæ˜¯ä¸ªéå¸¸å¿ƒç»†å–„è‰¯çš„äººã€‚ï¼ˆåœ¨å†™ä¸‹ä¸Šé¢ä¸€æ®µæ–‡å­—åæˆ‘æ‰‹è´±å»çœ‹äº†ä¸€ä¸‹ï¼Œä½œè€…æ˜¯ä¸ªæ™®æ—çš„é«˜èƒ½ç‰©ç†åšå£«ï¼Œæ–¯å¦ç¦çš„æœ¬ç§‘â€¦è¡Œå§ï¼Œæœç„¶æ˜¯è¿™ç§äººâ€¦â€¦æˆ‘è¯¥è¯´æƒŠè®¶å‘¢è¿˜æ˜¯æ¯«ä¸æƒŠè®¶å‘¢ï¼‰ Others æ‚ä¸ƒæ‚å…« ã€Šå¡å°”è¾¾ä¼ è¯´æ—¶ä¹‹ç¬›ã€‹PC ç§»æ¤ç‰ˆå‡†å¤‡ä¸‹ä¸ªæœˆå‘å¸ƒ: å®Œæ•´çš„æ—¶ä¹‹ç¬›åç¼–è¯‘ The rise of performative work - the Economist, more like College Classroom 101(Bypass paywall at http://archive.today/RJQQX) Satya Nadella, the boss of Microsoft, says that comments in chat help him to meet colleagues he would not otherwise hear from. Maybe so, but that is an irresistible incentive to pose questions that do not need answering and offer observations that are not worth making. ä¸ºè¯­è¨€å¤šæ ·æ€§ç°è±¡ç‚¹ç¯ä¹‹ä½œâ€”â€”ã€Šã€ˆå½¹å‰²èªã€‰å°è¾å…¸ã€‹è¯»åæ„Ÿï¼šä»æ–‡å­—å±‚é¢ä¿æŠ¤è¯­éŸ³è¯­è°ƒå±‚é¢çš„ã€Œå½¹å‰²èªã€ï¼Œæˆ–è€…è¯´æ–¹è¨€ ä»¥ä¸Šæµ·ä¸ºä¸»é¢˜çš„è§†é¢‘åˆ›ä½œè€…Gåƒ§ä¸œåœ¨ä¸å°‘è§†é¢‘é‡Œæå€¡è¦è®¤è¯†ä¸Šæµ·æ–¹è¨€é‡Œçš„æ­£å­—ï¼Œå³é‚£äº›æ™®é€šè¯ä¸­ä¸å¸¸å¬ã€ä¸å¸¸è§ä½†é¢‘é¢‘å‡ºç°åœ¨æ–¹è¨€å£å¤´è¡¨è¿°ä¸­çš„è¯æ‰€å¯¹åº”çš„æ±‰å­—ã€‚æˆ‘è§‰å¾—è¿™æ˜¯ä¸€ä¸ªæœ‰ç›Šçš„æè®®ï¼Œæ‰¾å‡ºäº†æ–¹è¨€é‡Œçš„æ­£å­—ï¼Œä¾¿æœ‰åŠ©äºæ¢ç´¢å…¶ä¼ æ’­å’Œæ¼”å˜çš„è¿‡ç¨‹ï¼ŒåŠå…¶æ‰€è±¡å¾çš„äººç¾¤å½¢è±¡ã€‚è€Œè¿™äº›è€ƒå¯Ÿå°±å¦‚åŒæœ¬ä¹¦ã€Šã€ˆå½¹å‰²èªã€‰å°è¾å…¸ã€‹æ‰€æåˆ°çš„é‚£æ ·ï¼Œä¼šåè¿‡æ¥è¢«è¿ç”¨åˆ°æ›´å¤šä½œå“çš„åˆ›ä½œä¸­ï¼Œå½¢æˆä¸€ä¸ªä¸ªå›ºå®šçš„è§’è‰²å½¢è±¡ç”¨è¯ï¼Œä¸ºè¯­è¨€çš„ä¸°å¯Œå’Œå¤šæ ·æ€§æ³¨å…¥æ´»åŠ›ã€‚ èƒ¡èåœå‘¨å› ä¸€æ°§åŒ–ç¢³ä¸­æ¯’è€Œæ„å¤–èº«äº¡ ä¸€è·¯èµ°å¥½ End of Life of Captura: å¶ç„¶æ‰¾åˆ°çš„å®ç”¨å½•å±è½¯ä»¶ï¼Œä½†æ˜¯ç”±äºå¯è€»çš„å°†å¼€æºè½¯ä»¶å¥—å£³æ”¶è´¹è¡Œä¸ºï¼Œä½œè€…é€‰æ‹©äº†åœæ­¢æ›´æ–° ç‹å· - èŒå¨˜ç™¾ç§‘: ä»€ä¹ˆç»å¯¹çš„å…­è¾¹å½¢æˆ˜å£«ï¼Œæœå®ç‰¹æ”»çŒªçŒªä¾ çš„ç¼–å‰§å¯¼æ¼”é…éŸ³æ›²è¯3Då¼•æ“å¼€å‘åŠ¨ç”»åˆ¶ä½œï¼Œå…¨ä½ ä¸€ä¸ªäººå•Šï¼Ÿï¼","categories":[],"tags":[{"name":"Journal","slug":"Journal","permalink":"https://yao-lirong.github.io/blog/tags/Journal/"}]},{"title":"è§¦ä¹ & RPG Codex: RPGæ–‡æœ¬å†™ä½œè®¨è®º","slug":"2022-11-01-è§¦ä¹-&-RPG-Codex-RPGæ–‡æœ¬å†™ä½œè®¨è®º","date":"2022-11-01T04:00:00.000Z","updated":"2025-09-03T00:06:15.566Z","comments":true,"path":"2022-11-01-è§¦ä¹-&-RPG-Codex-RPGæ–‡æœ¬å†™ä½œè®¨è®º/","permalink":"https://yao-lirong.github.io/blog/2022-11-01-%E8%A7%A6%E4%B9%90-&-RPG-Codex-RPG%E6%96%87%E6%9C%AC%E5%86%99%E4%BD%9C%E8%AE%A8%E8%AE%BA/","excerpt":"æœ¬æ–‡æ˜¯å¯¹è§¦ä¹ç¿»è¯‘çš„åŸè½½äºRPG Codexçš„ä¸€ç¯‡æ–‡ç« çš„æ‘˜æŠ„ã€‚ä½œè€…ä¸»è¦å–·äº†ç°ä»£RPGå­˜åœ¨çš„å‡ ä¸ªé—®é¢˜ï¼Œç¯‡å¹…è¿‡é•¿è§¦ä¹å°†å…¶åˆ†ä¸º 1. æ€æ ·é¿å…â€œå¥‡å¹»ç—…â€ï¼Ÿ 2. åˆ›ä½œè€…çš„æ°´å¹³é—®é¢˜ 3. æ€æ ·æ‰æ˜¯åˆæ ¼çš„â€œæ¸¸æˆæ–‡æœ¬â€ï¼Ÿ 4. ä½™è®ºå’Œç»“è®º å››ä¸ªéƒ¨åˆ†","text":"æœ¬æ–‡æ˜¯å¯¹è§¦ä¹ç¿»è¯‘çš„åŸè½½äºRPG Codexçš„ä¸€ç¯‡æ–‡ç« çš„æ‘˜æŠ„ã€‚ä½œè€…ä¸»è¦å–·äº†ç°ä»£RPGå­˜åœ¨çš„å‡ ä¸ªé—®é¢˜ï¼Œç¯‡å¹…è¿‡é•¿è§¦ä¹å°†å…¶åˆ†ä¸º 1. æ€æ ·é¿å…â€œå¥‡å¹»ç—…â€ï¼Ÿ 2. åˆ›ä½œè€…çš„æ°´å¹³é—®é¢˜ 3. æ€æ ·æ‰æ˜¯åˆæ ¼çš„â€œæ¸¸æˆæ–‡æœ¬â€ï¼Ÿ 4. ä½™è®ºå’Œç»“è®º å››ä¸ªéƒ¨åˆ† æˆ‘ä¹Ÿä¸çŸ¥é“ä¸ºä»€ä¹ˆè¿™ç§è¶…é•¿æ–‡æˆ‘ç«Ÿç„¶ä»å¤´çœ‹åˆ°å°¾è¿˜æ‘˜æŠ„äº†ï¼Œå…¨æ–‡éƒ½æ˜¯ä½œè€…çš„ä¸»è§‚è§‚ç‚¹ï¼Œä½†æ˜¯æˆ‘ç«Ÿç„¶éƒ½å¾ˆè®¤åŒã€‚åŸæ¥æ˜¯å‡†å¤‡æ”¾åœ¨ç½‘ç»œæ—¥å¿—é‡Œé¢çš„ï¼Œä½†æ˜¯è¿™ä¸ªBæ˜¯è¿™èƒ½å†™ï¼Œå–·äº†å¥½å‡ å¼ çº¸ï¼Œå¯¼è‡´æ‘˜æŠ„ç¯‡å¹…ä¹Ÿå¾ˆé•¿ã€‚ä½œè€…ä¸»è¦è®¨è®ºäº†å¦‚ä¸‹å‡ ä¸ªé—®é¢˜ï¼Œç¬¬ä¸‰ç‚¹åª’ä»‹åŠ›é‡æˆ‘æ˜¯å®Œå…¨åŒæ„çš„ï¼Œä¸€äºŒéƒ¨åˆ†åŒæ„ã€‚ å¯¹æ¸¸æˆè®¾å®šèƒŒæ™¯çŸ¥è¯†çš„è¿‡åº¦å±•ç°ä»¥åŠè¿‡åº¦æè¿°: è¿‡åº¦è¯¦ç»†çš„èƒŒæ™¯æ•…äº‹æ‘§æ¯äº†æ•…äº‹çš„ç¥ç§˜æ„Ÿï¼Œå‰¥å¤ºäº†ç©å®¶çš„æƒ³è±¡ç©ºé—´ã€‚ åœ¨æ—§ä¸‰éƒ¨æ›²ç”µå½±ä¸­ï¼Œæ¯å½“è¾¾æ–¯Â·ç»´è¾¾è°ˆåŠâ€œæ˜Ÿé™…é­”æ³•â€æ—¶ï¼Œä»–é€šå¸¸éƒ½ä¼šæ•…æ„ä½¿ç”¨ä¸€äº›è¯­ä¹‰æ¨¡ç³Šçš„â€œå¤§è¯â€ã€‚æ¯”å¦‚ä»–æåŠæ­»æ˜Ÿæ—¶ä¼šè¯´ï¼Œâ€œæ²¡æœ‰ä¸œè¥¿èƒ½å’ŒåŸåŠ›ç›¸æ¯”â€ã€‚ä¸ºä»€ä¹ˆï¼Ÿâ€œå› ä¸ºä½ ä¸çŸ¥é“é»‘æš—é¢çš„åŠ›é‡ã€‚â€ä½ éœ€è¦çŸ¥é“çš„å°±æ˜¯è¿™ä¹ˆå¤šäº†ã€‚â€œæ˜Ÿé™…é­”æ³•â€å¼ºå¤§åˆç¥ç§˜ï¼Œéå¸¸ç‰›Ã—ã€‚è¿™å°±å¤Ÿäº†ã€‚ä¸ä¹‹ç›¸åçš„æ˜¯ï¼Œåœ¨ã€Šæ˜Ÿçƒå¤§æˆ˜å‰ä¼ 1ï¼šå¹½çµçš„å¨èƒã€‹å½“ä¸­ï¼ŒåŸåŠ›è¿™ç§ç¥ç§˜åŠ›é‡çš„è¿ä½¿æ°´å¹³æœ€ç»ˆå¾—åˆ°äº†è§£é‡Šâ€”â€”å®ƒå–å†³äºä¸€ä¸ªäººèº«ä½“é‡Œçº¤åŸä½“æ•°é‡çš„å¤šå°‘ã€‚é‚£ä¹ˆï¼Œè¿™ä¸ªè§£é‡Šæœ‰å¿…è¦ä¹ˆï¼Ÿæœ‰äº†è¿™ä¸ªè§£é‡Šä¹‹åï¼Œâ€œæ˜Ÿçƒå¤§æˆ˜â€ä¸–ç•Œå°±å˜å¾—æ›´é…·äº†ä¹ˆï¼Ÿ å¹¶ä¸”æœ‰æ—¶ä½œè€…å¯ä»¥ä½¿ç”¨åœºæ™¯åŠ¨ä½œç­‰æè¿°ï¼Œä½†æ˜¯å´é€‰æ‹©äº†æ–‡å­—ï¼Œæ²¡æœ‰åˆ©ç”¨æ¸¸æˆè¿™ä¸ªåª’ä»‹ã€‚ åŒæ ·çš„çŸ›ç›¾è¿˜å‘ç”Ÿåœ¨é‚£äº›å…´è‡´å‹ƒå‹ƒåœ°è·Ÿä½ æè¿°ä»–ä»¬æ•…ä¹¡çš„NPCèº«ä¸Šã€‚ä»–ä»¬çš„æ•…ä¹¡æœ‰æ— æ•°è®©äººå¿ƒé©°ç¥å¾€çš„åœ°ç‚¹ï¼Œæ¯”å¦‚æœ‰æ°´åº•å¤å¢“çš„æ¹–åŒºã€ç«å±±å–·å‘å½¢æˆçš„ç¾¤å²›ã€æ°”å€™ä¸¥é…·çš„è‹”åŸã€‚è¿™äº›åœ°æ–¹è¦æ˜¯æˆ‘çœŸçš„éƒ½èƒ½äº²èº«åˆ°è®¿ï¼Œé‚£ä¸çŸ¥è¯¥æœ‰å¤šå¼€å¿ƒã€‚ç„¶è€Œæˆ‘ä¸èƒ½ï¼Œæˆ‘è¿˜æ˜¯å¾—è·Ÿç€æ— èŠçš„ä¸»çº¿ç•…æ¸¸ä¹å‘³çš„å¥‡å¹»ä¸–ç•Œï¼ŒNPCçš„æè¿°å†æ€ä¹ˆç‚«é…·ä¹Ÿä¸æˆ‘æ— å…³ã€‚æ›´æƒ¨çš„æ˜¯ï¼Œæˆ‘å·²ç»å¾ˆæ¸…æ¥šè¿™äº›ç‚«é…·çš„ç©æ„ä¸€ä¸ä¸€æ¯«éƒ½ä¸ä¼šçœŸæ­£åœ°å‡ºç°åœ¨æ¸¸æˆå¯ä½“éªŒçš„å†…å®¹é‡Œäº†ã€‚ å¼€å‘è€…çš„çŸ¥è¯†å’Œå†™ä½œæ°´å¹³: æœ‰ç°å®åŸºç¡€çš„èƒŒæ™¯çŸ¥è¯†ç ”ç©¶æ²¡åšè¶³å°±ä¼šå½±å“åˆ°å…·ä½“çš„æ•…äº‹æƒ…èŠ‚ï¼Œäºæ˜¯åœ¨ç¼–å†™è¿™äº›æƒ…èŠ‚çš„æ—¶å€™ï¼Œä½œè€…ä»¬å¾€å¾€ä¼šæƒ³å½“ç„¶åœ°åŠ å…¥ä¸€äº›ä»–ä»¬è‡ªå·±çš„æ„è§æˆ–è®®é¢˜ï¼Œè€Œä¸æ˜¯å»ç¼–å†™çœŸæ­£å’Œæ¸¸æˆä¸­çš„èƒŒæ™¯çŸ¥è¯†ç›¸ç¬¦åˆçš„å†…å®¹ã€‚è¿™ä¹ˆä¸€æ¥ï¼Œç©å®¶åœ¨æ¸¸æˆé‡Œçš„ä¸€åˆ‡æ‰€è§æ‰€é—»ã€æ‰€çŸ¥æ‰€æ„Ÿä¼¼ä¹å°±éƒ½éœ€è¦å¤šä¸€å±‚ï¼ˆç”šè‡³å¤šå‡ å±‚ï¼‰æºè‡ªç°ä»£ç¤¾ä¼šçŸ¥è¯†çš„è§£é‡Šï¼Œæ— è®ºè¿™äº›è§é—»å¤šä¹ˆçç¢ã€‚ è¦æè¿°ä¸€ä¸ªé’é“œæ—¶ä»£çš„ç¤¾ä¼šä¸­çš„é‚ªæ¶åŠ›é‡ï¼Œä½†ä½ è„‘å­é‡Œå¡çš„å´éƒ½æ˜¯ç°ä»£çš„è§‚ç‚¹å’Œæ¦‚å¿µâ€”â€”æœ€å¤šä¹Ÿå°±ä¸Šæº¯åˆ°19ä¸–çºªã€‚ä¸ºå•¥ä½ è§‰å¾—è¿™äº›è§‚ç‚¹å’Œæ¦‚å¿µæ˜¯è‡ªå¤ä»¥æ¥å°±æœ‰çš„ï¼Ÿä½ å¥½æ­¹ä¹Ÿè¯¥å»è¯»ä¸€æœ¬å…³äºå¤å¸Œè…Šå†å²æˆ–ç¥è¯æ–¹é¢çš„å…¥é—¨æ‰‹å†Œå§ï¼Ÿå»çœ‹çœ‹é‚£äº›çœŸå®çš„å¤ä»£å†å²ä¸Šæ›¾ç»å‘ç”Ÿè¿‡çš„æ¯«æ— äººæ€§çš„äº‹ä»¶ï¼Œè¿™äº›äº‹ä»¶åš10éƒ¨ã€Šæš´å›ã€‹ä¹Ÿå¤Ÿäº†ã€‚ å†™æ‰‹ä»¬åœ¨è¿ä½¿è¯­è¨€æ–¹é¢çš„çŸ­æ¿ï¼šç°å¦‚ä»Šï¼Œå¾ˆå¤šâ€œç²¾å¿ƒæ‰“é€ çš„RPGå¤§ä½œâ€éƒ½ä¼šå»æ’°å†™ä¸€äº›ç¯‡å¹…ä¸çŸ­çš„ã€æ•£æ–‡å¼çš„æ–‡æ®µå¡«å……åˆ°æ¸¸æˆé‡Œã€‚å½“ä½ å°è¯•å¾€æ–‡æ®µé‡Œå¡å…¥æ›´å¤šå«ä¹‰å¤æ‚çš„å¤§è¯æˆ–å°è¯•ç³…åˆè¿›æ›´å¤šæ„è±¡æ—¶ï¼Œè¦ä¿æŒæ–‡æ®µè¡Œæ–‡é£æ ¼ä¸€è‡´å’Œå†…å®¹å‰åè¿è´¯å°±ä¼šæ›´åŠ å›°éš¾ã€‚ çªç„¶é—´ï¼Œä¸€é˜µå¤æ€ªçš„å™ªå£°åœ¨ä½ å…±æœ‰çš„ä¸–ç•Œä¸­å“èµ·ï¼Œå°±åƒä¸€å£é’Ÿï¼Œå¦‚æœè¿™é’Ÿä¼šè…çƒ‚çš„è¯ã€‚ ï¼ˆSuddenly, a grotesque noise rings through your shared worlds, like a bell if bells could rot.ï¼‰ â€”â€”æƒ³æƒ³æœ€åè¿™ä¸ªå°å¥ï¼Œâ€œå¦‚æœè¿™é’Ÿä¼šè…çƒ‚çš„è¯â€ï¼Œç„¶åæƒ³æƒ³è¿™å¤§æ¦‚æ˜¯ä¸ªä»€ä¹ˆåœºé¢ã€‚è¿™ä¸€å°å¥åˆ°åº•è¡¨è¾¾äº†ä»€ä¹ˆï¼Ÿé’Ÿçš„è…çƒ‚ä¼šå¯¹å£°éŸ³äº§ç”Ÿä»€ä¹ˆæ ·çš„å½±å“ï¼Ÿä¼šä½¿å£°éŸ³å˜å¾—æ›´â€œå¤æ€ªâ€ï¼Ÿè€Œä¸”è¯´å›æ¥ï¼Œè¿™ä¸ªâ€œå¤æ€ªâ€æ‰€è¦è¡¨è¾¾çš„æ„æ€ä¹Ÿç›¸å½“æ¨¡ç³Šã€‚è¿™é’Ÿçš„å£°éŸ³ä¼šå˜å¾—æ›´é«˜äº¢ï¼Ÿæ›´ä½æ²‰ï¼Ÿæˆ–æ˜¯æœ‰äº›èµ°æ ·ï¼Œè¢«æ‰­æ›²äº†ï¼Ÿåˆæˆ–è€…åƒæ˜¯è¢«æ‚ä½äº†é‚£æ ·ï¼Œå˜å¾—ä½æ²‰è€Œå«æ··ï¼Ÿæ‰€ä»¥ï¼Œåˆ°åº•åº”è¯¥æ˜¯å•¥æ ·å‘¢ï¼Ÿåˆ°è¿™é‡Œæˆ‘è¿˜æ²¡æè¿™ä¸ªé’Ÿè¦æ€æ ·è…çƒ‚çš„é—®é¢˜ã€‚å½“ç„¶ï¼Œæˆ‘è§‰å¾—ä»ä¿®è¾çš„è§’åº¦æ¥è¯´ï¼Œè¯´è¿™ä¸ªé’Ÿâ€œè…çƒ‚â€ä¹Ÿä¸æ˜¯å®Œå…¨ä¸èƒ½æ¥å—ï¼Œé‚£å¤§æ¦‚å°±æ˜¯æŒ‡é‡‘å±åˆ¶æˆçš„é’Ÿå› é”ˆèš€å˜å¾—æ®‹ç¼ºä¸å…¨ã€‚åªæ˜¯ï¼Œå¦‚æœè¯´â€œè¿™é’Ÿé”ˆåäº†â€å¬ç€å°±éå¸¸æ²¡æœ‰æ„Ÿè§‰ï¼Œå°¤å…¶æ˜¯æ²¡æœ‰é‚£ç§è¶…å‡¡è„±ä¿—è¿›å…¥å¼‚ä¸–ç•Œçš„æ„Ÿè§‰ã€‚å°±è·Ÿå‰é¢æåˆ°çš„å¯¹çº½è’™æ‹‰ä¸–ç•Œçš„ç©ºæ°”è¿›è¡Œæè¿°çš„å¥å¼ä¸€æ ·ï¼Œâ€œæŸæ ·ä¸œè¥¿å°±åƒXä¸€æ ·ï¼Œå¦‚æœXå¯ä»¥Yçš„è¯â€è¿™ä¸ªä¸çŸ¥æ‰€è°“çš„å¥å¼å‡ºç°å¾—å®åœ¨å¤ªå¤šäº†ã€‚ ç‰¹åˆ«è¾£çœ¼ç›çš„å¥å¼è¿˜ä¸å…‰è¿™ä¸€ä¸ªï¼Œè¿˜æœ‰ä¸€ä¸ªï¼šâ€œä½ æ„Ÿå—åˆ°äº†æŸç§â€¦â€¦æœ‰äº›å¼‚æ ·çš„ä¸œè¥¿ã€‚è¿™æ˜¯ä¸€ç§æ°”å‘³ï¼Œå¦‚æœä½ çš„æƒ…ç»ªèƒ½è¢«é—»è§çš„è¯ã€‚â€ æ²¡èƒ½å®Œå…¨å‘æŒ¥ç”µå­æ¸¸æˆè¿™ä¸€åª’ä»‹çš„æ½œåŠ›: åˆ«å†ç•¸å½¢åœ°é‡è§†æ–‡æœ¬äº†ï¼Œæ–‡æœ¬æ˜¯æ‡’æ”¿ï¼Œæ˜¯æœ€ç®€å•çš„æœ€æ²¡æœ‰æŠ€æœ¯å«é‡çš„è§£å†³æ–¹æ¡ˆã€‚ æ›´å¤§çš„æ–‡å­—é‡ä¸ç­‰äºæ›´å¥½çš„æ¸¸æˆ: ã€Šæˆ˜äº‰ä¸å’Œå¹³ã€‹å…±æœ‰çº¦1890é¡µï¼Œæ€»å…±57ä¸‡è¯ã€‚æŠ˜ç£¨ï¼šçº½è’™æ‹‰ä¹‹æ½®ã€‹çš„æ–‡å­—é‡åˆ™æ˜¯ã€Šæˆ˜äº‰ä¸å’Œå¹³ã€‹çš„ä¸¤å€ï¼Ÿï¼è¿™äº›æ–‡æœ¬å®é™…ä¸Šå……æ–¥ç€å¦‚ä¸Šçš„é•¿éš¾å¥ å½¢å¼ä¸Šæ¨¡ä»¿å°è¯´: æ’è¿›å¯¹è¯å½“ä¸­çš„æè¿°æ€§å’Œæ„Ÿå¹æ€§çš„è¯­å¥äº†ï¼Œæ¯”å¦‚ï¼šã€Œâ€¦ï¼Œè¯´ç€ï¼Œä»–å¹äº†å£æ°”ã€‚ã€ä¸ºä»€ä¹ˆä¸è®©æ¼”å‘˜å¯¹ç€åšç›¸åº”åŠ¨ä½œå‘¢ï¼Ÿè¿™äº›æè¿°æ€§çš„è¯­å¥åœ¨ä¹¦é‡Œæ˜¯å¿…è¦çš„ï¼Œå› ä¸ºä¹¦é‡Œåªæœ‰æ–‡å­—ã€‚ä½†æ¸¸æˆæœ‰ç”»é¢ã€æœ‰å¯¹è¯æ¡†ï¼Œæœ‰æ¯”åªåŒ…å«æ–‡å­—çš„ä¹¦ç±å¤šå¾—å¤šçš„è¡¨ç°æ‰‹æ³•ï¼Œè¿™äº›æè¿°æ€§è¯­å¥è¿˜æœ‰ä»€ä¹ˆç”¨å‘¢ï¼Ÿ æ‰€è°“çš„â€œåšå¾—åƒä¸€æœ¬å°è¯´ä¸€æ ·â€çš„RPGï¼Œå…¶å®åªä¸è¿‡æ˜¯å¯¹è¿‡å¾€æ¸¸æˆçš„å½¢å¼ä¸åŠ¨è„‘å­çš„å¤åˆ¶ã€‚å®ƒä»¬å¹¶æ²¡æœ‰çœŸçš„å»æ€è€ƒï¼Œå¦‚æœè¦æŠŠä¸€ä¸ªRPGåšå¾—åƒä¸€æœ¬å°è¯´ä¸€æ ·çš„è¯ï¼Œåº”è¯¥èŠ±äº›ä»€ä¹ˆæ ·çš„å·¥å¤«ã€‚æ­£é¢ä¾‹å­: ã€Šä¼ è¯´ä¹‹ä¸‹ã€‹çš„è§’è‰²éƒ½æ‹¥æœ‰å„è‡ªå¯¹è¯æ–‡æœ¬çš„ä¸“å±å­—ä½“ï¼Œä¸”ä¸ä»…å¦‚æ­¤ï¼Œä»–ä»¬è¯´è¯çš„æ—¶å€™è¿˜æœ‰å„ç§å“”å“”åŸåŸçš„å£°éŸ³ä½œä¸ºå¯¹è§’è‰²çš„æ ‡è®°ã€‚ åˆ¶ä½œè€…ä»¬æ˜æ˜å¯ä»¥ç”¨ä¸€äº›æ›´å¦™çš„æ–¹å¼æ¥å™äº‹ï¼Œæ¯”å¦‚è¯­éŸ³ã€å›¾åƒä»¥åŠäº’åŠ¨è®¾è®¡æ•…å¸ƒç–‘é˜µï¼Œè‚†æ„æ‰å¼„ç©å®¶ã€‚è¿™æ ·çš„å¯èƒ½æ€§æ˜¯ç”µå­æ¸¸æˆç‹¬æœ‰çš„ï¼Œä½†å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œåˆ¶ä½œè€…ç«Ÿç„¶é€‰æ‹©è¯­éŸ³æ—¥å¿—å’Œè¿è¯­éŸ³éƒ½ä¸å¸¦çš„æ—¥å¿—ã€‚è€Œä¸”è¿™äº›æ—¥å¿—å†™å¾—æ ¹æœ¬ä¸åƒæ—¥å¿—ï¼Œæ¯•ç«Ÿä½ çœŸçš„åœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­å†™è¿‡æ—¥è®°ä¹ˆï¼Ÿ é…éŸ³æ¼”å‘˜çš„å£°éŸ³å‡ºæ¼”ã€ç²¾ç»†çš„è§’è‰²é¢éƒ¨è¡¨æƒ…åŠ¨ç”»ï¼Œä»¥åŠåœ¨å¯¹è¯è¿‡ç¨‹ä¸­è§’è‰²ä»¬çš„åŠ¨ä½œéƒ½å¯ä»¥ç”¨æ¥ä»£æ›¿æ–‡å­—ã€‚è¯šç„¶è¿™æ˜¯è¦èŠ±å¾ˆå¤šé’±çš„ï¼Œå¹¶ä¸”åœ¨è¿™ä¸Šå¤´èŠ±é’±å°±å¿…ç„¶æ„å‘³ç€å‡å°‘å¯¹è¯çš„æ–‡å­—é‡ä»¥åŠå‡ºåœºè§’è‰²çš„æ•°é‡ã€‚ä½†æ˜¯ï¼Œè¿™å¯èƒ½æ˜¯æ„è§å¥½äº‹ï¼Œé€¼è¿«ä½ åè¿‡æ¥æŠŠé’±èŠ±åœ¨åˆ€åˆƒä¸Šï¼Œå‡å°‘ç‚¹è§’è‰²ï¼Œæ›´æ³¨é‡æ¯ä¸ªäººçš„å¡‘é€ ã€‚ é€‰æ‹©ä¸åæœå…¶å®åº”è¯¥é€šè¿‡æ›´éšæ™¦ã€å¾®å¦™çš„æ–¹å¼å‘ˆç°ç»™ç©å®¶ï¼Œè€Œä¸æ˜¯ä»…ä»…æ‘†æ˜è½¦é©¬ï¼Œè®©ç©å®¶åœ¨å¯¹è¯æ¡†é‡Œç‚¹é€‰ã€‚æ­£é¢ä¾‹å­: ã€Šè€»è¾±ã€‹å¦‚æœæ€äººå¤ªå¤šï¼Œæ¯ä¸ªå…³å¡é‡Œé­é‡çš„è­¦å«æ•°é‡éƒ½å˜å¤šäº†ï¼Œè€Œä¸”NPCä»¬ä¹Ÿä¼šè°ˆè®ºä½ å››å¤„æ€äººçš„ç››ä¸¾ï¼Œå…³å¡ä¸­çš„å¸ƒæ™¯ä¹Ÿä¼šæœ‰æ‰€å˜åŒ–ï¼Œè€Œä¸æ˜¯å¼¹å‡ºä¸€ä¸ªå·¨å¤§çš„â€œæ··ä¹±åº¦å¤§å¹…ä¸Šå‡ï¼â€ ä½†æœ€ä»¤æˆ‘ä¸çˆ½çš„ï¼Œè¿˜æ˜¯ç©å®¶åœˆå­é‡Œçš„è™šä¼ªã€‚å°±æˆ‘çš„è§‚å¯Ÿæ¥çœ‹ï¼Œå¯¹RPGä¸­å†™ä½œçš„è®¨è®ºé€šå¸¸æ˜¯æŒ‰ç…§è¿™ä¹ˆä¸ªè½¨è¿¹æ¥è¿›è¡Œçš„ã€‚å…ˆæ˜¯æœ‰äººè¯´ï¼šâ€œè¿™æ¸¸æˆçš„å†™ä½œå¥½æ£’å•Šï¼Œå°±åƒä¸€æœ¬ä¹¦ä¸€æ ·ã€‚â€ç„¶åæœ‰äººè¯´ï¼šâ€œä¸ï¼Œå®ƒå®é™…ä¸Šå¾ˆçƒ‚ã€‚â€å†ä¹‹åï¼Œåˆæœ‰äººå‡è£…ç†å®¢ä¸­è¯´ï¼šâ€œå—ï¼Œè¿™ä¸è¿‡å°±æ˜¯æ¸¸æˆé‡Œçš„å†™ä½œï¼Œæ¸¸æˆé‡Œçš„å†™ä½œæœ¬æ¥å°±ä¸èƒ½è·Ÿä¹¦æ¯”ï¼Œæ‰€ä»¥ä½ åœ¨è¿™æ ä¸ªä»€ä¹ˆåŠ²å‘¢ï¼Ÿâ€æ‰€ä»¥ï¼Œè¿™è®¨è®ºäº§å‡ºäº†ä»€ä¹ˆç»“æœï¼Ÿæ¸¸æˆé‡Œçš„å†™ä½œåˆ°åº•æ˜¯çœŸçš„çƒ‚ï¼Œè¿˜æ˜¯è¯´æ¢ä¸ªè¯„ä¼°çš„è§’åº¦ä»¥åï¼Œå®ƒå…¶å®ä¹Ÿæœ‰å¯å–ä¹‹å¤„å‘¢ï¼Ÿ å¦‚æœæ¸¸æˆé‡Œçš„å†™ä½œéƒ½å¾ˆçƒ‚çš„è¯ï¼Œé‚£è¿™ä¸ªè¡Œä¸šé‡Œé‚£ä¹ˆå¤šé›‡ä½£å†™æ‰‹ï¼Œæ˜¯æ€ä¹ˆä¸€è¾¹æŒä¹‹ä»¥æ’åœ°äº§å‡ºåä¸½è€Œæ— ç‰©çš„æ–‡å­—ï¼Œä¸€è¾¹è¿˜èƒ½ç¾æ»‹æ»‹åœ°æŠŠè¿™ä¸ªå¥—è·¯ç©ä¸‹å»çš„ï¼Ÿç”šè‡³å¾ˆå¤šæ—¶å€™ï¼Œè¿˜ä¸æ˜¯ç©ä¸‹å»è¿™ä¹ˆç®€å•ï¼Œè€Œæ˜¯çœŸçš„èƒ½å¾—åˆ°å¾ˆå¤šäººçš„å–å½©ã€‚æ‰€ä»¥ï¼Œä»–ä»¬æ˜¯æ€ä¹ˆèƒ½å‡­å€Ÿè¿™ä¹ˆåƒåœ¾çš„å†™ä½œæ°´å‡†å¾—åˆ°è¿‘ä¹æ‘‡æ»šæ˜æ˜Ÿçš„è¿½æ§çš„ï¼Ÿä»–ä»¬åˆæ˜¯æ€ä¹ˆèƒ½ç»§ç»­æ¥åˆ°è¿™ç§åˆ›ä½œæ€§çš„å·¥ä½œï¼Œè€Œä¸æ˜¯å»åšç‚¹æ›´é€‚åˆä»–ä»¬çš„å·¥ä½œï¼Œæ¯”å¦‚å»éº¦å½“åŠ³ç¿»è‚‰é¥¼çš„å‘¢ï¼Ÿ ç­”æ¡ˆæ˜¾è€Œæ˜“è§ã€‚é‚£å°±æ˜¯å¾ˆå¤šäººå¹¶æ²¡æœ‰æ·±å…¥åœ°å»è§‚å¯Ÿå’Œæ€è€ƒç°ä»£RPGä¸­å­˜åœ¨çš„é—®é¢˜ï¼Œä»…ä»…æ˜¯æŠŠRPGå½“ä¸ªå¿«é¤ä¸€æ ·å•ƒè¿‡å»å°±ç®—äº†ã€‚è¿™ä¹ˆä¸€æ¥ï¼Œä»–ä»¬è‡ªç„¶ä¸ä¼šæŠ±æ€¨ã€‚ä½†é‚£äº›çœŸæ­£çš„å¤§å¸ˆå´ä¸ä¼šä¸ºè¿™ç§æ°´å‡†çš„å†™ä½œå”±èµæ­Œï¼Œè¿™å°±è·Ÿé‚£äº›æ‰€è°“çš„ç”µå­æ¸¸æˆè®°è€…å’Œä¸“å®¶å¾ˆä¸ä¸€æ ·ã€‚è¿™ä¼™è®°è€…å’Œä¸“å®¶å¯æ˜¯èƒ½èˆ”å¾—å¾ˆï¼Œä½†å‡¡BioWareå‡ºäº†ä¸ªå•¥æ¸¸æˆï¼Œä»–ä»¬ä¸€å®šä¼šç¬¬ä¸€æ—¶é—´èµ¶åˆ°ç°åœºï¼ŒçŒ®ä¸Šå„ç§æº¢ç¾ä¹‹è¯ï¼Œè¯´è¿™ä¸ªæ¸¸æˆåˆå¸¦æ¥äº†ä»€ä¹ˆå™äº‹ä¸Šçš„é©å‘½æ€§åˆ›æ–°ã€‚ä»–ä»¬è¿™ä¹ˆå¹²çš„åŸå› ä¹Ÿä¸éš¾ç†è§£â€”â€”ä»–ä»¬è·Ÿé‚£äº›å†™æ‰‹æ ¹æœ¬å°±æ¥è‡ªåŒä¸€ä¸ªçƒ‚é€äº†çš„ä¼ªå­¦æœ¯å…±åŒä½“ã€‚é™¤äº†æŠ±å›¢å–æš–ä¹‹å¤–ï¼Œå¦ä¸€ä¸ªåŸå› æ˜¯ï¼Œä»–ä»¬ä¾›èŒçš„æ¸¸æˆæ–°é—»ç½‘ç«™ä»å‘è¡Œå•†é‚£é‡Œæ‹¿åˆ°çš„å¤§å¼ æ”¯ç¥¨ã€‚è¦æ‹¿åˆ°è¿™äº›é’±å¹¶ä¸å›°éš¾ï¼Œåªè¦ä»–ä»¬èƒ½é¡ºç€å‘è¡Œå•†çš„æ„æ€è¯´è¯ï¼Œå¹¶ä¸”ä¸å¸¦åŠç‚¹çŠ¹è±«åœ°ç»™é‚£äº›è¢«æ¨ä¸Šå¸‚åœºçš„åº¸ä½œæ‰“å‡ºæ»¡åˆ†å°±å¥½äº†ã€‚ çœ‹èµ·æ¥è¿™ä¸ªä¸šç•Œå®Œå…¨å°±æ˜¯ç”±æ— èƒ½çš„äººã€è‡ªæ‹çš„äººã€è§åˆ©å¿˜ä¹‰çš„äººå’Œæ»¡å˜´ç«è½¦çš„äººæ„æˆçš„ã€‚ çŸ³é»‘æ­£æ•°ã€Šç¡è§‰çš„ç¬¨è›‹ã€‹","categories":[],"tags":[]},{"title":"Deploy a Reddit Bot on Heroku","slug":"2022-09-04-Deploy-a-Reddit-Bot-on-Heroku","date":"2022-09-04T04:00:00.000Z","updated":"2022-09-07T01:20:18.000Z","comments":true,"path":"2022-09-04-Deploy-a-Reddit-Bot-on-Heroku/","permalink":"https://yao-lirong.github.io/blog/2022-09-04-Deploy-a-Reddit-Bot-on-Heroku/","excerpt":"Iâ€™ve created a bot to send warm welcomes to newly admitted Cornell prefrosh.","text":"Iâ€™ve created a bot to send warm welcomes to newly admitted Cornell prefrosh. Simple Auto-Reply Bot This Let Me Google It For You Bot tutorial perfectly explains how to listen to reddit post stream and reply to a post. We use the following code to declare a reddit bot: 1234567reddit = praw.Reddit( client_id=&quot;CLIENT_ID&quot;, client_secret=&quot;CLIENT_SECRET&quot;, username=&quot;USERNAME&quot;, password=&quot;PASSWORD&quot;, user_agent=&quot;LMGTFY (by u/USERNAME)&quot;,) If we want to put our code onto GitHub, this will expose our client secret and account password. Therefore, we can make a separate file called praw.ini, where we specify these private information. Note an ini file cannot contain most special characters, so you need to change your password to only words and digits. 123456[bot527]client_id=d123071240924wclient_secret=D123412541254username=Harmonyanopassword=YouthinkIwillTellYouThisHuhuser_agent=bot With this, we can declare our bot with the following command. Note the customize name â€œbot527â€ need to match in both the ini file and the declaration . 1reddit = praw.Reddit(&quot;bot527&quot;) Deploy on Heroku Create a Heroku app, follow the instructions in Deploy/Heroku Git tab. For a Heroku app to run, it needs several additional files: Runtime.txt: Though itâ€™s in question whether this is really needed or not (the app runs normally too without it?) 1python-3.7.9 Procfile: This is a Heroku specific file that declares what command Heroku should execute to start your app. A detailed explanation in here 1worker: python bot.py requirements.txt: python package requirements, obtained by pip freeze &gt; requirements.txt 1praw==7.6.0 Finally, after you deploying all the codes to Heroku, DONâ€T FORGET THE MOST IMPORTNAT PART: you need to turn on the resources tab on Heroku for your worker (spent 1h figuring this out). For where to find it, watch this video Submit &amp; Edit a Post Submit a Post onto a Subreddit: submission = reddit.subreddit(\"test\").submit(\"title\", selftext=text) Edit an Existed Post: submission.edit(body=submission.body + \"edited\")","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"How to Succeed in CS6784 (also in Academic Life in General)","slug":"2022-08-23-How-to-Succeed-in-CS6784-(also-in-Academic-Life-in-General)","date":"2022-08-23T04:00:00.000Z","updated":"2022-10-25T18:21:18.000Z","comments":true,"path":"2022-08-23-How-to-Succeed-in-CS6784-(also-in-Academic-Life-in-General)/","permalink":"https://yao-lirong.github.io/blog/2022-08-23-How-to-Succeed-in-CS6784-(also-in-Academic-Life-in-General)/","excerpt":"","text":"Write a Good Peer Review Paragraph 1/5: Summary Summarize the paper in your own words, no quote. Be concise. Boil it down to the very essence. Be neutral. Do not yet talk about problems, concerns. Paragraph 2/5: High Level Evaluation This is the place for general comments that are subjective in nature: Did you find the paper well-written? Did the idea strike you as incremental or highly original? What does it build on / are the original parts? Were there sufficient experiments? Is the paper likely to be of interest to many people or of great interest to a small community? Paragraph 3/5: High Level Technical Some possible topics to consider are: Were any important parts missing? Does the approach make sense? Any evaluations that should have been included? What part excited you the most? Donâ€™t judge. For each criticism you have, give advice instead. Speak as if you are their advisors. Paragraph 4/5: Low Level Technical This is a place for very specific comments. It shows the authors you read the paper carefully. Most papers have at least one (small) mistake per page. For example: Any sections or equations that werenâ€™t clear? Any figures that are hard to read? Captions of it given wrong? X tilde labeled incorrectly? Any mistakes with indices / equations? Paragraph 5/5: Review Summary This is a summary of your own review (not the paper). Do it in one or two sentences. Make Good Slides Overview Number of Slides: Allow roughly 1 minute per slide Sections: Problem statement, Approach, Results, Conclusion Dos and Donâ€™ts Never change notation throughout a talk. Keep notation consistent across figures Avoid appearance of only an equation. When you have an equation, also include illustrations of it to explain how it behaves. If thatâ€™s not possible, include some intuitive explanations. Label each figure very clearly. Donâ€™t use unfinished figures. Always attach semantic meaning to symbols and animation effects and be consistent through the talk. e.g. If you want to use arrow â†’ to represent â€œreduce toâ€, then use it with this meaning through the talk. Never assume people remember previous slides. Call back to meanings of symbols and other background information. Donâ€™t assume your audience pays attention at all. If there is something important to say, say it repeatedly. Hammer the point home. Make it crystal clear. Other Helpful Tips Each slide should have a single â€œtake homeâ€ message. You should be able to verbalize that when asked. Try to stick to one running example. Explain every aspect of the paper in the same setting. (e.g. assume x is movies, y is movie ratings; x is images of faces, y is the age of the person; â€¦) Use images, movies, etc (unlike this file) Donâ€™t just do texts Write a Good Research Paper Layout Abstract: Summarize the paper in a few sentences (5-8) Introduction: Provide Motivation, explain why what you are doing is important Related Work: What have people done so far, what should the reader know about the literature Background: Summarize some tools that you use but your readers may not understand Method: Explain your method. Try to keep it as simple and clear as possible! Results: Evaluate your method. For each experiment be clear what point it is making, what are you demonstrating Conclusion/Discussion: What have you learned from your research. Where is this going? Any high level observations that are interesting? Style Citations Cite generously. Always mention other work in positive light. Writing style NEVER try to make something look more complicated than it is. Always simplify!! Equations The more important an equation, the more text you should have around it Formality Avoid informal wording (â€œWhen we ran these jobs we got these results.â€) Graphs / Tables When you discuss graphs / tables, say clearly what the reader should pay attention to. Donâ€™t assume the reader draws the correct conclusion by themselves. Explain Why, not What you did What you did is meaningless without providing the reason. Avoid at all cost. E.g. Now we integrate the function f(x,z) and obtain f(z). As a next step we add a constant term. The result is a loss function that we use for training. You should explain why: As our model is independent of x we can simplify our setup by marginalizing over x. The resulting function f(z) no longer depends on x, which allows us to â€¦. 5 General Tips Do extensive background reading (you should know every paper ever published on the topic) Have a clear research question. Propose a solution and explain every step of the derivation. (Make it look like it is completely natural.) The more important an equation, the more text should be around it. Conduct clear experiments and make sure each one proves a well-defined point. (Be honest, you are researchers not salespeople!!!) Write well! Polish, polish, polish!","categories":[],"tags":[]},{"title":"JavaScript Manual","slug":"2022-06-11-JavaScript-Manual","date":"2022-06-11T04:00:00.000Z","updated":"2023-04-20T21:05:30.000Z","comments":true,"path":"2022-06-11-JavaScript-Manual/","permalink":"https://yao-lirong.github.io/blog/2022-06-11-JavaScript-Manual/","excerpt":"I hate web programming, but looks like I really have to learn it. Notes from Liao Xuefengâ€™s JS course","text":"I hate web programming, but looks like I really have to learn it. Notes from Liao Xuefengâ€™s JS course Introduction Variables and Objects Declare a variable with var: var x = 3 JavaScript has both null and undefined, but most of the time we just use null Print out value in browser: console.log() Ternary if-else Operator: condition ? then : else Strict Mode JavaScriptåœ¨è®¾è®¡ä¹‹åˆï¼Œä¸ºäº†æ–¹ä¾¿åˆå­¦è€…å­¦ä¹ ï¼Œå¹¶ä¸å¼ºåˆ¶è¦æ±‚ç”¨varç”³æ˜å˜é‡ã€‚è¿™ä¸ªè®¾è®¡é”™è¯¯å¸¦æ¥äº†ä¸¥é‡çš„åæœï¼šå¦‚æœä¸€ä¸ªå˜é‡æ²¡æœ‰é€šè¿‡varç”³æ˜å°±è¢«ä½¿ç”¨ï¼Œé‚£ä¹ˆè¯¥å˜é‡å°±è‡ªåŠ¨è¢«ç”³æ˜ä¸ºå…¨å±€å˜é‡ï¼š 1i = 10; // iç°åœ¨æ˜¯å…¨å±€å˜é‡ åœ¨åŒä¸€ä¸ªé¡µé¢çš„ä¸åŒçš„JavaScriptæ–‡ä»¶ä¸­ï¼Œå¦‚æœéƒ½ä¸ç”¨varç”³æ˜ï¼Œæ°å¥½éƒ½ä½¿ç”¨äº†å˜é‡iï¼Œå°†é€ æˆå˜é‡iäº’ç›¸å½±å“ï¼Œäº§ç”Ÿéš¾ä»¥è°ƒè¯•çš„é”™è¯¯ç»“æœã€‚ ä¸ä¹‹ç›¸å¯¹ï¼Œä½¿ç”¨varç”³æ˜çš„å˜é‡æ˜¯å±€éƒ¨å˜é‡ã€‚ åœ¨strictæ¨¡å¼ä¸‹è¿è¡Œçš„JavaScriptä»£ç ï¼Œå¼ºåˆ¶é€šè¿‡varç”³æ˜å˜é‡ï¼Œæœªä½¿ç”¨varç”³æ˜å˜é‡å°±ä½¿ç”¨çš„ï¼Œå°†å¯¼è‡´è¿è¡Œé”™è¯¯ã€‚å¯ç”¨strictæ¨¡å¼çš„æ–¹æ³•æ˜¯åœ¨JavaScriptä»£ç çš„ç¬¬ä¸€è¡Œå†™ä¸Šï¼š 1&#x27;use strict&#x27;; Strings Strings are immutable in JS. 123456789var s = &#x27;Hello, world!&#x27;;s.length; // 13s[6]; // &#x27; &#x27;s[13]; // undefined è¶…å‡ºèŒƒå›´çš„ç´¢å¼•ä¸ä¼šæŠ¥é”™ï¼Œä½†ä¸€å¾‹è¿”å›undefined// å¯ä»¥ç”¨ + é“¾æ¥å¤šä¸ªå­—ç¬¦ä¸²ï¼Œä½†ä¹Ÿæœ‰ä¸€ç§æ›´ç®€æ´çš„æ–¹æ³•å¯ä»¥åœ¨å­—ç¬¦ä¸²ä¸­åµŒå¥—å…¶ä»–å˜é‡var name = &#x27;å°æ˜&#x27;;var message = &quot;ä½ å¥½, $&#123;name&#125;&quot;; Array 12var arr = [1, 2, 3.14, &#x27;Hello&#x27;, null, true];arr.length; // 6 You can assign values to array, but å¦‚æœé€šè¿‡ç´¢å¼•èµ‹å€¼æ—¶ï¼Œç´¢å¼•è¶…è¿‡äº†èŒƒå›´ï¼ŒåŒæ ·ä¼šå¼•èµ·Arrayå¤§å°çš„å˜åŒ–ï¼š 123var arr = [1, 2, 3];arr[1] = 99; // arr == [1, 99, 3]arr[5] = &#x27;x&#x27;; // arr == [1, 2, 3, undefined, undefined, &#x27;x&#x27;] arr.push(e) adds variable e to the end of the array, arr.pop() delete an element from the end of the array arr.unshift(e) adds variable e to the beginning of the array, arr.shift() delete an element from the beginning of the array Object JavaScript Object is a key-value map that can be accessed both in traditional object way and the python dict way. 12345var xiaohong = &#123; name: &#x27;å°çº¢&#x27;, birth: 1990, tags: [&#x27;js&#x27;, &#x27;web&#x27;, &#x27;mobile&#x27;], &#x27;middle-school&#x27;: &#x27;No.1 Middle School&#x27;&#125;; xiaohong çš„å±æ€§å middle-school ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„å˜é‡ï¼Œå°±éœ€è¦ç”¨''æ‹¬èµ·æ¥ã€‚è®¿é—®è¿™ä¸ªå±æ€§ä¹Ÿæ— æ³•ä½¿ç”¨.æ“ä½œç¬¦ï¼Œå¿…é¡»ç”¨ ['xxx'] æ¥è®¿é—®ã€‚å…¶ä»–è§„åˆ™çš„å˜é‡è™½ç„¶ä¹Ÿå¯ä»¥ç”¨ xiaohong['name'] æ¥è®¿é—® xiaohong çš„ name å±æ€§ï¼Œä¸è¿‡ xiaohong.name çš„å†™æ³•æ›´ç®€æ´ã€‚ 123xiaohong[&#x27;middle-school&#x27;]; // &#x27;No.1 Middle School&#x27;xiaohong[&#x27;name&#x27;]; // &#x27;å°çº¢&#x27;xiaohong.name; // &#x27;å°çº¢&#x27; ç»™ä¸å­˜åœ¨çš„å±æ€§èµ‹å€¼ä»¥å£°æ˜æ–°çš„å±æ€§ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ delete åˆ é™¤ä¸€ä¸ªæ—¢æœ‰çš„å±æ€§ 1234xiaoming.age = 18; // æ–°å¢ä¸€ä¸ªageå±æ€§xiaoming.age; // 18delete xiaoming.age; // åˆ é™¤ageå±æ€§xiaoming.age; // undefined Use in to detect whether an object has a certain property. ä¸è¿‡è¦å°å¿ƒï¼Œå¦‚æœinåˆ¤æ–­ä¸€ä¸ªå±æ€§å­˜åœ¨ï¼Œè¿™ä¸ªå±æ€§ä¸ä¸€å®šæ˜¯xiaomingçš„ï¼Œå®ƒå¯èƒ½æ˜¯xiaomingç»§æ‰¿å¾—åˆ°çš„ã€‚æ¯”å¦‚ toString å®šä¹‰åœ¨ object å¯¹è±¡ä¸­ï¼Œè€Œæ‰€æœ‰å¯¹è±¡éƒ½ç»§æ‰¿ objectï¼Œæ‰€ä»¥ xiaoming ä¹Ÿæ‹¥æœ‰ toString å±æ€§ã€‚è¦åˆ¤æ–­ä¸€ä¸ªå±æ€§æ˜¯å¦æ˜¯xiaomingè‡ªèº«æ‹¥æœ‰çš„ï¼Œè€Œä¸æ˜¯ç»§æ‰¿å¾—åˆ°çš„ï¼Œå¯ä»¥ç”¨hasOwnProperty()æ–¹æ³•ï¼š 1234&#x27;name&#x27; in xiaoming; // true &#x27;toString&#x27; in xiaoming; // truexiaoming.hasOwnProperty(&#x27;name&#x27;); // truexiaoming.hasOwnProperty(&#x27;toString&#x27;); // false Loop for loop: for (i=0; i&lt;arr.length; i++) &#123;...&#125; for of loop: for (var key of xiaoming) &#123;...&#125;. This is a better version of for in loop JS has. To filter out those inherited properties, use 1234for (var key of xiaoming) &#123; if (xiaoming.hasOwnProperty(key)) &#123; console.log(key); // &#x27;name&#x27;, &#x27;age&#x27;, &#x27;city&#x27; &#125; &#125; while loop: while (n &gt; 0) &#123; ... &#125; do while loop: do &#123; ... &#125; while() Function 1234567var abs = function (x) &#123; return x;&#125;;function abs(x) &#123; return x;&#125; ç”±äºJavaScriptå…è®¸ä¼ å…¥ä»»æ„ä¸ªå‚æ•°è€Œä¸å½±å“è°ƒç”¨ï¼Œå› æ­¤ä¼ å…¥çš„å‚æ•°æ¯”å®šä¹‰çš„å‚æ•°å¤šä¹Ÿæ²¡æœ‰é—®é¢˜ï¼Œè™½ç„¶å‡½æ•°å†…éƒ¨å¹¶ä¸éœ€è¦è¿™äº›å‚æ•°ï¼š 12abs(10, &#x27;blablabla&#x27;); // è¿”å›10abs(-9, &#x27;haha&#x27;, &#x27;hehe&#x27;, null); // è¿”å›9 ä¼ å…¥çš„å‚æ•°æ¯”å®šä¹‰çš„å°‘ä¹Ÿæ²¡æœ‰é—®é¢˜ï¼šæ­¤æ—¶abs(x)å‡½æ•°çš„å‚æ•°xå°†æ”¶åˆ°undefinedï¼Œè®¡ç®—ç»“æœä¸ºNaNã€‚ 1abs(); // è¿”å›NaN JSON JSON æ˜¯ JavaScript Object Notation çš„ç¼©å†™ï¼Œå®é™…ä¸Šæ˜¯ JavaScript çš„ä¸€ä¸ªå­é›†ã€‚æ‰€ä»¥æˆ‘ä»¬å¯ä»¥éå¸¸æ–¹ä¾¿åœ°å°† Java Object è½¬æ¢æˆ JSONã€‚ 1var s = JSON.stringify(xiaoming, null, &quot; &quot;); è¦è¾“å‡ºå¾—å¥½çœ‹ä¸€äº›ï¼Œå¯ä»¥åŠ ä¸Šå‚æ•°ï¼ŒæŒ‰ç¼©è¿›è¾“å‡ºï¼š 1JSON.stringify(xiaoming, null, &#x27; &#x27;); ç¬¬äºŒä¸ªå‚æ•°ç”¨äºæ§åˆ¶å¦‚ä½•ç­›é€‰å¯¹è±¡çš„é”®å€¼ï¼Œå¦‚æœæˆ‘ä»¬åªæƒ³è¾“å‡ºæŒ‡å®šçš„å±æ€§ï¼Œå¯ä»¥ä¼ å…¥Arrayï¼š 1JSON.stringify(xiaoming, [&#x27;name&#x27;, &#x27;birth&#x27;], &#x27; &#x27;); ç»“æœï¼š 12&#123; &quot;name&quot;: &quot;å°æ˜&quot;, &quot;birth&quot;: 1990&#125; è¿˜å¯ä»¥ä¼ å…¥ä¸€ä¸ªå‡½æ•°ï¼Œè¿™æ ·å¯¹è±¡çš„æ¯ä¸ªé”®å€¼å¯¹éƒ½ä¼šè¢«å‡½æ•°å…ˆå¤„ç†ï¼š 12345678function convert(key, value) &#123; if (typeof value === &#x27;string&#x27;) &#123; return value.toUpperCase(); &#125; return value;&#125;JSON.stringify(xiaoming, convert, &#x27; &#x27;); ä¸Šé¢çš„ä»£ç æŠŠæ‰€æœ‰å±æ€§å€¼éƒ½å˜æˆå¤§å†™ï¼š 12345&#123; &quot;name&quot;: &quot;å°æ˜&quot;, &quot;birth&quot;: 1990, &#x27;middle-school&#x27;: &#x27;No.1 MIDDLE SCHOOL&#x27;&#125; å¦‚æœæˆ‘ä»¬è¿˜æƒ³è¦ç²¾ç¡®æ§åˆ¶å¦‚ä½•åºåˆ—åŒ–å°æ˜ï¼Œå¯ä»¥ç»™xiaomingå®šä¹‰ä¸€ä¸ªtoJSON()çš„æ–¹æ³•ï¼Œç›´æ¥è¿”å›JSONåº”è¯¥åºåˆ—åŒ–çš„æ•°æ®ï¼š 1234567891011121314var xiaoming = &#123; name: &#x27;å°æ˜&#x27;, age: 14, birth: 1990, middle-school: &#x27;No.1 MIDDLE SCHOOL&#x27; toJSON: function () &#123; return &#123; // åªè¾“å‡ºnameå’Œageï¼Œå¹¶ä¸”æ”¹å˜äº†keyï¼š &#x27;Name&#x27;: this.name, &#x27;Age&#x27;: this.age &#125;; &#125;&#125;;JSON.stringify(xiaoming); // &#x27;&#123;&quot;Name&quot;:&quot;å°æ˜&quot;,&quot;Age&quot;:14&#125;&#x27; æ‹¿åˆ°ä¸€ä¸ªJSONæ ¼å¼çš„å­—ç¬¦ä¸²ï¼Œæˆ‘ä»¬ç›´æ¥ç”¨JSON.parse()æŠŠå®ƒå˜æˆä¸€ä¸ªJavaScriptå¯¹è±¡ï¼š 1234JSON.parse(&#x27;[1,2,3,true]&#x27;); // [1, 2, 3, true]JSON.parse(&#x27;&#123;&quot;name&quot;:&quot;å°æ˜&quot;,&quot;age&quot;:14&#125;&#x27;); // Object &#123;name: &#x27;å°æ˜&#x27;, age: 14&#125;JSON.parse(&#x27;true&#x27;); // trueJSON.parse(&#x27;123.45&#x27;); // 123.45 jQuery $ is an alias to jQuery. Therefore, if you encounter error Uncaught TypeError: $ is not a function, you can just replace the $ with jQuery instead (e.g. jQuery('#abc')) Intro to Selector jQuery Object ä¸€ä¸ª jQuery å‘½ä»¤è¿”å›çš„å¯¹è±¡æ˜¯ jQuery å¯¹è±¡ã€‚å®ƒç±»ä¼¼æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªå¼•ç”¨äº†DOMèŠ‚ç‚¹çš„å¯¹è±¡ã€‚ä»¥ä¸‹é¢çš„æŸ¥æ‰¾ä¸ºä¾‹ï¼Œ å¦‚æœidä¸ºabcçš„&lt;div&gt;å­˜åœ¨ï¼Œè¿”å›çš„jQueryå¯¹è±¡å¦‚ä¸‹ï¼š 1[&lt;div id=&quot;abc&quot;&gt;...&lt;/div&gt;] å¦‚æœidä¸ºabcçš„&lt;div&gt;ä¸å­˜åœ¨ï¼Œè¿”å›çš„jQueryå¯¹è±¡å¦‚ä¸‹ï¼š 1[] æ€»ä¹‹jQueryçš„é€‰æ‹©å™¨ä¸ä¼šè¿”å›undefinedæˆ–è€…nullï¼Œè¿™æ ·çš„å¥½å¤„æ˜¯ä½ ä¸å¿…åœ¨ä¸‹ä¸€è¡Œåˆ¤æ–­if (div === undefined)ã€‚ jQueryå¯¹è±¡å’ŒDOMå¯¹è±¡ä¹‹é—´å¯ä»¥äº’ç›¸è½¬åŒ–ï¼š 123var div = $(&#x27;#abc&#x27;); // jQueryå¯¹è±¡var divDom = div.get(0); // å‡è®¾å­˜åœ¨divï¼Œè·å–ç¬¬1ä¸ªDOMå…ƒç´ var another = $(divDom); // é‡æ–°æŠŠDOMåŒ…è£…ä¸ºjQueryå¯¹è±¡ é€šå¸¸æƒ…å†µä¸‹ä½ ä¸éœ€è¦è·å–DOMå¯¹è±¡ï¼Œç›´æ¥ä½¿ç”¨jQueryå¯¹è±¡æ›´åŠ æ–¹ä¾¿ã€‚å¦‚æœä½ æ‹¿åˆ°äº†ä¸€ä¸ªDOMå¯¹è±¡ï¼Œé‚£å¯ä»¥ç®€å•åœ°è°ƒç”¨$(aDomObject)æŠŠå®ƒå˜æˆjQueryå¯¹è±¡ï¼Œè¿™æ ·å°±å¯ä»¥æ–¹ä¾¿åœ°ä½¿ç”¨jQueryçš„APIäº†ã€‚ æŒ‰IDæŸ¥æ‰¾ åœ¨IDå‰åŠ ä¸Š # ä»¥è¿›è¡ŒIDæŸ¥æ‰¾ 12// æŸ¥æ‰¾&lt;div id=&quot;abc&quot;&gt;:var div = $(&#x27;#abc&#x27;); æŒ‰tagæŸ¥æ‰¾ ç›´æ¥å†™ä¸Štagåç§°è¿›è¡ŒtagæŸ¥æ‰¾ï¼š 12var ps = $(&#x27;p&#x27;); // è¿”å›æ‰€æœ‰&lt;p&gt;èŠ‚ç‚¹ps.length; // æ•°ä¸€æ•°é¡µé¢æœ‰å¤šå°‘ä¸ª&lt;p&gt;èŠ‚ç‚¹ æŒ‰classæŸ¥æ‰¾ åœ¨classåç§°å‰åŠ ä¸€ä¸ª. è¿›è¡ŒæŒ‰classæŸ¥æ‰¾ 1234var a = $(&#x27;.red&#x27;); // æ‰€æœ‰èŠ‚ç‚¹åŒ…å«`class=&quot;red&quot;`éƒ½å°†è¿”å›// ä¾‹å¦‚:// &lt;div class=&quot;red&quot;&gt;...&lt;/div&gt;// &lt;p class=&quot;green red&quot;&gt;...&lt;/p&gt; é€šå¸¸å¾ˆå¤šèŠ‚ç‚¹æœ‰å¤šä¸ªclassï¼Œæˆ‘ä»¬å¯ä»¥æŸ¥æ‰¾åŒæ—¶åŒ…å«redå’Œgreençš„èŠ‚ç‚¹ï¼š 1234var a = $(&#x27;.red.green&#x27;); // æ³¨æ„æ²¡æœ‰ç©ºæ ¼ï¼// ç¬¦åˆæ¡ä»¶çš„èŠ‚ç‚¹ï¼š// &lt;div class=&quot;red green&quot;&gt;...&lt;/div&gt;// &lt;div class=&quot;blue green red&quot;&gt;...&lt;/div&gt; æŒ‰å±æ€§æŸ¥æ‰¾ ä¸€ä¸ªDOMèŠ‚ç‚¹é™¤äº†idå’Œclasså¤–è¿˜å¯ä»¥æœ‰å¾ˆå¤šå±æ€§ï¼Œå¾ˆå¤šæ—¶å€™æŒ‰å±æ€§æŸ¥æ‰¾ä¼šéå¸¸æ–¹ä¾¿ï¼Œæ¯”å¦‚åœ¨ä¸€ä¸ªè¡¨å•ä¸­æŒ‰å±æ€§æ¥æŸ¥æ‰¾ï¼š 123var email = $(&#x27;[name=email]&#x27;); // æ‰¾å‡º&lt;??? name=&quot;email&quot;&gt;var passwordInput = $(&#x27;[type=password]&#x27;); // æ‰¾å‡º&lt;??? type=&quot;password&quot;&gt;var a = $(&#x27;[items=&quot;A B&quot;]&#x27;); // æ‰¾å‡º&lt;??? items=&quot;A B&quot;&gt; å½“å±æ€§çš„å€¼åŒ…å«ç©ºæ ¼ç­‰ç‰¹æ®Šå­—ç¬¦æ—¶ï¼Œéœ€è¦ç”¨åŒå¼•å·æ‹¬èµ·æ¥ã€‚ æŒ‰å±æ€§æŸ¥æ‰¾è¿˜å¯ä»¥ä½¿ç”¨å‰ç¼€æŸ¥æ‰¾æˆ–è€…åç¼€æŸ¥æ‰¾ï¼š 1234var icons = $(&#x27;[name^=icon]&#x27;); // æ‰¾å‡ºæ‰€æœ‰nameå±æ€§å€¼ä»¥iconå¼€å¤´çš„DOM// ä¾‹å¦‚: name=&quot;icon-1&quot;, name=&quot;icon-2&quot;var names = $(&#x27;[name$=with]&#x27;); // æ‰¾å‡ºæ‰€æœ‰nameå±æ€§å€¼ä»¥withç»“å°¾çš„DOM// ä¾‹å¦‚: name=&quot;startswith&quot;, name=&quot;endswith&quot; è¿™ä¸ªæ–¹æ³•å°¤å…¶é€‚åˆé€šè¿‡classå±æ€§æŸ¥æ‰¾ï¼Œä¸”ä¸å—classåŒ…å«å¤šä¸ªåç§°çš„å½±å“ï¼š 12var icons = $(&#x27;[class^=&quot;icon-&quot;]&#x27;); // æ‰¾å‡ºæ‰€æœ‰classåŒ…å«è‡³å°‘ä¸€ä¸ªä»¥`icon-`å¼€å¤´çš„DOM// ä¾‹å¦‚: class=&quot;icon-clock&quot;, class=&quot;abc icon-home&quot; ANDæŸ¥æ‰¾ ç›´æ¥å†™å¤šä¸ªæ¡ä»¶ï¼Œæ¡ä»¶é—´ä¸åŠ ç©ºæ ¼æ¥æ‰§è¡ŒANDæŸ¥æ‰¾ã€‚ å¦‚æœæˆ‘ä»¬æŸ¥æ‰¾$('[name=email]')ï¼Œå¾ˆå¯èƒ½æŠŠè¡¨å•å¤–çš„&lt;div name=\"email\"&gt;ä¹Ÿæ‰¾å‡ºæ¥ï¼Œä½†æˆ‘ä»¬åªå¸Œæœ›æŸ¥æ‰¾&lt;input&gt;ï¼Œå°±å¯ä»¥è¿™ä¹ˆå†™ï¼š 1var emailInput = $(&#x27;input[name=email]&#x27;); // ä¸ä¼šæ‰¾å‡º&lt;div name=&quot;email&quot;&gt; å‰æ–‡ä¸­çš„åŒæ—¶æŸ¥æ‰¾å¤šä¸ªclassä¹Ÿæ˜¯ä¸€ä¸ªä¾‹å­ã€‚åŒæ ·çš„ï¼Œæ ¹æ®tagå’Œclassæ¥ç»„åˆæŸ¥æ‰¾ä¹Ÿå¾ˆå¸¸è§ï¼š 1var tr = $(&#x27;tr.red&#x27;); // æ‰¾å‡º&lt;tr class=&quot;red ...&quot;&gt;...&lt;/tr&gt; ORæŸ¥æ‰¾ æŠŠå¤šä¸ªé€‰æ‹©å™¨ç”¨,ç»„åˆèµ·æ¥ï¼ŒæŸ¥æ‰¾æ‰€æœ‰ç¬¦åˆä»»ä¸€é€‰æ‹©å™¨æ¡ä»¶çš„ DOM èŠ‚ç‚¹ã€‚ 12$(&#x27;p,div&#x27;); // æŠŠ&lt;p&gt;å’Œ&lt;div&gt;éƒ½é€‰å‡ºæ¥$(&#x27;p.red,p.green&#x27;); // æŠŠ&lt;p class=&quot;red&quot;&gt;å’Œ&lt;p class=&quot;green&quot;&gt;éƒ½é€‰å‡ºæ¥ è¦æ³¨æ„çš„æ˜¯ï¼Œé€‰å‡ºæ¥çš„å…ƒç´ æ˜¯æŒ‰ç…§å®ƒä»¬åœ¨HTMLä¸­å‡ºç°çš„é¡ºåºæ’åˆ—çš„ï¼Œè€Œä¸”ä¸ä¼šæœ‰é‡å¤å…ƒç´ ã€‚ä¾‹å¦‚ï¼Œ&lt;p class=\"red green\"&gt;ä¸ä¼šè¢«ä¸Šé¢çš„$('p.red,p.green')é€‰æ‹©ä¸¤æ¬¡ã€‚ Descendent Selector ä»¥å¦‚ä¸‹ç»“æ„ä¸ºä¾‹ 12345678&lt;!-- HTMLç»“æ„ --&gt;&lt;div class=&quot;testing&quot;&gt; &lt;ul class=&quot;lang&quot;&gt; &lt;li class=&quot;lang-javascript&quot;&gt;JavaScript&lt;/li&gt; &lt;li class=&quot;lang-python&quot;&gt;Python&lt;/li&gt; &lt;li class=&quot;lang-lua&quot;&gt;Lua&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt; å±‚çº§é€‰æ‹©å™¨ï¼ˆDescendant Selectorï¼‰ å¦‚æœä¸¤ä¸ªDOMå…ƒç´ å…·æœ‰å±‚çº§å…³ç³»ï¼Œå°±å¯ä»¥ç”¨$('ancestor descendant')æ¥é€‰æ‹©ï¼Œå±‚çº§ä¹‹é—´ç”¨ç©ºæ ¼éš”å¼€ã€‚ è¦é€‰å‡ºä¸Šä¾‹ä¸­çš„ JavaScriptï¼Œå¯ä»¥ç”¨å±‚çº§é€‰æ‹©å™¨ï¼š 12$(&#x27;ul.lang li.lang-javascript&#x27;); // [&lt;li class=&quot;lang-javascript&quot;&gt;JavaScript&lt;/li&gt;]$(&#x27;div.testing li.lang-javascript&#x27;); // [&lt;li class=&quot;lang-javascript&quot;&gt;JavaScript&lt;/li&gt;] å› ä¸º&lt;div&gt;å’Œ&lt;ul&gt;éƒ½æ˜¯&lt;li&gt;çš„ç¥–å…ˆèŠ‚ç‚¹ï¼Œæ‰€ä»¥ä¸Šé¢ä¸¤ç§æ–¹å¼éƒ½å¯ä»¥é€‰å‡ºç›¸åº”çš„&lt;li&gt;èŠ‚ç‚¹ã€‚ è¦é€‰æ‹©æ‰€æœ‰çš„&lt;li&gt;èŠ‚ç‚¹ï¼Œç”¨ï¼š 1$(&#x27;ul.lang li&#x27;); è¿™ç§å±‚çº§é€‰æ‹©å™¨ç›¸æ¯”å•ä¸ªçš„é€‰æ‹©å™¨å¥½å¤„åœ¨äºï¼Œå®ƒç¼©å°äº†é€‰æ‹©èŒƒå›´ï¼Œå› ä¸ºé¦–å…ˆè¦å®šä½çˆ¶èŠ‚ç‚¹ï¼Œæ‰èƒ½é€‰æ‹©ç›¸åº”çš„å­èŠ‚ç‚¹ï¼Œè¿™æ ·é¿å…äº†é¡µé¢å…¶ä»–ä¸ç›¸å…³çš„å…ƒç´ ã€‚ä¾‹å¦‚ï¼š 1$(&#x27;form[name=upload] input&#x27;); å°±æŠŠé€‰æ‹©èŒƒå›´é™å®šåœ¨nameå±æ€§ä¸ºuploadçš„è¡¨å•é‡Œã€‚å¦‚æœé¡µé¢æœ‰å¾ˆå¤šè¡¨å•ï¼Œå…¶ä»–è¡¨å•çš„&lt;input&gt;ä¸ä¼šè¢«é€‰æ‹©ã€‚ å¤šå±‚åµŒå¥—ä¹Ÿæ˜¯å…è®¸çš„ï¼š 1$(&#x27;form.test p input&#x27;); // åœ¨formè¡¨å•é€‰æ‹©è¢«&lt;p&gt;åŒ…å«çš„&lt;input&gt; å­é€‰æ‹©å™¨ï¼ˆChild Selectorï¼‰ Child Selector $('parent&gt;child') ä¸ Descendant Selector å‡ ä¹å®Œå…¨ä¸€æ ·ï¼Œä½†æ˜¯é™å®šäº†å±‚çº§å…³ç³»å¿…é¡»æ˜¯çˆ¶å­å…³ç³»ï¼Œå°±æ˜¯&lt;child&gt;èŠ‚ç‚¹å¿…é¡»æ˜¯&lt;parent&gt;èŠ‚ç‚¹çš„ç›´å±å­èŠ‚ç‚¹ã€‚è¿˜æ˜¯ä»¥ä¸Šé¢çš„ä¾‹å­ï¼š 12$(&#x27;ul.lang&gt;li.lang-javascript&#x27;); // å¯ä»¥é€‰å‡º[&lt;li class=&quot;lang-javascript&quot;&gt;JavaScript&lt;/li&gt;]$(&#x27;div.testing&gt;li.lang-javascript&#x27;); // [], æ— æ³•é€‰å‡ºï¼Œå› ä¸º&lt;div&gt;å’Œ&lt;li&gt;ä¸æ„æˆçˆ¶å­å…³ç³» è¿‡æ»¤å™¨ï¼ˆFilterï¼‰ è¿‡æ»¤å™¨ä¸€èˆ¬ä¸å•ç‹¬ä½¿ç”¨ï¼Œå®ƒé€šå¸¸é™„åŠ åœ¨é€‰æ‹©å™¨ä¸Šï¼Œå¸®åŠ©æˆ‘ä»¬æ›´ç²¾ç¡®åœ°å®šä½å…ƒç´ ã€‚è§‚å¯Ÿè¿‡æ»¤å™¨çš„æ•ˆæœï¼š 1234567$(&#x27;ul.lang li&#x27;); // é€‰å‡ºJavaScriptã€Pythonå’ŒLua 3ä¸ªèŠ‚ç‚¹$(&#x27;ul.lang li:first-child&#x27;); // ä»…é€‰å‡ºJavaScript$(&#x27;ul.lang li:last-child&#x27;); // ä»…é€‰å‡ºLua$(&#x27;ul.lang li:nth-child(2)&#x27;); // é€‰å‡ºç¬¬Nä¸ªå…ƒç´ ï¼ŒNä»1å¼€å§‹$(&#x27;ul.lang li:nth-child(even)&#x27;); // é€‰å‡ºåºå·ä¸ºå¶æ•°çš„å…ƒç´ $(&#x27;ul.lang li:nth-child(odd)&#x27;); // é€‰å‡ºåºå·ä¸ºå¥‡æ•°çš„å…ƒç´  æŸ¥æ‰¾å’Œè¿‡æ»¤ æœ¬èŠ‚ä½¿ç”¨å¦‚ä¸‹ä¾‹å­ 12345678&lt;!-- HTMLç»“æ„ --&gt;&lt;ul class=&quot;lang&quot;&gt; &lt;li class=&quot;js dy&quot;&gt;JavaScript&lt;/li&gt; &lt;li class=&quot;dy&quot;&gt;Python&lt;/li&gt; &lt;li id=&quot;swift&quot;&gt;Swift&lt;/li&gt; &lt;li class=&quot;dy&quot;&gt;Scheme&lt;/li&gt; &lt;li name=&quot;haskell&quot;&gt;Haskell&lt;/li&gt;&lt;/ul&gt; æŸ¥æ‰¾ ç”¨find()æŸ¥æ‰¾ï¼š 123var ul = $(&#x27;ul.lang&#x27;); // è·å¾—&lt;ul&gt;var dy = ul.find(&#x27;#swift&#x27;); // è·å¾— Luavar equiv = $(&#x27;ul.lang&gt;#swift&#x27;); // ä¸å‰ä¸¤è¡Œç­‰æ•ˆ èŠ‚ç‚¹ä¸­ç§»åŠ¨ æ­¤å°èŠ‚ä»‹ç»çš„æ‰€æœ‰å‡½æ•°éƒ½æ˜¯å½“æ— å‚æ•°è°ƒç”¨æ—¶ï¼Œè¿”å›ç›®æ ‡èŠ‚ç‚¹ã€‚ä¼ å…¥å‚æ•°æ—¶ï¼Œå‚æ•°æ˜¯è¿‡æ»¤æ¡ä»¶ï¼Œå½“ç¬¦åˆæ¡ä»¶æ—¶è¿”å›ç›®æ ‡èŠ‚ç‚¹ï¼Œä¸ç¬¦åˆæ—¶è¿”å›ç©º jQuery å¯¹è±¡ å¦‚æœè¦ä»å½“å‰èŠ‚ç‚¹å¼€å§‹å‘ä¸ŠæŸ¥æ‰¾ï¼Œä½¿ç”¨parent()æ–¹æ³•ï¼š 123var swf = $(&#x27;#swift&#x27;); // è·å¾—Swiftvar parent = swf.parent(); // è·å¾—Swiftçš„ä¸Šå±‚èŠ‚ç‚¹&lt;ul&gt;var a = swf.parent(&#x27;.red&#x27;); // è·å¾—Swiftçš„ä¸Šå±‚èŠ‚ç‚¹&lt;ul&gt;ï¼ŒåŒæ—¶ä¼ å…¥è¿‡æ»¤æ¡ä»¶ã€‚å¦‚æœulä¸ç¬¦åˆæ¡ä»¶ï¼Œè¿”å›ç©ºjQueryå¯¹è±¡ å¯¹äºä½äºåŒä¸€å±‚çº§çš„èŠ‚ç‚¹ï¼Œå¯ä»¥é€šè¿‡next()å’Œprev()æ–¹æ³•ï¼Œä¾‹å¦‚å½“æˆ‘ä»¬å·²ç»æ‹¿åˆ°SwiftèŠ‚ç‚¹åï¼š 1234567var swift = $(&#x27;#swift&#x27;);swift.next(); // Schemeswift.next(&#x27;[name=haskell]&#x27;); // ç©ºçš„jQueryå¯¹è±¡ï¼Œå› ä¸ºSwiftçš„ä¸‹ä¸€ä¸ªå…ƒç´ Schemeä¸ç¬¦åˆæ¡ä»¶[name=haskell]swift.prev(); // Pythonswift.prev(&#x27;.dy&#x27;); // Pythonï¼Œå› ä¸ºPythonåŒæ—¶ç¬¦åˆè¿‡æ»¤å™¨æ¡ä»¶.dy å‡½æ•°å¼ç¼–ç¨‹ filter()æ–¹æ³•å¯ä»¥è¿‡æ»¤æ‰ä¸ç¬¦åˆé€‰æ‹©å™¨æ¡ä»¶çš„èŠ‚ç‚¹ï¼š 12var langs = $(&#x27;ul.lang li&#x27;); // æ‹¿åˆ°JavaScript, Python, Swift, Schemeå’ŒHaskellvar a = langs.filter(&#x27;.dy&#x27;); // æ‹¿åˆ°JavaScript, Python, Scheme æˆ–è€…ä¼ å…¥ä¸€ä¸ªå‡½æ•°ï¼Œè¦ç‰¹åˆ«æ³¨æ„å‡½æ•°å†…éƒ¨çš„thisè¢«ç»‘å®šä¸ºDOMå¯¹è±¡ï¼Œä¸æ˜¯jQueryå¯¹è±¡ï¼š 1234var langs = $(&#x27;ul.lang li&#x27;); // æ‹¿åˆ°JavaScript, Python, Swift, Schemeå’ŒHaskelllangs.filter(function () &#123; return this.innerHTML.indexOf(&#x27;S&#x27;) === 0; // è¿”å›Så¼€å¤´çš„èŠ‚ç‚¹&#125;); // æ‹¿åˆ°Swift, Scheme map()æ–¹æ³•æŠŠä¸€ä¸ªjQueryå¯¹è±¡åŒ…å«çš„è‹¥å¹²DOMèŠ‚ç‚¹è½¬åŒ–ä¸ºå…¶ä»–å¯¹è±¡ï¼š 1234var langs = $(&#x27;ul.lang li&#x27;); // æ‹¿åˆ°JavaScript, Python, Swift, Schemeå’ŒHaskellvar arr = langs.map(function () &#123; return this.innerHTML;&#125;).get(); // ç”¨get()æ‹¿åˆ°åŒ…å«stringçš„Arrayï¼š[&#x27;JavaScript&#x27;, &#x27;Python&#x27;, &#x27;Swift&#x27;, &#x27;Scheme&#x27;, &#x27;Haskell&#x27;] Modifying DOM Contents HTML æœ¬å°èŠ‚ä½¿ç”¨ä»¥ä¸‹ä¾‹å­ï¼š 12345&lt;!-- HTMLç»“æ„ --&gt;&lt;ul id=&quot;test-ul&quot;&gt; &lt;li class=&quot;js&quot;&gt;JavaScript&lt;/li&gt; &lt;li name=&quot;book&quot;&gt;Java &amp;amp; JavaScript&lt;/li&gt;&lt;/ul&gt; ä½¿ç”¨ text() å’Œ html() æ–¹æ³•åˆ†åˆ«è·å–èŠ‚ç‚¹çš„æ–‡æœ¬å’ŒåŸå§‹HTMLæ–‡æœ¬ã€‚æ— å‚æ•°è°ƒç”¨æ˜¯è·å–æ–‡æœ¬/HTMLï¼Œä¼ å…¥å‚æ•°å°±å˜æˆè®¾ç½®æ–‡æœ¬/HTMLã€‚ 123456$(&#x27;#test-ul li[name=book]&#x27;).text(); // &#x27;Java &amp; JavaScript&#x27;$(&#x27;#test-ul li[name=book]&#x27;).html(); // &#x27;Java &amp;amp; JavaScript&#x27;var j1 = $(&#x27;#test-ul li.js&#x27;);j1.html(&#x27;&lt;span style=&quot;color: red&quot;&gt;JavaScript&lt;/span&gt;&#x27;); // ç¬¬ä¸€è¡Œè¢«è®¾ç½®æˆçº¢è‰²çš„ JavaScript$(&#x27;#test-ul li[name=book]&#x27;).text(&#x27;ä¹¦&#x27;); // ç¬¬äºŒè¡Œè¢«è®¾ç½®æˆ &quot;ä¹¦&quot; ä¸€ä¸ªjQueryå¯¹è±¡å¯ä»¥åŒ…å«0ä¸ªæˆ–ä»»æ„ä¸ªDOMå¯¹è±¡ï¼Œå®ƒçš„æ–¹æ³•å®é™…ä¸Šä¼šä½œç”¨åœ¨å¯¹åº”çš„æ¯ä¸ªDOMèŠ‚ç‚¹ä¸Šã€‚å¦‚æœä½œç”¨åœ¨ä¸€ä¸ªç©ºçš„ jQuery èŠ‚ç‚¹ä¸Šï¼Œä¹Ÿä¸ä¼šæŠ¥é”™ 12$(&#x27;#test-ul li&#x27;).text(&#x27;JS&#x27;); // ä¸¤ä¸ªèŠ‚ç‚¹éƒ½å˜æˆäº†JS$(&#x27;#not-exist&#x27;).text(&#x27;Hello&#x27;); // ä¸ä¼šæŠ¥é”™ï¼Œæ²¡æœ‰èŠ‚ç‚¹è¢«è®¾ç½®æˆ &#x27;Hello&#x27; CSS å’Œ HTML ç±»ä¼¼ï¼Œå¯¹ jQuery å¯¹è±¡ä¸‹çš„ css('name') è¯»å– CSS å±æ€§ï¼Œ css('name', 'value') æ–¹æ³•è®¾ç½® CSS å±æ€§ 12345var div = $(&#x27;#test-div&#x27;);div.css(&#x27;color&#x27;); // &#x27;#000033&#x27;, è·å–CSSå±æ€§div.css(&#x27;color&#x27;, &#x27;#336699&#x27;); // è®¾ç½®CSSå±æ€§div.css(&#x27;color&#x27;, &#x27;&#x27;); // æ¸…é™¤CSSå±æ€§div.css(&#x27;background-color&#x27;, &#x27;#ffd351&#x27;).css(&#x27;color&#x27;, &#x27;red&#x27;); // è¿ç»­è®¾ç½®ä¸¤ä¸ª CSS å±æ€§ Modifying DOM Structure å¯¹äºå¦‚ä¸‹HTMLç‰‡æ®µï¼Œ 12345678&lt;div id=&quot;test-div&quot;&gt; &lt;ul&gt; &lt;li&gt;&lt;span&gt;JavaScript&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;span&gt;Python&lt;/span&gt;&lt;/li&gt; &lt;li&gt;&lt;span&gt;Swift&lt;/span&gt;&lt;/li&gt; &lt;/ul&gt;&lt;/div&gt; æ·»åŠ  DOM é¦–å…ˆè¦æ‹¿åˆ°&lt;ul&gt;èŠ‚ç‚¹ï¼š 1var ul = $(&#x27;#test-div&gt;ul&#x27;); ç„¶åï¼Œè°ƒç”¨append()ä¼ å…¥HTMLç‰‡æ®µã€‚append()æŠŠDOMæ·»åŠ åˆ°æœ€åï¼Œprepend()åˆ™æŠŠDOMæ·»åŠ åˆ°æœ€å‰ã€‚ 1ul.append(&#x27;&lt;li&gt;&lt;span&gt;Haskell&lt;/span&gt;&lt;/li&gt;&#x27;); é™¤äº†æ¥å—å­—ç¬¦ä¸²ï¼Œappend()è¿˜å¯ä»¥ä¼ å…¥åŸå§‹çš„DOMå¯¹è±¡æˆ–jQueryå¯¹è±¡ 12345678// åˆ›å»ºDOMå¯¹è±¡:var ps = document.createElement(&#x27;li&#x27;);ps.innerHTML = &#x27;&lt;span&gt;Pascal&lt;/span&gt;&#x27;;// æ·»åŠ DOMå¯¹è±¡:ul.append(ps);// æ·»åŠ jQueryå¯¹è±¡:ul.append($(&#x27;#scheme&#x27;)); åŒçº§èŠ‚ç‚¹å¯ä»¥ç”¨after()æˆ–è€…before()æ–¹æ³•ã€‚å³å¦‚æœè¦æŠŠæ–°èŠ‚ç‚¹æ’å…¥åˆ°æŒ‡å®šä½ç½®ï¼Œä¾‹å¦‚ï¼ŒJavaScriptå’ŒPythonä¹‹é—´ï¼Œé‚£ä¹ˆï¼Œå¯ä»¥å…ˆå®šä½åˆ°JavaScriptï¼Œç„¶åç”¨after()æ–¹æ³•ï¼š 12var js = $(&#x27;#test-div&gt;ul&gt;li:first-child&#x27;);js.after(&#x27;&lt;li&gt;&lt;span&gt;Lua&lt;/span&gt;&lt;/li&gt;&#x27;); åˆ é™¤ DOM è¦åˆ é™¤DOMèŠ‚ç‚¹ï¼Œæ‹¿åˆ°jQueryå¯¹è±¡åç›´æ¥è°ƒç”¨remove()æ–¹æ³•å°±å¯ä»¥äº†ã€‚å¦‚æœjQueryå¯¹è±¡åŒ…å«è‹¥å¹²DOMèŠ‚ç‚¹ï¼Œå®é™…ä¸Šå¯ä»¥ä¸€æ¬¡åˆ é™¤å¤šä¸ªDOMèŠ‚ç‚¹ï¼š 12var li = $(&#x27;#test-div&gt;ul&gt;li&#x27;);li.remove(); // æ‰€æœ‰&lt;li&gt;å…¨è¢«åˆ é™¤ Event å‡è®¾è¦åœ¨ç”¨æˆ·ç‚¹å‡»äº†è¶…é“¾æ¥æ—¶å¼¹å‡ºæç¤ºæ¡†ï¼Œæˆ‘ä»¬ç”¨jQueryè¿™æ ·ç»‘å®šä¸€ä¸ªclickäº‹ä»¶ï¼š 1234567891011/* HTML: * * &lt;a id=&quot;test-link&quot; href=&quot;#0&quot;&gt;ç‚¹æˆ‘è¯•è¯•&lt;/a&gt; * */// è·å–è¶…é“¾æ¥çš„jQueryå¯¹è±¡:var a = $(&#x27;#test-link&#x27;);a.on(&#x27;click&#x27;, function () &#123; alert(&#x27;Hello!&#x27;);&#125;); onæ–¹æ³•ç”¨æ¥ç»‘å®šä¸€ä¸ªäº‹ä»¶ï¼Œæˆ‘ä»¬éœ€è¦ä¼ å…¥äº‹ä»¶åç§°å’Œå¯¹åº”çš„å¤„ç†å‡½æ•°ã€‚ å¦ä¸€ç§æ›´ç®€åŒ–çš„å†™æ³•æ˜¯ç›´æ¥è°ƒç”¨click()æ–¹æ³•ï¼šä¸¤è€…å®Œå…¨ç­‰ä»·ã€‚æˆ‘ä»¬é€šå¸¸ç”¨è¿™ç§å†™æ³•ã€‚ 123a.click(function () &#123; alert(&#x27;Hello!&#x27;);&#125;); äº‹ä»¶ç±»å‹ é¼ æ ‡äº‹ä»¶ click: é¼ æ ‡å•å‡»æ—¶è§¦å‘ï¼› dblclickï¼šé¼ æ ‡åŒå‡»æ—¶è§¦å‘ï¼› mouseenterï¼šé¼ æ ‡è¿›å…¥æ—¶è§¦å‘ï¼› mouseleaveï¼šé¼ æ ‡ç§»å‡ºæ—¶è§¦å‘ï¼› mousemoveï¼šé¼ æ ‡åœ¨DOMå†…éƒ¨ç§»åŠ¨æ—¶è§¦å‘ï¼› hoverï¼šé¼ æ ‡è¿›å…¥å’Œé€€å‡ºæ—¶è§¦å‘ä¸¤ä¸ªå‡½æ•°ï¼Œç›¸å½“äºmouseenteråŠ ä¸Šmouseleaveã€‚ é”®ç›˜äº‹ä»¶ é”®ç›˜äº‹ä»¶ä»…ä½œç”¨åœ¨å½“å‰ç„¦ç‚¹çš„DOMä¸Šï¼Œé€šå¸¸æ˜¯&lt;input&gt;å’Œ&lt;textarea&gt;ã€‚ keydownï¼šé”®ç›˜æŒ‰ä¸‹æ—¶è§¦å‘ï¼› keyupï¼šé”®ç›˜æ¾å¼€æ—¶è§¦å‘ï¼› keypressï¼šæŒ‰ä¸€æ¬¡é”®åè§¦å‘ã€‚ å…¶ä»–äº‹ä»¶ focusï¼šå½“DOMè·å¾—ç„¦ç‚¹æ—¶è§¦å‘ï¼› blurï¼šå½“DOMå¤±å»ç„¦ç‚¹æ—¶è§¦å‘ï¼› changeï¼šå½“&lt;input&gt;ã€&lt;select&gt;æˆ–&lt;textarea&gt;çš„å†…å®¹æ”¹å˜æ—¶è§¦å‘ï¼› submitï¼šå½“&lt;form&gt;æäº¤æ—¶è§¦å‘ï¼› readyï¼šå½“é¡µé¢è¢«è½½å…¥å¹¶ä¸”DOMæ ‘å®Œæˆåˆå§‹åŒ–åè§¦å‘ã€‚ ready å…¶ä¸­ï¼Œreadyä»…ä½œç”¨äºdocumentå¯¹è±¡ã€‚ç”±äºreadyäº‹ä»¶åœ¨DOMå®Œæˆåˆå§‹åŒ–åè§¦å‘ï¼Œä¸”åªè§¦å‘ä¸€æ¬¡ï¼Œæ‰€ä»¥éå¸¸é€‚åˆç”¨æ¥å†™å…¶ä»–çš„åˆå§‹åŒ–ä»£ç ã€‚å‡è®¾æˆ‘ä»¬æƒ³ç»™ä¸€ä¸ª&lt;form&gt;è¡¨å•ç»‘å®šsubmitäº‹ä»¶ï¼Œä¸‹é¢çš„ä»£ç æ²¡æœ‰é¢„æœŸçš„æ•ˆæœï¼š 1234567891011121314&lt;html&gt;&lt;head&gt; &lt;script&gt; // ä»£ç æœ‰è¯¯: $(&#x27;#testForm&#x27;).on(&#x27;submit&#x27;, function () &#123; alert(&#x27;submit!&#x27;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;form id=&quot;testForm&quot;&gt; ... &lt;/form&gt;&lt;/body&gt; å› ä¸ºJavaScriptåœ¨æ­¤æ‰§è¡Œçš„æ—¶å€™ï¼Œ&lt;form&gt;å°šæœªè½½å…¥æµè§ˆå™¨ï¼Œæ‰€ä»¥$('#testForm)è¿”å›[]ï¼Œå¹¶æ²¡æœ‰ç»‘å®šäº‹ä»¶åˆ°ä»»ä½•DOMä¸Šã€‚æ‰€ä»¥æˆ‘ä»¬è‡ªå·±çš„åˆå§‹åŒ–ä»£ç å¿…é¡»æ”¾åˆ°documentå¯¹è±¡çš„readyäº‹ä»¶ä¸­ï¼Œä¿è¯DOMå·²å®Œæˆåˆå§‹åŒ–ã€‚è¿™æ ·å†™å°±æ²¡æœ‰é—®é¢˜äº†ã€‚å› ä¸ºç›¸å…³ä»£ç ä¼šåœ¨DOMæ ‘åˆå§‹åŒ–åå†æ‰§è¡Œã€‚ 123456789101112131415&lt;html&gt;&lt;head&gt; &lt;script&gt; $(document).on(&#x27;ready&#x27;, function () &#123; $(&#x27;#testForm).on(&#x27;submit&#x27;, function () &#123; alert(&#x27;submit!&#x27;); &#125;); &#125;); &lt;/script&gt;&lt;/head&gt;&lt;body&gt; &lt;form id=&quot;testForm&quot;&gt; ... &lt;/form&gt;&lt;/body&gt; ç”±äºreadyäº‹ä»¶ä½¿ç”¨éå¸¸æ™®éï¼Œæ‰€ä»¥å¯ä»¥è¿™æ ·ç®€åŒ–ï¼š 123456$(document).ready(function () &#123; // on(&#x27;submit&#x27;, function)ä¹Ÿå¯ä»¥ç®€åŒ–: $(&#x27;#testForm).submit(function () &#123; alert(&#x27;submit!&#x27;); &#125;);&#125;); ç”šè‡³è¿˜å¯ä»¥å†ç®€åŒ–ä¸ºï¼š 123$(function () &#123; // init...&#125;); ä¸Šé¢çš„è¿™ç§å†™æ³•æœ€ä¸ºå¸¸è§ã€‚å¦‚æœä½ é‡åˆ°$(function () &#123;...&#125;)çš„å½¢å¼ï¼Œç‰¢è®°è¿™æ˜¯documentå¯¹è±¡çš„readyäº‹ä»¶å¤„ç†å‡½æ•°ã€‚ å®Œå…¨å¯ä»¥åå¤ç»‘å®šäº‹ä»¶å¤„ç†å‡½æ•°ï¼Œå®ƒä»¬ä¼šä¾æ¬¡æ‰§è¡Œï¼š 123456789$(function () &#123; console.log(&#x27;init A...&#x27;);&#125;);$(function () &#123; console.log(&#x27;init B...&#x27;);&#125;);$(function () &#123; console.log(&#x27;init C...&#x27;);&#125;); äº‹ä»¶å‚æ•° æœ‰äº›äº‹ä»¶ï¼Œå¦‚mousemoveå’Œkeypressï¼Œæˆ‘ä»¬éœ€è¦è·å–é¼ æ ‡ä½ç½®å’ŒæŒ‰é”®çš„å€¼ï¼Œå¦åˆ™ç›‘å¬è¿™äº›äº‹ä»¶å°±æ²¡ä»€ä¹ˆæ„ä¹‰äº†ã€‚æ‰€æœ‰äº‹ä»¶éƒ½ä¼šä¼ å…¥Eventå¯¹è±¡ä½œä¸ºå‚æ•°ï¼Œå¯ä»¥ä»Eventå¯¹è±¡ä¸Šè·å–åˆ°æ›´å¤šçš„ä¿¡æ¯ï¼š 12345$(function () &#123; $(&#x27;#testMouseMoveDiv&#x27;).mousemove(function (e) &#123; $(&#x27;#testMouseMoveSpan&#x27;).text(&#x27;pageX = &#x27; + e.pageX + &#x27;, pageY = &#x27; + e.pageY); &#125;);&#125;); å–æ¶ˆç»‘å®š ä¸€ä¸ªå·²è¢«ç»‘å®šçš„äº‹ä»¶å¯ä»¥è§£é™¤ç»‘å®šï¼Œé€šè¿‡off('click', function)å®ç°ï¼š 12345678910function hello() &#123; alert(&#x27;hello!&#x27;);&#125;a.click(hello); // ç»‘å®šäº‹ä»¶// 10ç§’é’Ÿåè§£é™¤ç»‘å®š:setTimeout(function () &#123; a.off(&#x27;click&#x27;, hello);&#125;, 10000); éœ€è¦ç‰¹åˆ«æ³¨æ„çš„æ˜¯ï¼Œä¸‹é¢è¿™ç§å†™æ³•æ˜¯æ— æ•ˆçš„ï¼š 123456789// ç»‘å®šäº‹ä»¶:a.click(function () &#123; alert(&#x27;hello!&#x27;);&#125;);// è§£é™¤ç»‘å®š:a.off(&#x27;click&#x27;, function () &#123; alert(&#x27;hello!&#x27;);&#125;); è¿™æ˜¯å› ä¸ºä¸¤ä¸ªåŒ¿åå‡½æ•°è™½ç„¶é•¿å¾—ä¸€æ¨¡ä¸€æ ·ï¼Œä½†æ˜¯å®ƒä»¬æ˜¯ä¸¤ä¸ªä¸åŒçš„å‡½æ•°å¯¹è±¡ï¼Œoff('click', function () &#123;...&#125;)æ— æ³•ç§»é™¤å·²ç»‘å®šçš„ç¬¬ä¸€ä¸ªåŒ¿åå‡½æ•°ã€‚ ä¸ºäº†å®ç°ç§»é™¤æ•ˆæœï¼Œå¯ä»¥ä½¿ç”¨off('click')ä¸€æ¬¡æ€§ç§»é™¤å·²ç»‘å®šçš„clickäº‹ä»¶çš„æ‰€æœ‰å¤„ç†å‡½æ•°ã€‚ åŒç†ï¼Œæ— å‚æ•°è°ƒç”¨off()ä¸€æ¬¡æ€§ç§»é™¤å·²ç»‘å®šçš„æ‰€æœ‰ç±»å‹çš„äº‹ä»¶å¤„ç†å‡½æ•°ã€‚ äº‹ä»¶è§¦å‘æ¡ä»¶ ä¸€ä¸ªéœ€è¦æ³¨æ„çš„é—®é¢˜æ˜¯ï¼Œäº‹ä»¶çš„è§¦å‘æ€»æ˜¯ç”±ç”¨æˆ·æ“ä½œå¼•å‘çš„ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬ç›‘æ§æ–‡æœ¬æ¡†çš„å†…å®¹æ”¹åŠ¨ï¼š 1234var input = $(&#x27;#test-input&#x27;);input.change(function () &#123; console.log(&#x27;changed...&#x27;);&#125;); å½“ç”¨æˆ·åœ¨æ–‡æœ¬æ¡†ä¸­è¾“å…¥æ—¶ï¼Œå°±ä¼šè§¦å‘changeäº‹ä»¶ã€‚ä½†æ˜¯ï¼Œå¦‚æœç”¨JavaScriptä»£ç å»æ”¹åŠ¨æ–‡æœ¬æ¡†çš„å€¼ï¼Œå°†ä¸ä¼šè§¦å‘changeäº‹ä»¶ï¼š 12var input = $(&#x27;#test-input&#x27;);input.val(&#x27;change it!&#x27;); // æ— æ³•è§¦å‘changeäº‹ä»¶ æœ‰äº›æ—¶å€™ï¼Œæˆ‘ä»¬å¸Œæœ›ç”¨ä»£ç è§¦å‘changeäº‹ä»¶ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨æ— å‚æ•°çš„change()æ–¹æ³•æ¥è§¦å‘è¯¥äº‹ä»¶ï¼š 123var input = $(&#x27;#test-input&#x27;);input.val(&#x27;change it!&#x27;);input.change(); // è§¦å‘changeäº‹ä»¶ input.change()ç›¸å½“äºinput.trigger('change')ï¼Œå®ƒæ˜¯trigger()æ–¹æ³•çš„ç®€å†™ã€‚ ä¸ºä»€ä¹ˆæˆ‘ä»¬å¸Œæœ›æ‰‹åŠ¨è§¦å‘ä¸€ä¸ªäº‹ä»¶å‘¢ï¼Ÿå¦‚æœä¸è¿™ä¹ˆåšï¼Œå¾ˆå¤šæ—¶å€™ï¼Œæˆ‘ä»¬å°±å¾—å†™ä¸¤ä»½ä¸€æ¨¡ä¸€æ ·çš„ä»£ç ã€‚","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"åšå®¢SEOä¼˜åŒ–","slug":"2022-04-23-åšå®¢SEOä¼˜åŒ–","date":"2022-04-23T04:00:00.000Z","updated":"2022-06-08T19:37:38.000Z","comments":true,"path":"2022-04-23-åšå®¢SEOä¼˜åŒ–/","permalink":"https://yao-lirong.github.io/blog/2022-04-23-%E5%8D%9A%E5%AE%A2SEO%E4%BC%98%E5%8C%96/","excerpt":"è°·æ­Œå’Œæˆ‘ç½‘ç«™æœ‰ä»‡å—ï¼Œå¼„äº†å¥½å‡ å¤©ï¼Œæ€ä¹ˆåˆ«äººç­‰ä¸€å¤©å°±è¡Œäº†ï¼Œæˆ‘ç­‰ä¸€ä¸ªç¤¼æ‹œä¹Ÿæä¸å®šã€‚æ¢äº†åŸŸåä»¥åè¿˜ä¸å¦‚åŸæ¥ï¼ŒåŸæ¥è°·æ­Œè‡ªåŠ¨å°±ç»™æˆ‘ index äº†ã€‚è¿™æ ·æƒ³è¿˜æ˜¯è¦æ„Ÿè°¢è¥é”€å·å’Œçˆ¬è™«ï¼Œçˆ¬äº†æˆ‘ä¸€ä¸ªæˆ‘è‡ªå·±éƒ½çœ‹ä¸ä¸‹å»çš„é¢˜è§£ï¼Œç«Ÿç„¶è®©æˆ‘åŸæ¥çš„åšå®¢è¢«æ”¶å½•äº†ï¼Œå¯æƒœè¿™ä¸ªæ–°çš„å¼„èµ·æ¥å°±éº»çƒ¦äº†â€¦","text":"è°·æ­Œå’Œæˆ‘ç½‘ç«™æœ‰ä»‡å—ï¼Œå¼„äº†å¥½å‡ å¤©ï¼Œæ€ä¹ˆåˆ«äººç­‰ä¸€å¤©å°±è¡Œäº†ï¼Œæˆ‘ç­‰ä¸€ä¸ªç¤¼æ‹œä¹Ÿæä¸å®šã€‚æ¢äº†åŸŸåä»¥åè¿˜ä¸å¦‚åŸæ¥ï¼ŒåŸæ¥è°·æ­Œè‡ªåŠ¨å°±ç»™æˆ‘ index äº†ã€‚è¿™æ ·æƒ³è¿˜æ˜¯è¦æ„Ÿè°¢è¥é”€å·å’Œçˆ¬è™«ï¼Œçˆ¬äº†æˆ‘ä¸€ä¸ªæˆ‘è‡ªå·±éƒ½çœ‹ä¸ä¸‹å»çš„é¢˜è§£ï¼Œç«Ÿç„¶è®©æˆ‘åŸæ¥çš„åšå®¢è¢«æ”¶å½•äº†ï¼Œå¯æƒœè¿™ä¸ªæ–°çš„å¼„èµ·æ¥å°±éº»çƒ¦äº†â€¦ éªŒè¯æ‰€æœ‰æƒ é¦–å…ˆæˆ‘ä»¬éœ€è¦éªŒè¯ç½‘ç«™æ‰€æœ‰æƒï¼Œé€‰ç”¨ HTML tag æ–¹å¼ åœ¨ Hexo - Archer ä¸»é¢˜ä¸‹æ‰¾åˆ° layout - _partial - base-head.ejs ä¸­åœ¨ &lt;head&gt; tag ä¸‹æ·»åŠ éœ€è¦çš„éªŒè¯ tag å¯¹äºä¸åŒçš„ä¸»é¢˜ï¼Œä¸€ä¸ªå¿«é€Ÿæ‰¾åˆ° &lt;head&gt; åœ¨å“ªé‡Œç”Ÿæˆçš„æ–¹æ³•å°±æ˜¯ç›´æ¥æŸ¥æ‰¾ &lt;head&gt; tag æœ¬åœ°æ’ä»¶ç”Ÿæˆå¿…è¦æ–‡ä»¶ ä½¿ç”¨ npm install &lt;name&gt; --save å®‰è£…ä»¥ä¸‹å‡ ä¸ªæ’ä»¶: hexo-generator-robotstxt hexo-generator-sitemap hexo-generator-baidu-sitemap hexo-autonofollow Add the following pluginâ€™s settings to root directory _config.yml: 123456789101112131415161718192021222324252627sitemap: path: sitemap.xmlbaidusitemap: path: baidusitemap.xmlrobotstxt: useragent: &quot;*&quot; disallow: - /assets/ - /css/ - /avatar/ - /scripts/ - /font/ - /lib/ allow: - / - /archives/ - /categories/ - /tags/ - /about/ - /page/ sitemap: - https://yao-lirong.github.io/sitemap.xml - https://yao-lirong.github.io/baidusitemap.xmlnofollow: enable: true Google æœ‰äº›æ—¶å€™å¦‚æœä¸è¿›è¡Œè¿™äº›æ‰€è°“ã€ä¼˜åŒ–ã€ï¼Œä½ åªèƒ½ç­‰æœ‰äººé“¾æ¥åˆ°ä½ çš„é¡µé¢è°·æ­Œæ‰ä¼šæ”¶å½•ï¼Œæ‰€ä»¥è¿™äº›ä¼˜åŒ–å®é™…ä¸Šæ˜¯å¿…è¦çš„ã€‚ Canonical Tag ä¼˜åŒ–: å’Œå‰æ–‡ä¸€æ ·ï¼Œæ‰¾åˆ°åœ¨ &lt;head&gt; tag ä¸­å¯¹åº”ä½ç½®ï¼Œæ·»åŠ ä»¥ä¸‹ä»£ç  123456&lt;% var base_url = config.url; if (config.url.charAt(config.url.length - 1) !== &#x27;/&#x27;) base_url += &#x27;/&#x27;; var canonical_url = base_url + page.canonical_path.replace(&#x27;index.html&#x27;, &#x27;&#x27;);%&gt;&lt;link rel=&quot;canonical&quot; href=&quot;&lt;%= canonical_url %&gt;&quot;&gt; æäº¤ sitemap.xml: é¦–å…ˆä» Search Console ä¸­æäº¤ï¼Œåœ¨é€šè¿‡ ping æäº¤ä¸ŠåŒä¿é™© æäº¤ robots.txt: ä»è¿™é‡Œå¯ä»¥æäº¤å¹¶çœ‹åˆ°è°·æ­Œæœ€æ–°æŠ“å–åˆ°çš„ robots.txt æäº¤äº†è¿™äº›ä¸œè¥¿ä»¥åéœ€è¦ç­‰å¥½ä¹…ï¼Œè¿™æ—¶ä¸ºäº†ç¡®è®¤æˆ‘ä»¬ç½‘ç«™å•¥çš„ç¡®å®æ²¡é—®é¢˜ï¼Œå¿ƒç†æ±‚ä¸ªå®‰æ…°ï¼Œä½¿ç”¨ URL Inspection in Search Console, or directly at this link https://search.google.com/search-console/inspect?resource_id=&lt;url you want to check rn&gt;. å¦‚æœæ˜¾ç¤ºâ€URL is not on Googleâ€ï¼Œé€‰æ‹© â€œTEST LIVE URLâ€, åªè¦æˆ‘ä»¬çœ‹åˆ° â€œURL is available to Googleâ€ ä»¥åŠ â€œUser-declared canonicalâ€ è¿™ä¸€æ ç¡®å®æ˜¯æœ¬æ–‡ç½‘å€ä¸€èˆ¬å°±æ²¡é—®é¢˜ã€‚ æ­¤æ—¶ï¼Œä¸ºäº†åŠ å¿« index è¿›ç¨‹ï¼Œæˆ‘ä»¬å¯ä»¥ â€œRequest Indexingâ€ è™½ç„¶åªæœ‰è¿™ä¸€ä¸ª pageï¼Œä½†èŠéº»è‚‰ä¹Ÿæ˜¯è‚‰â€¦ Google Sitemap çš„é—®é¢˜ ä¸Šé¢ç”¨äº† URL inspection tool å…¨æ˜¯å› ä¸ºè€æ˜¾ç¤ºæˆ‘ sitemap couldnâ€™t fetch. æŸ¥è¯¢äº†ä¸€ä¸‹èƒ½åšçš„åªæœ‰ç­‰å¾…â€¦ è°·æ­Œå·¥ä½œäººå‘˜çš„å›å¤, ä¸€ä¸ªæè¿°é—®é¢˜æ¯”è¾ƒå…¨çš„ç½‘ç«™ Reference Hexoæœç´¢å¼•æ“ä¼˜åŒ–: å¤§éƒ¨åˆ†æœ‰ç”¨çš„ Google SEO ä¼˜åŒ–æ­¥éª¤éƒ½æ¥è‡ªè¿™é‡Œ Get Google to Index Your Site: ä»¥åŠå›½å¤–çš„ä¸€ä¸ªæ¯”è¾ƒå…¨çš„ Google æ’é›·ç½‘ç«™","categories":[],"tags":[{"name":"Logistics","slug":"Logistics","permalink":"https://yao-lirong.github.io/blog/tags/Logistics/"}]},{"title":"Video Editing (FFmpeg DaVinci)","slug":"2022-04-09-è§†é¢‘ç¼–è¾‘-(FFmpeg-DaVinci)","date":"2022-04-09T04:00:00.000Z","updated":"2023-05-18T09:48:32.000Z","comments":true,"path":"2022-04-09-è§†é¢‘ç¼–è¾‘-(FFmpeg-DaVinci)/","permalink":"https://yao-lirong.github.io/blog/2022-04-09-%E8%A7%86%E9%A2%91%E7%BC%96%E8%BE%91-(FFmpeg-DaVinci)/","excerpt":"ä¸»è¦è®°å½•è§†é¢‘çš„ä¸€äº›ç›¸å…³çŸ¥è¯†ä»¥åŠ FFmpeg å’Œ DaVinci çš„å¸¸è§ç”¨æ³•","text":"ä¸»è¦è®°å½•è§†é¢‘çš„ä¸€äº›ç›¸å…³çŸ¥è¯†ä»¥åŠ FFmpeg å’Œ DaVinci çš„å¸¸è§ç”¨æ³• FFmpeg - Video File Format Conversion For most simple tasks, you can just do 1ffmpeg -i input.avi output.mp4 and ffmpeg will figure out how to perform that conversion. FFmpeg åˆå¹¶æ–‡ä»¶: 12for f in *.flv; do echo &quot;file &#x27;$f&#x27;&quot; &gt;&gt; mylist.txt; doneffmpeg -f concat -i mylist.txt -c copy output.flv æ›´è¯¦ç»†çš„å®˜æ–¹æ–‡æ¡£åœ¨è¿™é‡Œã€‚å…·ä½“åœ°æ¥çœ‹ï¼Œæˆ‘ä»¬è¿™é‡Œç”¨çš„æ˜¯ concat demuxer, è¿™é¡¹åè®®æ”¯æŒä¸åŒçš„å®¹å™¨æ ¼å¼ï¼Œç”šè‡³æ˜¯æœ¬èº«ä¸æ”¯æŒ concat æ“ä½œçš„å®¹å™¨æ ¼å¼çš„åˆå¹¶ 1ffmpeg -i &quot;concat:input1|input2&quot; -codec copy output.mkv å¯¹äº ts ä¹‹ç±»æœ¬èº«æ”¯æŒ file-level concat çš„æ–‡ä»¶æ ¼å¼ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨å¦‚ä¸Šçš„ concat protocol (å‚è€ƒ stackoverflow ç­”æ¡ˆ1, ç­”æ¡ˆ2) FFmpeg è½¬æ¢æ ¼å¼: 12345# stream copy all streamsffmpeg -i input -map 0 -c copy output.mp4 # re-encode the video to H.264 and stream copy the audioffmpeg -i input.ts -c:v libx264 -c:a copy output.mp4 FFmpeg æ‰¹å¤„ç†è½¬æ¢æ ¼å¼: 12345#!/bin/bashfor i in *.avi;do ffmpeg -i &quot;$i&quot; -c:v libx265 -c:a copy X265_&quot;$i&quot;done Editing, Clipping, Encoding Extract Audio from Video: where -vn disables video processing 12ffmpeg -i input.mp4 -vn -acodec copy output-audio.aac # extract aacffmpeg -i input.mp4 -vn -acodec copy output-audio.opus # extract opus FFmpegæŸ¥çœ‹åª’ä½“ä¿¡æ¯: ä½¿ç”¨ ffprobe Extract Subtitles: On hdmv_pgs_subtitle, where we need sup format. 12ffmpeg -i video.mkv -map 0:s:0 -c copy subs.supffmpeg -i Movie.mkv -map 0:s:0 -c copy subs.srt FFmpeg H.265 Reencode: if you use all the settings as default, just do: 1ffmpeg -i input -c:v libx265 -c:a copy output.mp4 Clip Video: you should primarily read this wiki page, which introduces you to seeking in ffmpeg. In short, you should use -ss before -i in most cases. 1234567891011# -ss used before -i: parse input using keyframes, which is very fast# gives exactly the same outputffmpeg -ss 00:40:30 -i 20170301.mp4 -t 310 -c copy 1.mp4 ffmpeg -ss 00:40:30 -to 00:45:40 -i 20170301.mp4 -c copy 2.mp4# -ss used after -i: decodes but discards input until the timestamps reach position. # which is done very slowly, frame by frameffmpeg -i 20170301.mp4 -ss 00:40:30 -to 00:45:40 -c copy 3.mp4# Doesn&#x27;t work, will output something at most 45:40 longffmpeg -ss 00:40:30 -i 20170301.mp4 -to 00:45:40 -c copy 4.mp4 Broken File Fix Fill Missing Time Stamps with Empty Audio: 1ffmpeg -i input -af aresample=async=1 output.wav Fill Missing Frames (Change Variable Frame to Constant Frame): 1ffmpeg -i input -vf &quot;fps=30&quot; output.mp4 Create a Silent Audio Track 1ffmpeg -f lavfi -i anullsrc=channel_layout=stereo:sample_rate=44100 -i video.mov -c:v copy -c:a aac -shortest output.mov Others ffmpeg download m3u8 file with custome user-agent: If flag -user_agent is not working, you can use -headers, referenced here 12ffmpeg -user_agent &quot;SNH48 ENGINE&quot; -i &quot;https://xxx.m3u8&quot; -codec copy file.mp4ffmpeg -headers &#x27;User-Agent: Mozilla&#x27; -i &quot;https://xxx.m3u8&quot; -codec copy file.mp4 https://superuser.com/questions/1041816/combine-one-image-one-audio-file-to-make-one-video-using-ffmpeg FFmpeg - Audio ï¼ï¼ï¼æ•´ç†ï¼ï¼ï¼ https://stackoverflow.com/questions/46508055/using-ffmpeg-to-cut-audio-from-to-position https://stackoverflow.com/questions/71158575/output-file-is-empty-nothing-was-encoded-check-ss-t-frames-parameters-i 123ffmpeg -ss 60 -i presentation.aac -t 240 -c copy presentation_song.aac å¥½ç”¨ffmpeg -ss 60 -t 240 -i presentation.aac -c copy presentation_song.aac ä¸å¥½ç”¨ convert file format to .ogg with specififed sample rate: here we specified sample rate to be 44.1K 1ffmpeg -i input.wav -c:a libvorbis -ar 44100 output.ogg 1234567ffmpeg -framerate 30 -i z_Blue1_1_60_%d.png -c:v libx264 -r 30 output.mp4for color in &quot;Blue&quot; &quot;Red&quot; &quot;Green&quot; &quot;Yellow&quot;; do for ((i=1; i&lt;=3; i++)); do printf &quot;%s%d_1_60.png\\n&quot; &quot;$color&quot; &quot;$i&quot;; done; doneffmpeg -framerate 15 -i z_Blue1_1_60.png_%d.png -c:v libx264 -r 15 output.mp4è®°å¾—çœ‹ aphelion-defense/assets/textures/60/test.sh DaVinci Import and Bake Subtitles in DaVinci Zoom In and Zoom Out in DaVinci: achieve with key frames How to Fade in and Out Video Vertical timeline (Tiktok style) How to Control Audio Volume Levels ç¼–ç è§£ç æ ¼å¼ ç”¨ IDM ä¸‹è½½ YouTube ä¸Šè§†é¢‘ä¼šæœ‰ä¸¤ç§æ ¼å¼ mkv å’Œ mp4 ä¸¤ç§æ ¼å¼ï¼Œç»“è®ºï¼šmkv æ ¼å¼æ›´ä¼˜ éƒ½ä¸‹è½½ä¸‹æ¥åä½¿ç”¨ PotPlayer æ’­æ”¾æ—¶æŸ¥çœ‹å‘ç° mkv æ ¼å¼éœ€è¦ä½¿ç”¨ FFmpeg libdav1d decoder mp4 æ ¼å¼éœ€è¦ä½¿ç”¨ FFmpeg h264 decoder ä½¿ç”¨ ffprobe å‘ç° mkv æ ¼å¼ä½¿ç”¨ av1 æ ¼å¼ç¼–ç  mp4 æ ¼å¼ä½¿ç”¨ h264 æ ¼å¼ç¼–ç  æŸ¥è¯¢èµ„æ–™å¾—çŸ¥ av1 æ˜¯è°·æ­Œæ–°å‘å¸ƒçš„ç¼–è§£ç è§„èŒƒï¼Œç›¸æ¯” h265 å‹ç¼©ä¼˜åŠ¿éƒ½å¾ˆå¤§ï¼Œå°±ä¸ç”¨è¯´ h264 äº†ã€‚IDM å®˜æ–¹ä¹Ÿæ¨èä½¿ç”¨ av1 ç¼–ç çš„ mkv æ ¼å¼ã€‚ï¼ˆå®˜æ–¹FAQ: Can I download MP4 instead of MKV or what should I do to play MKV videos correctly? | I cannot play downloaded MKV video. What should I do?ï¼‰ One caveat: Google seems to be using vp9 as the encoder of live stream, but this is still better than h264 in mp4. å¯¹äº SNH48 å…¬æ¼”å½•æ’­æºï¼Œå‘ç°å®˜ç½‘æºä½¿ç”¨ h264 ts ç¼–ç ï¼ŒYouTube æºå¤§æ¦‚æ˜¯å•ç‹¬æ¨æµï¼Œè°·æ­Œç¼–ç ä¸º vp9ï¼Œä¸” YouTube æºæœ‰ 1080Pï¼Œå®˜ç½‘åªæœ‰720Pã€‚æ•…ä¼˜å…ˆé€‰æ‹© YouTube æº ï¼ˆä½†æ˜¯åæ¥å‘ç° YouTube æºå¥½åƒéŸ³é¢‘æ˜¯ opus æ ¼å¼ï¼ŒDavinci è¯†åˆ«ä¸äº†ï¼Œæœ€åç”¨çš„è¿˜æ˜¯åˆ«äººçš„ bilibili æºï¼‰","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"2021 Web Journal","slug":"2021-12-31-2021-ç½‘ç»œæ—¥å¿—","date":"2021-12-31T05:00:00.000Z","updated":"2023-12-26T14:25:01.578Z","comments":true,"path":"2021-12-31-2021-ç½‘ç»œæ—¥å¿—/","permalink":"https://yao-lirong.github.io/blog/2021-12-31-2021-%E7%BD%91%E7%BB%9C%E6%97%A5%E5%BF%97/","excerpt":"å¼€å§‹å­¦ä¹ é˜®ä¸€å³°è®°å½•è‡ªå·±çœ‹åˆ°çš„æœ‰æ„æ€çš„æ–‡ç« å’Œæ”¶é›†æœ‰ç”¨çš„å·¥å…·çš„ç¬¬ä¸€ä¸ªæ•´å¹´ The best science images of 2021","text":"å¼€å§‹å­¦ä¹ é˜®ä¸€å³°è®°å½•è‡ªå·±çœ‹åˆ°çš„æœ‰æ„æ€çš„æ–‡ç« å’Œæ”¶é›†æœ‰ç”¨çš„å·¥å…·çš„ç¬¬ä¸€ä¸ªæ•´å¹´ The best science images of 2021 å·¥å…·çš„ä½¿ç”¨ VScodeæ ¹æ®ä¸åŒè¯­è¨€è®¾ç½®ä¸åŒtabä»£è¡¨çš„ç©ºæ ¼ä¸ªæ•° åœ¨LINUXç³»ç»Ÿä¸‹ä½¿ç”¨SSHç™»é™†ä¸Šè·¯ç”±å™¨: æ³¨æ„å¯ä»¥ä½¿ç”¨flagfoxçœ‹ä¸€çœ¼è·¯ç”±å™¨çš„IP addressåˆ°åº•æ˜¯ä»€ä¹ˆï¼Œusernameå°±æ˜¯ç™»é™†è·¯ç”±å™¨ä½¿ç”¨çš„ç”¨æˆ·åï¼Œå¦‚æœä¸¤ä¸ªéƒ½å¡«å†™æ­£ç¡®æ˜¯ä¸ä¼šå‡ºç° â€œport XX refused connectionâ€è¿™ç§æƒ…å†µçš„ ï¼ˆè®°å¾—å¼€ merlin çš„ ssh è®¸å¯ï¼šAdministration - System - Enable SSHï¼‰ 1ssh &lt;username&gt;@&lt;IP_address&gt; æ‰¹é‡åˆæˆbilibiliçš„m4sç¼“å­˜æ–‡ä»¶ä¸ºMP4æ ¼å¼ ç¦ç”¨Windows Terminalå¤šè¡Œç²˜è´´çš„è­¦å‘Š apt vs apt-get: ç®€å•æ¥è¯´ï¼Œaptæ˜¯æ›´æ–°çš„é›†åˆç‰ˆçš„ apt-getï¼Œåº”è¯¥å°½é‡ä½¿ç”¨ apt ä¸ºæ—¥æ–‡æ–‡æ¡£æ·»åŠ æŒ¯ã‚Šä»®åçš„wordå® CodeBlocks è¿è¡Œé—®é¢˜è§£å†³: ld.exe: cannot open output file â€¦ : Permission denied Convert HTML back to Markdown with Pandoc: pandoc -f html --wrap=none -t markdown -o test.md &lt;filename&gt;. Experiment with --wrap=none/preserve/auto to choose the best. showdownjs: online two-way markdown and html converter GitHub ä»Šå¹´å¯¹äº Windows å˜ä¸ºå¼ºåˆ¶éœ€è¦ tokenï¼Œä¸”åªæœ‰ HTTPS æ‰èƒ½ä½¿ç”¨ Token Capture Group in Regex: When matching a pattern, use parenthesis (some_pattern_you_try_to_match) to define a capture group. (Two references: succinct, more detailed) Zotero åœ¨è®ºæ–‡å¯¹åº”åŸå§‹ç½‘é¡µç›´æ¥ä½¿ç”¨æµè§ˆå™¨æ’ä»¶è·å–çš„ä¿¡æ¯æœ€å…¨ï¼Œå¦‚æœæ²¡æœ‰å¯¹è¿™ä¹ˆå…¨é¢çš„ä¿¡æ¯çš„è¦æ±‚ï¼Œå¯ä»¥åœ¨ Google Scholar é¡µé¢é€‰æ‹© Cite -&gt; Refman (Refman æ¯” Endnote æ ¼å¼è·å–ä¿¡æ¯æ›´å¤šä¸€äº›) æ¶¨æŠ€æœ¯çŸ¥è¯† The intuition behind Shannonâ€™s Entropy BTæœ¯è¯­çš„è§£é‡Š åè®®æ··ä¹±çš„ USB-C What is SSH Port Forwarding and how does it work: å›¾ç¤ºå†™çš„ç‰¹åˆ«å¥½ æ··è¿¹äºäº’è”ç½‘ ä¸€çº¿ä¸ªäººç ´è§£åŠæ•´åˆ å¤§çœ¼ä»”æ—­, è½å°˜ä¹‹æœ¨, 423down, æœå£³å‰¥å£³ äºŒçº¿ç½‘èµšæ¬è¿ Nite07çš„å°çª, å°å†°ä¸‹è½½ç«™, ä½›ç³»è½¯ä»¶ Adobe å¤§ç¥ç ´è§£ç‰ˆ by vposy, å¤©æä¸‹è½½ PC è½¯ä»¶å†å²ç‰ˆæœ¬, apkdownload(æ¯” apkpure å…¨), ç ´è§£apk Moddroid ä¼Šæœ—PCè½¯ä»¶ç ´è§£, from èƒ¡èåœå‘¨ ç½‘ç«™æ¨è æŠ˜è…¾ Pot+LAV+madVRé…ç½®æ•™ç¨‹: ä½¿ç”¨ Icaros æ˜¾ç¤ºå¤šç§è§†é¢‘æ–‡ä»¶ç¼©ç•¥å›¾ ç¦ç”¨Win10è‡ªåŠ¨æ›´æ–°: configure automatic updates æ¿å— Disable Firefox Auto-Update: Go to about:policies to check flags that could be set. Create a policies.json, create a directory called distribution where the EXE is located, and place the json file there on Windows. åœ¨äº”ç§ä¸åŒç³»ç»Ÿä¸Šéƒ¨ç½²Rimeå¹¶åŒæ­¥ Web Annotation Tools: diigo: è¶…äº†æœ€é«˜å®¹é‡äº† weava: æ­£åœ¨ç”¨ beanote: å¯ä»¥è¯•è¯•ï¼Œè®°å½•ä¿å­˜åœ¨æœ¬åœ°ï¼Œæ— äº‘ç«¯æœåŠ¡ additor, Hypothesis: é‡ç‚¹å¹¶ä¸åœ¨è‡ªå·±çš„æœåŠ¡ä¿å­˜ï¼Œè€Œæ˜¯åœ¨åä½œï¼Œæƒ³ç­‰ä»–ä»¬ä¸€é˜µå­çœ‹çœ‹å‘å±•æ•ˆæœï¼Œç»“æœæœ€è¿‘åˆç”¨äº†ä¸€æ¬¡è¿˜æ˜¯ä¸å¥½ç”¨ å€¼å¾—çºªå¿µçš„æ–°é—» ä¼˜ç§€çš„ä»˜è´¹æ–°é—»èµ„è®¯ï¼šFTä¸­æ–‡ç½‘ï¼Œè´¢æ–°ç½‘ï¼Œè´¢ç»ç½‘ï¼Œ èƒ½å¤„çš„æ—¥æœ¬æ–°é—»ï¼šæ—¥æœ¬ç»æµæ–°é—», æœæ—¥æ–°é—», èµå¹ï½œé”¤å­æ‰‹æœºæœªå¿…æœ€å¥½ï¼Œä½†ä»–ä»¬çš„è®¾è®¡å¸ˆéƒ½å€¼å¾—è‡´æ•¬ ï¼ˆç°åœ¨çš„ç¤¾ä¼šï¼‰ä¸æ˜¯ä¸ºäº†äººçš„å‘å±•ï¼Œè€Œæ˜¯äººä¸ºäº†è¿™äº›ä¸œè¥¿è€Œå‘å±•ï¼Œåè¿‡æ¥äº†ã€‚è¿™äº›é’¢ç­‹æ°´æ³¥ï¼Œä¸€äº›æ•°æ®åä¸½çš„åŠå…¬æ¥¼ï¼Œä¸€äº›å†°å†·çš„æ²¡æœ‰ä»€ä¹ˆä»·å€¼çš„ä¸œè¥¿ï¼Œå·²ç»æˆä¸ºäº†äººè¿½æ±‚çš„å…¨éƒ¨äº†ã€‚ â€“ â€œèººå¹³å­¦å¤§å¸ˆâ€ï¼šä¸€ä¸ªå¥½çš„ç¤¾ä¼šæ˜¯å¯ä¸Šå¯ä¸‹çš„ æœ«æ—¥æ—¶é’Ÿ å…¨çƒäººå£è¡°é€€æœŸä¸´è¿‘ï¼Œç»æµæ–¹ç¨‹å¼åœ¨å˜, 30ä¸‡å¹´å†å²ä¸Šä¸¤æ¬¡é©å‘½è®©äººç±»ç¹è£ï¼Œåˆ°äº†è½¬æŠ˜ç‚¹ï¼Ÿ æ”¹å˜äººå£å¢é•¿è¶‹åŠ¿çš„æ˜¯å¥³æ€§çš„æ•™è‚²ç¨‹åº¦æé«˜å’ŒåŠ é€Ÿè¿›å…¥ç¤¾ä¼šå¯¼è‡´ç”Ÿè‚²ç‡ä¸‹é™ã€‚1åå¥³æ€§ä¸€ç”Ÿç”Ÿè‚²çš„å­©å­æ•°é‡ï¼ˆæ€»å’Œç”Ÿè‚²ç‡ï¼‰2017å¹´ä¸º2.4ï¼Œé€¼è¿‘äººå£æ— æ³•å¢é•¿çš„2.1ã€‚å°‘å­åŒ–æ˜¯æ¯ä¸ªäººçš„äººç”Ÿé€‰æ‹©ä¸æ–­ç´¯ç§¯çš„ç»“æœï¼Œå‡ ä¹æ²¡æœ‰ä¸€ä¸ªå›½å®¶èƒ½æ‰­è½¬å±€é¢ã€‚äººå£å¢é•¿ç‡åœ¨20ä¸–çºª60å¹´ä»£ååŠæœŸè¾¾åˆ°2.09ï¼…çš„å³°å€¼ï¼Œç°åœ¨å·²ç»ä¸‹é™åˆ°1ï¼…å·¦å³ã€‚ è„±ç¢³ä¹‹è·¯å­˜åœ¨èƒ½æºä¾›éœ€æ–­è£‚é£é™©: æ— è®ºä»¥ä¿å­˜ç°çŠ¶æˆ–æ¨åŠ¨å‡ç¢³ä¸ºå‰æï¼Œé¢„æµ‹2050å¹´çŸ³æ²¹å¤©ç„¶æ°”éœ€æ±‚ä»ç„¶é«˜äºç°åœ¨ã€‚å³ä¾¿å¦‚æ­¤ï¼Œæ¬§ç¾å›½é™…çŸ³æ²¹èµ„æœ¬è¿˜æ˜¯å¼€å§‹å‡å°‘å¯¹æ²¹ç”°å’Œæ°”ç”°çš„æŠ•èµ„ã€‚ç„¶è€Œä¸­ä¸œç”±äºä»–å›½å‡äº§ï¼Œæ­£åœ¨é€æ­¥æ‰©å¤§äº§èƒ½ã€‚å¦‚æœä»…ä»…æ˜¯ä¸­ä¸œå¢åŠ æŠ•èµ„ï¼Œå„æ–­åº¦æé«˜çš„è¯å°†ç»™ä¸–ç•Œçš„æ”¿æ²»å’Œç»æµå¸¦æ¥å¾ˆå¤§é£é™©ã€‚","categories":[],"tags":[{"name":"Journal","slug":"Journal","permalink":"https://yao-lirong.github.io/blog/tags/Journal/"}]},{"title":"Look Back on Cornell 21FA","slug":"2021-12-15-Look-Back-on-Cornell-21FA","date":"2021-12-15T05:00:00.000Z","updated":"2023-02-23T05:16:18.000Z","comments":true,"path":"2021-12-15-Look-Back-on-Cornell-21FA/","permalink":"https://yao-lirong.github.io/blog/2021-12-15-Look-Back-on-Cornell-21FA/","excerpt":"å›æ¥äº†ï¼Œæ€»ä½“æ¥è¯´æ˜¯æŒºåŠªåŠ›çš„ä¸€å­¦æœŸ","text":"å›æ¥äº†ï¼Œæ€»ä½“æ¥è¯´æ˜¯æŒºåŠªåŠ›çš„ä¸€å­¦æœŸ CS3410 Computer System Organization å¿…ä¿®è¯¾ï¼Œæ²¡å•¥å¥½è¯´çš„ï¼Œä¸Šè¯¾ä¹‹å‰æš‘å‡å’Œåœ¨é£æœºä¸Šè‡ªå·±çœ‹äº†å‡ ç« Codeé¢„ä¹ äº†ä¸€ä¸‹ï¼Œæ„Ÿè§‰æ˜¯Codeè®²äº†çš„éƒ¨åˆ†æ¯”Bracyè®²çš„å¥½å¤šäº†ã€‚å¹¸äºå‰æœŸæœ‰Codeï¼ŒçœŸä¸çŸ¥é“å…¶ä»–åŒå­¦èƒ½ä¸èƒ½å¼„æ‡‚å‰é¢é€»è¾‘é—¨é‚£ä¸€éƒ¨åˆ†ã€‚åªæœ‰ä¸¤ä¸ª Prelim æ²¡æœ‰ Finalï¼Œæ‰€ä»¥æˆ‘è€ƒå®Œ Prelim 2 ä¹‹åå°±æ‘†çƒ‚äº†ï¼Œä¸Šè¯¾è·Ÿå¬æ•…äº‹ä¸€æ ·ã€‚ A1 A2ï¼šç”»é€»è¾‘ç”µè·¯å›¾ï¼Œå…¶å®å¤§éƒ¨åˆ†è¿˜å¥½ï¼Œä½†æ˜¯æœ€åè¿muxéƒ½è¦å…¨ç¨‹è‡ªå·±è¿å®åœ¨å¤ªæŠ˜ç£¨äº† A3ï¼šé€šè¿‡å†…å­˜æº¢å‡ºæ”¹å˜è¿è¡Œç¨‹åºè®©å®ƒæ‰“å°ä¸€æ®µæ–‡å­—ï¼Œåº”è¯¥æ˜¯æœ€å¥½ç©çš„ä¸€ä¸ªä½œä¸š A4 A5ï¼šæ¨¡æ‹Ÿ RISCV interpreter å’Œ Cache æ“ä½œ æ¯”ç”»ç”µè·¯å›¾è¿˜æŠ˜ç£¨ä¸€äº›çš„æ˜¯æœ¬è¯¾çš„ quizï¼Œå¯ä»¥æ— é™æ¬¡å°è¯•ä½†æ˜¯æ¯æ¬¡å°è¯•é¢˜ç›®ä¸ä¸€æ ·è€Œä¸”æœ‰å¼ºåˆ¶æ—¶é—´é—´éš”ã€‚ç»å¸¸æˆ‘æ˜¯ç¬¬ä¸€æ¬¡å°±æœ‰9ï¼10ï¼Œç»“æœæœ€åé‚£ä¸ªé¢˜è¦ä¹ˆæˆ‘è‡ªå·±ä¸ä¼šåšç„¶ååå¤å‡ºç°ï¼Œè¦ä¹ˆåˆå‡ºäº†å¤§éƒ¨åˆ†çš„æ–°é¢˜å…¶ä¸­åˆæœ‰æˆ‘ä¸æ‡‚çš„ï¼Œè¦ä¹ˆå°±æ˜¯æˆ‘æ˜æ˜å…¨ä¼šç»“æœæ‰‹æ»‘é€‰é”™äº†ï¼Œä¸‹ä¸€æ¬¡å°±ä¼šéšåˆ°å‰ä¸¤ç§æƒ…å†µä¸ä¼šçš„é¢˜ã€‚åæ­£å°±æ˜¯æˆ‘ä¸ºäº†å…¶ä¸­çš„ä¸€é“é¢˜è¦æŠŠæ‰€æœ‰é¢˜è¿‡ä¸ª7,8éï¼Œä½†æ˜¯è¿‡ç¨‹ä¸­å¤§éƒ¨åˆ†çš„é¢˜æˆ‘å·²ç»åå¤åšåå¤å¡«ç­”æ¡ˆå¡«äº†æ— æ•°æ¬¡ï¼Œæ¯æ¬¡å¡«å®ƒçš„ç­”æ¡ˆé¡ºåºè¿˜ä¸ä¸€æ ·ï¼Œè¿˜è¦ä»”ç»†çœ‹å¥½äº†é˜²æ­¢æ‰‹æ»‘é€‰é”™ï¼ŒæŠ˜ç£¨ç‹ä¹‹ç‹ä¸­ç‹ã€‚ CS4780 Intro to Machine Learning æˆ‘å½“å¹´ä¸Šæˆ‘çš„ä¸€ç”Ÿä¹‹æ•Œ4710å°±æ˜¯ä¸ºäº† 21SP èƒ½ä¸Š 4780ï¼Œä½†æ˜¯é‚£å¹´ 4780 æ˜¯æ’­ç‰‡ï¼Œæ‰€ä»¥æ‹–åˆ°äº†æˆ‘å›æ¥åº·å¥ˆå°”çš„è¿™ä¸€å­¦æœŸã€‚å¤§éƒ¨åˆ†æ˜¯ç»å…¸çš„MLç®—æ³•ï¼ŒDeep Learning å’Œ Neural Network æ¶‰åŠæ¯”è¾ƒå°‘ã€‚Assignment å’Œ project éƒ½å¾ˆæ°´ï¼ŒåŸºæœ¬å°±æ˜¯å¡«ç©ºé¢˜ï¼ˆå¥½å§ä¸å…¨æ˜¯ï¼Œå‰æœŸ assignment å¤ªå˜æ€å¯¼è‡´åæ¥ç›´æ¥æŠŠä½œä¸šæˆç»©æ”¹æˆ S/U äº†ï¼›project ç”¨çš„å¹³å° vocareum ä¹Ÿæ˜¯å„ç§ä¹±ä¸ƒå…«ç³Ÿçš„é—®é¢˜ä¸€å¤§å †ï¼‰æ‰€ä»¥æœ€ç»ˆæˆç»©å¤§æ¦‚å…¨æ˜¯é è€ƒè¯•æ¥æ’çš„ã€‚ä¸Šä¹‹å‰å¤§å®¶éƒ½å¹ KW è®²å¾—ç‰¹åˆ«å¥½ï¼Œä½†æˆ‘çœŸè§‰å¾—ä¹Ÿå°±é‚£æ ·ï¼Œå¯èƒ½æ˜¯å…¶ä»–çš„å‡ ä¸ªè€å¸ˆè®²å¾—å¤ªçƒ‚äº†ï¼Ÿæˆ–è€…è¿™é—¨è¯¾æœ‰å¾ˆå¤šåˆ«çš„ä¸“ä¸šçš„æ¥å­¦è€Œä»–ä»¬çš„è€å¸ˆä¸€èˆ¬è®²è¯¾æ°´å‡†ä¸é«˜ï¼Ÿåæ­£æˆ‘è§‰å¾—ä¹Ÿå°±æ˜¯CSé™¢å¹³å‡æ°´å¹³å§ï¼Œæ¯”æˆ‘ä¸Šçš„è¯¾çš„è€å¸ˆå¹³å‡æ°´å¹³è¿˜ç¨å¾®ä½ä¸€ç‚¹ç‚¹ã€‚å› ä¸ºå‰é¢ç¡®å®æ¶‰åŠå¤ªå¤šæ•°å­¦ï¼Œæ‰€ä»¥æˆ‘å‡ ä¹æ¯æ¬¡ä¸‹è¯¾éƒ½ä¼šé—®ä¸¤ä¸ªè€å¸ˆé—®é¢˜ï¼Œä¸€å¼€å§‹éƒ½å¯¹æˆ‘æŒºè€å¿ƒçš„ï¼Œåæ¥ADè¿˜å¥½ï¼Œä½†KWæˆ‘èƒ½æ˜æ˜¾æ„Ÿè§‰åˆ°ä¸è€çƒ¦äº†ï¼ˆå“¦å½“ç„¶äº†å¯èƒ½æ˜¯æˆ‘æ—¥å¸¸æ•æ„Ÿäº†ï¼‰ï¼Œæœ‰æ¬¡æˆ‘å»æ‰¾ä»–é—®ä¸ªæ‰©å±•é—®é¢˜ä»–è·Ÿæˆ‘è¯´ï¼šä½ ä¸å¤ªéœ€è¦æ‹…å¿ƒè¿™ä¸ªã€‚å”‰ï¼Œå¥½å§ï¼Œä½ è¯´å•¥å°±æ˜¯å•¥ã€‚ sxy å› ä¸º prelim è€ƒç ¸äº†æ‰€ä»¥ drop äº†è¿™èŠ‚è¯¾ï¼Œä¸‹ç­å­¦æœŸæ²¡å¥¹å¸¦ä¸Šå¾—æ¯”è¾ƒç´¯ï¼ˆ ä½†æ˜¯å­¦æœŸæœ«å› ä¸ºä¸€æ³¢è¾ƒå¤§å‹çš„ COVID çˆ†å‘ï¼Œæœ¬è¯¾çš„ Final æ”¹æˆ optional äº†ï¼Œå¯ç»™å¥¹æ‚”æ­»äº†ã€‚å¥¹ä¸‹å­¦æœŸåˆä¸Šäº†ä¸€éè¿™é—¨è¯¾ï¼Œè§‰å¾— 22SP çš„è€å¸ˆæ¯” KW æ•™å¾—æ¸…æ¥šå¤šäº†ï¼Œæˆ‘ 22FA è¦ä¸Šä»–çš„è¯¾ï¼Œçœ‹çœ‹åˆ°åº•å’‹æ ·ã€‚ CS6850 Structure of Information Networks Jon KleingergçœŸçš„æ˜¯ç¥ï¼Œäººèªæ˜è¯¾è®²å¾—è¿˜æ¸…æ™°ã€‚å„ç§çœ‹ä¸Šå»å¾ˆéš¾çš„æ¨å¯¼ç»ä»–çš„è¯¾å°±è¿æˆ‘ä¹Ÿèƒ½å¬æ˜ç™½ã€‚æ¯èŠ‚è¯¾ä¸‹è¯¾çš„æ—¶å€™æˆ‘æ€»ä¼šè¿½ç€è¿™ä¸ªéº¦å…‹é˜¿ç‘Ÿå¤©æ‰å¥–å¾—ä¸»é—®äº›å¾ˆå‚»é€¼çš„åŸºç¡€æ•°å­¦é—®é¢˜ï¼Œæ¯å½“è¿™ç§æ—¶å€™æˆ‘å°±ä¼šè§‰å¾—æˆ‘åœ¨åº·å¥ˆå°”çš„å­¦è´¹å…¨éƒ½èŠ±åœ¨äº†åˆ€åˆƒä¸Šã€‚ï¼ˆä¸æˆ‘å…¶å®æ˜¯å¾ˆå¯¹ä¸èµ· Jon ç”¨è¿™ç§å‚»é€¼é—®é¢˜æŠ˜ç£¨ä»–çš„ï¼‰ è¿™èŠ‚è¯¾ä¸Šä¸‹æ¥æˆ‘å­¦åˆ°çš„ç»Ÿè®¡çŸ¥è¯†æ¯”æˆ‘åœ¨4710ä¸€ä¸ªå­¦æœŸå­¦çš„éƒ½è¦å¤šï¼Œè€Œä¸”å¾ˆå¤šè¯æ˜æŠ€å·§éƒ½æ˜¯ CS æˆ–è€…è¯´å·¥ç§‘é€šç”¨ï¼Œéå¸¸å®ç”¨ã€‚è¯¾ä¸Šè®²äº†å¾ˆå¤šæœ‰æ„æ€çš„å›¾ä¸Šç†è®ºï¼Œä¸è¿‡ä¸€å­¦æœŸä¸‹æ¥å…¶å®æˆ‘ä¹Ÿå°±è®°ç€ small world propertyï¼Œå’Œä»¥æˆ‘æ ¡å”¯ä¸€æ•°å­¦åå¸ˆ Steven Strogatz åŠå…¶å¼Ÿå­å‘½åçš„ Watts Strogatz Modelã€‚ä½œä¸šçš„æ¯”è¾ƒç®€å• project ä¹Ÿå¾ˆè‡ªç”±ï¼Œå°±ç®—åªæ˜¯ä¸ºäº†å­¦ç»Ÿè®¡è¯æ˜æŠ€å·§ä¹Ÿå¾ˆå€¼å¾—ä¸Šçš„ä¸€èŠ‚è¯¾ã€‚ Project åšçš„æ˜¯ Complexity é‡Œé¢çœ‹åˆ°è¿‡çš„ Random Boolean Networkï¼Œå…¶å®æœ¬æ¥æ˜¯æƒ³åšä¸€ä¸ª DNA Regulatory Network æ¨¡æ‹Ÿçš„ï¼Œä½†æ˜¯æ€ä¹ˆéƒ½æ‰¾ä¸åˆ°æ•°æ®ï¼Œæ‰€ä»¥æ”¹åšäº† RBNï¼Œå…¶å®å®éªŒå’Œæˆ‘çš„çŒœæƒ³ä¹Ÿæ ¹æœ¬å¯¹ä¸ä¸Šï¼Œåˆ°äº†åé¢åŸºæœ¬å°±æ˜¯æ‘†çƒ‚äº†çå†™çš„ã€‚ å› ä¸ºè¿™å­¦æœŸå¦å¤–ä¸¤ä¸ªè¯¾ç¡®å®å‹åŠ›æœ‰ç‚¹å¤§ï¼Œå‰æœŸæ˜¯ 3410 æ¶å¿ƒäººçš„ç”µè·¯å›¾ï¼ŒåæœŸæ˜¯æ²¡æœ‰ sxy çš„ 4780ï¼Œè€Œä¸”æˆ‘è¿˜éå¸¸è®¤çœŸåœ°ç»™ 4780 æ•´ç†ç¬”è®°ï¼Œæ‰€ä»¥è¿™èŠ‚è¯¾åˆ°ååŠæ®µçš„æ—¶å€™æˆ‘ä¼šå»ä¸Šè¯¾ï¼Œä¼šå»è®°ç¬”è®°ï¼Œä½†æ˜¯ç¬”è®°å°±ä¸æ•´ç†èªŠæŠ„åˆ°å¦ä¸€ä¸ªæœ¬å­ä¸Šäº†ã€‚ç»“æœå°±æ˜¯ååŠéƒ¨åˆ†è®©æˆ‘å†å›å¿†æŒ‡å®šå°±å›å¿†ä¸èµ·æ¥äº†ã€‚ä¸è¿‡å¹¸å¥½è¿™èŠ‚è¯¾åŒæ­¥ NYC ç›´æ’­æ‰€ä»¥æœ‰å½•æ’­ï¼ŒæŠŠ lecture recording ä¸‹äº†ä¸‹æ¥ã€‚å¯èƒ½ä¸‹è¾ˆå­ä¼šå»å†çœ‹ä¸€éå§â€¦ Research å­¦æœŸåˆçš„æ—¶å€™æˆ‘è·Ÿ Joe è°ˆè¯ï¼Œè·Ÿä»–è¯´æˆ‘è¿˜æ˜¯çº ç»“è¦å»åšresearchè¿˜æ˜¯æ‰¾å·¥ä½œã€‚ä»–è·Ÿæˆ‘è¯´æˆ‘éƒ½å¤§ä¸‰äº†ç°åœ¨è¿˜åœ¨çº ç»“æ˜¯ä¸æ˜¯æœ‰ç‚¹å¤ªæ™šäº†â€¦ æˆ‘æœ¬æ¥åˆšå›åº·å¥ˆå°”å¿ƒæƒ…æŒºå¥½çš„ï¼Œåˆè®©è¿™è€ä¸œè¥¿ç»™æˆ‘å¹²ç„¦è™‘äº†ã€‚ä¸è¿‡ç»è¿‡ä»–çš„ä»‹ç»æ‰¾åˆ°äº†æ–°æ¥çš„æ•™æˆ Kevin Ellisã€‚å»å¹´æ˜¥å¤©æˆ‘å’Œæœ¬æ ¡ PhD Spencer è°ˆè¯çš„æ—¶å€™ä»–å°±å’Œæˆ‘æèµ·æ¥è¿‡ Kevinï¼Œä»–åšçš„ä¸œè¥¿ç¡®å®æ˜¯æˆ‘ä¸€çœ‹å°±è§‰å¾—å¾ˆæœ‰æ„æ€ã€‚åŸæ¥å¤§ä¸€çš„æ—¶å€™æˆ‘ä¹Ÿæ‰¾è¿‡åº·å¥ˆå°”æ ¡å†…è€å¸ˆçš„ç ”ç©¶é¡¹ç›®ä½†æ˜¯æ€»è§‰å¾—éƒ½å¾ˆæ— èŠï¼ŒKevin ç»™æˆ‘ä»‹ç»çš„ Abstraction and Reasoning Corpus ç¡®å®è®©äººè§‰å¾—è¿™ä¸ªé—®é¢˜æ‰æ˜¯ AI åº”è¯¥ç€æ‰‹è§£å†³çš„é—®é¢˜ã€‚å¯èƒ½å› ä¸ºæ˜¯æ–°æ¥è€å¸ˆçš„åŸå› ï¼Œéå¸¸å¹¸è¿å’Œä»–è°ˆäº†ä»¥åä»–ä¹Ÿé«˜å…´è®©æˆ‘è·Ÿä»–ä¸€èµ·åšç ”ç©¶ã€‚ARC é‡Œçš„ log.md æ›´åŠ è¯¦ç»†åœ°è®°å½•äº†å…³äº research æˆ‘è¿™ä¸€å­¦æœŸéƒ½å¹²äº†ä»€ä¹ˆã€‚ PE1340 Juggling ç¥çº§å‡å‹è¯¾ï¼Œæ²¡ä¸Šè¿‡è¿™è¯¾çš„äººæ— æ³•æƒ³è±¡ä½ ç”¨äº†å‡ èŠ‚è¯¾å°±å­¦ä¼šäº†åœ¨ç©ºä¸­æ‰”ä¸‰ä¸ªçƒæ˜¯å¤šä¹ˆæœ‰æˆå°±æ„Ÿçš„ä¸€èŠ‚äº‹ï¼Œåœ¨åº·å¥ˆå°”è¿™ä¸ªå……æ»¡æŒ«è´¥æ„Ÿçš„Båœ°æ–¹ï¼Œå®ƒæ˜¯æˆ‘è¿™ä¸ªå­¦æœŸçš„å”¯ä¸€æ…°è—‰ã€‚ä¸ä»…å¦‚æ­¤ï¼Œä½ è¦æ˜¯å­¦å¾—å¿«çš„è¯è¿˜èƒ½å­¦ä¼šæ‰”æ£’å­ï¼Œè½¬ç›˜å­ï¼Œä¸è¿‡æˆ‘éƒ½ä¸ä¼šã€‚å”¯ä¸€ä¸€ä¸ªæˆ‘ä¼šçš„æ‰©å±•é¡¹ç›®æ˜¯ç©ºç«¹ï¼ˆæˆ‘ä¼šçš„åŒå­¦ä»¬ä¹Ÿéƒ½ä¼šï¼Œè¿™ç©æ„ç¡®å®å¥½å­¦ï¼‰ç­‰å›å›½å»å…¬å›­å’Œè€å¤§çˆ·æ–—æŠ€å»ã€‚ PE1628 Unicycling å°ä¸‘å­¦æœŸï¼Œæ—¢å­¦æ‰”çƒåˆå­¦ç‹¬è½®è½¦ï¼Œå…¨è®©æˆ‘ç»™ä¸‘å®Œäº†ã€‚ä¸Šé¢é‚£èŠ‚è¯¾æ˜¯æ…°è—‰ï¼Œè¿™èŠ‚è¯¾å®Œå…¨ç›¸åï¼Œæˆ‘æ¯«ä¸å®¢æ°”åœ°è¯´è¿™æ˜¯æˆ‘åœ¨åº·å¥ˆå°”å‡ å¹´ä»¥æ¥é­åˆ°çš„æœ€æ²‰é‡çš„è‡ªä¿¡å¿ƒæ‰“å‡»ã€‚ä¸€ä¸ªå­¦æœŸä¸Šä¸‹æ¥7èŠ‚è¯¾21ä¸ªå°æ—¶ï¼Œæˆ‘è¿˜æ˜¯ä¸ä¼šéª‘è¿™Bç©æ„ï¼Œåˆ«äººéƒ½èƒ½éª‘ç€è½¦è·³äº†ï¼Œæˆ‘è¿˜æå¢™è§’é‚£æ‰¶ç€å‘¢ã€‚æˆ‘å­¦ä¹ èƒ½åŠ›æ€ä¹ˆæ ·å’±å¦è¯´ï¼Œè¿™ç©æ„éš”å¾—è›‹æ˜¯çœŸç–¼ã€‚ NES2276 Sensational Religion ä¸ºäº†åˆ«æ¯•ä¸äº†ä¸šåšæ‰“ç®—éšä¾¿é€‰çš„ä¸€é—¨è¯¾ï¼Œå’Œä¼—å¤šæ–‡ç§‘è¯¾ä¸€æ ·ï¼Œå®ƒä¹Ÿæ˜¯é‚£ä¹ˆå¾—æ‰¯ã€‚è¯¾ä¸Šæœ€æ‰¯çš„ä¸€ä¸ªç¬é—´å¤§æ¦‚å°±æ˜¯çœ‹è¿™éƒ¨åä¸ºå¡‘æ–™è¢‹çš„çºªå½•ç‰‡ï¼Œçœ‹å®Œä¹‹åè¯¾ä¸ŠåŒå­¦ä¸€æœ¬æ­£ç»åœ°è®¨è®ºæ˜¯æˆ‘è§‰å¾—æˆ‘é™ç”Ÿä»¥æ¥ç¦»æ­£å¸¸ä¸–ç•Œè·ç¦»æœ€è¿œçš„æ—¶å€™ã€‚ Winter Break æœ€åæµ…è°ˆä¸€ä¸‹å‡æœŸã€‚æ„Ÿæ©èŠ‚çš„æ—¶å€™å¶ç„¶å’Œgjtè¯´ä¸Šäº†è¯ï¼Œgjtçƒ­æƒ…åœ°é‚€è¯·æˆ‘å»ä»–ä»¬é‚£ã€‚ä»–æ˜¯å’Œcqcå’Œå¤§å¸…ä½ä¸€ä¸ªå®¿èˆï¼Œlså¯’å‡ä¹Ÿå»äº†ã€‚è¿™å‡ ä¸ªäººçœŸæ˜¯ç”µç«å®¿èˆï¼Œæˆå¤©æ‰“å€’æ™šä¸Šä¸€ä¸¤ç‚¹ï¼Œèµ·æ¥å°±ç›´æ¥åƒä¸­åˆé¥­ï¼Œå†™ä½œä¸šè€ƒè¯•éƒ½æ‰¾ä»£å†™ï¼Œåæ­£å°±æ˜¯ stereotypical çš„ä¸­å›½æ¥çš„åœ¨ç¾ç•™å­¦ç”Ÿã€‚å¯’å‡å’Œä»–ä»¬å»äº†å‡ è¶ŸLAè¿˜å»äº†ä¸€è¶Ÿæ‹‰æ–¯ç»´åŠ æ–¯ï¼Œå»çš„æ—¶å€™ä»–ä»¬å‡ ä¸ªå¼€çš„ä¸€å·å…¬è·¯æˆ‘åœ¨åé¢ç›´æ¥ç»™æˆ‘æ™ƒåäº†ï¼Œbiangçš„ä¸å°±çœ‹ä¸ªæµ·å—ï¼Œåœ¨å“ªä¸æ˜¯çœ‹ã€‚æ­»äº¡è°·è¿˜æ˜¯æŒºæœ‰çœ‹å¤´çš„ï¼Œè¿˜ä¸€èµ·å»ç»´åŠ æ–¯çœ‹äº†çœ‹ä¸å¥½è¯´çš„èŠ‚ç›®ã€‚ å›æ¥ä»¥åæ‹¿ä»–ä»¬å‡ ä¸ªçš„é¡¶é…ç”µè„‘9å¤©è¿å¹²70ä¸ªé€šäº†2077ï¼Œåé¢åˆé€šäº†ç”ŸåŒ–å±æœº2,3é‡ç½®ç‰ˆï¼Œåæ­£å°±æ˜¯æ¯å¤©å¹²åˆ°å‡Œæ™¨äº”ç‚¹ï¼Œç„¶åä¸­åˆèµ·åºŠï¼Œåœ¨å›½å†…çš„qsqéƒ½ç»å¸¸è®©æˆ‘æ•´è’™é€¼ï¼Œæ¯•ç«ŸCA 5ç‚¹æ˜¯å›½å†…å…«ä¹ç‚¹é’Ÿï¼Œä»–éƒ½å¿«è¦ç¡äº†ï¼Œç›´è¨€æˆ‘äººç”Ÿå·²ç»ç©å®Œäº†ã€‚æˆ‘åˆšå»çš„æ—¶å€™è¿˜ç¬‘ä»–ä»¬ï¼Œæœ€åå‘ç°åŸæ¥æˆ‘æ‰æ˜¯ç½‘ç˜¾æœ€é‡çš„é‚£ä¸ªã€‚è·Ÿä»–ä»¬å‡ºå»çš„æ—¶å€™å› ä¸ºé—²ç€æ²¡äº‹å°±çœ‹ä¹¦çœ‹å°è¯´ï¼Œè¢«ä»–ä»¬è°ƒä¾ƒçˆ±å­¦ä¹ ï¼Œå›æ¥ä»¥åä»–ä»¬å‡ ä¸ªéƒ½å¼€å­¦äº†æˆ‘å°±æˆå¤©å ç€ç”µè„‘æ‰“æ¸¸æˆã€‚æˆ‘ç¡®å®ä¸€ç›´è¿™æ ·ï¼Œä¸»è¦å‡ºå»çš„æ—¶å€™æ²¡ç”µè„‘ï¼Œæˆ‘ä¹Ÿä¸çˆ±åœ¨å¤–é¢åˆ·æ‰‹æœºï¼Œå°±ä¼šå˜æˆæˆ‘æ¯æ¬¡å‡ºé—¨éƒ½ä¼šçœ‹ä¹¦çš„è¿™ç§å¥‡æ€ªæƒ…å†µï¼Œä¸è¿‡åªè¦æœ‰å°å¥½ç”µè„‘æˆ‘å°±åŸå½¢æ¯•éœ²äº†ã€‚ éå¸¸æ„Ÿè°¢è¿™å‡ ä¸ªäººè®©æˆ‘åº¦è¿‡äº†æ¥ç¾å›½ä»¥åæœ€å¿«ä¹çš„ä¸€æ®µæ—¶å…‰ï¼Œå¤ªè¿‡å¿«ä¹å¯¼è‡´æˆ‘ç¬¬ä¸€å¤©å›æ¥ç«Ÿç„¶æˆ’æ–­æ€§æŠ‘éƒäº†ï¼ˆå½“å¤©å›æ¥çš„é£æœºä¸Šæœ‰ç‚¹ç¼ºæ°§ä¹Ÿæ˜¯ä¸»è¦åŸå› ï¼‰","categories":[],"tags":[{"name":"Review","slug":"Review","permalink":"https://yao-lirong.github.io/blog/tags/Review/"}]},{"title":"SQL Manual","slug":"2021-09-16-Intro-to-SQL","date":"2021-09-16T04:00:00.000Z","updated":"2022-06-08T19:54:02.000Z","comments":true,"path":"2021-09-16-Intro-to-SQL/","permalink":"https://yao-lirong.github.io/blog/2021-09-16-Intro-to-SQL/","excerpt":"æäº¤å®ä¹ ç”³è¯·åå‘æ¥ä¸ªå°æµ‹éªŒï¼Œç»™æˆ‘åšå´©æºƒäº†ï¼Œç¬¬ä¸€ä¸ªè¦æˆ‘åšè¿™ç§çº§åˆ«çš„SQLï¼Œæˆ‘æœ€å¤šä¹Ÿå°±ä¼šä¸ª select from whereï¼Œè¶…çº²è¿‡äºä¸¥é‡ï¼Œåªèƒ½å›å¤´è¡¥ä¹ ","text":"æäº¤å®ä¹ ç”³è¯·åå‘æ¥ä¸ªå°æµ‹éªŒï¼Œç»™æˆ‘åšå´©æºƒäº†ï¼Œç¬¬ä¸€ä¸ªè¦æˆ‘åšè¿™ç§çº§åˆ«çš„SQLï¼Œæˆ‘æœ€å¤šä¹Ÿå°±ä¼šä¸ª select from whereï¼Œè¶…çº²è¿‡äºä¸¥é‡ï¼Œåªèƒ½å›å¤´è¡¥ä¹  Data Type åç§° ç±»å‹ è¯´æ˜ INT æ•´å‹ 4å­—èŠ‚æ•´æ•°ç±»å‹ï¼ŒèŒƒå›´çº¦+/-21äº¿ BIGINT é•¿æ•´å‹ 8å­—èŠ‚æ•´æ•°ç±»å‹ï¼ŒèŒƒå›´çº¦+/-922äº¿äº¿ REAL æµ®ç‚¹å‹ 4å­—èŠ‚æµ®ç‚¹æ•°ï¼ŒèŒƒå›´çº¦+/-1038 DOUBLE æµ®ç‚¹å‹ 8å­—èŠ‚æµ®ç‚¹æ•°ï¼ŒèŒƒå›´çº¦+/-10308 DECIMAL(M,N) é«˜ç²¾åº¦å°æ•° ç”±ç”¨æˆ·æŒ‡å®šç²¾åº¦çš„å°æ•°ï¼Œä¾‹å¦‚ï¼ŒDECIMAL(20,10)è¡¨ç¤ºä¸€å…±20ä½ï¼Œå…¶ä¸­å°æ•°10ä½ï¼Œé€šå¸¸ç”¨äºè´¢åŠ¡è®¡ç®— CHAR(N) å®šé•¿å­—ç¬¦ä¸² å­˜å‚¨æŒ‡å®šé•¿åº¦çš„å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ï¼ŒCHAR(100)æ€»æ˜¯å­˜å‚¨100ä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸² VARCHAR(N) å˜é•¿å­—ç¬¦ä¸² å­˜å‚¨å¯å˜é•¿åº¦çš„å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ï¼ŒVARCHAR(100)å¯ä»¥å­˜å‚¨0~100ä¸ªå­—ç¬¦çš„å­—ç¬¦ä¸² BOOLEAN å¸ƒå°”ç±»å‹ å­˜å‚¨Trueæˆ–è€…False DATE æ—¥æœŸç±»å‹ å­˜å‚¨æ—¥æœŸï¼Œä¾‹å¦‚ï¼Œ2018-06-22 TIME æ—¶é—´ç±»å‹ å­˜å‚¨æ—¶é—´ï¼Œä¾‹å¦‚ï¼Œ12:20:59 DATETIME æ—¥æœŸå’Œæ—¶é—´ç±»å‹ å­˜å‚¨æ—¥æœŸ+æ—¶é—´ï¼Œä¾‹å¦‚ï¼Œ2018-06-22 12:20:59 Table Constraints Constraint Description PRIMARY KEY This means that the values in this column are unique, and each value can be used to identify a single row in this table. AUTOINCREMENT For integer values, this means that the value is automatically filled in and incremented with each row insertion. Not supported in all databases. UNIQUE This means that the values in this column have to be unique, so you canâ€™t insert another row with the same value in this column as another row in the table. Differs from the PRIMARY KEY in that it doesnâ€™t have to be a key for a row in the table. NOT NULL This means that the inserted value can not be NULL. CHECK (expression) This allows you to run a more complex expression to test whether the values inserted are valid. For example, you can check that values are positive, or greater than a specific size, or start with a certain prefix, etc. FOREIGN KEY This is a consistency check which ensures that each value in this column corresponds to another value in a column in another table. For example, if there are two tables, one listing all Employees by ID, and another listing their payroll information, the FOREIGN KEY can ensure that every row in the payroll table corresponds to a valid employee in the master Employee list. Table Structure Foreign Key A foreign key is a field (or collection of fields) in one table, that refers to the primary key in another table. The foreign key constraint prevents invalid data from being inserted into the foreign key column, because it has to be one of the values contained in the parent table. 1234ALTER TABLE students ADD CONSTRAINT fk_class_id -- name the constraintFOREIGN KEY (class_id) -- use class_id column in students as FKREFERENCES classes (id); -- links to id in table classes Deleting the constraint wonâ€™t delete the column used as FK. 12ALTER TABLE studentsDROP FOREIGN KEY fk_class_id; Indexing We can index frequently accessed columns to speed up querying. Indexes are based on hash, so the more spread out the data in index columns are, the better indexing performs. ç´¢å¼•çš„æ•ˆç‡å–å†³äºç´¢å¼•åˆ—çš„å€¼æ˜¯å¦æ•£åˆ—ï¼Œå³è¯¥åˆ—çš„å€¼å¦‚æœè¶Šäº’ä¸ç›¸åŒï¼Œé‚£ä¹ˆç´¢å¼•æ•ˆç‡è¶Šé«˜ã€‚åè¿‡æ¥ï¼Œå¦‚æœè®°å½•çš„åˆ—å­˜åœ¨å¤§é‡ç›¸åŒçš„å€¼ï¼Œä¾‹å¦‚genderåˆ—ï¼Œå¤§çº¦ä¸€åŠçš„è®°å½•å€¼æ˜¯Mï¼Œå¦ä¸€åŠæ˜¯Fï¼Œå› æ­¤ï¼Œå¯¹è¯¥åˆ—åˆ›å»ºç´¢å¼•å°±æ²¡æœ‰æ„ä¹‰ã€‚ 12345ALTER TABLE studentsADD INDEX idx_score (score); -- indexing named as idx_score; it indexes column score ALTER TABLE studentsADD INDEX idx_name_score (name, score); -- create a two-column indexing of name and score Unique Add a UNIQUE constraint to make sure the uniqueness of studentâ€™s name (Assume no two students have the same name). 12ALTER TABLE studentsADD CONSTRAINT uni_name UNIQUE (name); Querying Table æ³¨æ„å­—ç¬¦ä¸²ç”¨çš„éƒ½æ˜¯å•å¼•å· ' '. Conditionals =: equal &lt;&gt;: not equal LIKE: case insensitive exact string comparison; % is wildcard. 'ab%' matches â€˜abâ€™ï¼Œâ€˜abcâ€™ï¼Œâ€˜abcdâ€™ _ is â€œappeared onceâ€. LIKE \"ab_\" matches â€œabcâ€, but not â€œabâ€ or â€œabcdâ€ BETWEEN â€¦ AND â€¦: number is within range of two values (inclusive). e.g. col_name BETWEEN 1.5 AND 10.5 IN (â€¦): number exists in a list. e.g. col_name IN (2, 4, 6) NOT â€¦: to negate a predicate 12345678-- sometimes we don&#x27;t need FROM-- this is usually used to test connection to data baseSELECT 1SELECT 100 + 200SELECT * FROM students WHERE (score &lt; 80 OR score &gt; 90) AND gender = &#x27;M&#x27;;SELECT * FROM students WHERE (NOT class_id &lt;&gt; 2) AND score LIKE &#x27;8%&#x27; ; Projections 12-- rename column score as pointsSELECT id, score points, name FROM students; Orders Query results are usually ordered by PK. If we want to change the order, we can 1234567891011-- order by score (default in ascending order æ­£åº)SELECT id, name, score FROM students ORDER BY score;-- order by score and gender (descending score and ascending id)SELECT id, name, score FROM students ORDER BY score DESC, id;-- together with WHERESELECT id, name, gender, scoreFROM studentsWHERE class_id = 1ORDER BY score DESC; Partial Results Query result is sometimes in huge amount. In this case, we only want to show part of the result. 1234567-- show only 3 resultSELECT id, name, gender, score FROM students ORDER BY score DESCLIMIT 3;-- show only 3 result, starting from the 7th.SELECT id, name, gender, score FROM students ORDER BY score DESCLIMIT 3 OFFSET 6; Groups 12345-- return #records in TABLE students, and name it numSELECT COUNT(*) num FROM students;-- return #records whose gender is &#x27;M&#x27;, and name the result &quot;boys&quot;SELECT COUNT(*) boys FROM students WHERE gender = &#x27;M&#x27;; å’Œ COUNT ç±»ä¼¼çš„è¿˜æœ‰ä»¥ä¸‹å‡½æ•°ï¼š å‡½æ•° è¯´æ˜ SUM è®¡ç®—æŸä¸€åˆ—çš„åˆè®¡å€¼ï¼Œè¯¥åˆ—å¿…é¡»ä¸ºæ•°å€¼ç±»å‹ AVG è®¡ç®—æŸä¸€åˆ—çš„å¹³å‡å€¼ï¼Œè¯¥åˆ—å¿…é¡»ä¸ºæ•°å€¼ç±»å‹ MAX è®¡ç®—æŸä¸€åˆ—çš„æœ€å¤§å€¼ï¼Œå¦‚æœæ˜¯å­—ç¬¦ä¸²ç±»å‹åˆ™è¿”å›æ’åºæœ€åçš„å­—ç¬¦ MIN è®¡ç®—æŸä¸€åˆ—çš„æœ€å°å€¼ï¼Œå¦‚æœæ˜¯å­—ç¬¦ä¸²ç±»å‹åˆ™è¿”å›æ’åºæœ€å‰çš„å­—ç¬¦ å…¶ä¸­ï¼Œå¦‚æœ WHERE æ¡ä»¶æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•è¡Œï¼ŒCOUNT()ä¼šè¿”å›0ï¼Œè€ŒSUM()ã€AVG()ã€MAX()å’ŒMIN()ä¼šè¿”å›NULLã€‚ åˆ†å®Œç»„åï¼Œæˆ‘ä»¬ä¸èƒ½å†ç”¨ WHERE å¯¹ç»„è¿›è¡Œç­›é€‰ï¼Œä»¥ç»„ä¸ºçº§åˆ«è¿›è¡Œç­›é€‰éœ€è¦ HAVING. 12345678910111213-- æŒ‰ç…§ class_id åˆ†ç»„(class_id=1, 2, 3, ... å„ä¸€ç»„)ï¼Œ åˆ†åˆ«è¿”å›æ¯ä¸€ç»„çš„æ€»è®°å½•æ•°SELECT class_id, COUNT(*) num FROM students GROUP BY class_id;-- åˆ†å®Œç»„åï¼ŒSELECT class_id, COUNT(*) num FROM students GROUP BY class_id HAVING COUNT(*) &gt; 36;-- å¯¹äºåƒ name è¿™ç§åœ¨ä¸€ä¸ªç»„å†…å¹¶ä¸æ˜¯ç›¸åŒçš„å€¼ï¼Œä¼šè¿”å› NULL / æŠ¥é”™-- å› æ­¤å¯¹äºèšåˆæŸ¥è¯¢ï¼Œæˆ‘ä»¬åªèƒ½æ”¾å…¥èšåˆæŸ¥è¯¢çš„ col åæˆ–è€…ä¸€äº›å…¶ä»–çš„èšåˆå‡½æ•°SELECT name, class_id, COUNT(*) num FROM students GROUP BY class_id;-- æŸ¥è¯¢æ¯ä¸ªç­çº§ç”·å¥³åˆ†åˆ«çš„å¹³å‡åˆ†SELECT class_id, gender, AVG(score) FROM students GROUP BY gender, class_id ORDER BY class_id, gender; Multiple Tables When you select from more than one table, database will return the Cartesian product of the results. 12345SELECT s.id sid, s.name, s.gender, s.score, c.id cid, c.name cnameFROM students s, classes cWHERE s.gender = &#x27;M&#x27; AND c.id = 1; Join ä¸å‰æ–‡çš„ Multiple Tables ä¸åŒçš„æ˜¯ï¼ŒMultiple Tables æŠŠæ‰€æœ‰ç»“æœå…ˆè°ƒå‡ºæ¥å†æ ¹æ®ç»“æœè¿›è¡Œç­›é€‰ï¼Œæ•ˆç‡å¾ˆæ…¢ï¼›è€Œæˆ‘ä»¬çš„ JOIN å¯ä»¥ INNER JOINåªè¿”å›åŒæ—¶å­˜åœ¨äºä¸¤å¼ è¡¨çš„è¡Œæ•°æ®ã€‚æ¯”å¦‚studentsè¡¨çš„class_idåŒ…å«1ï¼Œ2ï¼Œ3ï¼Œclassesè¡¨çš„idåŒ…å«1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œæ‰€ä»¥ï¼ŒINNER JOINæ ¹æ®æ¡ä»¶s.class_id = c.idè¿”å›çš„ç»“æœé›†ä»…åŒ…å«1ï¼Œ2ï¼Œ3ã€‚ RIGHT OUTER JOINè¿”å›å³è¡¨éƒ½å­˜åœ¨çš„è¡Œã€‚å¦‚æœæŸä¸€è¡Œä»…åœ¨å³è¡¨å­˜åœ¨ï¼Œé‚£ä¹ˆç»“æœé›†å°±ä¼šä»¥NULLå¡«å……å‰©ä¸‹çš„å­—æ®µã€‚ LEFT OUTER JOINåˆ™è¿”å›å·¦è¡¨éƒ½å­˜åœ¨çš„è¡Œã€‚å¦‚æœæˆ‘ä»¬ç»™studentsè¡¨å¢åŠ ä¸€è¡Œï¼Œå¹¶æ·»åŠ class_id=5ï¼Œç”±äºclassesè¡¨å¹¶ä¸å­˜åœ¨id=5çš„è¡Œï¼Œæ‰€ä»¥ï¼ŒLEFT OUTER JOINçš„ç»“æœä¼šå¢åŠ ä¸€è¡Œï¼Œå¯¹åº”çš„class_nameæ˜¯NULLï¼š FULL OUTER JOINï¼Œå®ƒä¼šæŠŠä¸¤å¼ è¡¨çš„æ‰€æœ‰è®°å½•å…¨éƒ¨é€‰æ‹©å‡ºæ¥ï¼Œå¹¶ä¸”ï¼Œè‡ªåŠ¨æŠŠå¯¹æ–¹ä¸å­˜åœ¨çš„åˆ—å¡«å……ä¸ºNULLï¼š 12345678-- Join æŒ‡ä»¤æ¨¡æ¿SELECT ... FROM tableA ??? JOIN tableB ON tableA.column1 = tableB.column2;-- ä¸Šæ–‡ä½¿ç”¨çš„ä¾‹å­å¯¹åº”çš„æŒ‡ä»¤SELECT s.id, s.name, s.class_id, c.name class_name, s.gender, s.scoreFROM students sFULL OUTER JOIN classes cON s.class_id = c.id; Join in Graphs Null An alternative to NULL values in your database is to have data-type appropriate default values, like 0 for numerical data, empty strings for text data, etc. But if your database needs to store incomplete data, then NULL values can be appropriate if the default values will skew later analysis (for example, when taking averages of numerical data). 123-- select all non-null valuesSELECT column, another_column, â€¦ FROM mytableWHERE column_name IS/IS NOT NULL Operating on Rows Insert When we insert something into the table, we donâ€™t have to specify value of the primary key column. Because the primary key is automatically calculated by the database. 12345678INSERT INTO table_name (col1, col2, ...) VALUES (v1, v2, ...) (v1, v2, ...);INSERT INTO students (class_id, name, gender, score) VALUES (1, &#x27;å¤§å®&#x27;, &#x27;M&#x27;, 87), (2, &#x27;äºŒå®&#x27;, &#x27;M&#x27;, 81); Update We can update a record in the table. 1234567891011UPDATE table_name SET col1=v1, col2=v2, ... WHERE ...;-- update a single recordUPDATE students SET name=&#x27;å¤§ç‰›&#x27;, score=66 WHERE id=1;-- update multiple recordsUPDATE students SET name=&#x27;å°ç‰›&#x27;, score=77 WHERE id&gt;=5 AND id&lt;=7;-- add 10 points to all scores below 80UPDATE students SET score=score+10 WHERE score&lt;80; Delete 1234DELETE FROM table_name WHERE ...;-- delete multiple records DELETE FROM students WHERE id&gt;=5 AND id&lt;=7; Operating on Table Create Table 1234567891011121314CREATE TABLE IF NOT EXISTS table_name ( column_name *DataType* *TableConstraint* DEFAULT *default_value*, another_column_name *DataType* *TableConstraint* DEFAULT *default_value*, â€¦ );Movies table schemaCREATE TABLE movies ( id INTEGER PRIMARY KEY, title TEXT, director TEXT, year INTEGER); Alter Table 1234567891011-- add a column to tableALTER TABLE mytable ADD column *DataType* *OptionalTableConstraint* DEFAULT default_value;-- remove a column from tableALTER TABLE mytableDROP column_to_be_deleted;-- renaming the tableALTER TABLE mytableRENAME TO new_table_name; Delete Table 1DROP TABLE IF EXISTS mytable; Others View 12345create view current_demographic_dim(current_demographic_key, current_salary_range, current_age_range)asselect demographic_key, salary_range, age_rangefrom SAMPLES.DEMOGRAPHIC_DIM; å®ç”¨SQLè¯­å¥ Reference å»–é›ªå³°çš„SQLæ•™ç¨‹ SQLBolt","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"Java Quick Guide","slug":"2021-09-10-Java-Quick-Guide","date":"2021-09-10T04:00:00.000Z","updated":"2022-09-05T04:04:52.000Z","comments":true,"path":"2021-09-10-Java-Quick-Guide/","permalink":"https://yao-lirong.github.io/blog/2021-09-10-Java-Quick-Guide/","excerpt":"","text":"Basics Basic File Structure: 12345public class &lt;SameAsFileName&gt; &#123; public static void main(String args[])&#123; &#125;&#125; Typecasting: int a = (int) pow(2,5); Binary: reference to formatting, 1234567int i = 0b10101010; // give binary valueSystem.out.println(Integer.toBinaryString(x)); // print binaryInteger.parseUnsignedInt(&quot;10101010&quot;, 2); //input binary// print with paddingString.format(formatPattern, Integer.toBinaryString(data)).replace(&#x27; &#x27;, &#x27;0&#x27;); String formatPattern = &quot;%&quot; + maximumExpectedSize + &quot;s&quot;; good String Create a string of all character c: String 10Spaces = new String(new char[10]).replace('\\0', ' ');","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"C Manual","slug":"2021-08-31-Introduction-to-C","date":"2021-08-31T04:00:00.000Z","updated":"2022-06-08T19:34:38.000Z","comments":true,"path":"2021-08-31-Introduction-to-C/","permalink":"https://yao-lirong.github.io/blog/2021-08-31-Introduction-to-C/","excerpt":"å¤§æ¦‚æ˜¯å†™è¿™ä¹ˆå¤šå¹´ C(++) ä»¥æ¥ç¬¬ä¸€æ¬¡æ­£å¼å­¦ C (è™½ç„¶å…¶å®åœ¨åº·å¥ˆå°”å­¦è¿‡ä¸€éC++)","text":"å¤§æ¦‚æ˜¯å†™è¿™ä¹ˆå¤šå¹´ C(++) ä»¥æ¥ç¬¬ä¸€æ¬¡æ­£å¼å­¦ C (è™½ç„¶å…¶å®åœ¨åº·å¥ˆå°”å­¦è¿‡ä¸€éC++) Compiling C Program 12345# compile hello.c and name the executable as default (a.out)gcc hello.c# compile hello.c and name the output executable &quot;sayhello&quot;gcc hello.c -o sayhello We usually write return 0, this exit code 0 means EXIT_SUCCESS. Prototype Definition prototype - declare a function (write down its name) definition - define a function (write down its content) .h stand for â€œheaderâ€ and it contains prototype of function .c stand for â€œcodeâ€ and it contains definition of function Complex &amp; Custom Data Types struct 12345struct rect_t &#123; int left; ... &#125;; struct rect_t myRect; ### typedef The keyword typedef allows a programmer to create a new type. 12struct _rect_t &#123; ... &#125;;typedef struct _rect_t rect_t; Now we can create instance of the new type: (Note how this is different from a struct instance declaration) 123rect_t myRect;myRect.left = 1;... Strings char *strstr(const char *haystack, const char *needle): finds the first occurrence of the substring needle in the string haystack. sprintf(char *str, const char *format, ...): â€œprints outâ€ formatted output to a string str, but instead of really printing them out, sprintf buffers the output to the string.(sprintf(str, \"Pi = %f\", 3.14); will set str to be Pi = 3.14) Dynamic Memory Allocation Consider the following program: 1234int * initArray(int howLarge) &#123; int myArray[howLarge]; for (int i = 0; i &lt; howLarge; i++) myArray[i] = i; return myArray; &#125; We cannot do this because the space allocated to myArray is only inside the scope of initArray and will be freed once we exit this function. So what we want is dynamic memory allocation so the memory will be allocated at a dynamic heap instead of the call stack. 123int *p = malloc(6 * sizeof(int)); // memory allocationp = realloc(p, 12 * sizeof(int)); // re-allocationfree(p); We can then rewrite the above function as: 1234int * initArray(int howLarge) &#123; int *myArray = malloc(howLarge * sizeof(int)); for (int i = 0; i &lt; howLarge; i++) myArray[i] = i; return myArray; &#125; Note the following when you use free: 12345678// you cannot free something on the stackint x = 3; int *p = &amp;x;free(p); // early termination// free can only be used to free address returned by mallocint *p = malloc(4*sizeof(int));p++;free(p); // early termination Debugging C in VSCode Install the extension â€œGDB Debugger - Beyondâ€ Replace whatâ€™s in launch.json - configurations with the following codes: 123456789&quot;configurations&quot;: [ &#123; &quot;type&quot;: &quot;by-gdb&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;name&quot;: &quot;Launch(gdb)&quot;, &quot;program&quot;: &quot;$&#123;fileDirname&#125;/$&#123;fileBasenameNoExtension&#125;&quot;, &quot;cwd&quot;: &quot;$&#123;workspaceRoot&#125;&quot; &#125;]","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"æ›´æ–°archerä¸»é¢˜ / è¿ç§»Hexoåšå®¢","slug":"2021-08-29-æ›´æ–°archerä¸»é¢˜--è¿ç§»Hexoåšå®¢","date":"2021-08-29T04:00:00.000Z","updated":"2022-04-23T07:35:52.000Z","comments":true,"path":"2021-08-29-æ›´æ–°archerä¸»é¢˜--è¿ç§»Hexoåšå®¢/","permalink":"https://yao-lirong.github.io/blog/2021-08-29-%E6%9B%B4%E6%96%B0archer%E4%B8%BB%E9%A2%98--%E8%BF%81%E7%A7%BBHexo%E5%8D%9A%E5%AE%A2/","excerpt":"é‡è¦æ–‡ä»¶ä¸å¤šï¼Œå…¨åœ¨ä¸‹é¢åˆ—å‡ºæ¥äº†ï¼Œè®°å¾—æŠŠå®ƒä»¬è¿ç§»å¥½å°±è¡Œ","text":"é‡è¦æ–‡ä»¶ä¸å¤šï¼Œå…¨åœ¨ä¸‹é¢åˆ—å‡ºæ¥äº†ï¼Œè®°å¾—æŠŠå®ƒä»¬è¿ç§»å¥½å°±è¡Œ 123456789101112. # ã€ŒHexo æ ¹ç›®å½•ã€â”œâ”€â”€ source # åšå®¢æºæ–‡ä»¶â”œâ”€â”€ themesâ”‚ â””â”€â”€ archer # ã€ŒArcher ä¸»é¢˜ç›®å½•ã€â”‚ â”œâ”€â”€ source # æ¸²æŸ“ç”¨æºæ–‡ä»¶â”‚ â”œâ”€â”€ assetsâ”‚ â””â”€â”€ favicon.ico # ç½‘ç«™ç¼©ç•¥å›¾æ ‡â”‚ â”œâ”€â”€ avatar # æ˜¾ç¤ºäººç‰©å¤´åƒâ”‚ â”œâ”€â”€ intro # ç½‘é¡µå¤´å›¾â”‚ â””â”€â”€ _config.yml # Archer ä¸»é¢˜é…ç½®æ–‡ä»¶â”‚â””â”€â”€ _config.yml # Hexo é…ç½®æ–‡ä»¶ å¦å¤–åˆ«å¿˜è®°æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå®‰è£…å¿…è¦æ’ä»¶ 123npm install hexo-generator-json-content --savenpm install hexo-wordcount --savenpm install hexo-generator-feed --save","categories":[],"tags":[{"name":"Logistics","slug":"Logistics","permalink":"https://yao-lirong.github.io/blog/tags/Logistics/"}]},{"title":"Install and Configure Aria2 on WSL","slug":"2021-06-28-Install-and-Configure-Aria2-on-Linux","date":"2021-06-28T04:00:00.000Z","updated":"2022-06-08T19:34:24.000Z","comments":true,"path":"2021-06-28-Install-and-Configure-Aria2-on-Linux/","permalink":"https://yao-lirong.github.io/blog/2021-06-28-Install-and-Configure-Aria2-on-Linux/","excerpt":"","text":"Tutorial Install Aria2c: sudo apt install aria2c and a web-based GUI: AriaNg Create configuration files: 123mkdir ~/.aria2touch ~/.aria2/aria2.session #ç”¨äºä¿å­˜æ—¥å¿—touch ~/.aria2/aria2.conf #åˆ›å»ºé…ç½®æ–‡ä»¶ A template for â€œaria2.confâ€ can be downloaded from aria2c.com. You should change the dir field to be download path, change input-file and save-session to be the path of aria2.session. aria2.conf doesnâ€™t support environment variable, so everything is at best written in absolute path. Run Aria2c with this configuration: aria2c --conf-path=/home/&lt;username&gt;/.aria2/aria2.conf. It will remember this as its configuration file and use it to start the service from now on. We can also add argument -D so Aria2c runs as daemon in the background. (Since the aria2câ€™s default configure file path is in ~/.aria2/, we donâ€™t really need the --conf-path argument; but use it to specify a conf path if you put it somewhere else) è®¾ç½® aria2c å¼€æœºè‡ªåŠ¨å¯åŠ¨ï¼šç¼–å†™è„šæœ¬ myStartUp.sh å¹¶æ”¾å…¥ /etc/init.d/. (Remember to change its privilege to everyone) 12345#!/bin/bash#Short-Description: My Startup Servicesaria2c -D --conf-path=/home/&lt;username&gt;/.aria2/aria2.conf More on Start Service on WSL startup, refer to this answer Caution On WSL, when you start aria2 service the first time, note: (full command means the above command with --conf-path, but since our conf path is the same as default path, we can take ) use the full command aria2c --conf-path=/home/&lt;username&gt;/.aria2/aria2.conf and donâ€™t start it in the background with -D. start it immediately after Windows is booted, before you open anything else or tweak anything Anything else than this full command or use this full command some time after Windows boot could cause problem. The problem is showing â€œException: [SocketCore.cc:312] errorCode=1 Failed to bind a socket, cause: Permission deniedâ€ even though no process is using port 6800. The reason for this problem is not clear. After staring aria2 once with the full command, we can shut it down and then start it in the background with aria2c -D --conf-path=/home/&lt;username&gt;/.config/aria2/aria2.conf. Now everything will work fine. Reference Linuxä¸­é…ç½®Aria2 RPC Server linuxè®¾ç½®å¼€æœºè‡ªå¯åŠ¨ WSL æœåŠ¡è‡ªåŠ¨å¯åŠ¨çš„æ­£ç¡®æ–¹æ³•","categories":[],"tags":[{"name":"Logistics","slug":"Logistics","permalink":"https://yao-lirong.github.io/blog/tags/Logistics/"}]},{"title":"On Intelligence","slug":"2021-06-23-On-Intelligence","date":"2021-06-23T04:00:00.000Z","updated":"2022-06-08T19:33:42.000Z","comments":true,"path":"2021-06-23-On-Intelligence/","permalink":"https://yao-lirong.github.io/blog/2021-06-23-On-Intelligence/","excerpt":"Complexity is a symptom of confusion, not a cause.","text":"Complexity is a symptom of confusion, not a cause. 1 Artificial Intelligence è®¡ç®—æœºå­¦ç•Œçš„ä¸»æµè§‚ç‚¹ï¼šä¸éœ€è¦å­¦ä¹ å¤§è„‘ æ­¤è§‚ç‚¹çš„èµ·å§‹ï¼šTuring Testï¼Œå³è®©äººä»¬è®¤ä¸ºå®ƒæ˜¯æ™ºèƒ½ï¼Œäº§ç”Ÿ intelligent behavior æ›´é‡è¦ the Chinese Room: åœ¨ä¸­æ–‡å±‹ä¸­æ™ºèƒ½æ²¡æœ‰äº§ç”Ÿï¼Œä½œè€…è®¤ä¸º Understanding cannot be measured by external behavior; it is instead an internal metric of how the brain remembers things and uses its memories to make predictions. ä½†ç»å¤§å¤šæ•°çš„æ‰€è°“â€AIâ€å’Œè¿™é‡Œçš„ä¸­æ–‡å±‹å’Œè¿™ä¸€å®šä¹‰æ— ä»»ä½•ç›¸ä¼¼ä¹‹å¤„ 2 Neural Networks ä¸€äº›å¯èƒ½å·²ç»è¿‡æ—¶çš„è§‚ç‚¹ï¼š Neural Network æ²¡æœ‰è€ƒè™‘ feedback å’Œ time changing inputs Cognitive Scientist è™½ç„¶æƒ³è®°å½•å¤§è„‘ä¸­çš„ feedbackï¼Œä½†æ˜¯è¿«äºç°æœ‰æŠ€æœ¯(fMRI)åªèƒ½è®°å½•è„‘å†…æ´»åŠ¨çš„ä½ç½®ï¼Œæ— æ³•è®°å½•è¿ç»­çš„å˜åŒ– 3 The Human Brain Mind is the creation of the cells in the brain. The cortex is extremely flexible and that the inputs to the brain are just patterns. It doesnâ€™t matter where the patterns come from; as long as they correlate over time in consistent ways, the brain can make sense of them. Function Hierarchy: è„‘çš„æ¯ä¸ªåŠŸèƒ½éƒ¨åˆ†éƒ½è¢«åˆ’ä¸º hierarchyï¼Œä»¥è¾“å…¥çš„è§†è§‰ä¸ºä¾‹ V1 (primary sensory areas): rawest, most basic level V2, V4, IT: concerned with more specialized or more abstract aspects association area: receive inputs from more than one sense è™½ç„¶æ˜¯ä¸€ä¸ª hierarchyï¼Œä½†æ˜¯å®é™…ä¸Šå½“æˆ‘ä»¬ä»ä½å±‚èµ°å‘é«˜å±‚çš„è¿‡ç¨‹ä¸­ï¼Œinformation always flows in the opposite direction as well, and with more projections feeding back down the hierarchy than up. Uniformity of Cortex Parts: Mountcastle found that parts of cortex performing different function is very similar in appearance and structure. From there, he argues that all regions of the cortex are performing the same operation. The thing that makes the vision area visual and the motor area motoric is how the regions of cortex are connected to each other and to other parts of the central nervous system. Plasticity of Cortex: æˆ‘ä»¬å‘ç°å¦‚æœå¤§è„‘æŸä¸ªéƒ¨åˆ†æŸåï¼Œå¦ä¸€ä¸ªéƒ¨åˆ†å¯ä»¥æ¥ç®¡å®ƒåŸå…ˆçš„äººç‰©ï¼Œè¿™ä½è¯äº† Mountcastle çš„è§‚ç‚¹ã€‚å¦æœ‰ä¸€ä¸ª Thought Experimentï¼šå‡è®¾æˆ‘ä»¬çš„å¤§è„‘å¹¶ä¸å…·æœ‰å¦‚æ­¤çš„å¯å¡‘æ€§ï¼Œé‚£ä¹ˆè¿™å°±æ„å‘³ç€æˆ‘ä»¬çš„æŸä¸ªå¤§è„‘éƒ¨ä½æ˜¯ä¸“é—¨ç”¨æ¥å­¦ä¹ ä¸­æ–‡æ±‰å­—çš„ï¼Œä½†æ˜¯å¯¹äºç”Ÿç‰©è¿›åŒ–æ¥è¯´ï¼Œæ±‰å­—è¿›åŒ–åœ°å¤ªå¿«äº†ï¼Œå¤§è„‘æ ¹æœ¬ä¸å¯èƒ½é€‚åº”åœ°è¿™ä¹ˆå¿«ï¼ˆæˆ–è€…å¤–å›½äººä¹Ÿå¯ä»¥è¿…é€Ÿå­¦ä¸­æ–‡äº¦èƒ½ä½è¯è¿™ä¸€è§‚ç‚¹ï¼‰ Similarity of Inputs into Brain: ä¸ç®¡è§†è§‰å¬è§‰è¿˜æ˜¯ä»€ä¹ˆè¾“å…¥ï¼ŒçœŸæ­£è¿›äº†äººä½“éƒ½æ˜¯ Action Potentials. They are all the same - just patterns. ä¹Ÿç”¨æ¥ä½è¯ Mountcastle çš„è§‚ç‚¹ã€‚There are spatial and and temporal patterns: Spatial Patterns: coincident patterns in time; they are created when multiple receptors in the same sense organ are stimulated simultaneously Temporal Patterns: patterns entering your sensory organs are constantly changing over time è¿›ä¸€æ­¥ç»™å‡ºäº†å…³äºä»¥ä¸Šä¸¤ç‚¹çš„ä¾‹å­ï¼šè®¤ä¸ºåŒæ—¶åšå‡ºååº”çš„å‡æ‰‹æ˜¯è‡ªå·±çš„æ‰‹ / é•œå¤´è¿èˆŒå¤´ä¸Šçš„å‹æ„Ÿæ¥æ”¶å™¨ï¼Œç”¨èˆŒå¤´çœ‹ä¸œè¥¿ 4 Memory é©³æ–¥äººè„‘æ¯”è®¡ç®—æœºæ›´å¿«ï¼Œè®¡ç®—åŠ›æ›´é«˜ -&gt; äººè„‘èƒ½åšåˆ°æ¯”è®¡ç®—æœºå¿«æ˜¯å› ä¸ºè¿è¡ŒåŸç†æ ¹æœ¬ä¸åŒ -&gt; å¼•å‡ºæœ¬ç« ä¸»æ—¨: the brain doesnâ€™t â€œcomputeâ€ the answers to problems; it retrieves the answers from memory. Four attributes of neocortical memory that are fundamentally different from computer memory: The neocortex stores sequences of patterns -&gt; predictions of future events The neocortex recalls patterns auto-associatively -&gt; recall memories appropriate for prediction The neocortex stores patterns in an invariant form -&gt; apply knowledge of past to new situations that are similar but not identical The neocortex stores patterns in a hierarchy. æ¥ä¸‹æ¥æˆ‘ä»¬å°†è¯¦ç»†ä»‹ç»å‰ä¸‰ä¸ªç‰¹å¾å¹¶åœ¨ç¬¬6ç« ä»‹ç»æœ€åä¸€ä¸ªç‰¹å¾ â€œé˜¶å±‚â€ Sequential Pattern: story is stored in your head in a sequential fashion and can only be recalled in the same sequence. You canâ€™t remember the entire story at once. ä¸€ä¸ªæœ‰è¶£çš„è§‚ç‚¹: Truly random thoughts donâ€™t exist. Memory recall almost always follows a pathway of association. Self-Associativity: The memory system can recall complete patterns when given only partial or distorted inputs. This is a result of Hebbian Learning: Firing together Wires together, so when only a part of the cell is activated, the whole group of cells will be activated. Invariant Representation: äººè„‘ä¸æ˜¯CDæˆ–ç¡¬ç›˜ï¼Œwe donâ€™t remember or recall things with complete fidelity. Instead, the brain remembers the important relationships in the world, independent of the details. æˆ‘ä»¬å¸¸ç”¨è§†è§‰æ¥ä¸¾ä¾‹å­ï¼šsome set of the cells in the face recognition area remain active as long as your friendâ€™s face is anywhere in your field of vision, regardless of its size, position, orientation, scale, and expression. This stability of cell firing is an invariant representation. å°å¼•å­å¯¼å…¥ä¸‹ä¸€ç« ï¼šä¸‹ä¸€ç« çš„ä¸»æ—¨æ˜¯äººè„‘çš„ä¸»è¦åŠŸèƒ½å°±æ˜¯ make predictions using memoriesï¼Œbut given that the cortex stores invariant information, how can it make specific predictions? It combines knowledge of the invariant structure with the most recent details. 5 A New Framework of Intelligence Prediction is not just one of the things your brain does. It is the primary function of the neocortex, and the foundation of intelligence. The cortex is an organ of prediction. è¿™æ˜¯ä½œè€…æœ¬ä¹¦ä¸­æœ€åŸºæœ¬çš„è§‚ç‚¹ï¼Œä¹Ÿå°±æ˜¯ä»–æ‰€è¯´çš„æ–°çš„æ™ºèƒ½æ¡†æ¶ (Memory-Prediction Framework of Intelligence) ã€‚å…·ä½“åœ°æ¥è§£é‡Š Prediction è¿™ä¸ªæ¦‚å¿µï¼šYour brain makes low-level sensory predictions about what it expects to see, hear, and feel at every given moment, and it does so in parallel. All regions of your neocortex are simultaneously trying to predict what their next experience will be. â€œPredictionâ€ means that the neurons involved in sensing your door become active in advance of them actually receiving sensory input. When the sensory input does arrive, it is compared with what was expected. Correct predictions result in understanding. Incorrect predictions result in confusion and prompt you to pay attention. ä¸å±€é™äº sensory inputï¼Œmotor output åœ¨æˆ‘ä»¬çš„å¤§è„‘ä¸­ä¹Ÿæ˜¯å’Œ sensory inputä¸€æ ·çš„ pattern, so neocortex can also remembers what behavior (pattern) leads to what sensory input (patter) and we can direct behavior to satisfy its predictions. ä½œè€…ä¸¾äº†å¾ˆå¤šå…³äº prediction çš„ä¾‹å­ï¼ˆé¢„çŸ¥ä¹æ›²çš„æ—‹å¾‹ï¼Œæœ‹å‹çš„æ ·å­ï¼Œä½ å¦ˆä¸‹ä¸€å¥è¯ä¼šè¯´ä»€ä¹ˆâ€¦ï¼‰å…¶ä¸­æœ€æœ‰æ„æ€çš„ä¾‹å­åº”è¯¥æ˜¯ â€œfilling inâ€ï¼Œå³æˆ‘ä»¬åŸæ¥äº†è§£è¿‡çš„äººè„‘çš„ â€œè‡ªåŠ¨è¡¥å…¨â€ åŠŸèƒ½ï¼šäººçœ¼è™½ç„¶æœ‰ç›²ç‚¹ä½†æˆ‘ä»¬è§†è§‰æ²¡æœ‰ç›²ç‚¹ï¼Œè‡ªåŠ¨å°†ä¸‰ä¸ªè§’è¡¥å…¨æˆä¸‰è§’å½¢ï¼Œæç»˜å‡ºè¢«æ ‘é®æŒ¡çš„å¤§æ¥¼çš„æ ·å­ï¼Œç­‰ç­‰ã€‚Your visual cortex is drawing on memories of similar patterns and is making a continuous stream of predictions that fill in for any missing input. Behavior Cortex Intelligence ä¹‹é—´åˆ°åº•æ˜¯ä¸ªä»€ä¹ˆå…³ç³»ï¼Ÿ ä»è¿›åŒ–å†ç¨‹æ¥çœ‹ï¼Œcortex èµ·åˆ°ä»€ä¹ˆä½œç”¨ï¼Ÿæˆ‘ä»¬ä¸ºä»€ä¹ˆè¦è¿›åŒ–å‡º Cortex: in the beginning, the cortex served to make more efficient use of existing behaviors, not to create entirely new behaviors. ä½†æ˜¯åæ¥åœ¨è¿›åŒ–è¿‡ç¨‹ä¸­æœ‰äº† new behaviorï¼Ÿ Reptile: Keen senses and well-developed brains endowed them with complex behavior, but relatively rigid Mammals: Neocortex covering the old brain (reptile brain) Now sensory patterns are simultaneously fed into the neocortex and the old brain. The recalled memory is compared with the sensory input stream. It both â€œfills inâ€ the current input and predicts what will be seen next. Humans: large front part of cortex for high-level planning and thought, so it could store more sophisticated types of memories and make predictions based on complex relationships motor cortex makes more connections with our muscles so cortex usurps motor control from other parts of the brain (old brain) and now the cortex can direct behavior to satisfy its predictions. æœ¬éƒ¨åˆ†ä¹Ÿåé©³äº†ç¬¬ä¸€ç« ä¸­æ‰€è°“çš„äººå·¥æ™ºèƒ½å­¦è€…çš„ behavior determines intelligence è§‚ç‚¹ï¼šæ—©åœ¨ reptile æ—¶æœŸï¼ŒåŠ¨ç‰©å°±æœ‰äº†ç”Ÿå­˜æœ¬èƒ½çš„ behaviorï¼Œä½†æ˜¯ç›´åˆ° cortex å‡ºç°ï¼Œå®ƒä»¬æ‰æœ‰äº† intelligenceã€‚è€Œ cortex çš„æ ¸å¿ƒåŠŸèƒ½å°±æ˜¯ prediction. To make predictions of future events, your neocortex has to store sequences of patterns. To recall the appropriate memories, it has to retrieve patterns by their similarity to past patterns (auto-associative recall). And, finally, memories have to be stored in an invariant form so that the knowledge of past events can be applied to new situations that are similar but not identical to the past. How the physical cortex accomplishes these tasks, plus a fuller exploration of its hierarchy, is the subject of the next chapter. 6 How the Cortex Works invariant representation: Light receptors in retina concentrate in fovea and sparse out in periphery, so retinal image relayed onto V1 is highly distorted. However, we donâ€™t perceive any retinal pattern change at all. This is a result of invariant representation. In the course of spanning four cortical stages from retina to IT: cells in retina and V2 are rapidly changing, spatially specific, tiny-feature recognition cells. When we go to IT region, something magical happens and the cells become constantly firing, spatially nonspecific, object recognition cells. (They now fire when seeing a face, no matter itâ€™s on the left or on the right) Integrating the Senses: æˆ‘ä»¬åˆ°ç°åœ¨ä¸ºæ­¢éƒ½æ˜¯è®¨è®ºåŒä¸€ç±»å‹è¾“å…¥é¢„æµ‹åŒä¸€ç±»å‹ç»“æœï¼Œå®é™…ä¸Š association area ä½¿å¾—æˆ‘ä»¬ä¹Ÿå¯ä»¥é¢„æµ‹å…¶ä»–ç±»å‹çš„ç»“æœï¼Œæ¯”å¦‚è§†è§‰è¾“å…¥ç”¨æ¥é¢„æµ‹å¬è§‰ï¼Œå—…è§‰ç­‰ç­‰çš„ç»“æœï¼Œäº¦å¯ä»¥ç”¨æ¥æŒ‡å¯¼åŠ¨ä½œ A New View of V1: å‰æ–‡çš„æ¨¡å‹æœ‰ä¸¤ä¸ªé—®é¢˜ï¼šä»…å½“åˆ°äº† IT è¿™ä¸€å±‚æ—¶ï¼Œæˆ‘ä»¬å¥‡è¿¹èˆ¬åœ°è·å¾—äº† invariant representationï¼›å¤§è„‘ä¸­å¤§éƒ¨åˆ†åŒºåŸŸéƒ½æ˜¯åƒ association area ä¸€æ ·å¾—åˆ°å¤šä¸ªè¾“å…¥ï¼Œä½†æˆ‘ä»¬çš„æ¨¡å‹ä¸­å¥½åƒ V2 åªæœ‰ V1 ä¸€ä¸ªè¾“å…¥ï¼ŒV4 åªæœ‰ V2 ä¸€ä¸ªã€‚ To answer these questions, we propose a new model: V1, V2, V4 are not single cortical regions. Rather, each is a collection of many smaller subregions. V1 has largest number of little cortical areas. V2 has fewer, but larger subregions, each connecting to a number of V1â€™s subregions. Same for V4 and we have a single IT which has a birdâ€™s eye view of the entire visual world. Now the job of any cortical region is to find out how its inputs are related, to memorize the sequence of correlations between them, and to use this memory to predict how the inputs will behave in the future. We can say each region of cortex forms invariant representation drawn from the input areas hierarchically below it. A Model of the World: ä½œè€…è®¤ä¸ºä¸–ç•Œä¸­ Every object is composed of a collection of smaller objects, and most objects are part of larger objects. In an analogous way, memories are stored in the hierarchical structure of the cortex. Time really matters and information flowing into the brain arrives as a sequence of patterns. å¯¹äºæ¯ä¸ª cortical regionï¼Œå®ƒè¯†åˆ«å‡ºæ¥è¿™ä¸ª sequenceï¼Œå°†å…¶æŠ½è±¡æˆä¸€ä¸ª name - a constant pattern of cell firingï¼Œå¹¶å°†è¿™ä¸ªåå­—å‘ç»™ä»–çš„ä¸Šçº§ã€‚æ‰€ä»¥æˆ‘ä»¬ä¹Ÿå¯ä»¥è¯´å¤§è„‘å­˜å‚¨çš„æ˜¯ Sequence of Sequences. By collapsing predictable sequences into â€œnamed objectsâ€ at each region in our hierarchy, we achieve more and more stability the higher we go. This creates invariant representations. Sequences of Sequences: Two processes are at the essence of learning. Assume we are sorting out colored papers. bottom-up classification: deciding what color this paper is top-down sequence recognition: deciding which sequence are we reading in Notice these two processes help each other. 1. If you know the most likely sequence for this series of inputs, you will use this knowledge to decide how to classify the ambiguous input. 2. recognizing any sequence would be impossible if you hadnâ€™t first classified each piece of paper. When we have finally recognized a color sequence, say â€œred red blue greenâ€, we just pass this name to the next higher region; just like the colors to this region, the name is just a pattern to be combined with other inputs, classified, and then put into yet a higher-order sequence. The next higher up region doesnâ€™t have to know what it means. What a Region of Cortex Looks Like: æˆ‘ä»¬è¯´è¿‡æ¯ä¸ª cortical region æœ‰å…­å±‚ (six layers ä»ä¸Šåˆ°ä¸‹åˆ†åˆ«ä¸º L1, L2, â€¦, L6 ä¸è¦è·Ÿè§†è§‰çš„ V1 V4 ææ··) ä½†æˆ‘ä»¬ä¸€èˆ¬ä¸æŠŠæ¯ä¸€å±‚çœ‹åšäººè„‘çš„åŸºæœ¬å•ä½ï¼Œè€Œæ˜¯æŠŠ columns running perpendicular to the layer çœ‹åš basic unit of computation in the cortex. ä½œè€…è®¤ä¸ºå®ƒæ˜¯ basic unit of prediction. æˆ‘ä»¬æ¥ä¸‹æ¥è®¨è®º How cortical regions communicate with each other å…±æœ‰ä¸‰ç§æ–¹æ³•ï¼š Upward Flow: Converge inputs from lower regions goes to the input layer of the next region through axons Downward Flow: Axons in layer 1 spread over long distances, so information flowing down the hierarchy from one column has the potential to activate many columns in the regions below it. Lateral Flow: L1 ç»™ L4,5 å‘æŒ‡ä»¤è¿åŠ¨ï¼ŒL4,5 æ”¶åˆ°æŒ‡ä»¤çš„åŒæ—¶ï¼Œä¸ä»…å‘ä¸‹ç»™è‚Œè‚‰å‘æ”¾è¿åŠ¨ä¿¡å·ï¼Œä¹ŸæŠŠè¿™ä¸ªæ¶ˆæ¯å‘Šè¯‰ thalamusï¼Œthalamus è¿‡ä¸€ä¼šåä¼šæŠŠè¿™ä¸ªæ¶ˆæ¯é‡æ–°ä¼ å›ç»™ L1ã€‚å…¶ä¸­ thalamus æ”¶åˆ°æ¥è‡ªè®¸å¤šä¸åŒ L4, L5 çš„ä¿¡æ¯ï¼Œç„¶åå†æŠŠè¿™äº›ä¿¡æ¯ä¸€èµ·è¿”å›ç»™æ‰€æœ‰ L1 ï¼Œè¿™æ ·æœ¬ column å°±çŸ¥é“çŸ¥é“å‘¨å›´å…¶ä»–äººç°åœ¨æ”¶åˆ°çš„ä¿¡æ¯ã€‚Column not only knows the sequence name (downward flow from above), but also where we are within the sequence (activity from other columns) How a Region of Cortex Works - The Details: How does a cortical region classifies inputs? Itâ€™s too complicated, we assume it does How does it learn sequences of patterns? Input from lower region -&gt; layer 4 fires -&gt; layers 2,3,5 fire -&gt; layer 1 fires to tell the region up some input has come. Fire together Wire together, so 2,3,5,1 wire together. 2,3,5 now can fire without a layer 4 input, so they learn to â€œanticipateâ€ when they should fire based on firing of 1. Half of input to layer 1 comes from layer 5 in neighboring columns. This information represents what was happening moments before. It represents columns that were active prior to your column becoming active. The other half of the input to layer 1 comes from layer 6 cells in hierarchically higher regions. This information is more stationary. It represents the name of the sequence you are currently experiencing. Combining these two information, a prediction/sequence is formed. How does it form a constant â€œnameâ€ for a sequence? constant names = constant input to the next region during learned sequences = need to turn off the output of the layer 2 and layer 3 cells when a column predicts its activity, or, alternately, to make these cells active when the column canâ€™t predict its activity. Layer 2 cell represent the name of the sequence and they stay on when we are within the sequence. Layer 3b cell represents donâ€™t fire when our column successfully predicts its input but do fire when it doesnâ€™t predict its activity. How does it make specific predictions? If you expect a fifth (prediction / invariant representation) and hear a D (specific input). In layer 2 we fire all intervals of fifth. In layer 4 we fire all intervals starting with D. The intersection between the two is our specific prediction. Flowing Up and Flowing Down: ä¸Šå±‚ç»™ä¸‹å±‚ prediction å½“ä¸‹å±‚å¾—åˆ°çš„è¾“å…¥ä¸ prediction ä¸ç¬¦ (unexpected)ï¼Œæˆ‘ä»¬å°†æ­¤ç‰¹å¾ä¼ å¯¼ç»™æ›´ä¸Šä¸€å±‚ï¼Œç›´åˆ° some higher region can interpret it as part of its normal sequence of events. That higher region generates a new prediction and propagates it down Can Feedback Really Do that? Feedback synapses are all far away from cellâ€™s body, so itâ€™s doubted whether the feedback currents can really make a difference. ä½†æ˜¯æ–°ç ”ç©¶å‘ç°ç¦»å¾—è¿œçš„ synapse å¯èƒ½æœ‰å…¶ä»–ç‰¹æ®Šçš„æ•ˆæœï¼ˆå¹¶ä¸ç¡®åˆ‡è¯å®ï¼‰ How the Cortex Learns: æ¯”å¦‚æˆ‘ä»¬æœ‰1,2,3å±‚ï¼Œä¸€å¼€å§‹å•ä¸ªæ–‡å­—åœ¨ç¬¬3å±‚ï¼Œéšç€æˆ‘ä»¬æŒç»­å­¦ä¹ å’Œä¸æ–­ç»ƒä¹ å•ä¸ªæ–‡å­—ç§»åˆ°äº†ç¬¬2å±‚ï¼Œç›¸å¯¹çš„ï¼Œæˆ‘ä»¬åœ¨ç¬¬3å±‚ä¹ å¾—çŸ­è¯­è¿™ä¸ª patternã€‚This ensures that we free up the top for learning more subtle, more complex relationships. è¿™ä¹Ÿæ˜¯æˆ‘ä»¬å˜å¾—æ›´ç†Ÿç»ƒçš„åŸå› ã€‚ The Hippocampus: æˆ‘ä»¬å¸¸è®¤ä¸ºæµ·é©¬ä½“æ˜¯ç”Ÿæˆæ–°è®°å¿†çš„ä¸­å¿ƒï¼Œåœ¨ä½œè€…çš„æ¨¡å‹ä¸­ï¼ŒHippocampus is the top region of neocortex. æˆ‘ä»¬åˆšåˆšè¯´ unexpected input è¢«ä¼ è¾“ç»™ä¸Šå±‚ï¼Œso if something gets to the top of the cortical pyramid, it is the information that canâ€™t be understood by previous experience, the input that is truly new and unexpected. Thatâ€™s what stored in Hippocampus, but it wonâ€™t be stored forever. Itâ€™s either transferred down to the cortex (é•¿æœŸè®°å¿†) or eventually lost (é—å¿˜) æ‰€è°“äººåœ¨å£®ä¸­å¹´æ—¶å¯¹â€æ–°äº‹ç‰©â€çš„è®°å¿†æ²¡æœ‰é‚£ä¹ˆå¥½å®é™…ä¸Šæ˜¯å› ä¸ºè¿™äº›â€æ–°â€çš„ä¸œè¥¿å®é™…ä¸Šæ—©å·²åœ¨ä»¥å‰çš„ç”Ÿæ´»ä¸­å‡ºç°è¿‡ï¼Œæ‰€ä»¥äººå¯¹ç¬¬ä¸€æ¬¡è®°å¿†ç‰¹åˆ«æ·±åˆ»ï¼Œå¯¹ä¹‹åçš„ç±»ä¼¼äº‹ç‰©å°±æ²¡é‚£ä¹ˆå¥½è®°æ€§ã€‚ï¼ˆå®ƒç«Ÿç„¶å’Œ How the Cortex Learns è¿™å¾ˆæ‰¯çš„ä¸€èŠ‚è”èµ·æ¥äº†ï¼‰ An Alternative Path up the Hierarchy: è¿™é‡Œè¦ä»‹ç»çš„æ˜¯ä» Layer5 -&gt; thalamus çš„è·¯å¾„ã€‚è¿™æ¡è·¯å¾„å¯å¼€å¯å…³ï¼Œå®ƒè¦ä¹ˆè¢«ä¸Šå±‚æ¿€æ´»æ‰“å¼€ï¼Œè¦ä¹ˆè¢«ä¸‹å±‚çš„ unexpected input æ¿€æ´»ã€‚æˆ‘ä»¬è®¤ä¸ºè¿™æ¡è·¯å¾„ä»£è¡¨æ³¨æ„åŠ›ï¼Œä¸¤ç§å¼€å¯æ–¹å¼åˆ†åˆ«å¯¹åº”ä¸»åŠ¨å…³æ³¨(pay attention)ï¼Œä»¥åŠå› ä¸ºå¥‡æ€ªçš„ç°è±¡è€Œè¢«åŠ¨å…³æ³¨ (attention is caught) Closing Thoughts: åˆ†äº«äº†ä½œè€…ä»é›¶æƒ³ç»“æ„å†™ä»£ç æœ€åç«Ÿç„¶èƒ½è·‘çš„ä¾‹å­ï¼Œä½†æ˜¯ç›¸å¯¹çš„å¦‚æœåˆ«äººåªç»™ä½ çœ‹ä¸€å †ä»£ç ç»“æ„è§„åˆ’ï¼Œä½ å¯èƒ½ä¼šæ€€ç–‘è¿™ä¸œè¥¿åˆ°åº•èƒ½ä¸èƒ½è·‘ï¼Œç±»æ¯”åˆ°è„‘ç»“æ„ä¸­ï¼Œæ€€ç–‘çš„åŸå› æ˜¯ it is because our intuitive sense of the capacity of the cortex and the power of its hierarchical structure is inadequate. 7 Consciousness and Creativity Animals and Human Intelligence: Memory and Prediction are the core of â€œIntelligenceâ€ and they are used by all livings. There is just a continuum of methods and sophistication in how they do it. One-cell animal: They used DNA as the medium for memory. Individuals could not learn and adapt within their lifetimes. They could only pass on the DNA-based memory of the world to their offspring through their genes. Modifiable Nervous System: An individual could now learn about the structure of its world and adapt its behavior accordingly within its lifetime. But an individual still could not communicate this knowledge to its offspring other than by direct observation. Neocortex was also created at this time. Human Intelligence: It begins with the invention of language and the expansion of our large neocortex. The more important is language. We humans can learn a lot of the structure of the world within our lifetimes, and we can effectively communicate this to many other humans via language. What is Creativity? Recall that we make predictions by combining the invariant memory recall of what should happen next with the details pertaining to this moment in time. All cortical predictions are predictions by analogy. We are being creative when our memory-prediction system operates at a higher level of abstraction, when it makes uncommon predictions, using uncommon analogies. æ³¨æ„ GEB ä¸­ä¹Ÿæåˆ°è¯´ analogy æ˜¯æ™ºæ…§çš„æ ¸å¿ƒ What is Consciousness? æœ‰äººè®¤ä¸º consciousness/mind åœ¨èº«ä½“ä¹‹å¤–ï¼Œä½†æ˜¯å®é™…ä¸Šå®ƒå°±åœ¨è„‘ä¸­ã€‚Your thoughts, which are located in the brain, are physically separate from the body and the rest of the world. Mind is independent of body, but not of brain. 8 The Future of Intelligence Because I have been immersed in the neuroscience and computer fields for over two decades, perhaps my brain has built a high-level model of how technological and scientific change occurs, and that model predicts rapid progress. Now is the turning point. General Direction of Intelligent Machine: Our intelligent machine may have a set of senses that differ from a humanâ€™s. attach to these senses a hierarchical memory system that works on the same principles as the cortex. We will then have to train the memory system much as we teach children. Over repetitive training sessions, our intelligent machine will build a model of its world as seen through its senses. The intelligent machine must learn via observation of its world. Once our intelligent machine has created a model of its world, it can then see analogies to past experiences, make predictions of future events. è¿™ä¸ªæ™ºèƒ½æœºå™¨çš„æ•´ä½“è¿ä½œæ–¹æ³•å’Œå¤§è„‘ç›¸åŒï¼Œä½†æ˜¯å®ƒå¹¶ä¸éœ€è¦ä¸å¤§è„‘é•¿å¾—ç›¸ä¼¼æˆ–å¾—åˆ°å’Œå¤§è„‘ç›¸åŒçš„è¾“å…¥ï¼Œå®ƒåªéœ€è¦å¤åˆç»“æ„çš„ï¼Œèƒ½å¤Ÿç”¨æ¥ä½œâ€œé¢„æµ‹â€çš„è¾“å…¥å³å¯ã€‚What makes it intelligent is that it can understand and interact with its world via a hierarchical memory model and can think about its world in a way analogous to how you and I think about our world. Ethical Problems? No. The strongest applications of intelligent machines will be where the human intellect has difficulty, areas in which our senses are inadequate, or in activities we find boring. In general, these activities have little emotional content. In the following areas, Intelligent Machines will exceed we humans: Speed: Transistor switch is much faster than human brainâ€™s electrical signals. Capacity: we can add capacity to machineâ€™s mind by doing the followings (these are also what we do in DL/ML) Adding depth to the hierarchy will lead to deeper understanding: the ability to see higher-order patterns. Enlarging the capacity within regions will allow the machine to remember more details, or perceive with greater acuity. Adding new senses and sensory hierarchies permits the device to construct better models of the world Replicability: we humans learn knowledge and form our own model of the world rather slowly. However, an intelligent machine need not undergo this long learning curve, since chips and other storage can be replicated endlessly and the contents transferred easily. Sensory Systems: Input patterns to the machine donâ€™t have to be analogous to animal senses, or even to derive from the real world at all. In fact, the author suspects that out inability to tackle issue may be related to a mismatch between the human senses and the physical phenomena we want to understand. Intelligent machines can have custom senses more sensitive than our own, or senses that are distributed, or senses for very small phenomena. They might think in three, four, or more dimensions. Appendix: The Thousand Brain Theory Notes from Microsoft Research - The Thousand Brains Theory by Jeff Hawkins Local Cortical Circuit Inside a local cortical circuit, neurons are organized in layers. Most connections go vertically across the layers; limited connections go horizontally within layer. Recent find: all layers have a motor output. So itâ€™s always sensorimotor input, no pure sensory input. Vernon Mountcastle: neocortex is remarkably uniform in appearance and structure because they are actually performing the same basic intrinsic function. A cortical column is the unit of replication. If you understand one of it, you understand the whole brain. Layer 2,3 - object Layer 4 - main input layer Layer 6 - location relative to the object L6 sends information to L4, L4 processes these information with its own other input. Over time it forms a representation of what the object itself is in layer L2,3. On top of that, if we have multiple cortical involved (imagine multiple fingers touching the cup instead of only one), we can instantly build a mental image of the cup by the connections across cortical units happened in L2,3. This is like a voting mechanism where each finger has a guess of its feeling and they settle what the object really is by talking to each other. Building a Reference Map A reference map is the sense of relative location as we are touching the cup Contrast to the classical view, the vast majority of connections between cortical regions are not hieratical at all. Hypothesis: the grid cells in entorhinal cortex also exist in every cortical column of every neocortex region. They donâ€™t create reference frames for location but reference frames for the objects we interact (the cup). In the classical view, we have a hierarchy in our neocortex. The real structure is similar, ä½†æˆ‘ä»¬å¹¶ä¸æ˜¯ æ¯æŸ„ -&gt; æ¯èº« -&gt; æ•´ä¸ªæ¯å­ è¿™ç§çœŸæ­£çš„é˜¶æ¢¯å¼å»ºæ¨¡ï¼Œè€Œæ˜¯æ¯ä¸ªâ€œå±‚çº§â€éƒ½å½¢æˆä¸€ä¸ªè‡ªå·±çš„æ¯å­æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹å¹¶ä¸ç›¸åŒ. This model allows all models to â€œvoteâ€. Everyone tries to guess whatâ€™s going on.","categories":[],"tags":[{"name":"Book","slug":"Book","permalink":"https://yao-lirong.github.io/blog/tags/Book/"}]},{"title":"TensorFlow 1.x Manual","slug":"2021-05-28-Introduction-to-TensorFlow-1.x","date":"2021-05-28T04:00:00.000Z","updated":"2022-06-08T19:53:42.000Z","comments":true,"path":"2021-05-28-Introduction-to-TensorFlow-1.x/","permalink":"https://yao-lirong.github.io/blog/2021-05-28-Introduction-to-TensorFlow-1.x/","excerpt":"æµ·å°”å®ä¹ æœŸé—´è®°å½•ä¸‹çš„ TensorFlow ç¬”è®°","text":"æµ·å°”å®ä¹ æœŸé—´è®°å½•ä¸‹çš„ TensorFlow ç¬”è®° Basic Notion Graph: often refers to Computation Graph, which describes how to compute the output Eager execution: evaluates operations immediately, without building graphs Enabling eager execution changes how TensorFlow operations behaveâ€”now they immediately evaluate and return their values to Python. tf.Tensorobjects reference concrete values instead of symbolic handles to nodes in a computational graph. Since there isnâ€™t a computational graph to build and run later in a session, itâ€™s easy to inspect results using print() or a debugger. Evaluating, printing, and checking tensor values does not break the flow for computing gradients. Operation: å›¾ä¸­çš„èŠ‚ç‚¹, takes Tensor object as input, and produces Tensor objects as output Tensor: multi-dimensional arrays with a uniform type (called dtype), åŒ…å«ä¸€ä¸ª n ç»´çš„æ•°ç»„æˆ–åˆ—è¡¨. ä¸€ä¸ªé™æ€ç±»å‹ rank, å’Œ ä¸€ä¸ª shape. It does not hold the values of that operationâ€™s output, but instead provides a means of computing those values. It is a symbolic handle of input/output of Operation. å›¾ä¸Šæ“ä½œé—´ä¼ é€’çš„æ•°æ®éƒ½æ˜¯ Tensor: A Tensor can be passed as an input to another Operation. This builds a dataflow connection between operations, which enables TensorFlow to execute an entire Graph that represents a large, multi-step computation. Session: launch the computation of a graph InteractiveSession: a better graph runner that allows you to compute each operation step by step instead of only giving out the final result, as in Session 12345678910# Build a dataflow graph.a = tf.constant([[1.0, 2.0], [3.0, 4.0]])b = tf.constant([[1.0, 1.0], [0.0, 1.0]])c = tf.matmul(a, b)# Construct a `Session` to execute the graph.sess = tf.compat.v1.Session()# Execute the graph and store the value that `e` represents in `result`.result = sess.run(e) a, b, c are Tensor here. c = tf.matmul(a, b) creates an Operation of type â€œMatMulâ€ (Matrix Multiplication) that takes tensors a and b as input, and produces c as output. Variable: represent shared, persistent state your program manipulates (parameters of the model) it is a tf.Tensor whose value can be changed by running ops on it Placeholder: a tensor whose value will later be fed. Operations on Tensors tf.reduce_xxx(t, axis=i): If we have a tensor t of dimension $d_1 d_2 â€¦ d_n $, apply r = reduce_xxx(t, axis = i), Each entry along axis i will be collapsed into a single entry, so r will have dimension $d_1 d_2 â€¦ d_{i-1} d_{i+1} â€¦ d_n $: 1234567891011121314151617a=np.random.randint(1,10,(2,3,4))&#x27;&#x27;&#x27;2 arrays of dimension 3 X 4[[[8 5 7 1] [9 7 2 2] [7 7 4 6]] [[7 7 8 4] [7 4 3 6] [5 3 2 8]]]&#x27;&#x27;&#x27;sess = tf.Session()with sess.as_default(): r = (tf.reduce_sum(a, axis=1)).eval() # reduce along axis of length 3&#x27;&#x27;&#x27;[[24 19 13 9] [19 14 13 18]]&#x27;&#x27;&#x27; tf.reshape(t, list): Reorder all the elements in t so that we have a new dimension in r: d1â€² = list[0], d2â€² = list[1], ... If we have dâ€²i = âˆ’1 as one of the dimension, $d_iâ€™ = $, so 1r = tf.reshape(a, [-1,2,2]).eval() # r will havee shape (6, 2, 2) tf.concat([t1, t2, ...], axis = i): pile all the arrays along axis i. These arrays must have the same length along the other axis. In the result, only the length along axis i will increase, the length of other axis remain the same. tf.tile(t, [m1,m2,...]): multiple axis i with mi, so the result tensor dimension is (d1 Ã— m1, d2 Ã— m2, ...) Debug with Tensorboard tf.summary: Follow the official guide tf.estimator: Specify model_dir when initializing your estimator. Everything about the trained model will be stored in this directory, including event files logging training process. Reference Utility Sometimes we encounter module 'tensorflow' has no attribute ... because TensorFlow changed/refactored its function name. We can use this list to manually update all changed names or directly use this script.","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"Look Back on Cornell 21SP","slug":"2021-05-24-Look-Back-on-Cornell-21SP","date":"2021-05-24T04:00:00.000Z","updated":"2023-02-23T04:15:40.000Z","comments":true,"path":"2021-05-24-Look-Back-on-Cornell-21SP/","permalink":"https://yao-lirong.github.io/blog/2021-05-24-Look-Back-on-Cornell-21SP/","excerpt":"ç”Ÿå¹´ä¸æ»¡ç™¾ å¸¸æ€€åƒå²å¿§ æ˜¼çŸ­è‹¦å¤œé•¿ ä½•ä¸ç§‰çƒ›æ¸¸ ä¸ºä¹å½“åŠæ—¶ ä½•èƒ½å¾…æ¥å…¹ æ„šè€…çˆ±æƒœè´¹ ä½†ä¸ºåä¸–å—¤ ä»™äººç‹å­ä¹” éš¾å¯ä¸ç­‰æœŸ","text":"ç”Ÿå¹´ä¸æ»¡ç™¾ å¸¸æ€€åƒå²å¿§ æ˜¼çŸ­è‹¦å¤œé•¿ ä½•ä¸ç§‰çƒ›æ¸¸ ä¸ºä¹å½“åŠæ—¶ ä½•èƒ½å¾…æ¥å…¹ æ„šè€…çˆ±æƒœè´¹ ä½†ä¸ºåä¸–å—¤ ä»™äººç‹å­ä¹” éš¾å¯ä¸ç­‰æœŸ è¿™å­¦æœŸæ˜¯æ”¾å‡çš„å­¦æœŸï¼Œçªå¦‚å…¶æ¥çš„COVID-19è®©æˆ‘æ„è¯†åˆ°äººç”Ÿè‹¦çŸ­ï¼Œä¸ºæœªæ¥å¥‹æ–—ä¸å¦‚åŠæ—¶äº«ä¹ï¼Œæ´»åœ¨å½“ä¸‹ã€‚å’Œå®¶é‡Œäººä¸€èµ·è¿‡ä¸ªå¹´ï¼Œå¤šçœ‹çœ‹åŠ¨æ¼«çœ‹çœ‹ç”µå½±ï¼Œè‡ªå·±çˆ±å¹²ç‚¹å•¥å¹²ç‚¹å•¥å§ã€‚ æ²¡é€‰ä»»ä½•CSä¸“ä¸šè¯¾ï¼Œä¸è¿‡TAäº†4820ã€‚å”¯ä¸€ä¸€èŠ‚ç±»ä¼¼äºä¸“ä¸šè¯¾çš„æ˜¯ MATH3360ï¼Œå…¶ä»–éƒ½æ˜¯éšä¾¿ä¸Šä¸Šï¼Œä¸»è¦æ—¶é—´èŠ±è´¹åœ¨è‡ªå·±é”»ç‚¼é”»ç‚¼èº«ä½“å’Œå­¦æ—¥è¯­å­¦ä¹ç†ä¸Šã€‚æƒ³èµ·æ¥é”»ç‚¼èº«ä½“çš„åŸå› æ˜¯å»å¹´å»æ¸…åä¹‹å‰ä½“æ£€åŒ»ç”Ÿè¯´æˆ‘å¿ƒç‡è¿‡ç¼“ï¼Œè®©æˆ‘å›å¿†èµ·ä½“æ£€ä¹‹å‰è¿˜ä¸€ä¸ªäººåœ¨ä¸Šæµ·å¾ˆçƒ¦èºï¼Œæ¯å¤©ç†¬å¤œåˆ°ä¸¤ä¸‰ç‚¹æ‰“æ¸¸æˆæ—©ä¸Šä¹ç‚¹èµ·ï¼Œåˆ°äº†æ™šä¸Šå°±å¼€å§‹å¿ƒæ…Œã€‚è¿™ä¸¤ä»¶äº‹åŠ èµ·æ¥æˆ‘çªç„¶è§‰å¾—è‡ªå·±ä¼šä¸ä¼šè¿‡ä¸¤å¹´çªç„¶çŒæ­»äº†ï¼Œä¸ºäº†é˜²æ­¢çŒæ­»è¿™å­¦æœŸè¿åŠ¨è¿åŠ¨ï¼Œç»“æœå­¦æœŸæœ«å†å»ä½“æ£€çš„æ—¶å€™å‘ç°å¿ƒç‡è¿˜æ˜¯é‚£æ ·ï¼Œä¼°è®¡å¤©ç”Ÿå¿ƒè„å°±è¿™ä¸ªæ ·ï¼Œå’Œæˆ‘è¿ä¸è¿åŠ¨æ²¡å•¥åµå…³ç³»ã€‚ JAPAN2202 Intermediate Japanese II ã‚‚ã—ã‚‚ã“ã®ãƒ¡ãƒ¼ãƒ«ã‚’èª­ã‚ãŸãªã‚‰ã€ã“ã®ç¬é–“ã€ã‚ãªãŸã®å¹¸ã›ã¯2å€ã«ã‚‚ï¼“å€ã«ã‚‚ãªã‚Šã¾ã™ã€‚ ãªãœãªã‚‰ã‚ãªãŸã«ã¯ã€ã‚ãªãŸã®ã“ã¨ã‚’æ€ã£ã¦ã“ã‚Œã‚’é€ã£ã¦ãã‚ŒãŸèª°ã‹ãŒã„ã‚‹ã ã‘ã§ãªãã€æ–‡å­—ã‚‚èª­ã‚ã‚‹ã‹ã‚‰ã§ã™ã€‚ ã‘ã‚Œã©ãªã«ã‚ˆã‚Šã‚ãªãŸã¯ç”Ÿãã¦ã„ã‚‹ã‹ã‚‰ã§ã™ã€‚ â€‹ ãƒ¼ãƒ¼ã€Œä¸–ç•ŒãŒã‚‚ã—ï¼‘ï¼ï¼äººã®æ‘ã ã£ãŸã‚‰ã€ å› ä¸ºæœ¬äººç»å…¸çœ¼é«˜æ‰‹ä½ï¼Œæ‰˜ä¸Šå­¦æœŸåœ¨æ¸…åè®¤è¯†çš„Leoå¸®æˆ‘åšäº† placement exam å¸®æˆ‘è€ƒåˆ°äº† 2000 çº§æ—¥è¯­è¯¾ï¼Œä»¥ä¸ºè‡ªå·±ä½œä¸ºä¸€ä¸ªä¸­å›½äººï¼Œå¼€å­¦å‰æ¶è¡¥ä¸€ä¸‹å°±èƒ½èµ¶ä¸Šè¯¾ç¨‹è¿›åº¦ã€‚äºæ˜¯å¼€è¯¾å‰è‡ªå·±é€Ÿåº¦çœ‹å®Œäº†ã€Šå¤§å®¶çš„æ—¥æœ¬è¯­ã€‹åˆçº§ä¸¤å†Œï¼Œç„¶åæŠŠã€Šä¸Šç´šã¸ã®ã¨ã³ã‚‰ã€‹ä»–ä»¬è®²è¿‡çš„å‰ä¸¤è¯¾ä¹Ÿè‡ªå·±çœ‹äº†ã€‚æœ¬æ¥å¼€å­¦å‰è¿˜æ˜¯æ¯”è¾ƒæœ‰ä¿¡å¿ƒçš„ï¼Œç»“æœçœŸè¦å»ä¸Šè¯¾è¾“å‡ºèƒ½åŠ›è¿˜æ˜¯å¤ªå·®äº†ï¼Œè€Œä¸”è€å¸ˆä¸€ç‚¹åˆ°æˆ‘åå£åƒåœ°è¯´ä¸å‡ºè¯æ¥ï¼ŒçœŸçš„æœ¬æ¥å¤§ä¸€è¿™æ¯›ç—…éƒ½å¿«å¥½äº†ï¼Œzoomä¸€å¹´ç»™æˆ‘å¹²å›åŸå‹ç”šè‡³åŠ é‡äº†ã€‚æœ€åå°±æ˜¯è¿™é—¨è¯¾è¦æ±‚æ—¶é—´å¤ªé•¿äº†ï¼Œä¸€å¤©æˆ‘å¯èƒ½è¦èŠ±6hä»¥ä¸Šåœ¨å®ƒä¸Šé¢ï¼Œæ›²çº¿æœ‰ç‚¹é™¡å³­ï¼Œæœ€ç»ˆé€‰æ‹©äº†dropã€‚å¯èƒ½ä»2201å¼€å§‹è·Ÿä¼šæ›´å¥½å—ï¼Ÿä½†æ˜¯2201çš„é‚£äº›çŸ¥è¯†ç‚¹åˆå¤ªåŸºç¡€äº†ï¼Œè‡ªå·±å°±æ˜¯åœ¨ä¸€ä¸ªä¸Šä¸å»ä¸‹ä¸æ¥çš„å°´å°¬åœ°æ–¹ï¼Œå…¶å®æœ€å¥½å°±æ˜¯æˆ‘å½“æ—¶20FAä¹‹å‰æŠŠã€Šå¤§å®¶çš„æ—¥æœ¬è¯­ã€‹ä¸¤å†Œéƒ½çœ‹å®Œï¼Œè¯´å®è¯éƒ½æ€ªæˆ‘å¦ˆé€¼æˆ‘å»çš„é‚£ä¸ªå®ä¹ ï¼ŒæŠŠæˆ‘è®¡åˆ’ä¹Ÿæ‰“ä¹±äº†ï¼Œèº«ä½“ä¹Ÿæåäº†ã€‚ é€€è¯¾ä»¥åè‡ªå·±å­¦å¾—ä¹ŸæŒºèµ·åŠ²çš„ï¼Œä¸€ä¸ªå¤šæœˆæŠŠã€Šä¸Šç´šã¸ã®ã¨ã³ã‚‰ã€‹è¿™æœ¬ä¹¦è‡ªå·±çœ‹å®Œäº†ï¼ŒçŸ¥è¯†ç‚¹ä¹Ÿç®—å¤§ä½“æŒæ¡ï¼Œä¸æ˜ç™½çš„æ‰¾äº†ä¸ªä¸€å¯¹ä¸€ä¸Šäº†ä¸¤èŠ‚è¯¾ä¹Ÿéƒ½ææ˜ç™½äº†ã€‚è¯æ±‡é‡ä¸å’‹åœ°ä½†æ˜¯è§‰å¾—è‡ªå·±å¬åŠ›é˜…è¯»éƒ½è¿˜å‡‘åˆã€‚è‡ªå·±çœ‹ä½è´ºç¬¬äºŒå­£å’Œè‘¡è„åŸæ¥çš„ç”Ÿè‚‰éƒ½ç®—æ˜¯èƒ½çœ‹çš„åœ°æ­¥ï¼Œæ€»å¾—æ¥è¯´è¿™å­¦æœŸæ—¥è¯­è¿˜æ˜¯å¾ˆæœ‰æ”¶è·çš„ã€‚ å…¶ä»–è¯¾ç¨‹ ä»¥ä¸‹å‡ é—¨è¯¾é™¤æ•°å­¦å¤–æˆ‘å…¨éƒ¨æ‘†çƒ‚SUï¼Œæœ€ç»ˆæˆç»©éƒ½åœ¨å°´å°¬çš„ A- å·¦å³ï¼Œæˆ‘è¯´å®è¯ï¼Œæ—©çŸ¥é“æˆ‘å°±ç›´æ¥ä¸äº¤ä½œä¸šäº†ï¼Œæ‘†äº†ä½†åˆæ²¡å®Œå…¨æ‘†ï¼Œå­¦äº†ä½†åˆæ²¡å®Œå…¨å­¦ã€‚ BIONB2220 Intro to Neuroscience: ç®—æ˜¯è¿™å‡ é—¨é‡Œæˆ‘å”¯ä¸€ä¸€é—¨ç”¨å¿ƒå­¦çš„è¯¾ï¼ŒæŒºä¸é”™çš„ç¥ç»ç§‘å­¦å…¥é—¨ï¼Œæ¯ä¸€ç« éƒ½æ˜¯ç”±å¯¹åº”é¢†åŸŸçš„ç ”ç©¶äººå‘˜æ¥ä¸Šçš„ ARKEO2661 Ancient Ships and Seafaring: æŠ˜ç£¨ï¼Œæˆ‘æœ¬ä»¥ä¸ºèƒ½æŒºæœ‰æ„æ€çš„ï¼Œä½†æ˜¯è¿™ç§ä½ åªæ˜¯ç¨å¾®æ„Ÿå…´è¶£çš„ä¸œè¥¿è¢«å½“æˆè¯¾å’Œè€ƒè¯•çš„ä¸œè¥¿æ¥ä¸ŠçœŸçš„å¾ˆæŠ˜ç£¨ï¼Œè€ƒè¯•éƒ½æ˜¯é€‰æ‹©é¢˜ï¼Œä½†æ˜¯ç¬¬ä¸€æ¬¡è€ƒå¾—ä¸å¥½è®©æˆ‘å†³å®šSUè¿™é—¨è¯¾äº†ã€‚ç»“æœç¬¬äºŒæ¬¡è¿‘ä¹è€ƒäº†æ»¡åˆ†ï¼Œä¸»è¦æ˜¯ç¬¬äºŒæ¬¡å­¦èªæ˜äº†ï¼Œç›´æ¥æŠŠæ‰€æœ‰çš„slideåˆå¹¶æˆä¸€ä¸ªå¤§çš„pdfï¼Œæœä¸€ä¸‹ç­”æ¡ˆåŸºæœ¬å°±æœ‰äº†ï¼Œå”‰è¦æ˜¯ç¬¬ä¸€æ¬¡å°±çŸ¥é“çš„è¯ï¼Œè¿™é—¨è¯¾ä¹Ÿèƒ½ç®—ä¸ªGPA booster PSYCH2150 Psychology of Language: æŠ˜ç£¨ï¼ŒåŒä¸Šï¼ŒçœŸçš„ä¸èƒ½é€‰è¿™ç§åªæ˜¯ç¨å¾®æ„Ÿå…´è¶£çš„è¯¾ä¸Šã€‚æˆ‘ç¬¬ä¸€æ¬¡å‘è§‰è¯­è¨€å­¦è¿™ä¹ˆæ— èŠè¿™ä¹ˆæ‰¯æ·¡ã€‚ å¦å¤– MATH3360ï¼Œçº¯ç²¹æ˜¯ä¸ºäº†å‡‘ä¸€ä¸ª Algebra Requirement ä¸Šçš„è¯¾ï¼Œä¸Šå­¦æœŸå‰æˆ‘è¿˜è€ƒè™‘ double major mathï¼Œè®©4710ç»™æˆ‘å¹²æ²‰é»˜ä»¥åæˆ‘çœŸçš„å¯¹æ•°å­¦é™¢è¯´æ‹œæ‹œäº†ï¼Œä½†æ˜¯ä¸Šå®Œè¿™é—¨è¯¾å†éšä¾¿é€‰ä¸€é—¨æˆ‘å°±èƒ½æ‹¿ä¸ª Math Minorï¼Œä½†æ˜¯è½¬å¿µä¸€æƒ³ï¼Œæˆ‘æ‹¿ä¸ªminoræœ‰å•¥ç”¨å‘¢ï¼Ÿå¥½è ¢ï¼Œè¿™å­¦æœŸçœŸçš„ä¸è¯¥ä¸Šè¿™é—¨è¯¾ã€‚ åœ¨å®¶çš„è¿™ä¸ªå­¦æœŸä¹Ÿè‡ªå­¦äº†ä¸€äº›ä¹ç†ï¼Œé€šè¿‡ Functional Ear Trainer è¿™ä¸ªè½¯ä»¶æŒæ¡äº†å¤§è°ƒçš„é€šè¿‡æ ¹éŸ³æ‰¾éŸ³ï¼Œæ€»å¾—æ¥è¯´å¯¹äºå°å­¦æ—¶å€™è¢«å¼ºé€¼ç€ç…§è°±å­å¼¹ç´å¿«ä¹ä¸å°‘ã€‚","categories":[],"tags":[{"name":"Review","slug":"Review","permalink":"https://yao-lirong.github.io/blog/tags/Review/"}]},{"title":"Setting up a Server","slug":"2021-05-15-Setting-up-a-Server","date":"2021-05-15T04:00:00.000Z","updated":"2021-08-28T21:33:50.000Z","comments":true,"path":"2021-05-15-Setting-up-a-Server/","permalink":"https://yao-lirong.github.io/blog/2021-05-15-Setting-up-a-Server/","excerpt":"","text":"Initial Server Setup Logging In We chose â€œuse ssh keys to log inâ€ when creating the server, so we need to first get our root password by â€œreset root passwordâ€. Next time when you log in, you will be prompted to change password. log into server ssh root@your_server_ip. Passphrase set when creating ssh keys are needed. Adding User Check currently available users with cat /etc/passwd Add a new user with adduser &lt;username&gt; If a wrong user is added accidentally, delete it with deluser &lt;username&gt; Grant this newly added user sudo privilege by â€œappendingâ€ it to sudo â€œGroupâ€ usermod -aG sudo &lt;username&gt; Logging in as New User We can log in with the following two ways: Enabling ssh password login: go to /etc/ssh/sshd_config and change PasswordAuthentication no to PasswordAuthentication yes. Restart the service after editing sudo service ssh restart. Continue use SSH Authentication: We want to copy the keys with the correct ownership and permissions, so use rsync --archive --chown=sammy:sammy ~/.ssh /home/sammy (Replace â€œsammyâ€ with your username) explains what â€“archive does --chown=USER:GROUP forces all files to be owned by USER with group GROUP be sure that the source directory (~/.ssh) does not include a trailing slash (check to make sure you are not using ~/.ssh/) If you accidentally add a trailing slash to the command, rsync will copy the contents of the root accountâ€™s ~/.ssh directory to the sudo userâ€™s home directory instead of copying the entire ~/.ssh directory structure. We can now log in as the newly added user &lt;username&gt;@your_server_ip Setting up Firewall Before everything, you should check IPV6 is enabled by going to nano /etc/default/ufw and check IPV6=yes. Set up a default profile to deny all incoming and allow all outgoing. 12ufw default deny incomingufw default allow outgoing This is enough for a PC but not enough for a server. We would need to allow ssh, HTTP, and HTTPS. 123ufw allow sshufw allow httpufw allow https The Firewall will then allow traffic from the default ports specified by these applications. For example, ssh uses port 22, so ufw allow ssh is equivalent to ufw allow 22. Enable and check firewallâ€™s status: 12ufw enableufw status verbose For more commands related to UFW, check UFW Essentials. Install PHP å®‰è£…phpï¼Œå¯ç”¨æƒ³è¦å®‰è£…çš„ç‰ˆæœ¬æ›¿æ¢ â€œ7.4â€: apt install php7.4-cli å®‰è£…æ‰€éœ€è¦çš„æ’ä»¶ï¼Œå¯ä»¥é€šè¿‡ aptitude search php7.4 |grep -i mysql æ¥å¯»æ‰¾å¯¹åº”çš„æ’ä»¶ï¼ˆå¯ç”¨è‡ªå·±éœ€è¦çš„ mbstring, GD, ç­‰æ›¿æ¢ mysqlï¼‰ conf.d - individual site configuration stored here","categories":[],"tags":[{"name":"Logistics","slug":"Logistics","permalink":"https://yao-lirong.github.io/blog/tags/Logistics/"}]},{"title":"Tsinghua DSA ä½œä¸šæ€»ç»“ (3)","slug":"2021-02-11-Tsinghua-DSA-ä½œä¸šæ€»ç»“-(3)","date":"2021-02-11T05:00:00.000Z","updated":"2022-06-08T19:33:26.000Z","comments":true,"path":"2021-02-11-Tsinghua-DSA-ä½œä¸šæ€»ç»“-(3)/","permalink":"https://yao-lirong.github.io/blog/2021-02-11-Tsinghua-DSA-%E4%BD%9C%E4%B8%9A%E6%80%BB%E7%BB%93-(3)/","excerpt":"CSTæ•°æ®ç»“æ„ï¼ˆ2020ç§‹ï¼‰PA3","text":"CSTæ•°æ®ç»“æ„ï¼ˆ2020ç§‹ï¼‰PA3 3.1 Not Found ç®—æ³• è¦æ‰¾äºŒè¿›åˆ¶å­—ç¬¦ä¸² A ä¸­æœ€çŸ­çš„æœªå‡ºç°è¿‡çš„å­ä¸² Bï¼Œæˆ‘ä»¬å…ˆè€ƒè™‘ä¸€ä¸ªæ¯”è¾ƒé•¿çš„å­ä¸²ï¼Œå…¶é•¿åº¦ä¸º 24ã€‚ æ³¨æ„åˆ° A çš„é•¿åº¦æœ€é•¿ä¸º 16777216 = 2^24ã€‚å› ä¸ºè¿˜è¦æå¤´å»å°¾ï¼Œæ‰€ä»¥ A ä¸­é•¿åº¦ä¸º 24 çš„å­ä¸²çš„æ€»æ•°å¿…å®šå°äº 2^24 ä¸ªï¼Œè€Œé•¿åº¦ä¸º 24 çš„å­—ç¬¦ä¸²æ€»å…±æœ‰ 2^24 ç§ï¼Œæ‰€ä»¥ A ä¸­å¿…å®šæœ‰æŸä¸ªé•¿åº¦ä¸º 24 çš„å­—ç¬¦ä¸²æ˜¯ä¸å­˜åœ¨çš„ã€‚ æˆ‘ä»¬ç”¨ bitmap è¾¹è¯»å…¥ï¼Œè¾¹è®°å½•ä¸‹æ‰€æœ‰å‡ºç°è¿‡çš„é•¿ä¸º 24 çš„å­ä¸²ã€‚è¿™ä¸ª bitmap åªå­˜é•¿åº¦ä¸º 24 çš„å­ä¸²ï¼Œæˆ‘ä»¬å«å®ƒ bitmap24ã€‚è¯»å…¥å®Œæˆåï¼Œæ³¨æ„åˆ°ä»»ä½•ä¸€ä¸ªåœ¨ A ä¸­å‡ºç°çš„é•¿ä¸º 23 çš„å­ä¸²å¿…å®šæ˜¯æŸä¸€ 24 å­ä¸²æå¤´æˆ–å»å°¾å¾—åˆ°çš„ï¼Œäºæ˜¯æˆ‘ä»¬éå†æ‰€æœ‰åœ¨ 24 å­ä¸²ï¼Œå¯¹ä»–ä»¬æå¤´å»å°¾ï¼Œå°†å¾—åˆ°çš„ä¸¤ä¸ªç»“æœå­˜å…¥ bitmap23 ä¸­ï¼Œå¦‚æ­¤åšç›´åˆ° bitmap1 å­˜å®Œã€‚ æœ€åæˆ‘ä»¬ä»é•¿åº¦ 24 å¼€å§‹éå†ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªé•¿åº¦ n ä½¿å¾—æ‰€æœ‰é•¿åº¦ä¸º n çš„å­ä¸²éƒ½åœ¨ A ä¸­å‡ºç°äº†ï¼Œé‚£ä¹ˆæ‰€è¦æ‰¾çš„â€œæœ€çŸ­æœªå‡ºç°å­ä¸²â€ B å¿…ç„¶æœ‰é•¿åº¦ n+1ï¼Œæˆ‘ä»¬åªéœ€è¦å†éå†ä¸€é bitmap(n+1) æ‰¾åˆ°ç¬¬ä¸€ä¸ªä¸å­˜åœ¨çš„å­—ç¬¦ä¸²å³å¯ ç»†èŠ‚ è¯»å…¥å­—ç¬¦ä¸²çš„æ—¶å€™å½“æ€»é•¿åº¦è¾¾åˆ° 24 ä»¥åï¼Œæˆ‘ä»¬å°±è¦è¯»ä¸€ä¸ªæ–°çš„å¼ƒä¸€ä¸ªæ—§çš„ï¼Œå› ä¸ºæ ¹æ®é¢˜ç›®åˆ†æ B æœ€é•¿ä¹Ÿå°±æ˜¯ 24 ä¸€ä¸ª int æ˜¯ 4 byte = 32 bit = 2^5 bitï¼Œæ‰€ä»¥ bitmap24 éœ€è¦ 224/25 = 219 ä¸ª intï¼Œbitmap1 â€¦ bitmap 5 å„è‡ªä»…éœ€ 1ä¸ª int å› ä¸ºæˆ‘ä»¬æ˜¯å°†äºŒè¿›åˆ¶å­—ç¬¦ä¸²ç”¨ int æ–¹å¼å­˜åœ¨ bitmap ä¸­ï¼Œå¦‚æœè¿™ä¸ªå­—ç¬¦ä¸²æœ‰ leading 0s, å®ƒä»¬åœ¨è¾“å‡ºæ—¶ä¼šè¢«å¿½ç•¥æ‰ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦æ ¹æ® bitmap-n è¿™ä¸ªé•¿åº¦ n æ¥è¡¥å…¨ leading 0s ä»£ç  123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145#include&lt;cstdio&gt;#include&lt;iostream&gt;using namespace std;// int_size[i] is the number of ints needed to store all strings of length iconst int int_size[25] = &#123; 1, // there should be no bitmap for string of length 0, // but we give it 1 to make the whole program consistent 1, 1, 1, 1, 1, // 2^1 2^2 2^3 2^4 2^5 each only needs one int 2, 4, 8, 16, 32, // 2^6, ... 10 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536, 131072, 262144, 524288 &#125;;// ones[i] is 2^i - 1const int ones[25] = &#123; 0, 1, 3, 7, 15, 31, 63, 127, 255, 511, //10 1023, 2047, 4095, 8191, 16383, 32767, 65535, 131071, 262143, 524287, //20 1048575, 2097151, 4194303, 8388607, 16777215&#125;;// bitmap[i] is the bitmap for binary strings of length iunsigned int *bitmap[25];// make our bitmap contain a binary string x of length nvoid setbit(int n, unsigned int x);// returns true if our bitmap contains a binary string x of length nbool checkbit(int n, unsigned int x);// print a binary string x of length nvoid print_binary(int n, unsigned int x);int main()&#123; for (int i = 0; i &lt;= 24; i++) &#123; bitmap[i] = new unsigned int[int_size[i]]; for (int j = 0; j &lt; int_size[i]; j++) bitmap[i][j] = 0; &#125; // n is the total number of characters we read in // s is the string at our sliding window // c is the character we just read in // input is 0 if c is &#x27;0&#x27;, is 1 if c is &#x27;1&#x27; unsigned int n = 0, s = 0, input = 0; char c = getchar(); n = 1; // read till nothing more to read or the string is 24 char long for (; c!=&#x27;\\n&#x27; &amp;&amp; n&lt;24; c = getchar()) &#123; input = c - &#x27;0&#x27;; s = (s &lt;&lt; 1) | input; n += 1; &#125; // n is the number of characters read in, including the line feed // n-1 is the actual length of s setbit(n-1, s); // we probably halted because n==24, so we read in 24 valid 0 1 characters // If so, there can be more to be read, so we try to read more but keep the string at 24 characters long // skip this loop if the string is finished with a space for (; c!=&#x27;\\n&#x27;; c = getchar()) &#123; input = c - &#x27;0&#x27;; s = (s &lt;&lt; 1) | input; s = s &amp; 0xFFFFFF; // keeps only the first 24 characters setbit(24, s); n += 1; &#125; n -= 1; // n is the number of characters read in, including the line feed // delete 1 to obtain the actual string length // len is the length of answer string // ans is the binary string in int representation // full is true if all the strings of length i is in our bitmap unsigned int len = 0, ans = 0; bool full = false; for (int i = n&gt;24 ? 24 : n; i&gt;0 &amp;&amp; !full; i--) &#123; full = true; // we assume this level is full for (int j = 0; j &lt; ones[i] + 1; j++) &#123; // iterate all strings 0 ~ 2^i if (checkbit(i, j)) &#123; // percolate down to its substring setbit(i - 1, j &gt;&gt; 1); setbit(i - 1, j &amp; ones[i - 1]); &#125; else if (full) &#123; // current substring doesn&#x27;t exist, and all the previous substrings do exist // so this is the FIRST substring that doesn&#x27;t exist ans = j; len = i; full = false; &#125; &#125; &#125; print_binary(len, ans);&#125;void setbit(int n, unsigned int x) &#123; // x%32 å°±æ˜¯å­˜å‚¨ x çš„ bitï¼Œå³ä»å·¦å‘å³ x%32 ä¸ªä½ç½®çš„é‚£ä¸ª bit // ä½†ç”±äºè®¡ç®—æœºä¸­å­˜å‚¨æ•°æ˜¯ä»å³å‘å·¦å­˜çš„ï¼Œæˆ‘ä»¬éœ€è¦è®© 1 ä»å³ç«¯å¼€å§‹ç§»åŠ¨ ( 31- x%32 ) ä¸ªä½ç½®æ‰å¯ä»¥ // è¿™æ ·æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªç¬¬ x%32 ä¸º1ï¼Œå…¶ä»–ä½ä¸º 0 çš„äºŒè¿›åˆ¶æ•°ï¼Œé€šè¿‡ or ä¸åŸ bitmap å‚¨å€¼åˆå¹¶ // bitmap[x/32] |= (1&lt;&lt;(31 - x%32)); bitmap[n][x&gt;&gt;5] |= (1&lt;&lt;(31 - x&amp;31));&#125;;bool checkbit(int n, unsigned int x) &#123; // bitmap[x/32] &amp; (1&lt;&lt;(31 - x%32)) is determined solely by the x%32 bit of this int chunk // If that bit is 0, the whole expression is 0 // If that bit is 1, the whole expression is greater than 1 and thus evaluate to true // return bitmap[x/32] &amp; (1&lt;&lt;(31 - x%32)); return bitmap[n][x&gt;&gt;5] &amp; (1&lt;&lt;(31 - x&amp;31));&#125;void print_binary(int n, unsigned int x) &#123; // int æ˜¯ä»å³å¾€å·¦å­˜çš„ï¼Œä¸”æˆ‘ä»¬åªèƒ½è®¿é—®æœ€å³è¾¹çš„ least-significant digit // æˆ‘ä»¬è¦ä»å·¦å¾€å³æ‰“å°ï¼Œåªèƒ½å°†ä»å³å‘å·¦çš„æ¯ä¸ª bit é¡ºåºå­˜èµ·æ¥å†å€’åºæ‰“å° int ans[25]; int m = 0; while (x != 0) &#123; ans[m] = x &amp; 1; x = x &gt;&gt; 1; m++; &#125; // è¡¥å…¨ leading 0s for (int i = m; i &lt; n; i++) &#123; ans[i] = 0; &#125; for (int i = n - 1; i &gt;= 0; i--) &#123; printf(&quot;%d&quot;,ans[i]); &#125; printf(&quot;\\n&quot;);&#125; å¤æ‚åº¦åˆ†æ è¯»å…¥é•¿åº¦ä¸º n çš„å­—ç¬¦ä¸²ï¼Œè€—æ—¶ O(n) å¦‚æœ n &gt;24 åˆ™ä» bitmap24 å¼€å§‹éå†ï¼Œå¦‚æœ n&lt;=24 åˆ™ä» bitmap(n) å¼€å§‹éå†ï¼Œè€—æ—¶ O(2min(24, n)) å½“ n è¾¾åˆ° 2^24 çº§åˆ«æ—¶ï¼Œæ•´ä½“å¤æ‚åº¦è¿˜æ˜¯ O(n) Reference ç”¨C++å®ç°bitmap 3.3 Kth ç®—æ³• é¢˜ç›®è¦æ±‚æ‰¾å‡º a,b,c ä¸‰ä¸ªæ•°ç»„å¯¹åº”çš„ä¸‰å…ƒæ•°å¯¹ä¸­å’Œä¸ºç¬¬ k å¤§çš„é‚£ä¸ªä¸‰å…ƒæ•°å¯¹ï¼Œè§‚å¯Ÿåˆ°å¦‚æœ a,b,c æ˜¯æœ‰åºæ•°å¯¹ï¼Œé‚£ä¹ˆå¿…æœ‰ a[i]+b[j]+c[k] &lt; a[i+1]+b[j]+c[k], a[i]+b[j]+c[k] &lt; a[i]+b[j+1]+c[k], a[i]+b[j]+c[k] &lt; a[i]+b[j]+c[k+1]. äºæ˜¯ï¼Œæˆ‘ä»¬ç»´æŠ¤ä¸€ä¸ªä¼˜å…ˆé˜Ÿåˆ—ï¼Œæ¯æ¬¡å‡ºé˜Ÿ (i,j,k) å°±å…¥é˜Ÿ (i+1,j,k) (i,j+1,k) (i,j,k+1)ã€‚å¦‚æ­¤åš k æ¬¡ï¼Œå‡ºé˜Ÿçš„å°±æ˜¯æˆ‘ä»¬è¦æ‰¾çš„ä¸‰å…ƒå¯¹ã€‚æˆ‘ä»¬ç°åœ¨å°†â€œæ‰¾ç¬¬ k å¤§â€è½¬å˜æˆäº†ä¸€ä¸ªä¸‰ç»´å›¾çš„éå†é—®é¢˜ã€‚ å®ç°ä¸­è¦æ³¨æ„çš„æ˜¯ä¸èƒ½è®©åŒä¸€ä¸ªç‚¹å¤šæ¬¡å…¥é˜Ÿï¼Œæˆ‘ä»¬å¯ä»¥å¼€ä¸€ä¸ª vis æ•°ç»„ï¼Œä½†æ˜¯æ¯ä¸ªæ•°ç»„æœ€å¤šæœ‰ 500000 ä¸ªå…ƒç´ ï¼Œä¸‰ç»´ vis æ•°ç»„ç©ºé—´ç»å¯¹ä¸å¤Ÿã€‚äºæ˜¯æˆ‘ä»¬æƒ³ä¸€ç§éå†é¡ºåºï¼Œä½¿å¾—æ¯ä¸ªç‚¹åªè¢«éå†ä¸€æ¬¡ã€‚é¦–å…ˆè€ƒè™‘æœ€ç®€å•çš„ä¸€ç»´ï¼Œå•ä¸ªçš„ x è½´ï¼Œå°±æ˜¯ä¸åœåœ°éå†ä¸‹ä¸€ä¸ªè€Œå·² i, i+1, i+2, ... ï¼›æ‰©å±•åˆ°äºŒç»´å…¶å®å°±æ˜¯å¤šä¸ªä¸€ç»´æƒ…å†µï¼Œæˆ‘ä»¬é€šè¿‡ (0,j), (1,j), ... (i-1,j) åˆ°è¾¾ (i,j) é‚£æˆ‘ä»¬å¦‚ä½•åˆ°è¾¾ (0,j) å‘¢ï¼Ÿé€šè¿‡ (0,0) çš„ä¸€ç»´æ‰©å¼ ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œå½“ x è½´ä¸º 0 æ—¶ï¼Œæˆ‘ä»¬æ—¢å‘ x æ–¹å‘æ‰©å¼ ï¼Œä¹Ÿå‘ y æ–¹å‘æ‰©å¼ ï¼Œè€Œå½“ x è½´ä¸ä¸º 0 æ—¶ï¼Œæˆ‘ä»¬åªå‘ x æ–¹å‘æ‰©å¼ ã€‚ å¯¹äºä¸‰ç»´æƒ…å†µï¼Œæƒ³è±¡ x,y,z æ­£æ–¹å‘ä¸ºå³ï¼Œå‰ï¼Œä¸‹ã€‚åˆ™åœ¨ä»»æ„æ—¶åˆ»ï¼Œæˆ‘ä»¬éƒ½å‘ x æ‰©å¼ ï¼›ä»…å½“ x=0 æ—¶ï¼Œæˆ‘ä»¬å‘ y æ–¹å‘æ‰©å¼ ï¼›ä»…å½“ x=0 ä¸” y=0 æ—¶ï¼Œæˆ‘ä»¬å‘ z æ–¹å‘æ‰©å¼ ã€‚å¹¶ä¸”ç”±äºæˆ‘ä»¬æ ¹æ®ä¼˜å…ˆçº§é€‰å–æ¯ä¸€æ¬¡çš„æ‰©å¼ è¾¹ç•Œï¼Œæˆ‘ä»¬ä¸€å®šä¹Ÿæ˜¯ä¼˜å…ˆçº§æœ€é«˜çš„å…ˆè¢«æ‰¾åˆ°ã€‚ ç»†èŠ‚ Heap çš„å®ç°ï¼šsink æ—¶é¦–å…ˆåˆ¤æ–­å­©å­å­˜ä¸å­˜åœ¨ï¼ˆå­©å­åæ ‡ä¸å…ƒç´ æ€»æ•°æ¯”è¾ƒï¼‰å¦‚æœå·¦å­©å­å­˜åœ¨ä¸”â€œå³å­©å­ä¸å­˜åœ¨ï¼Œæˆ–å·¦å­©å­ä¼˜å…ˆçº§æ¯”å³å­©å­é«˜â€ï¼Œåˆ™ä¸å·¦å­©å­äº’æ¢ï¼›å¦‚æœå³å­©å­å­˜åœ¨ä¸”å³å­©å­ä¼˜å…ˆçº§æ›´é«˜ï¼Œåˆ™ä¸å³å­©å­äº’æ¢ ä¸‰ç»´çš„éå†é¡ºåºï¼šå°è¯•å‘ y æ–¹å‘æ‰©å¼ æ—¶ï¼Œå¦‚æœ x!=0ï¼Œè·³è¿‡æ­¤æ¬¡æ‰©å¼ ï¼›å°è¯•å‘ z æ–¹å‘æ‰©å¼ æ—¶ï¼Œå¦‚æœ x!=0 || y!=0ï¼Œè·³è¿‡æ­¤æ¬¡æ‰©å¼  æ•°ç»„çš„æ’åºï¼šåœ¨æœ¬é¢˜æä¾›æ¥å£ä¸­ï¼Œæˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—®æ•°ç»„ a,b,c ä¸­çš„å…ƒç´ ï¼Œæ‰€ä»¥æˆ‘ä»¬è‡ªå·±å¼€å¦å¤–ä¸‰ä¸ªæ•°ç»„ s,u,t å…¶ä¸­ s[i] è¡¨ç¤º a ä¸­ç¬¬ i å¤§çš„å…ƒç´ æ‰€å¯¹åº”åœ¨ a ä¸­çš„ä½ç½®ã€‚å³ s,u,t å­˜ 1â€¦nï¼Œ ä»£è¡¨ a,b,c ä¸­çš„ä¸‹æ ‡ã€‚ä¸ºå–å¾— sï¼Œæˆ‘ä»¬ä½¿ç”¨ sort(s,n) ä½†æ¯”è¾ƒå™¨ç”¨çš„å´æ˜¯ a çš„æ¯”è¾ƒå™¨ ä»£ç  123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146#include &quot;kth.h&quot;#define _CRT_SECURE_NO_WARNINGS#include&lt;iostream&gt;#include&lt;cstdio&gt;using namespace std;const int N = 500007, K = 2000003;int dir[3][3] = &#123; &#123;1,0,0&#125;, &#123;0,1,0&#125;, &#123;0,0,1&#125; &#125;;// sort x-axis by only comparing sums along x-axisint sortx_cmp(const void* a, const void* b) &#123; if (compare(*(int*)a, 1, 1, *(int*)b, 1, 1) == 1) return -1; else if (compare(*(int*)b, 1, 1, *(int*)a, 1, 1) == 1) return 1; else return 0;&#125;int sorty_cmp(const void* a, const void* b) &#123; if (compare(1, *(int*)a, 1, 1, *(int*)b, 1) == 1) return -1; else if (compare(1, *(int*)b, 1, 1, *(int*)a, 1) == 1) return 1; else return 0;&#125;int sortz_cmp(const void* a, const void* b) &#123; if (compare(1, 1, *(int*)a, 1, 1, *(int*)b) == 1) return -1; else if (compare(1, 1, *(int*)b, 1, 1, *(int*)a) == 1) return 1; else return 0;&#125;struct triple &#123; int x, y, z; triple() &#123; x = 0; y = 0; z = 0; &#125;; triple(int a, int b, int c) &#123; x = a; y = b; z = c; &#125; triple(const triple&amp; from) &#123; this-&gt;x = from.x; this-&gt;y = from.y; this-&gt;z = from.z; &#125;&#125;;// myPQ is my priority queuetriple myPQ[K*2];const triple INF = triple(10e7, 10e7, 10e7);// a, b, c is the array given in problem int a[N], b[N], c[N];inline bool operator&lt;(const triple&amp; t1, const triple&amp; t2) &#123; return compare(a[t1.x], b[t1.y], c[t1.z], a[t2.x], b[t2.y], c[t2.z]);&#125;inline bool operator&gt;(const triple&amp; t1, const triple&amp; t2) &#123; return compare(a[t2.x], b[t2.y], c[t2.z], a[t1.x], b[t1.y], c[t1.z]);&#125;// refactorred PQ that only uses strictly greater/lesser to be consistent with compare functionclass PriorityQueue &#123; int n = 0; triple* a = myPQ;public: void add(triple x) &#123; a[++n] = x; swim(n); &#125; triple extract() &#123; if (n == 0) throw &quot;Nothing to extract&quot;; triple result = a[1]; swap(a[1], a[n]); a[n--] = INF; sink(1); return result; &#125; bool isEmpty() &#123; return n == 0; &#125; void print() &#123; for (int i = 1; i &lt;= n; i++) &#123; printf(&quot;%d in heap: (%d, %d, %d)\\n&quot;, i, ::a[a[i].x], b[a[i].y], c[a[i].z]); &#125; &#125;private: void swim(int i) &#123; while (i &gt; 1 &amp;&amp; !(a[i / 2] &lt; a[i])) &#123; swap(a[i / 2], a[i]); i = i / 2; &#125; &#125; void sink(int i) &#123; int l = i * 2, r = i * 2 + 1; while ((l &lt;= n &amp;&amp; !(a[i] &lt; a[l])) || (r &lt;= n &amp;&amp; !(a[i] &lt; a[r]))) &#123; if (l &lt;= n &amp;&amp; (r &gt; n || !(a[l] &gt; a[r]))) &#123; // l is in the heap and (r is not in the heap, or l is the better choice compared to r) swap(a[i], a[l]); i = l; l = i * 2; r = i * 2 + 1; continue; &#125; else if (a[l] &gt; a[r] &amp;&amp; r &lt;= n) &#123; swap(a[i], a[r]); i = r; l = i * 2; r = i * 2 + 1; continue; &#125; else return; &#125; &#125;&#125;;void get_kth(int n, int k, int *x, int *y, int *z) &#123; for (int i = 0; i &lt;= n; i++) &#123; a[i] = b[i] = c[i] = i; &#125; qsort(a+1, n, sizeof(int), sortx_cmp); qsort(b+1, n, sizeof(int), sorty_cmp); qsort(c+1, n, sizeof(int), sortz_cmp); PriorityQueue q; q.add(triple(1, 1, 1)); for (int i = 1; i &lt; k; i++) &#123; // extract k-1 triples triple now = q.extract(); int nowx = now.x, nowy = now.y, nowz = now.z; for (int j = 0; j &lt; 3; j++) &#123; int nextx = nowx + dir[j][0], nexty = nowy + dir[j][1], nextz = nowz + dir[j][2]; if (nextx &gt; n || nexty &gt; n || nextz &gt; n) continue; if ((j == 1 &amp;&amp; nowx != 1) || (j == 2 &amp;&amp; (nowx != 1 || nowy != 1))) continue; q.add(triple(nextx, nexty, nextz)); &#125; &#125; triple result = q.extract(); *x = a[result.x]; *y = b[result.y]; *z = c[result.z];&#125; å¤æ‚åº¦åˆ†æ å…±æœ‰ä¸‰ä¸ªæ•°ç»„ï¼Œä¸€ä¸ªæ•°ç»„ä¸­æœ‰ n ä¸ªå…ƒç´ ï¼Œæ‰¾å¤§å°ä¸º k å¯¹çš„ä¸‰å…ƒæ•°å¯¹ã€‚é¦–å…ˆå¯¹ä¸‰ä¸ªæ•°ç»„è¿›è¡Œæ’åº O(nlogn)ï¼Œæ¯æœ‰ä¸€ä¸ªæ•°å¯¹å‡ºä¼˜å…ˆé˜Ÿåˆ—ï¼Œå°±æœ‰æœ€å¤šä¸‰ä¸ªå…¥ä¼˜å…ˆé˜Ÿåˆ—ï¼Œå…±æ“ä½œ k æ¬¡ï¼Œæ¯æ¬¡æ“ä½œ O(logk)ï¼Œæ€»å…± O(klogk)ã€‚æ€»æ—¶é—´ O(nlogn + klogk) 3.4 Component ç®—æ³• å †çš„åˆå¹¶ å·¦åæ ‘ é¢˜ç›®çš„è¯¢é—®æ°¸è¿œæ˜¯æŸä¸€è”é€šåˆ†é‡ä¸­ç¬¬ k å¤§çš„ç‚¹çš„æƒå€¼ï¼Œk æ˜¯ä¸€ä¸ªå¸¸æ•°ã€‚ç¬¬ k å¤§åˆå¯ä»¥çœ‹åšå‰ k ä¸ªæœ€å¤§å…ƒç´ ä¸­æœ€å°çš„å…ƒç´ ï¼Œå³å¦‚æœæˆ‘ä»¬ç»´æŠ¤ä¸€ä¸ªå°æ ¹å †ï¼Œä½¿å®ƒæ’æœ‰ k ä¸ªå…ƒç´ ï¼ˆn&lt;k æ—¶è¾“å‡º -1ï¼Œn&gt;k æ—¶å¼¹å‡º n-k æ¬¡æœ€å°çš„å…ƒç´ ï¼‰é‚£ä¹ˆè¿™ k ä¸ªå…ƒç´ å¿…ç„¶æ˜¯è¿é€šå—ä¸­å‰ k å¤§çš„å…ƒç´ ï¼Œå †é¡¶å…ƒç´ å°±æ˜¯æˆ‘ä»¬çš„è¯¢é—®ã€‚ å½“åŠ å…¥çš„æ–°è¾¹ (u,v) è”é€šä¸¤ä¸ªä¸æ›¾è”é€šçš„è¿é€šå—æ—¶ï¼Œå¯¹åº”çš„ä¸¤ä¸ªå †å¿…é¡»åˆå¹¶ã€‚æ”¯æŒå¿«é€Ÿåˆå¹¶æ“ä½œçš„ä¼˜å…ˆé˜Ÿåˆ—ï¼Œæˆ‘ä»¬é€‰æ‹©å·¦å¼å †ã€‚(u,v) å°†å—è”é€šï¼Œå®é™…ä¸Šæ˜¯å°†å…¶æ‰€åœ¨çš„å †åˆå¹¶èµ·æ¥ï¼Œæˆ‘ä»¬å¿…é¡»èƒ½å¤Ÿé«˜æ•ˆæ‰¾åˆ° (u,v) æ‰€å±å“ªä¸ªå †ï¼Œå³å…¶æ‰€å±å †çš„æ ¹æ˜¯è°ï¼Œä½¿ç”¨å¹¶æŸ¥é›†å­˜å‚¨è¿™ä¸ªä¿¡æ¯ã€‚ ç»†èŠ‚ æ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰ç¼–å·ï¼Œæˆ‘ä»¬ä¸ç”¨ä¼ ç»Ÿçš„ class å»ºä¼˜å…ˆçº§é˜Ÿåˆ—ï¼Œè€Œç›´æ¥ç”¨æ•°ç»„å­˜æ¯ä¸ªç‚¹å¯¹åº”çš„ä¿¡æ¯ï¼Œé€Ÿåº¦æ›´å¿«ï¼Œè®¿é—®æ›´æ–¹ä¾¿ ä»£ç  123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119#define _CRT_SECURE_NO_WARNINGS#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;iomanip&gt;using namespace std;const bool DEBUG = false;const int N = 1000007;int n, m, k, q;// We use a min-heap å°æ ¹å † to store the points// delMax getMax refers to the &quot;max priority&quot; element, which has the smallest value// value[i] is the value of the point i// father[i] is the root of the heap i belongs to// lchild[i], rchild[i] is the left and right child of the point i in heap// npl[i] is the null-path-length of heap i// sze[i] is the size of heap iint value[N], father[N], lchild[N], rchild[N], npl[N], sze[N];// find(i) returns the root of the heap i belongs toinline int find(int x) &#123; return x == father[x] ? x : (father[x] = find(father[x]));&#125;// merge heap b into heap aint merge(int a, int b) &#123; if (a == 0) return b; if (b == 0) return a; if (value[a] &gt; value[b]) swap(a,b); rchild[a] = merge(rchild[a], b); father[rchild[a]] = find(a); if (lchild[a] == 0 || npl[lchild[a]] &lt; npl[rchild[a]]) &#123; int temp = lchild[a]; lchild[a] = rchild[a]; rchild[a] = temp; &#125; npl[a] = rchild[a] == 0 ? 1 : npl[rchild[a]] + 1; sze[a] = sze[lchild[a]] + sze[rchild[a]] + 1; return a;&#125;// getMax(x) returns the value of root of the heap x represents// Requires: x is the root of a heapint getMax(int x) &#123; // x is the root, root is the max, so we just return the value of x return value[x];&#125;// delMax(x) returns the new root after deleting root in heap x// Requires: x is the root of a heapint delMax(int x) &#123; int ans = value[x]; sze[x] -= 1; int new_root = merge(lchild[x], rchild[x]); father[new_root] = new_root; // new root is now a root, so its father is itself father[x] = new_root; // this deleted node, and all the nodes pointing to the deleted node should now point to the new root return ans;&#125;// deletes the Max element until this heap has no more than k elementsvoid prune(int x) &#123; if (sze[x] &lt;= k) return; delMax(find(x)); // needs to find(x) because delMax requires a root prune(find(x)); // after being deleted, x becomes a stranded point // prune must take in the new root of the heap&#125;// print all points and their informationvoid print() &#123; if (!DEBUG) return; cout &lt;&lt; &quot;# value Parent Lchild Rchild npl size &quot; &lt;&lt; endl; for (int i = 1; i &lt;= n; i++) &#123; cout &lt;&lt; setw(2) &lt;&lt; i; cout &lt;&lt; setw(6) &lt;&lt; value[i]; cout &lt;&lt; setw(6) &lt;&lt; father[i]; cout &lt;&lt; setw(8) &lt;&lt; lchild[i]; cout &lt;&lt; setw(8) &lt;&lt; rchild[i]; cout &lt;&lt; setw(6) &lt;&lt; npl[i]; cout &lt;&lt; setw(6) &lt;&lt; sze[i]; cout &lt;&lt; endl; &#125;&#125;int main() &#123; scanf(&quot;%d%d%d%d&quot;, &amp;n, &amp;m, &amp;k, &amp;q); for (int i = 1; i &lt;= n; i++) &#123; scanf(&quot;%d&quot;, value + i); father[i] = i; lchild[i] = rchild[i] = npl[i] = 0; // points to null sze[i] = 1; &#125; sze[0] = 0; npl[0] = 0; father[0] = lchild[0] = rchild[0] = 10e9; for (int i = 1; i &lt;= m; i++) &#123; int a, b; scanf(&quot;%d%d&quot;, &amp;a, &amp;b); if (find(a) == find(b)) continue; // already connected, another edge doesn&#x27;t make a difference int merged = merge(find(a), find(b)); prune(merged); &#125; for (int i = 1; i &lt;= q; i++) &#123; int op, a, b; scanf(&quot;%d&quot;, &amp;op); if (op == 1) &#123; scanf(&quot;%d%d&quot;, &amp;a, &amp;b); if (find(a) == find(b)) continue; int merged = merge(find(a), find(b)); prune(merged); &#125; else if (op == 2) &#123; scanf(&quot;%d&quot;, &amp;a); if (sze[find(a)] &lt; k) printf(&quot;-1\\n&quot;); else printf(&quot;%d\\n&quot;, getMax(find(a))); &#125; &#125;&#125; å¤æ‚åº¦åˆ†æ åˆå§‹åŒ–åï¼Œæ¯ä¸ªç‚¹æœ€å¤šè¢«å…¥å †ä¸€æ¬¡ï¼ˆæ‰€åœ¨è¿é€šå—ä¸ä»–äººè”é€šï¼‰ï¼Œå‡ºå †ä¸€æ¬¡ï¼ˆå› ä¸ºä¸å±äºå‰ k å¤§è€Œè¢«å¼¹å‡ºå †ï¼‰æ¯æ¬¡å‡ºå…¥å †æ“ä½œæ˜¯ä¸¤ä¸ªå·¦å¼å †çš„ mergeï¼Œå¤æ‚åº¦ O(logn)ã€‚å…± n ä¸ªç‚¹ï¼Œæ‰€ä»¥æ€»ä½“å¤æ‚åº¦æ˜¯ O(n logn) Reference é¢˜è§£ P3377 ã€æ¨¡æ¿ã€‘å·¦åæ ‘(å¯å¹¶å †) è¯¾ç¨‹ä»£ç ","categories":[],"tags":[{"name":"Tsinghua","slug":"Tsinghua","permalink":"https://yao-lirong.github.io/blog/tags/Tsinghua/"}]},{"title":"Tsinghua DSA ä½œä¸šæ€»ç»“ (2)","slug":"2021-02-10-Tsinghua-DSA-ä½œä¸šæ€»ç»“-(2)","date":"2021-02-10T05:00:00.000Z","updated":"2022-06-08T19:33:28.000Z","comments":true,"path":"2021-02-10-Tsinghua-DSA-ä½œä¸šæ€»ç»“-(2)/","permalink":"https://yao-lirong.github.io/blog/2021-02-10-Tsinghua-DSA-%E4%BD%9C%E4%B8%9A%E6%80%BB%E7%BB%93-(2)/","excerpt":"CSTæ•°æ®ç»“æ„ï¼ˆ2020ç§‹ï¼‰PA2a","text":"CSTæ•°æ®ç»“æ„ï¼ˆ2020ç§‹ï¼‰PA2a 2-1 Build å¿ƒå¾— List -&gt; ç¼–å·å­˜æ ‘ æˆ‘ç”¨çš„æ˜¯è‡ªå·±å†™çš„ List å­˜æ ‘ï¼Œå¯¹äºä¸€ä¸ªèŠ‚ç‚¹ï¼Œå®ƒæœ‰ä¸€ä¸ªæŒ‡é’ˆæŒ‡å‘åŒ…å«å®ƒæ‰€æœ‰å­©å­çš„ Listï¼Œå¹¶æœ‰ height size å­˜å‚¨è¯¥ç‚¹çš„é«˜åº¦åŠå­æ ‘è§„æ¨¡ï¼Œå½“å‘ç”ŸèŠ‚ç‚¹ç§»åŠ¨æ—¶ï¼Œé€’å½’åœ°å‘ä¸Šæ›´æ–°ã€‚ä½†æ˜¯è¿™æ ·çš„è¯æ¯æ¬¡æ›´æ–°æ—¶ï¼Œå¿…é¡»éå†å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰å­©å­ï¼Œæ‰èƒ½ç¡®è®¤æ˜¯å¦éœ€è¦æ›´æ–°è¯¥ç‚¹çš„é«˜åº¦æˆ–å­æ ‘è§„æ¨¡ï¼Œè¿™æ ·ä¸ç¬¦åˆé¢˜ç›®ä¸­ â€œå¤æ‚åº¦ä¸ cost æˆçº¿æ€§â€ çš„è¦æ±‚ã€‚æ‰€ä»¥ä¼šTLEï¼Œè§£å†³æ–¹æ³•æ˜¯åœ¨æ¯ä¸€ä¸ªç‚¹éƒ½å­˜ä¸€ä¸ªå®ƒå‘åçœ‹èƒ½çœ‹åˆ°çš„æœ€å¤§å­æ ‘é«˜åº¦ä»¥åŠå®ƒåé¢æ‰€æœ‰ç‚¹çš„å­æ ‘è§„æ¨¡å’Œï¼Œè¿™æ ·æ¯æ¬¡åˆ é™¤æŸä¸€ç‚¹æ—¶ï¼Œåªéœ€è¦æ›´æ–°å®ƒå‰é¢å…„å¼Ÿçš„è¿™ä¸¤ä¸ªå€¼å°±å¥½äº†ï¼Œç¬¦åˆæˆ‘ä»¬å¯¹ cost çš„å®šä¹‰ã€‚ List å­˜è¿˜ä¼šå‘ç”Ÿ MLE çš„é—®é¢˜ã€‚æ—¢ç„¶é¢˜ç›®ä¸­å·²ç»ç»™å‡ºæ¯ä¸ªåº—çš„åºå·ï¼Œå…¶å®æˆ‘ä»¬ä¸éœ€è¦ç”¨ List å­˜ï¼Œåªéœ€è¦ç”¨å¤šä¸ªæ•°ç»„å­˜å‚¨ç›¸å¯¹åº”çš„ä¿¡æ¯ï¼ˆå‰åèŠ‚ç‚¹ï¼Œçˆ¶å­èŠ‚ç‚¹ï¼Œæœ¬ä¹¦è§„æ¨¡åŠé«˜åº¦ï¼Œå…¶å‘åçœ‹æ‰€æœ‰å…„å¼Ÿçš„æœ€å¤§é«˜åº¦å’Œå­—æ•°è§„æ¨¡å’Œï¼‰å³å¯ï¼Œè¿™æ ·ä¹Ÿè§£å†³äº†æˆ‘ä»¬ä¸€å¼€å§‹è¯»å…¥æ—¶éœ€è¦è‡ªå»ºé‚»æ¥è¡¨çš„é—®é¢˜ 2-4-2 Kidd ç®—æ³• çº¿æ®µæ ‘ï¼Œç¦»æ•£åŒ–ã€‚ çº¿æ®µæ ‘çš„æ¯ä¸ªèŠ‚ç‚¹æ‰€ä»£è¡¨çš„åŒºé—´å¿…é¡»ä¸€é—­ä¸€å¼€ï¼ˆæˆ‘çš„å®ç°ä¸­æ˜¯å·¦é—­å³å¼€çš„ï¼‰ï¼Œå¦‚æœæ˜¯é—­åŒºé—´ä¼šä½¿åŒä¸€ä¸ªç‚¹è¢«å‚¨å­˜åœ¨ç›¸é‚»çš„åŒºé—´ä¸­ä¸¤æ¬¡ã€‚ çº¿æ®µæ ‘ä¸­æ¯ä¸ªèŠ‚ç‚¹è¦å­˜ä¸¤ä¸ªä¸œè¥¿ï¼š1. æœ¬èŠ‚ç‚¹å¯¹åº”çš„åŒºé—´è¢«ç¿»è½¬çš„æ¬¡æ•° 2. æœ¬èŠ‚ç‚¹æ‰€åŒ…å«çš„ä¸Šæ‰€æœ‰å­åŒºé—´ï¼ˆåŒ…æ‹¬å®ƒè‡ªå·±ï¼‰è¢«ç¿»è½¬çš„æ¬¡æ•°ã€‚å…¶ä¸­ 2 é€šè¿‡ æœ¬èŠ‚ç‚¹è¢«ç¿»è½¬çš„æ¬¡æ•° * æœ¬èŠ‚ç‚¹ä»£è¡¨çš„åŒºé—´çš„å¤§å° + ä¸¤ä¸ªå­©å­åŒºé—´çš„æ‰€æœ‰å­åŒºé—´è¢«ç¿»è½¬çš„æ¬¡æ•° å¾—æ¥ã€‚ æ‰€ä»¥åœ¨æ¯æ¬¡æŸ¥è¯¢æ—¶ï¼Œå¦‚æœåªæ˜¯å•çº¯çš„ç›¸äº¤ï¼Œç›¸äº¤éƒ¨åˆ†ä¹Ÿåœ¨è¿™ä¸ªåŒºé—´è¢«å½“åšä¸€ä¸ªæ•´ä½“ç¿»è½¬æ—¶æ‰€ç¿»è½¬äº†ï¼Œæ‰€ä»¥æˆ‘ä»¬è®¡ç®—å‡ºç›¸äº¤èŒƒå›´çš„å¤§å°ï¼Œä¹˜ä¸Šæ­¤åŒºé—´è¢«ç¿»è½¬çš„æ¬¡æ•°ï¼›å¦‚æœæŸ¥è¯¢åŒºé—´åŒ…å«åœ¨å½“å‰åŒºé—´é‡Œé¢ï¼ˆæ°å¥½æ˜¯å½“å‰åŒºé—´ï¼‰ï¼Œæˆ‘ä»¬åªéœ€è¦åŠ ä¸Šå½“å‰åŒºé—´åŠå…¶æ‰€æœ‰å­åŒºé—´è¢«åè½¬çš„æ¬¡æ•°å°±å¥½äº† ä»£ç  ç¦»æ•£åŒ–éƒ¨åˆ†æœ‰ä¸¥é‡é”™è¯¯ï¼Œæ—¢ç„¶ç¬¬ä¸€æ­¥å°±æœ‰é”™æ‰€ä»¥å‰©ä¸‹çš„å¯¹ä¸å¯¹å’±å…¶å®ä¹Ÿä¸çŸ¥é“ã€‚ä½†æ˜¯æ€è·¯å¤§æ¦‚å°±è¿™ä¹ˆä¸ªæ€è·¯ï¼ˆ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165#include&lt;cstdio&gt;#include&lt;iostream&gt;using namespace std;int sort_cmp (const void * a, const void * b) &#123; return ( *(int*)a - *(int*)b );&#125;const int N = 200003;// isQuery[i] is true if the ith operation is a query &#x27;Q&#x27;, is false if the ith operation is a flip &#x27;H&#x27;bool isQuery[N]; int interval[N][2];// a stores the unique discretized intervalint a[N*2], unique_num = 0;struct treeNode&#123; bool isNode = false; // true if this is a leaf in segment tree int l, r; // this node represents the interval [l,r) int v; // this node stores value v; this interval *only* has been flipped v times long long total; // the points in this interval and all its subintervals have been flipped total times&#125;st[(N*2)&lt;&lt;1];void build(int li, int ri, int x);void update(int li, int ri, int x);long long query(int li, int ri, int x);int bisearch(int li, int ri, int g);int original_to_discrete(int x);int discrete_to_original(int y);int temp[N*4];int main()&#123; int n, m; scanf(&quot;%d%d&quot;, &amp;n, &amp;m); cin.ignore(100,&#x27;\\n&#x27;); char o; int l, r; for(int i=0; i&lt;m; i++)&#123; scanf(&quot;%c%d%d&quot;, &amp;o, &amp;l, &amp;r); isQuery[i] = (o==&#x27;Q&#x27;); interval[i][0] = l; interval[i][1] = r; temp[i*4 + 0] = l; temp[i*4 + 1] = l+1; temp[i*4 + 2] = r; temp[i*4 + 3] = r+1; cin.ignore(100,&#x27;\\n&#x27;); &#125; qsort(temp, 4*m, sizeof(int), sort_cmp); a[unique_num++] = temp[0]; for(int i=1; i&lt;4*m; i++) &#123; if(temp[i]!=temp[i-1]) a[unique_num++] = temp[i]; &#125; build(0, unique_num, 0); for(int i=0; i&lt;m; i++)&#123; if(isQuery[i])&#123; cout&lt;&lt;query(original_to_discrete(interval[i][0]), original_to_discrete(interval[i][1]), 0)&lt;&lt;endl; &#125; else &#123; update(original_to_discrete(interval[i][0]), original_to_discrete(interval[i][1]), 0); &#125; &#125; return 0;&#125;// node x in s-tree represents the interval [li,ri)void build(int li, int ri, int x)&#123; st[x].isNode = true; st[x].l = li; st[x].r = ri; st[x].v = 0; //cout&lt;&lt;&quot;building node &quot;&lt;&lt;x&lt;&lt;&quot;represents [&quot;&lt;&lt;st[x].l&lt;&lt;&quot;, &quot;&lt;&lt;st[x].r&lt;&lt;&quot;)&quot;&lt;&lt;endl; if(li+1 != ri) &#123; int mid = (li+ri)/2; build(li,mid,(x&lt;&lt;1) + 1); build(mid,ri,(x&lt;&lt;1) + 2); &#125; return;&#125;// currently at s-tree node x, updating interval [li,ri]void update(int li, int ri, int x)&#123; int dis = discrete_to_original(st[x].r-1) - discrete_to_original(st[x].l) + 1; if(li&lt;=st[x].l &amp;&amp; ri&gt;=st[x].r-1)&#123; // interval(x) \\subseteq [li,ri] st[x].v += 1; st[x].total += dis; return; // we should immediately stop updating any children of this node, because that will do a duplicate update &#125; if(!st[(x&lt;&lt;1)+1].isNode) return; // if this is a leaf node, return if(st[(x&lt;&lt;1)+1].isNode &amp;&amp; li &lt;= st[(x&lt;&lt;1)+1].r-1)&#123; // intersects left child update(li, ri, (x&lt;&lt;1)+1); &#125; if(st[(x&lt;&lt;1)+2].isNode &amp;&amp; ri &gt;= st[(x&lt;&lt;1)+2].l)&#123; // intersects right child update(li, ri, (x&lt;&lt;1)+2); &#125; // &#x27;st[x].v * dis&#x27; is the number of flips caused by &quot;this&quot; interval being flipped // st[(x&lt;&lt;1)+1].total is the total number of flips this node&#x27;s left child has // st[(x&lt;&lt;1)+2].total is the total number of flips this node&#x27;s right child has st[x].total = st[x].v * dis + st[(x&lt;&lt;1)+1].total + st[(x&lt;&lt;1)+2].total; return;&#125;long long query(int li, int ri, int x)&#123; long long res = 0; if(li&lt;=st[x].l &amp;&amp; ri&gt;=st[x].r-1)&#123; // interval(x) \\subseteq [li,ri] res += st[x].total; return res; &#125; int dis = discrete_to_original(min(st[x].r-1, ri)) - discrete_to_original(max(st[x].l, li)) + 1; res += st[x].v * dis; if(st[(x&lt;&lt;1)+1].isNode &amp;&amp; li &lt;= st[(x&lt;&lt;1)+1].r-1)&#123; res += query(li, ri, (x&lt;&lt;1)+1); &#125; if(st[(x&lt;&lt;1)+2].isNode &amp;&amp; ri &gt;= st[(x&lt;&lt;1)+2].l)&#123; res += query(li, ri, (x&lt;&lt;1)+2); &#125; return res;&#125;int bisearch(int li, int ri, int g)&#123; int mid = 0; while(ri &gt; li+1)&#123; mid = (li+ri)&gt;&gt;1; if(a[mid]&lt;=g) li = mid; else ri = mid; &#125; return li;&#125;int discrete_to_original(int y)&#123; return a[y];&#125;int original_to_discrete(int x)&#123; return bisearch(0, unique_num, x);&#125; 2.7 Virus å¿ƒå¾— å †çš„ sink çš„è¾¹ç•Œæ¡ä»¶åº”è¯¥æ˜¯ 1234int l=i*2, r=i*2+1;while((l&lt;=n &amp;&amp; a[i]&gt;=a[l]) || (r&lt;=n &amp;&amp; a[i]&gt;=a[r]))&#123; ...&#125; è€Œä¸æ˜¯ 12345678int height(int x)&#123; if(x==0) return 1; int digit=0; while(x&gt;0) &#123;x=x&gt;&gt;1; digit++;&#125; return digit;&#125;while((a[i]&gt;=a[l]||a[i]&gt;=a[r])&amp;&amp;i&lt;pow(2,height(n)))&#123; ...&#125; å †æ˜¯ä¸€ä¸ªå®Œå…¨äºŒå‰æ ‘ (Complete Binary Tree) è€Œä¸æ˜¯ä¸€ä¸ªå®Œç¾äºŒå‰æ ‘ (Perfect Binary Tree) ä»£ç  ä»…å±•ç¤ºäº†å †çš„å®ç°éƒ¨åˆ† 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788const int M=1000007;const int INF=10e7;const int N = 1007;struct point &#123; int id; // id = x*N + y int t; point(int x, int y, int ti) &#123; id = x*N + y; t = ti; &#125; point() &#123; id = 0; t = 0; &#125; point(int n) : point() &#123;&#125; point(const point &amp;from) &#123; this-&gt;id = from.id; this-&gt;t = from.t; &#125;&#125;;point myPQ[M];inline bool operator&lt;(const point &amp;p1, const point &amp;p2) &#123; return p1.t &lt; p2.t;&#125;inline bool operator&gt;(const point &amp;p1, const point &amp;p2) &#123; return p1.t &gt; p2.t;&#125;inline bool operator&lt;=(const point &amp;p1, const point &amp;p2) &#123; return p1.t &lt;= p2.t;&#125;inline bool operator&gt;=(const point &amp;p1, const point &amp;p2) &#123; return p1.t &gt;= p2.t;&#125;class PriorityQueue &#123; int n = 0; point *a = myPQ;public: void add(point x) &#123; a[++n] = x; swim(n); &#125; point extract() &#123; point result = a[1]; swap(a[1],a[n]); a[n--]=INF; sink(1); return result; &#125; bool isEmpty() &#123;return n == 0;&#125;private: void swim(int i) &#123; while(i&gt;1 &amp;&amp; a[i/2]&gt;=a[i])&#123; swap(a[i/2],a[i]); i = i/2; &#125; &#125; void sink(int i) &#123; int l=i*2, r=i*2+1; while((l&lt;=n &amp;&amp; a[i]&gt;=a[l]) || (r&lt;=n &amp;&amp; a[i]&gt;=a[r]))&#123; if(a[l]&lt;=a[r]&amp;&amp;l&lt;=n)&#123; swap(a[i],a[l]); i = l; l=i*2; r=i*2+1; continue; &#125; else if (a[l]&gt;a[r]&amp;&amp;r&lt;=n)&#123; swap(a[i],a[r]); i = r; l=i*2; r=i*2+1; continue; &#125; else return; &#125; &#125;&#125;;","categories":[],"tags":[{"name":"Tsinghua","slug":"Tsinghua","permalink":"https://yao-lirong.github.io/blog/tags/Tsinghua/"}]},{"title":"Tsinghua DSA ä½œä¸šæ€»ç»“ (1)","slug":"2021-02-09-Tsinghua-DSA-ä½œä¸šæ€»ç»“-(1)","date":"2021-02-09T05:00:00.000Z","updated":"2022-06-08T19:33:28.000Z","comments":true,"path":"2021-02-09-Tsinghua-DSA-ä½œä¸šæ€»ç»“-(1)/","permalink":"https://yao-lirong.github.io/blog/2021-02-09-Tsinghua-DSA-%E4%BD%9C%E4%B8%9A%E6%80%BB%E7%BB%93-(1)/","excerpt":"CSTæ•°æ®ç»“æ„ï¼ˆ2020ç§‹ï¼‰PA1a","text":"CSTæ•°æ®ç»“æ„ï¼ˆ2020ç§‹ï¼‰PA1a 1-1 A*B Problem å¿ƒå¾— æ¯ä¸ªæ•°ç»„å­˜ä¸€ä½çš„è¯é€Ÿåº¦å¤ªæ…¢è¿‡ä¸äº†ï¼Œå¿…é¡»å‹ä½ 10e5 æ˜¯ 10 * 10^5 æ‰€ä»¥æ˜¯ 10^6 â€¦ æˆ‘ä»¬æŠŠä¸€ä¸ªå¤§æ•´æ•°åˆ†æˆå‡ å—å­˜åœ¨æ•°ç»„é‡Œçš„æ—¶å€™ï¼Œå¦‚æœè¿™ä¸ªæ•°å¤´ä¸Šæœ‰0çš„è¯ï¼Œ0å°±ä¼šè¢«å¿½ç•¥äº†ï¼ˆä¸å‹ä½çš„è¯æ²¡æœ‰è¿™ä¸ªé—®é¢˜ï¼Œå› ä¸º0ä¹Ÿå°±æ˜¯1ä½ï¼‰æ¯”å¦‚4ä½4ä½å­˜ï¼Œ100046000303025ä¼šå˜æˆ[3025, 30, 460, 100]ï¼Œç›´æ¥è¾“å‡ºä¼šå˜æˆ100460303025ï¼Œæ˜æ˜¾ä¸å¯¹ï¼Œæ‰€ä»¥æˆ‘ä»¬è¾“å‡ºçš„æ—¶å€™è¦è®°å¾—è¡¥å…¨0 ä»£ç  123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;cstring&gt;using namespace std;// N is the maximum number of digits of the input, M is the maximum number of digits of the productconst int N = 5007, M = 10023;// we multiply each 10000 together and store them in a single entry, 10e3 has 4 0s .const int ten = 10e3, d_ten = 4;// a is input A in e4 base, b is input B in e4 base, c is their product in e4 base.int a[N], b[N], c[M];// a_len is the number of entires in a needed to store input A, so it&#x27;s the digit needed to store A in e4 base; b_len is that for Bint a_len, b_len;// digit is a helper array we will need during multiplicationint digit[] = &#123;1,10,100,1000,10000&#125;;// inputA and inputB is A and B read in from streamchar inputA[N], inputB[N];// multiplies e4 base A and B together and store the result in Mvoid multiply();// returns the length of product in e4 baseint get_clen();// print padding zero in each entry of array C when outputting the resultvoid print_padding_zero(int,int);int main()&#123; int n = 0; scanf(&quot;%d&quot;,&amp;n); for (int i=0; i&lt;n; i++)&#123; memset(a,0,sizeof(a)); memset(b,0,sizeof(b)); memset(c,0,sizeof(c)); memset(inputA,0,sizeof(inputA)); memset(inputB,0,sizeof(inputB)); scanf(&quot;%s&quot;,inputA); int ina_len = strlen(inputA); a_len = (ina_len-1)/d_ten + 1; scanf(&quot;%s&quot;,inputB); int inb_len = strlen(inputB); b_len = (inb_len-1)/d_ten + 1; // store the number in reverse order and e4 baes in array a,b for (int i=ina_len-1; i&gt;=0;)&#123; int tostore = 0; for (int j=0; j&lt;d_ten &amp;&amp; i-j&gt;=0 ; j++)&#123; int ASCII = inputA[i-j] - &#x27;0&#x27;; tostore += ASCII*digit[j]; &#125; a[a_len-1 - i/d_ten] = tostore; i = i-d_ten; &#125; for (int i=inb_len-1; i&gt;=0;)&#123; int tostore = 0; for (int j=0; j&lt;d_ten &amp;&amp; i-j&gt;=0 ; j++)&#123; int ASCII = inputB[i-j] - &#x27;0&#x27;; tostore += ASCII*digit[j]; &#125; b[b_len-1 - i/d_ten] = tostore; i = i-d_ten; &#125; multiply(); int c_index = get_clen(); printf(&quot;%d&quot;, c[c_index]); for (int i=c_index-1; i&gt;=0; i--)&#123; print_padding_zero(c[i], ten/10); printf(&quot;%d&quot;, c[i]); &#125; printf(&quot;\\n&quot;); &#125; return 0;&#125;void multiply()&#123; for(int i=0; i&lt;a_len; i++)&#123; for(int j=0; j&lt;b_len; j++)&#123; int product = a[i] * b[j]; c[i+j] += product; c[i+j+1] += c[i+j] / ten; // carry over digit c[i+j] %= ten; // only stores e4 base number &#125; &#125;&#125;inline int get_clen()&#123; int n = a_len + b_len + 3; while (c[n]==0 &amp;&amp; n&gt;0) n--; return n;&#125;/** * Each entry in array C should store an e4 base number, but sometimes it stores a number smaller than that. * That&#x27;s because it ignores the leading 0s (leading 0s in reversely stored C) when in this case 00XX. * Example: 1004 0030 57 stored in C has form [57, 30, 1004], this function helps print out the first 00 in 0030 **/inline void print_padding_zero(int n, int digit)&#123; if (n&lt;digit) printf(&quot;0&quot;); if (digit == 10) return; print_padding_zero(n,digit/10);&#125; Reference é«˜ç²¾åº¦ä¹˜æ³• é«˜ç²¾åº¦ä¹˜æ³•çš„å‹ä½ 1-3 Filename å¿ƒå¾— ç¼–è¾‘è·ç¦»ï¼Œç§»åŠ¨çª—å£èŠ‚çœç©ºé—´ å­—ç¬¦ä¸²çš„è¯»å…¥ï¼šä¸€å¼€å§‹ä»¥ä¸ºæ˜¯ getline çš„é—®é¢˜ï¼Œè¯»ä¸è¿›æ¥å­—ç¬¦ä¸²ï¼Œå®é™…ä¸Šæ˜¯å› ä¸ºä»…ç”¨ scanf è¯»å…¥3ä¸ªæ•´æ•°åä¼šç•™ä¸‹ä¸€ä¸ªæ¢è¡Œç¬¦åœ¨ buffer ä¸­ã€‚ä½¿ç”¨ cin.ignore(100,'\\n') åˆ é™¤æ¢è¡Œç¬¦ï¼ˆå¿½ç•¥ 100 ä¸ªå­—ç¬¦ï¼Œæˆ–è€…å¿½ç•¥1ä¸ª '\\n'ï¼›å¿½ç•¥æ‰€æœ‰è¯»å…¥ï¼Œç›´åˆ°æ€»å…±å¿½ç•¥äº† 100 ä¸ªå­—ç¬¦ï¼Œæˆ–è€…å¿½ç•¥äº† 1 ä¸ªæ¢è¡Œç¬¦ï¼‰ dpæ•°ç»„å¼€åˆ° 10012 ä¼šçˆ†ç‚¸ï¼Œæ”¹ç”¨æ»šåŠ¨çª—å£ï¼Œdp[0][j] è¡¨ç¤º $ x_1x_2â€¦x_{i-1}$ åˆ° y1y2...yj ï¼ˆå‰ä¸€æ­¥ï¼‰æ‰€éœ€è¦çš„æ“ä½œï¼Œdp[1][j] è¡¨ç¤º $ x_1x_2â€¦x_{i-1}$ åˆ° y1y2...yj ï¼ˆè¿™ä¸€æ­¥ï¼‰æ‰€éœ€è¦çš„æ“ä½œã€‚å‡ ä¸ªå®ç°ç»†èŠ‚åœ¨æ³¨é‡Šä¸­å·²æ ‡å‡º TLE: ç¬¬ä¸€æ„Ÿè§‰æƒ³çš„æ˜¯åœ¨æ¯æ¬¡è®¡ç®— i, s.t.x1x2...xi å˜æˆ y æ‰€éœ€è¦çš„æ“ä½œåï¼ˆå³è®¡ç®—å®Œæˆ dp[i][0...m]åï¼‰ï¼Œæ‰«ä¸€éæ•°ç»„ï¼Œå¦‚æœæ‰€æœ‰å€¼éƒ½å¤§äº k çš„è¯ï¼Œå°±åœæ­¢æŸ¥æ‰¾ã€‚ä½†æ˜¯è¿™æ ·ä¸ä¼šå¯¹æ•°æ®è§„æ¨¡æœ‰ä»»ä½•å¯è§‚çš„ç¼©å‡ï¼Œå› ä¸ºå¦‚æœè¯´æˆ‘ä»¬æœ‰é•¿ä¸º 105 çš„ä¸¤ä¸ªå­—ç¬¦ä¸²ï¼Œå¹¶ä¸”ä»–ä»¬å¯ä»¥åœ¨ k æ“ä½œå†…äº’ç›¸è½¬æ¢ï¼ˆæç«¯æƒ…å†µä¸¤ä¸ªç›¸åŒçš„å­—ç¬¦ä¸²ï¼‰ï¼Œæˆ‘ä»¬ä»ç„¶éœ€è¦è¿›è¡Œ O(mn) = 105 Ã— 105 æ¬¡æ“ä½œã€‚ æ ¹æ®ä¹ é¢˜è¯¾çš„è§£å†³æ–¹æ³•ï¼Œå…¶å®å½“ä¸¤ä¸ªæ•°ç»„é—´çš„é•¿åº¦å·®è¶…è¿‡ k æ—¶å°±ç»å¯¹ä¸å¯èƒ½ä»ä¸€ä¸ªè½¬æ¢æˆå¦ä¸€ä¸ªäº†ã€‚æ‰€ä»¥ï¼Œå¯¹äºæ¯ä¸ª x çš„å­ä¸² x1x2...xiï¼Œæˆ‘ä»¬åªéœ€è¦çœ‹ yi âˆ’ kyi âˆ’ k + 1...yi + k å°±å¯ä»¥äº†ã€‚å½“ç„¶è¿˜è¦æ³¨æ„ i âˆ’ k, i + kåˆ«è¶Šç•Œï¼Œæ‰€ä»¥å®é™…ä¸Šæ˜¯çœ‹ ymin(1, i âˆ’ k)...ymax(m, i + k) è¿™ä¸ªå­åºåˆ— è¿™ä¸ªæ”¹åŠ¨ä¼šé€ æˆä¸€äº› WAï¼Œç›´è§‰ä¸€ä¸‹å­æƒ³åˆ°æ˜¯æœ‰å¯èƒ½åœ¨æœ€åé€€å‡ºå¾ªç¯æ—¶ï¼Œæˆ‘ä»¬å› ä¸º k çš„é™åˆ¶å‹æ ¹å°±æ²¡æ‰«åˆ° dp[n][m](= dp[1][m])ã€‚å®é™…ä¸Šé—®é¢˜å·®ä¸å¤šï¼Œæ˜¯å› ä¸º dp[i][j] = min(dp[i-1][j], dp[i][(j-1)]) + 1; è¿™å¥è¯ä¸­ dp[0][j] æˆ‘ä»¬ä¸€å¼€å§‹å…¨åˆå§‹åŒ–ä¸º0ï¼Œå¯¹äº dp[i][i+k] è¿™ä¸ªä½ç½®ï¼Œå®ƒçš„ä¸€ç§æ–¹æ¡ˆ dp[i-1][i+k] æ°¸è¿œä¸ä¼šè¢«ä¸Šä¸€æ­¥æ›´æ–°åˆ°ï¼Œå› ä¸ºä¸Šä¸€æ­¥åªæ›´æ–° dp[i-1][(i-1)-k] ~ dp[i-1][(i-1)+k] å³ dp[i-1][i+k] æ’ç­‰äº0ï¼Œå³ dp[i][i+k] æ°¸è¿œä¼šé‡‡å– dp[i-1][i+k] è¿™ä¸€æ–¹æ¡ˆã€‚å°† dp[0][j] åˆå§‹åŒ–ä¸º infinity è§£å†³ ä»£ç  123456789101112131415161718192021222324252627282930313233343536373839404142434445#include&lt;iostream&gt;#include&lt;cstdio&gt;using namespace std;const int N = 501007, Inf = 501; // Inf is &quot;effective infinite&quot; : k&lt;=500char a[N], b[N]; // a, b store the string x, yint dp[2][N]; // For each iteration i, dp[0] is equivalent to dp[i-1], dp[1] is equivalent to dp[i]int main()&#123; int n,m,k; //length of x, length of y, max number of operations scanf(&quot;%d%d%d&quot;, &amp;n, &amp;m, &amp;k); cin.ignore(100,&#x27;\\n&#x27;); cin.getline(a+1, n+1); cin.getline(b+1, m+1); // initialize dp[0][j] to be the operations needed to edit an empty string to y1y2...yj // initialize the rest of the array to be infinite for(int j=0;j&lt;=m;j++) dp[0][j] = j, dp[1][j] = Inf; for(int i=1; i&lt;=n; i++) &#123; // start from the 1st character // dp[0][0] represents dp[i-1][0] in an ordinary dp array // dp[i-1][0] represents the distance between x1x2...x_&#123;i-1&#125; to the empty string dp[0][0] = i-1; for(int j=max(1, i-k);j&lt;=min(m,i+k);j++)&#123; // only looks at y[i-k] to y[i+k] if(a[i]==b[j]) dp[1][j] = dp[0][(j-1)]; else dp[1][j] = min(dp[0][j], dp[1][(j-1)]) + 1; &#125; // &quot;previous&quot; of next iteration i+1 is current value from this iteration i for(int j=max(1, i-k);j&lt;=min(m,i+k);j++) dp[0][j] = dp[1][j]; &#125; printf(&quot;%d\\n&quot;, dp[1][m]&lt;=k ? dp[1][m] : -1); return 0;&#125; Reference C++ cin.ignore()çš„ç”¨æ³•è¯¦è§£ C++ cin&gt;&gt; cin.get() cin.getline() 1.4 Risk å¿ƒå¾— Queap, äºŒåˆ†æœç´¢ æ¯æ¬¡è¯¢é—®çš„æ—¶å€™ï¼Œå‡è®¾æˆ‘ä»¬è¦çœ‹å‰ m å¤©ï¼Œç°åœ¨çš„ Queap ä¸­å­˜äº† qsize å¤©ï¼Œå¦‚æœ qsize&gt;m çš„è¯ï¼Œæˆ‘ä»¬å­˜äº†ä¸€äº›æ²¡å¿…è¦çœ‹çš„å¤©ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±éœ€è¦æŠŠè¿™äº›æ²¡å¿…è¦çš„å¤©ç»™æ¨å‡ºå»ï¼Œæ‰€ä»¥çœ‹å‡ºæ¥æˆ‘ä»¬éœ€è¦æ¨å‡º qsize-m ä¸ªæ²¡å¿…è¦çš„å¤©ã€‚ç„¶è€Œæˆ‘çš„å®ç°åœ¨ dequeap å’Œ enqueap æ—¶ä¼šå®æ—¶æ›´æ–° qsize æ‰€ä»¥å®é™…ä¸Š Queap åªä¼šå¼¹å‡ºå¤§æ¦‚ä¸€åŠçš„å…ƒç´ ï¼Œä¼šé€ æˆå¾ˆå¤§çš„é—®é¢˜ã€‚æ‰€ä»¥æˆ‘ä»¬å¿…é¡»å…ˆè®°å½• qsize-m ç„¶åå†æ›´æ–° æœ€åçš„Tæ¬¡è¯¢é—®æ˜¯å¯¹å·²ç»æœ‰çš„æ•°æ®ï¼Œè¯¢é—®æœ‰å¤šå°‘åœ¨ç›¸åº”çš„åŒºé—´å†…ã€‚æˆ‘ä»¬è¿™é‡Œå¯ä»¥ä½¿ç”¨æ’åºåäºŒåˆ†æŸ¥æ‰¾åŒºé—´åˆ†ç•Œç‚¹çš„ä½ç½®ï¼Œè€Œä¸æ˜¯å¯¹äºæ¯ä¸ªå…ƒç´ éƒ½çœ‹æ˜¯åœ¨å“ªä¸ªåŒºé—´å†…ã€‚è¿™æ ·å¯ä»¥å¤§å¤§ç¼©çŸ­æ—¶é—´ ä»£ç  123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168#define _CRT_SECURE_NO_WARNINGS#include&lt;iostream&gt;#include&lt;cstdio&gt;using namespace std;// elements in queue/queap are the number of infections of previous days// size of queue/queap is the number of days we need to keep track of// Queue Nodestruct qNode &#123; long long value; qNode* next, * prev;&#125;;qNode *qHead = new qNode, * qTail = new qNode;// Queap Node; Invariant: node n in a queap [h...n...t] is the max element in interval in [h...n]struct pNode &#123; long long value, num; pNode* next, * prev;&#125;;pNode *pHead = new pNode, * pTail = new pNode;long long qsize = 0;// enqueue value v into Q;// update &quot;max value available&quot; in queap Pvoid enqueap(long long v) &#123; qNode* q = new qNode; pNode* p = new pNode; qsize += 1; q-&gt;value = v, q-&gt;next = qHead-&gt;next; q-&gt;prev = qHead; qHead-&gt;next-&gt;prev = q; qHead-&gt;next = q; pNode* i = pHead-&gt;next; int num = 0; while (i != pTail) &#123; if (v &gt;= i-&gt;value) &#123; num += i-&gt;num; i = i-&gt;next; delete i-&gt;prev;&#125; else break; &#125; // i is the first interval max greater than inserted value // replace everything between pHead and i with the newly inserted value if (num &gt; 0) &#123; p-&gt;value = v; p-&gt;num = num+1; p-&gt;next = i; p-&gt;prev = pHead; i-&gt;prev = p; pHead-&gt;next = p; &#125; else &#123; // num==0 says v &lt; pHead-&gt;next, insert p in between Head and Head-&gt;next p-&gt;value = v; p-&gt;num = 1; p-&gt;next = i; p-&gt;prev = pHead; i-&gt;prev = p; pHead-&gt;next = p; &#125; return;&#125;// dequeue one element from Q and from Pvoid dequeap() &#123; if (qsize &lt;=0) return; qsize -= 1; qNode *qDel = qTail-&gt;prev; qTail-&gt;prev = qTail-&gt;prev-&gt;prev; qTail-&gt;prev-&gt;next = qTail; delete qDel; pNode *pDel = pTail-&gt;prev; if (pDel-&gt;num &gt; 1) pDel-&gt;num--; //there is still element after deletion else if (pDel-&gt;num == 1)&#123; //only one element left, there will be 0 elements after this deletion, so let&#x27;s just delete this node altogether pTail-&gt;prev = pDel-&gt;prev; pDel-&gt;prev-&gt;next = pTail; delete pDel; &#125; else throw &quot;0 element in pNode error&quot;; // there is no element in the top node, which is not supposed to happen return;&#125;// returns the Max value in the Queap; returns 0 if Queap is emptyinline long long getMax() &#123; return qsize&gt;0 ? pTail-&gt;prev-&gt;value : 0;&#125;// print both queue and queap for debugging purposesvoid printQueue() &#123; qNode* q = new qNode; q = qHead-&gt;next; pNode* p = new pNode; p = pHead-&gt;next; cout&lt;&lt;&quot;printing out queue Q:&quot;&lt;&lt;endl; while (q != qTail) &#123; cout &lt;&lt; q-&gt;value &lt;&lt; &quot; &quot;; q = q-&gt;next; &#125; cout &lt;&lt; endl; cout&lt;&lt;&quot;printing out queap P:&quot;&lt;&lt;endl; while (p != pTail) &#123; long long v = p-&gt;value; for (int i = 0; i &lt; p-&gt;num; i++) &#123; cout &lt;&lt; v &lt;&lt; &quot; &quot;; &#125; p = p-&gt;next; &#125; cout &lt;&lt; endl;&#125;// cmp function for qsortinline int sort_cmp (const void * a, const void * b)&#123; return ( *(long long*)a - *(long long*)b );&#125;//returns the last element &lt;=g in [l,r]int bisearch(const long long a[], int l, int r, long long g) &#123; int mid = -1; while(l&lt;r) &#123; mid = (l+r)&gt;&gt;1; a[mid] &lt;= g ? l=mid+1 : r=mid; &#125; return l-1;&#125;long long observed[1000007]; int input[1000007];int main()&#123; // initializes Q and P qHead-&gt;next = qTail, qTail-&gt;prev = qHead; pHead-&gt;next = pTail, pTail-&gt;prev = pHead; int n; scanf(&quot;%d&quot;, &amp;n); for (int i = 0; i &lt; n; i++) &#123; scanf(&quot;%d&quot;, &amp;input[i]); &#125; // For each day, we first check which day is the earliest day we have to keep track of // If there are some days we no longer have to keep track of, we dequeue them from the queap and queue // Then record the maximum infection number maintained by queap and enqueue the infection number of today for (int i = 0; i &lt; n; i++) &#123; long long m; scanf(&quot;%lld&quot;, &amp;m); long long num = qsize-m; for(long long j=0; j &lt; num; j++)&#123; dequeap(); &#125; observed[i] = getMax(); enqueap(input[i]); &#125; qsort(observed, n, sizeof(long long), sort_cmp); // There are T queries, always on already observed infection number // We only care about number of days in a certain range, not the date or any other information // Therefore, we can use binary search to get the number of days in this given range. int T; scanf(&quot;%d&quot;, &amp;T); for (int i=0; i&lt;T; i++)&#123; long long p,q; scanf(&quot;%lld%lld&quot;, &amp;p, &amp;q); int pnum = 0, qnum = 0; pnum = bisearch(observed,0,n,p-1) + 1; // &lt;p \\equiv &lt;=p-1; returns the index of the last element &lt;p, so there are index+1 elements qnum = bisearch(observed,0,n,q-1) - pnum + 1; // similarly, &lt;q \\equiv &lt;=q-1; bisearch(observed,0,n,q-1) - bisearch(observed,0,n,p-1) gives the number of elements in range [p,q) printf(&quot;%d %d\\n&quot;, pnum, qnum); &#125; return 0;&#125; Reference åŒå‘é“¾è¡¨(ç»“æ„ä½“+æŒ‡é’ˆ) å®šä¹‰ç»“æ„ä½“å˜é‡åŠåˆå§‹åŒ–; ç»“æ„ä½“å®šä¹‰å˜é‡çš„ä¸‰ç§æ–¹æ³• unsigned long long int scanf","categories":[],"tags":[{"name":"Tsinghua","slug":"Tsinghua","permalink":"https://yao-lirong.github.io/blog/tags/Tsinghua/"}]},{"title":"Look Back on Cornell/Tsinghua 20FA","slug":"2021-01-11-CornellTsinghua-20FA-æ€»ç»“","date":"2021-01-11T05:00:00.000Z","updated":"2022-06-08T19:56:44.000Z","comments":true,"path":"2021-01-11-CornellTsinghua-20FA-æ€»ç»“/","permalink":"https://yao-lirong.github.io/blog/2021-01-11-CornellTsinghua-20FA-%E6%80%BB%E7%BB%93/","excerpt":"CS4820 Intro Analysis of Algorithms I got to do all the stuff I want. â€¦ Iâ€™m actually one of the Ithacaâ€™s firefighters now and on average we have a really big and nice fire each year so I got to work when that comes. â€“ Dexter Kozen, 2020/12/16","text":"CS4820 Intro Analysis of Algorithms I got to do all the stuff I want. â€¦ Iâ€™m actually one of the Ithacaâ€™s firefighters now and on average we have a really big and nice fire each year so I got to work when that comes. â€“ Dexter Kozen, 2020/12/16 å› ä¸ºç½‘è¯¾çš„åŸå› ä¸æƒ³ä¸Šå†™ä»£ç çš„è¯¾ï¼Œ4820æ˜¯æˆ‘æœ¬å­¦æœŸä¸Šçš„å”¯ä¸€ä¸€èŠ‚CSè¯¾ï¼Œä¹Ÿæ˜¯æ‹¿çš„ç¬¬ä¸€ä¸ªCS A+ã€‚ä½†æ˜¯æ€»ä½“æ¥è¯´ 4820 å’Œ 3110 ä¸Šåˆ°æœ€åéƒ½æ²¡æœ‰ 2112 å’Œ 2802 æœ‰ä¸€ç§æˆ‘çœŸçš„æˆé•¿äº†çš„æˆå°±æ„Ÿï¼Œå¯èƒ½æ˜¯å› ä¸º 4820 è¦†ç›–çš„ä¸œè¥¿å¤ªå¤šï¼Œå¯¼è‡´çŸ¥è¯†é—´æ¯”è¾ƒå‰²è£‚ï¼Œç”¨æ¥è¯æ˜ä¸€ä¸ªç®—æ³•çš„æŠ€å·§åœ¨å¦ä¸€ä¸ªæ¨¡å—å°±ç”¨ä¸å¤ªä¸Šäº†ã€‚ ä»–ä»¬è¯´ä»€ä¹ˆä¸Šå®Œ 4820 å¯¹é¢è¯•æœ‰å¸®åŠ©ï¼Œæˆ‘è§‰å¾—è¿™å®Œå…¨å°±æ˜¯æ‰¯æ·¡çš„ï¼Œå¯èƒ½ç¡®å®åˆ·é¢˜çš„æ—¶å€™ä½ æ›´å®¹æ˜“çœ‹å‡ºæ¥è¿™åº”è¯¥ç”¨ä»€ä¹ˆç®—æ³•äº†ï¼Œä½†æ˜¯è¿™é—¨è¯¾æ‰€æœ‰çš„ç¼–ç¨‹è®­ç»ƒåªèƒ½è¯´æ˜¯éå¸¸åˆçº§ï¼ˆåˆ°è¿æˆ‘éƒ½è§‰å¾—ä¸éš¾çš„æ°´å¹³ï¼‰è¯¾ç¨‹é‡ç‚¹è¿˜æ˜¯åœ¨ç®—æ³•çš„åˆ†æå’Œè¯æ˜ä¸Šï¼Œå’Œè¯æ˜é¢˜ä¸€å¯¹æ¯”ï¼Œç»™çš„ç¼–ç¨‹é¢˜çœŸå°±è·Ÿè¿‡å®¶å®¶ä¸€æ ·ã€‚æœ€åä¸€æ¬¡ä½œä¸šå¤åˆ»äº† sxy çš„å£®ä¸¾äº¤æˆäº† releaseï¼Œå¹¸äºè¿˜æœ‰ä¸ªç¼–ç¨‹é¢˜çš„ 10 åˆ†ä¿åº•ï¼Œè¿™æ¬¡ä½œä¸šå°±æ‹¿äº† 10/30 åˆ†ã€‚ä½†æ˜¯ç”±äºå‰é¢ä½œä¸šè€ƒè¯•éƒ½ä¸é”™ï¼Œè€Œä¸”å»ä¸äº†è·¨æ—¶å·® Office Hour å¯¼è‡´æˆ‘æ‰€æœ‰é—®é¢˜éƒ½åœ¨ Piazza ä¸Šé—®äº†ï¼Œparticipation grade ç‰¹åˆ«é«˜ã€‚xzy åœ¨è¯¾ç¨‹ä¸­é—® participation grade æ€ä¹ˆç®—æ—¶å‘ç°äº†ä»¥åæˆ‘æ‰å»çœ‹çš„ï¼Œæˆ‘çš„ Piazza è´¡çŒ®æ˜¯æ•´ä¸ªç­çš„ç¬¬äºŒï¼Œäººå®¶ç¬¬ä¸€æ˜¯æˆå¤©å›ç­”é—®é¢˜ï¼Œæˆ‘æ˜¯æˆå¤©ä»€ä¹ˆéƒ½æ²¡ææ‡‚åœ¨ä¸Šé¢é—®é—®é¢˜ã€‚ä¸è¿‡ç”¨ Kozen çš„è¯è¯´ï¼Œè¿™ä¹Ÿæ˜¯ä¸€ç§ â€œcontribute to the intellectual content of the courseâ€ æ–¹å¼ã€‚æ‰€ä»¥å¤§æ¦‚æ˜¯å› ä¸ºæé«˜çš„ participation grade ä»¥åŠå¯¹ Kozen çš„è¯šæ³è¯·æ±‚ï¼Œè€äººå®¶æœ€åé«˜æŠ¬è´µæ‰‹ç»™æˆ‘äº†ä¸ª A+ ï¼ˆä¸è¿‡è¦æ˜¯æ²¡è¯¯äº¤ä½œä¸šä¹Ÿæ˜¯æˆ‘åº”å¾—çš„å•¦ï¼‰ å¯¹äº Dexter Kozenï¼Œè¯´å®è¯æ„Ÿè§‰ä»–çš„æ•™å­¦æ°´å¹³å¹¶ä¸å¦‚ Myers å’Œ Halpernï¼Œæœ‰çš„æ—¶å€™åŸºæœ¬ä¸Šæ˜¯å®Œå…¨ç…§ç€è¯¾æœ¬æ¥çš„ï¼Œå¦‚æœä»–æ˜¯å®Œå…¨æŒ‰ç…§è¯¾æœ¬æ¥çš„ï¼Œé‚£ä¹ˆä¸€èˆ¬çœ‹è¯¾æœ¬ç”šè‡³æ¯”ä»–è®²å¾—å¥½ï¼›ä½†æ˜¯å½“ä»–æŒ‰ç…§è‡ªå·±çš„è¯æ˜æ–¹æ³•è®²çš„æ—¶å€™ï¼Œä»–çš„æ–¹æ³•åˆæ¯”ä¹¦ä¸Šçš„å¥½ç†è§£å¾ˆå¤šâ€¦ä¸è¿‡æ¯”ä¸‹è‚¯å®šæ˜¯æœ‰ä½™çš„ï¼Œæ¯”å…¶ä»–å‡ ä¸ªæˆ‘ä¸Šè¿‡è¯¾ä½†æ˜¯æ²¡åœ¨è¿™æåçš„å«å…½å¥½å¤šäº†ã€‚è€Œä¸” Dexter Kozen è¿˜ä¼šåœ¨æœ€åä¸€èŠ‚è¯¾ç»™ä½ å¼¹å‰ä»–å¬ï¼Œå°±è¿™è¿˜è¦å•¥è‡ªè¡Œè½¦ï¼Ÿ è¯¾ç¨‹å†…å®¹åˆ†å¸ƒæ–¹é¢ï¼ˆå¯èƒ½ä¸æ˜¯ Kozen è€Œæ˜¯ä¹¦æœ¬çš„é—®é¢˜ï¼‰åˆ†æ²»å’ŒåŠ¨æ€è§„åˆ’ä¸¤ç« ï¼Œæˆ‘å¹¶ä¸è®¤ä¸ºç¬¬ä¸€æ¬¡æ¥è§¦è¿™äº›æ¦‚å¿µçš„åŒå­¦èƒ½å¬æ‡‚ä»»ä½•ä¸œè¥¿ï¼Œåˆ†æ²»ç›´æ¥ç»™çš„æ˜¯ FFT å’Œæ‰¾å¹³é¢ä¸­æœ€è¿‘ç‚¹çš„ä¸¤ä¸ªå¾ˆå˜æ€çš„ä¾‹å­ï¼ŒåŠ¨è§„ç›´æ¥æ˜¯ä»å¤šç»´åŠ¨è§„å¼€å§‹è®²çš„ï¼ˆä¹¦ä¸Šæ˜¯æŒ‰ç»´åº¦é¡ºåºæ¥çš„ï¼Œè¿™ç¡®å®æ˜¯Kozenä¸€æ—¶å…´èµ·ï¼‰ç½‘ç»œæµè¿™ä¸€èŠ‚ ä½œä¸º Jon Kleinberg å’Œ Eva Tardos çš„ä¸»åœºï¼Œè®²å¾—ä¾‹å­éƒ½éå¸¸æœ‰æ„æ€ã€‚ MATH4710 Basic Probability å‚»é€¼ä¸­çš„å‚»é€¼è¯¾ï¼Œæˆ‘ä¸è®¤ä¸ºåœ¨ä¸Šå®Œè¿™èŠ‚è¯¾ä»¥åæˆ‘å¯¹æ¦‚ç‡å’Œç»Ÿè®¡çš„ç†è§£å¯¹æ¯”2802ä¹‹åæœ‰ä»»ä½•è¿›æ­¥ã€‚å½“æ—¶æ˜¯ä¸ºäº†æ‰“ç®—æ˜¥å­£ä¸Šæœºå™¨å­¦ä¹ ï¼Œæ‰€ä»¥å³ä½¿çŸ¥é“è¿™æ³•å›½äººè®²å¾—å±ä½†ä¹Ÿæ˜¯é¡¶ç€å¤´ä¸Šè½å±çš„é£é™©ä¸Šçš„ã€‚æ²¡æƒ³åˆ°äººå®¶æ³•å›½äººè¿™ä¹ˆå®è¯šï¼Œä½ è§‰å¾—æˆ‘è®²å¾—å±ï¼Œæˆ‘å°±çœŸå°±ç”¨å®é™…è¡ŒåŠ¨è¯æ˜è€å­è®²å¾—å°±æ˜¯å±ï¼Œä½ è¿˜æ‹¿ä»–æ²¡åŠæ³•ï¼Œä½ è¯´æ°”ä¸æ°”ï¼Ÿä¸Šè¿™ä¸ªæ³•å›½äººçš„è¯¾ä¸Šåˆ°å­¦æœŸæœ«ï¼Œæˆ‘ç”šè‡³éƒ½ä¸çŸ¥é“ Poisson æˆ–è€…å…¶ä»–æ¦‚ç‡åˆ†å¸ƒçš„å›¾åƒé•¿ä»€ä¹ˆæ ·ï¼Œæˆ‘å¯¹æ¯ä¸€ä¸ªåˆ†å¸ƒçš„è®¤çŸ¥å®Œå…¨æ˜¯å‰²è£‚çš„ï¼Œç›´åˆ°æœŸæœ«è€ƒè¯•æˆ‘è¿˜è¦ä¸€ä¸ªä¸ªæŸ¥æåˆ°çš„åˆ†å¸ƒçš„ distribution function åˆ°åº•æ˜¯ä»€ä¹ˆã€‚æ¯ä¸€æ¬¡çš„ä½œä¸šå’Œè€ƒè¯•éƒ½åœ¨éå¸¸ç¦»è°±çš„åœ°æ–¹ç»™æˆ‘æ‰£åˆ†ï¼Œæœ€åæˆç»©ä¹Ÿè´¼éš¾çœ‹ï¼Œå®Œå®Œå…¨å…¨åœ°æ‰“å‡»äº†æˆ‘å­¦ä¹ æ•°å­¦çš„ä¿¡å¿ƒï¼Œä¸å¦‚è¯´æ•´ä¸ªåº·å¥ˆå°”æ•°å­¦é™¢çš„å­˜åœ¨ï¼Œé™¤äº†å°‘æ•°å‡ ä¸ªæ•™æˆä»¥å¤–ï¼Œå°±æ˜¯ä¸ºäº†æ‰“å‡»ä½ å­¦ä¹ æ•°å­¦çš„ä¿¡å¿ƒã€‚æ•´ä¸ªé™¢é‡Œé¢ï¼Œé™¤äº†ç ”ç©¶åšä¸å‡ºæ¥æ‰€ä»¥åªèƒ½æŠ˜ç£¨å­¦ç”Ÿå–ä¹çš„æ•™æˆï¼Œè¿˜æœ‰ç ”ç©¶åšä¸å‡ºæ¥è€Œä¸”æœ¬èº«å®åŠ›å°±ä¸è¡Œæ‰€ä»¥åœ¨è¯»åšæœŸé—´å¿…é¡»å…¼èŒåŠ©æ•™äºæ˜¯å°±ä¹Ÿè·Ÿç€è™å¾…å­¦ç”Ÿçš„å˜æ€åšå£«ç”Ÿã€‚ä¸åŒ–ç®€æ‰£1åˆ†ï¼Œä½ è¯´100åˆ†æ»¡åˆ†ï¼Œä¸­ä½æ•° 7,80 ä½ æ‰£ä¹Ÿå°±ç®—äº†ï¼Œ60æ»¡åˆ†ä¸­ä½æ•°58çš„è€ƒè¯•ä½ å› ä¸ºä¸åŒ–ç®€ç»™æˆ‘æ‰£2åˆ†ï¼Œè€Œä¸”è®©æˆ‘åŒ–ç®€çš„è¿˜æ˜¯ä¸€ä¸ªå¸¦äº†å››é¡¹ç»„åˆæ•°çš„è¶…æ¶å¿ƒå¼å­ï¼Œä½ æ€ä¹ˆä¸ç›´æ¥è®©æˆ‘é»˜å†™ Ï€ çš„å1000ä½å‘¢ï¼Ÿ EAS1540 Introductory Oceanography å¤§å¤šæ•°äººå¼ºæ¨çš„ç§‘å­¦è¯¾ï¼Œè¯´å®åœ¨è¯æ²¡ä»€ä¹ˆæ„æ€ã€‚ä¸ªäººæ„Ÿè§‰ä¸å¦‚ DEA1500ï¼ˆè™½ç„¶æ˜¯ä¸ä¸€æ ·çš„ distribution requirementï¼‰Gary Evansåœ¨æˆ‘å¿ƒé‡Œè¿˜æ˜¯æš‚æ—¶çš„é€‰ä¿®è¯¾ä¹‹ç¥çš„åœ°ä½ã€‚å¤§å®¶éƒ½è¯´è¿™é—¨ç§‘å­¦è¯¾è®²å¾—ä¸œè¥¿ç®€å•ï¼ˆæ¯•ç«Ÿæ˜¯è¿ç¾å›½äººéƒ½æ¨èçš„ç§‘å­¦è¯¾ï¼‰å®é™…ä¹Ÿç¡®å®å¦‚æ­¤ï¼Œä½†æ˜¯ç®€å•çš„éƒ¨åˆ†ä»–è®²çš„æˆ‘éƒ½ä¼šï¼Œé¡¶å¤šä¹Ÿå°±æ˜¯é«˜ä¸­åœ°ç†é«˜ä¸€æ°´å¹³ï¼›éš¾çš„éƒ¨åˆ†å‘¢ä»–è¯´å®è¯åˆæ²¡è®²æ˜ç™½ï¼Œè€Œä¸” Bruce Monger åœ¨æ•´ä¸ªå­¦æœŸéƒ½åœ¨ä¸åœçš„è®²ç¯ä¿ç¯ä¿ï¼Œæ‰€ä»¥æ¥çš„æ²¡æœ‰ Gary æœ€åä¸€è¯¾ç”»é¾™ç‚¹ç›é‚£æ ·ä»¤äººå°è±¡æ·±åˆ»ï¼Œä¸è¿‡ Bruce Monger çš„ç›®æ ‡ä¹Ÿè¾¾åˆ°äº†ï¼Œç°åœ¨æˆ‘ç¡®å®æ¸…æ¥šåœ°æ„è¯†åˆ°å¦‚æœ 2030 å’Œ 2050 æ§æ¸©ç›®æ ‡æ²¡è¾¾åˆ°çš„è¯ï¼Œåœ°çƒçœŸçš„ä¼šç­äº¡ã€‚ INFO1998 Freshmen Team Projects (Intro to Machine Learning) æ²¡æ„æ€ï¼Œæ•™ä½ æ€ä¹ˆç”¨ sklearn åº“çš„è¯¾ CS2024 C++ Programming è¿˜æ˜¯æŒºä¸é”™çš„ï¼Œäº”å…­å¹´ä»¥åï¼Œæˆ‘ç»ˆäºç¬¬ä¸€æ¬¡æ­£å¼å­¦ä¹ äº†C++è¿™é—¨è¯­è¨€ï¼Œå°±æ˜¯ä½œä¸šæœ‰äº›æ— èŠã€‚ CS4320 Introduction to Database Systems æˆ‘dropäº†è¿™é—¨è¯¾ ä¸€é—¨æ•™æ•°æ®åº“çš„è¯¾ï¼Œå¼€è¯¾ä¸¤ä¸ªç¤¼æ‹œç«Ÿç„¶ä»ç„¶æ²¡æ•™å­¦ç”Ÿä»¬å¦‚ä½•åœ¨ä½ çš„ç”µè„‘ä¸Šå®‰è£…æ•°æ®åº“æ¥ä½¿ç”¨åŸºæœ¬çš„ SQL æŒ‡ä»¤ï¼›è€å¸ˆæ“ç€ä¸€å£è°ä¹Ÿå¬ä¸æ‡‚çš„å¾·å›½å£éŸ³ï¼Œè®©æˆ‘æ¢¦å›æˆ‘æ‰˜ç¦æ°´å¹³åªæœ‰80åˆ†çš„æ—¶å€™å…ƒç´ å¬æ‰˜ç¦å¬åŠ›çš„é‚£ä¸ªç§‹å¤©ï¼›å½•åƒä¸Šä¼  youtube å…¬å¼€ï¼Œå°±å¥½åƒé™¤äº†ä½ çš„å­¦ç”Ÿä»¥å¤–è°è¿˜ä¼šé—²ç€æ²¡äº‹ä¸å»ä¸ŠCMUçš„æ•°æ®åº“ï¼Œæ¥ä¸Šæ‚¨çš„è¯¾ç»ƒä¹ å¾·è¯­ä¸€æ ·ï¼ˆä½†è¿˜æ˜¯è¦èµæ‰¬ä¸€ä¸‹è¿™ä¸ªè€å¸ˆå…¬å¼€ä¸Šä¼ ï¼Œä»–å®é™…ä¸Šä¹Ÿå°†è¿‘å‡ å¹´çš„æ‰€æœ‰è¯¾ç¨‹å½•åƒä¸Šä¼ åˆ°äº† Cornell VODï¼Œåªæ˜¯æˆ‘ä¸æ¸…æ¥šåˆ°åº•è°ä¼šå»çœ‹è®²å¾—è¿™ä¹ˆçƒ‚çš„è¯¾ï¼‰ åœ¨æ¸…åè®¤è¯†çš„åŒå­¦ Leo ç«Ÿç„¶è·Ÿæˆ‘è¯´ä»–æœ€åè¿™é—¨è¯¾å¾—äº†ä¸€ä¸ª A+ï¼Œè€Œä»–å¾— A+ çš„è¯€çªå°±æ˜¯è‡ªå·±åŸæ¥æ¥è§¦è¿‡æ•°æ®åº“ï¼Œä¸å»ä¸Šè¯¾ï¼Œä½œä¸šå‘ä¸‹æ¥ä»¥åè‡ªå·±æŸ¥æ‰¾ç›¸å…³èµ„æ–™è¿›è¡Œå­¦ä¹ ï¼Œä¹Ÿæ˜¯éå¸¸ç¦»è°±ï¼Œä¸çŸ¥é“å¾·å›½äººå‘ç°åŸæ¥ä»–è§‰å¾—åšå¾—ä¸é”™çš„å­¦ç”Ÿéƒ½æ˜¯é€šè¿‡è¿™ç§æ–¹å¼â€œåšçš„ä¸é”™â€çš„ä¼šä½œä½•æ„Ÿæƒ³ã€‚ ä¸¤å¹´ä»¥æ¥ï¼Œæˆ‘é¦–æ¬¡æ„Ÿè§‰åˆ°æˆ‘çš„å­¦è´¹èŠ±å¾—å€¼ï¼Œå°±æ˜¯åœ¨è¿™ä¸ªåŠ¨è¡çš„2020å¹´ï¼ŒCornell å¯¹å®ƒçš„ä¸­å›½å­¦ç”Ÿè¯´ï¼Œä½ å¯ä»¥å»æ¸…åŒ—ä¸Šäº¤ä¸­çš„ä¸€æ‰€å­¦æ ¡è¿›è¡Œä½ çš„çº¿ä¸‹ç§‹å­£å­¦æœŸï¼Œå…¶ä»–çš„æ‰€è°“ Ivy å’Œ Ivy+ ä»¬ï¼Œå¤§æ°”éƒ½ä¸æ•¢å‡ºä¸€ä¸ªï¼Œæ›´åˆ«è¯´å»æ¸…åŒ—ä¸Šäº¤äº†ã€‚åº·å¥ˆå°”ç‰›é€¼ï¼ å…¶å®ä¸€å¼€å§‹æˆ‘æ˜¯å½•çš„ä¸Šæµ·äº¤é€šå¤§å­¦ï¼Œåæ¥å¥½åƒè¢«è¡¥å½•çš„æ¸…åï¼Œæœ‰äº†TOP2ï¼Œè°è¿˜ä¼šå»ä¸Šæµ·ä¸€ä¸ªä¸çŸ¥åçš„å°å­¦æ ¡å‘¢ï¼Ÿ 30240184 æ•°æ®ç»“æ„ ç°åœ¨æˆ‘ä»¬è¦æ¥è¯æ˜ä¸€ä¸‹å®ƒçš„æ­£ç¡®æ€§â€¦â€¦â€¦â€¦â€¦ä¸ºä»€ä¹ˆè¦è¯æ˜å‘¢ï¼Ÿå°±å¥½åƒä½ ä¸èƒ½è¯´è‡ªå·±æ˜¯ä¸–ç•Œä¸€æµå¤§å­¦ä½ å°±æ˜¯äº†ï¼Œä½ è‚¯å®šå¾—è¯æ˜ä¸€ä¸‹è‡ªå·±ç¡®å®æœ‰åŒ¹é…çš„å®åŠ›æ‰è¡Œ â€“ é‚“ä¿Šè¾‰ï¼Œäºä¸ºä»€ä¹ˆè¦è¯æ˜äºŒåˆ†æŸ¥æ‰¾çš„æ­£ç¡®æ€§ è¿™æ˜¯ä¸€é—¨ç¥å¥‡çš„è¯¾ç¨‹ï¼Œæ— è®ºè®²å¾—æ¦‚å¿µæ˜¯ç®€å•çš„é“¾è¡¨è¿˜æ˜¯éš¾çš„çº¿æ®µæ ‘ï¼Œéƒ½èƒ½è®©å­¦ç”Ÿå—ç›Šï¼Œé‚“ä¿Šè¾‰è€å¸ˆæ˜¯ä¼Ÿå¤§çš„è€å¸ˆï¼Œä»–è®©æˆ‘ä¸€ä¸ªåŸæ¥è§‰å¾—çº¿æ®µæ ‘æˆ–kdæ ‘è¿™ç§ä¸œè¥¿ç¦»æˆ‘å¾ˆè¿œçš„äººï¼Œæ„Ÿå—åˆ°äº†åŸæ¥æˆ‘ä¹Ÿèƒ½å¬æ˜ç™½è¿™ä¹ˆå¤æ‚çš„æ•°æ®ç»“æ„ã€‚ä»–ä¹Ÿè®©æˆ‘è®¤è¯†åˆ°ï¼Œæˆ‘æ ¡çš„ Nate Foster çœŸæ˜¯ä¸ª cjbï¼Œocaml çš„çº¢é»‘æ ‘å®ç°ä¸æ˜¯å› ä¸º pattern matching æ‰€ä»¥ä»£ç æ‰é‚£ä¹ˆå°‘ï¼Œæ˜¯å› ä¸ºå®ƒä½¿ç”¨çš„æ˜¯ 3-4 é‡æ„è€Œä¸æ˜¯ä¼ ç»Ÿçš„æ—‹è½¬ï¼Œè¦æ˜¯ C++ å†™é‡æ„ä»£ç é‡ä¹Ÿä¼šå¤§å¹…å‡å°‘â€¦ é‚“ä¿Šè¾‰è€å¸ˆä¹Ÿé¼“åŠ±äº†æˆ‘ï¼Œè¯´ä¸å®šæˆ‘å’Œæ¸…åçš„åŒå­¦ä»¬å®åŠ›å·®è·æ²¡æœ‰æˆ‘åŸæ¥æƒ³è±¡çš„é‚£ä¹ˆå·¨å¤§ï¼Œæˆ‘å·®çš„å°±æ˜¯ä¸€å ‚è¿™ä¹ˆå¥½çš„è¯¾ï¼Œä¸€ä¸ªå…¨æ˜¯å­¦CSåŒå­¦çš„å®¿èˆï¼Œä¸€ä¸ªè€å¿ƒè®¤çœŸçš„è€å¸ˆè€Œå·²ã€‚æ¸…åŒ—å’ŒMITæ˜¯æˆ‘å¿ƒç›®ä¸­çš„åœ£åœ°ï¼Œæˆ‘ä»¥ä¸ºé‡Œé¢çš„äººéƒ½æ˜¯æ„¿æ„ç©·å…¶ä¸€ç”Ÿä¸ºå…¨äººç±»æœåŠ¡çš„äººï¼Œæˆ‘ä¹Ÿä»¥ä¸ºæˆ‘è¿™æ¬¡æ¥ä¹‹åï¼Œè¿™ä¸ªæƒ³æ³•è¦ä¹ˆç ´ç¢è¦ä¹ˆå°è¯ï¼Œå› ä¸ºè¿™é—¨è¯¾ï¼Œå› ä¸ºé‚“ä¿Šè¾‰è€å¸ˆï¼Œæˆ‘ç°åœ¨æ›´å€¾å‘äºè¯´æˆ‘çš„è¿™ä¸ªæƒ³æ³•è¢«å°è¯äº†ã€‚ å®é™…ä¸Šä¸Šå®Œè¿™é—¨è¯¾ä»¥åæˆ‘å¯¹è‡ªå·±çš„è®¤çŸ¥æ›´è¿·èŒ«äº†ï¼Œè™½ç„¶ PA1 åšçš„ä¸æ˜¯é‚£ä¹ˆå¥½ï¼ˆå’Œæ¸…ååŒå­¦æ¯”ï¼Œè‡ªå·±çš„é¢„æœŸè¿˜æ˜¯è¾¾åˆ°äº†çš„ï¼‰PA2 å› ä¸ºåº·å¥ˆå°”æœŸæœ«è€ƒï¼Œæ‘”ä¼¤äº†è…¿ï¼Œç”Ÿç—…ç­‰ç­‰å‡ ä¹æ²¡åšï¼Œä½†å’± PA3 æ‹¿äº†æ»¡åˆ†å•Šï¼Œè€Œä¸” PA3 æ˜¯å”¯ä¸€ä¸€ä¸ªçœŸæ­£æœ‰ TA æŒ‡å¯¼çš„çš„ Programming Assignmentï¼Œå…¶ä»–çš„éƒ½æ˜¯åˆ«çš„åŒå­¦å¯ä»¥ç›´æ¥é—®ä»–ä»¬ç­é‡Œå®¿èˆé‡Œçš„ä¿¡ç«å¤§ä½¬ï¼Œæˆ‘åªèƒ½é—­é—¨é€ è½¦ã€‚å››èˆäº”å…¥ï¼Œæˆ‘æ˜¯ä¸æ˜¯è¦æ˜¯æœ‰ä¸€å®šç¨‹åº¦çš„å¸®åŠ©ï¼Œå’Œæ¸…ååŒå­¦æ¯”ä¸€ç‚¹ä¹Ÿä¸å·®å‘¢ï¼Ÿè¯´å®è¯æˆ‘æ¥ä¹‹å‰ç¡®å®å¿ƒé‡Œé¢æœ‰ç‚¹è¿™æ ·æƒ³ï¼Œæ¯•ç«Ÿæ¸…åçš„äººè™½ç„¶èªæ˜ï¼Œä½†æ˜¯å¤§éƒ¨åˆ†äººé«˜ä¸­ä¸‰å¹´æ²¡ä»»ä½•ç¼–ç¨‹ç»å†ï¼Œæˆ‘è™½ç„¶è ¢ï¼Œä½†æ˜¯å¯¹è‡ªå·±CSè¿˜æ˜¯æ¯”è¾ƒæœ‰ä¿¡å¿ƒçš„ã€‚ç›´åˆ°ä¸Šå®Œè¿™é—¨è¯¾ï¼ŒæœŸæœ«è€ƒè¯•å‡ ä¹éƒ½ä¸ä¼šçš„æƒ…å†µä¸‹ï¼Œæˆ‘çš„å¿ƒé‡Œè¿˜æ˜¯æŠ±æœ‰é‚£ä¹ˆä¸€ä¸ä¸å¸Œæœ›ï¼šè¯´ä¸å®šå’±å’Œæ¸…åäººæ¯”ä¸€ç‚¹ä¸å·®å‘¢ã€‚è¯´åˆ°è¿™ä¸ªï¼Œæˆ‘å’Œå…¶ä»–äººè¯´èµ·æ¸…åè¿™é—¨è¯¾å¾ˆéš¾çš„æ—¶å€™ï¼Œä»–ä»¬è¡¨ç°å¾—ç«Ÿç„¶æ˜¯æƒŠè®¶è€Œä¸æ˜¯ç†æ‰€å½“ç„¶ï¼Œä»–ä»¬ç«Ÿç„¶çœŸçš„è§‰å¾—åº·å¥ˆå°”æä¾›çš„æ•™è‚²è¶³ä»¥è®©æˆ‘ä»¬å¯ä»¥å’Œæ¸…åäººæŠ—è¡¡ã€‚çœ‹æ¥åœ¨æœ‰è‡ªçŸ¥ä¹‹æ˜è¿™ç‚¹ä¸Šæˆ‘è¿˜æ˜¯æ¯”å…¶ä»–åŒå­¦é«˜ä¸€ç‚¹çš„ï¼ˆ é€‰è¿™é—¨è¯¾è¿˜è¦æ„Ÿè°¢ czï¼Œæ˜¯ä»–è·Ÿæˆ‘è¯´äº†è¿™é—¨è¯¾è¯„ä»·å¾ˆå¥½æˆ‘æ‰ä¼šå»é€‰ï¼Œä¸ç„¶â€œæ•°æ®ç»“æ„â€è¿™ç§è¯¾æˆ‘ç»å¯¹è§‰å¾—æˆ‘éƒ½å­¦å¾—ä¼šäº†ï¼Œæ‡’å¾—ä¸Šã€‚å®é™…ä¸Šæˆ‘ä¸€å¼€å§‹ä¸æ˜¯åœ¨é‚“è€å¸ˆé—¨ä¸‹å­¦ä¹ ï¼Œä¸€å¼€å§‹ç»™å›½é™…äº¤æ¢ç”Ÿçš„åé¢åªæœ‰å¦ä¸€ä¸ªè®²å¸ˆçš„ç­äº†ï¼Œä½†æˆ‘ç¬¬ä¸€èŠ‚è¯¾å»å¬äº†ä»¥åï¼Œå¥¹è®²å°¾é€’å½’ç«Ÿç„¶è¯´ç”¨åˆ°çš„ç©ºé—´ä¼šæ˜¯ O(n)ï¼Œå…¶ä¸­ n æ˜¯è°ƒç”¨æ¬¡æ•°ã€‚åˆ«çš„æˆ‘ä¸ç¡®å®šï¼Œä½†æ˜¯ Myers æ›¾ç»æ˜ç¡®åœ°è¯´è¿‡å°¾é€’å½’çš„å¥½å¤„å°±æ˜¯å¯ä»¥é‡å¤åœ°ä½¿ç”¨è°ƒç”¨æ ˆï¼Œå¦‚æ­¤ä¸€æ¥ä¸ä¼šæœ‰æº¢å‡ºï¼ˆå½“ç„¶äº†è¯´ä¸å®š Java å’Œ C++ å¹¶ä¸ä¸€æ ·ï¼‰äºæ˜¯ä¸‹è¯¾ä»¥åæˆ‘å»è¯¢é—®ä¸ºä»€ä¹ˆæ˜¯ O(n) å’Œå¥¹è®²äº†æˆ‘çš„æƒ³æ³•ï¼Œå¥¹è¡¨ç°å¾—æŒºä¸è€çƒ¦ï¼Œç„¶åæˆ‘è¿½ç€å¥¹å‡ºäº†æ•™å®¤ï¼Œå¥¹ä¸€è¾¹å¼€è‡ªè¡Œè½¦çš„é”ä¸€è¾¹å¬æˆ‘è¯´è¯ï¼Œæœ€åå°±æ’‚ä¸‹ä¸€ä¸ª â€æ©ï¼Œé‚£å¯èƒ½æ˜¯è¿™æ ·å§â€œ å°±èµ°äº†ã€‚è¿™ä¸ªè¡¨ç°è®©æˆ‘å›å¿†èµ·äº†æˆ‘çš„é«˜ä¸­ç­ä¸»ä»»ä¹Ÿæ˜¯è¿™æ ·ï¼Œè¯´è‡ªå·±å¾ˆå–œæ¬¢å­¦ç”Ÿï¼Œå¾ˆå–œæ¬¢æ•™å­¦ï¼Œæœ€åä½ å»æ‰¾å¥¹çš„æ—¶å€™å¥¹æ ¹æœ¬æ˜¯æ¼ ä¸å…³å¿ƒï¼Œè™šä¼ªçš„ä¸€Bï¼Œå¹¸äºæˆ‘åæ¥è®¤è¯† Leoï¼ŒçŸ¥é“äº†ä»–ï¼ˆå¹¶ä¸çŸ¥é“è‡ªå·±åº”è¯¥è·Ÿæˆ‘ä¸€ä¸ªç­ï¼‰ä¸€ç›´åœ¨å¬é‚“è€å¸ˆçš„è¯¾ï¼Œå»å¬äº†ä»¥åçœŸæ˜¯ä¸€ä¸ªå¤©ä¸Šä¸€ä¸ªåœ°ä¸‹ã€‚æ¸…åçš„åŒå­¦ä»¬å•Šï¼Œä½ ä»¬éƒ½åœ¨æ¸…åäº†ï¼Œä¸ºä»€ä¹ˆè¦æŠ˜ç£¨è‡ªå·±ï¼Œä¸è·Ÿç€é‚“è€å¸ˆå­¦å‘¢ï¼Ÿ ä¸Šå®Œè¿™é—¨è¯¾æˆ‘ä¹Ÿåœ¨æƒ³ï¼Œæ˜¯ä¸æ˜¯åªæœ‰å·®çš„è€å¸ˆï¼Œæ²¡æœ‰å·®çš„å­¦ç”Ÿï¼Ÿå¦‚æœæ¯ä¸ªäººéƒ½å¬é‚“è€å¸ˆçš„è¯¾ï¼Œæˆ‘å¾ˆæ€€ç–‘ä»–ä»¬ä¼šå¬ä¸æ‡‚ï¼ˆæ¯•ç«Ÿæˆ‘éƒ½å¬æ‡‚äº†ï¼‰å¯æ˜¯å…¶ä»–å¤§å­¦çš„åŒå­¦ä»¬å¹¶æ— æ³•äº«å—åˆ°è¿™ç­‰å¾…é‡ï¼Œåªèƒ½é€¼ç€è‡ªå·±å¬è®²é‚£ä¸ªè®²å¾—çƒ‚çš„ã€‚å°±å¥½åƒ qsq åœ¨åŒ—å¸ˆå¤§ï¼Œæˆ–è€…æˆ‘è‡ªå·±åœ¨åº·å¥ˆå°”çš„ç»å†å®Œå…¨ä¸€æ ·ï¼Œä¸€ä¸ªå·®çš„è€å¸ˆä¸ä»…å¸®ä¸åˆ°å­¦ç”Ÿï¼Œè¿˜ä¼šä¸¥é‡åœ°æ‰“å‡»ä¸€ä¸ªäººçš„è‡ªä¿¡å¿ƒï¼Œè®©ä»–æ·±æ·±åœ°æ€€ç–‘æˆ‘åˆ°åº•å–œä¸å–œæ¬¢è¿™ä¸ªå­¦ç§‘ï¼Œè¿™ä¸ªå­¦ç§‘åˆ°åº•é€‚ä¸é€‚åˆæˆ‘ç­‰ç­‰æ­¤ç±»ã€‚ Logic, Computing, Games æ¸…åå¤§å­¦ç‰¹è˜æ•™æˆï¼Œæ–¯å¦ç¦å¤§å­¦åèª‰æ•™æˆï¼Œä»€ä¹ˆä»€ä¹ˆå¾ˆå‰å®³çš„ç ”ç©¶æ‰€çš„åˆ›å§‹äºº Johan van Benthemï¼æ¥ç»™ä½  ä¸Šç½‘è¯¾ï¼ è€Œä¸”è¿™ç½‘è¯¾è¿˜æ˜¯å¦‚æœä½ æƒ³è¦é—®é—®é¢˜å¿…é¡»ç­‰è€å¸ˆä¸€èŠ‚è¯¾ä¸‹è¯¾ä»¥åï¼Œä½ æ‰èƒ½å’ŒåŠ©æ•™ä¸¾æ‰‹ç¤ºæ„è¯´æˆ‘æœ‰ä¸ªé—®é¢˜ï¼Œç„¶åä»–ä¼šç»™ä½ ä¸€ä¸ªéº¦å…‹é£ä½ æ‰èƒ½é—®ã€‚å­¦ç”Ÿæ²¡æœ‰ä»»ä½•ç›´æ¥è”ç³»æ•™æˆçš„æ–¹æ³•ï¼Œå¿…é¡»é€šè¿‡åŠ©æ•™ï¼ŒåŠ©æ•™åˆä¸€å‰¯çˆ±ç­”ä¸ç†çš„æ ·å­ï¼Œè¯¾ç¨‹æ¨èé˜…è¯»ä¹Ÿæ²¡æœ‰ï¼Œå¿…è¦å…ˆä¿®çŸ¥è¯†ä¹Ÿä¸å†™ï¼Œç”šè‡³è¿ä¸ª syllabus éƒ½æ²¡å¾—ã€‚æ•™æˆçš„è¯¾è®²å¾—å…¶å®è¿˜ä¸é”™ï¼Œç¬¬ä¸€èŠ‚è¯¾æˆ‘æ„Ÿè§‰è‡ªå·±å¬åˆ°äº†å‰äºŒååˆ†é’Ÿï¼Œå½“æˆ‘åé¢å®Œå…¨å¬ä¸æ‡‚æƒ³è¦è‡ªå·±é˜…è¯»ææ–™å¯»æ±‚å¸®åŠ©æ—¶ï¼Œå‘ç°è¿™é—¨è¯¾å±éƒ½ä¸æä¾›ï¼Œä¹Ÿä¸çŸ¥é“æ˜¯è¿™ä¸ªæ•™æˆä¸ä¸Šå¿ƒï¼Œè¿˜æ˜¯åŠ©æ•™ä»€ä¹ˆéƒ½ä¸ç®¡åªç®¡å‘æ•™æˆæŠ¥å‘Šâ€œä¸€åˆ‡å®‰å¥½â€ï¼Œæˆ–è€…æ˜¯å…¨æ¸…åçš„è¯¾éƒ½æ˜¯è¿™ä¸ªå¾·è¡Œï¼Œæˆ‘åæ­£ä¸Šä¸ä¸‹å»è¿™è¯¾äº†ï¼Œä¹Ÿæ˜¯å¾ˆé—æ†¾çš„ï¼Œæ¯•ç«Ÿå¯¹æ–¹çœ‹èµ·æ¥çœŸçš„æ˜¯å¾ˆæœ‰åçš„æ•™æˆï¼Œæ¯”åº·å¥ˆå°”çš„å“²å­¦é™¢ä¼°è®¡å¥½ä¸å°‘å‘¢â€¦ è¯è¯´åæ¥æˆ‘è¿˜å»çœ‹äº†å‡ èŠ‚ï¼Œå‘ç°äººæ˜¯è¶Šæ¥è¶Šå°‘ï¼Œçœ‹åˆ°æ¸…åçš„åŒå­¦ä»¬ä¹Ÿé€€äº†æˆ‘æ˜¯å¾ˆå¼€å¿ƒçš„ï¼Œä¸è¿‡ä»–ä»¬å¯èƒ½æ˜¯å› ä¸ºå¬ä¸æ‡‚è‹±è¯­é€€çš„å§ï¼Ÿæˆ‘ä¹Ÿä¸çŸ¥é“ Introduction to Artificial Intelligence åœ†äº†ä¸€ä¸ªè‡ªå·±â€œä¸Šå‰é™¢çš„è¯¾â€çš„è¿™ä¸€è£…é€¼æ¢¦ï¼Œç¬¬ä¸€èŠ‚è¯¾æ˜¯ä¸ªè€å¤´å­ï¼Œè‹±è¯­è®²å¾—ä¹Ÿä¸å¾ˆæºœé“ä½†å°±æ˜¯è¦è¯´è‹±è¯­ï¼Œç¬¬ä¸€èŠ‚è¯¾å•¥ä¹Ÿæ²¡è®²å°±è®²äº†è®²AIçš„å†å²ä»€ä¹ˆçš„ï¼Œå¾ˆæ˜¯æ²¡æ„æ€ã€‚åæ¥å‘ç°è¿™ä¸ªè‹±è¯­è®²å¾—ä¸æºœé“ï¼Œè¯´è¯ä¹Ÿä¸æºœé“çš„è€å¤´å­æ˜¯å§šæœŸæ™ºè€å…ˆç”Ÿâ€¦å˜¶ï¼Œå¯¹ä¸èµ· ç¬¬äºŒèŠ‚è¯¾å°±å¼€å§‹æœ‰æ„æ€äº†ï¼Œä¸€ä¸Šæ¥å°± reinforcement learning çš„ä»€ä¹ˆå¾ˆå‰å®³çš„äººæ¥è®²å¾ˆå…ˆè¿›çš„ reinforcement learningï¼Œæœ‰æ„æ€æ˜¯æœ‰æ„æ€ï¼Œä¸è¿‡æ˜¯å±€é™äºå‰é™¢åŒå­¦ä»¬çš„æœ‰æ„æ€ï¼Œæˆ‘å·²ç»å¬ä¸æ‡‚äº†ï¼Œæ—©æ—©æ‹œæ‹œï¼Œå¬äº†ä¸€èŠ‚è¯¾å°±è¡Œäº† è¯¾å ‚ä¸Šè¿˜æœ‰æ¥è‡ª Princeton çš„åŒå­¦ä»¬ï¼ˆçœ‹åˆ°å¥¹ä»¬ Gmail å³ä¸Šè§’çš„æ ¡æ ‡ç¡®å®šçš„ï¼‰æˆ‘ç¬¬äºŒèŠ‚è¯¾å°±ä¸å»äº†ï¼Œä¸çŸ¥é“æˆ‘ä»¬ Princeton çš„å°åŒå­¦æ˜¯ä»€ä¹ˆæ—¶å€™ä¸å»çš„ï¼Œè¿˜æ˜¯å¥¹ä»¬éƒ½èƒ½å¬æ‡‚ã€‚ä¸è¿‡ä½ è¯´å¥¹ä»¬æœ‰å‰é™¢åŒå­¦çš„å®åŠ›ï¼Œæˆ‘æ˜¯ç»å¯¹ä¸ä¿¡çš„ã€‚","categories":[],"tags":[{"name":"Cornell","slug":"Cornell","permalink":"https://yao-lirong.github.io/blog/tags/Cornell/"},{"name":"Review","slug":"Review","permalink":"https://yao-lirong.github.io/blog/tags/Review/"},{"name":"Tsinghua","slug":"Tsinghua","permalink":"https://yao-lirong.github.io/blog/tags/Tsinghua/"}]},{"title":"2020 Web Journal","slug":"2020-12-31-2020-ç½‘ç»œæ—¥å¿—","date":"2020-12-31T05:00:00.000Z","updated":"2022-06-08T19:31:52.000Z","comments":true,"path":"2020-12-31-2020-ç½‘ç»œæ—¥å¿—/","permalink":"https://yao-lirong.github.io/blog/2020-12-31-2020-%E7%BD%91%E7%BB%9C%E6%97%A5%E5%BF%97/","excerpt":"A cartoon intro to DNS over HTTPS: HTTP, DNS, DNS over HTTPS ç®€ä»‹ (ä¸­æ–‡ç‰ˆ 1 2) VS Codeä¸Šä¹Ÿèƒ½ç©è½¬Jupyter Notebook ä»€ä¹ˆæ˜¯ç”Ÿæˆå‡½æ•°ï¼Ÿ: æœ‰è‡ªå¸¦æ•°å­¦å…¬å¼çš„dpfç‰ˆï¼Œæ¥æºä¸ºè±†ä¸ç½‘ã€‚å…¶ä¸­ç¬¬ä¸‰é¡µç»“å°¾å¼å­åº”ä¸º $g(x)+xg(x) = \\frac{g(x)}{x} - 1$, æ­¤æ®µç»“å°¾ï¼ˆåœ¨ç¬¬å››é¡µå¼€å¤´ï¼‰çš„å¼å­åº”ä¸º $g(x) = \\frac{-x}{x^2+x-1}$. IDMä½¿ç”¨æŠ€å·§","text":"A cartoon intro to DNS over HTTPS: HTTP, DNS, DNS over HTTPS ç®€ä»‹ (ä¸­æ–‡ç‰ˆ 1 2) VS Codeä¸Šä¹Ÿèƒ½ç©è½¬Jupyter Notebook ä»€ä¹ˆæ˜¯ç”Ÿæˆå‡½æ•°ï¼Ÿ: æœ‰è‡ªå¸¦æ•°å­¦å…¬å¼çš„dpfç‰ˆï¼Œæ¥æºä¸ºè±†ä¸ç½‘ã€‚å…¶ä¸­ç¬¬ä¸‰é¡µç»“å°¾å¼å­åº”ä¸º $g(x)+xg(x) = \\frac{g(x)}{x} - 1$, æ­¤æ®µç»“å°¾ï¼ˆåœ¨ç¬¬å››é¡µå¼€å¤´ï¼‰çš„å¼å­åº”ä¸º $g(x) = \\frac{-x}{x^2+x-1}$. IDMä½¿ç”¨æŠ€å·§","categories":[],"tags":[{"name":"Journal","slug":"Journal","permalink":"https://yao-lirong.github.io/blog/tags/Journal/"}]},{"title":"C++ Manual","slug":"2020-11-29-C++-å¸¸è§é—®é¢˜","date":"2020-11-29T05:00:00.000Z","updated":"2023-05-15T01:05:08.000Z","comments":true,"path":"2020-11-29-C++-å¸¸è§é—®é¢˜/","permalink":"https://yao-lirong.github.io/blog/2020-11-29-C++-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","excerpt":"","text":"char ï¼š1ä¸ªå­—èŠ‚ char*(å³æŒ‡é’ˆå˜é‡): 8ä¸ªå­—èŠ‚ short int : 2ä¸ªå­—èŠ‚ intï¼š 4ä¸ªå­—èŠ‚ unsigned int : 4ä¸ªå­—èŠ‚ float: 4ä¸ªå­—èŠ‚ double: 8ä¸ªå­—èŠ‚ long: 8ä¸ªå­—èŠ‚ long long: 8ä¸ªå­—èŠ‚ unsigned long: 8ä¸ªå­—èŠ‚ I/O è¯»å…¥å­—ç¬¦ä¸²å¯ä»¥ç”¨ scanf(\"%s\") æˆ– getline() è¯»å…¥å­—ç¬¦ä¸”å¿½ç•¥ç©ºæ ¼å¯ä»¥ç”¨ scanf(\" %c\")ï¼Œæ³¨æ„ %c å‰é¢çš„ç©ºæ ¼ C++ cin.ignore()çš„ç”¨æ³•è¯¦è§£ C++ cin&gt;&gt; cin.get() cin.getline() unsigned long long int scanf æ–‡ä»¶çš„è¯»å–åŠå†™å…¥: 12freopen(&quot;myfile.txt&quot;,&quot;r&quot;,stdin);freopen (&quot;myfile.txt&quot;,&quot;w&quot;,stdout); Class and Header It is not possible to create an instance of a class without invoking the constructor STLçš„ä½¿ç”¨ ä¸ºä»€ä¹ˆ std::vector ä¸æ”¯æŒ push_frontï¼Ÿ æŒ‡é’ˆçš„ä½¿ç”¨ æŒ‡é’ˆå˜é‡çš„ä¼ å€¼å’Œä¼ å€ C++ delete å’Œ delete []çš„åŒºåˆ« NULLå’Œnullptrçš„åŒºåˆ« ç±»ä¸ç»“æ„ä½“çš„ä½¿ç”¨ C++ä¸­ç»“æ„ä½“ä¸ç±»çš„åŒºåˆ«ï¼ˆstructä¸classçš„åŒºåˆ«ï¼‰ å®šä¹‰ç»“æ„ä½“å˜é‡åŠåˆå§‹åŒ–; ç»“æ„ä½“å®šä¹‰å˜é‡çš„ä¸‰ç§æ–¹æ³• C++æ„é€ å‡½æ•°ä»€ä¹ˆæ—¶å€™ä¼šè¢«è°ƒç”¨ C++ä¸­å¦‚ä½•å£°æ˜ä¸¤ä¸ªé€’å½’è°ƒç”¨çš„ç±» String Split a String: strtok: Reference 1, Reference 2 123456789char str[] =&quot;- This, a sample string.&quot;;char * pch;pch = strtok (str,&quot; ,.-&quot;);while (pch != NULL)&#123; printf (&quot;%s\\n&quot;,pch); // Note to use NULL the next time you call strtok pch = strtok (NULL, &quot; ,.-&quot;);&#125; Convert a char array to integer: sscanf(s, \"%i\", &amp;imm) automatically detects whether s is an decimal 142 or a hex 0xa2c (Note the 0x before a hex number is necessary) 123char myarray[5] = &#123;&#x27;-&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;\\0&#x27;&#125;;int i;sscanf(myarray, &quot;%d&quot;, &amp;i); Read in both hex and dec number: scanf(\"%i\", ) Strings in C (char arrays) end with a terminating null-character '\\0' å…¶å®ƒé—®é¢˜ switch statement gives â€œa label can only be part of a statementâ€¦â€: switch åè¦åŠ åˆ†å· ; 12345switch (option) &#123; case &#x27;a&#x27;: ; ... case &#x27;b&#x27;: ; ... &#125;","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"Python Manual","slug":"2020-11-29-Python-å¸¸è§é—®é¢˜","date":"2020-11-29T05:00:00.000Z","updated":"2023-04-11T20:38:42.000Z","comments":true,"path":"2020-11-29-Python-å¸¸è§é—®é¢˜/","permalink":"https://yao-lirong.github.io/blog/2020-11-29-Python-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","excerpt":"","text":"python æ•´å‹ä¸äºŒè¿›åˆ¶æ•°å€¼çš„ç›¸äº’è½¬æ¢ pyhton çš„å¼‚æˆ–ä¸ Hamming Distance Pythonä¹‹æ­£åˆ™è¡¨è¾¾å¼â€”â€”æŸ¥æ‰¾ Pythonç±»å‹å¼ºåˆ¶è½¬æ¢ multi-line statements: 123total = item_one + \\ item_two + \\ item_three List Find Median of List in Python: statistics.median(list) Union of two lists: to remove all repetitions, use res = list(set().union(lst1, lst2, lst3, ...)) concatenate two lists: lst1 + lst2 Hash a list: you cannot hash a list, because list is mutable. You can only hash immutable objects. Therefore, to hash a list, you first convert it to a tuple: hash(tuple([1,2,3])). Take only the elements indexed at xth multiple to form a new list: lst[::x] so the third argument of : means step, just as in range. Generate range with floats: use np.arange(start, stop, step), or np.linspace(start, stop, num_wanted) Unzip a zipped list: list(zip(*test_list)) note * is the unpacking operator to unpack the iterable into separate elements that can then be passed as arguments to the zip() function. Dict Sort a dictionary: dct= dict(sorted(dct.items(), key=lambda item:item[0])) to sort by keys; change to item[1] to sort by values. Remove an item from dict by key: dct.pop(your_key) Function Access &amp; Change global variable in local functions: you can access global variable in local functions without any other keywords. However, if you want to change the global variable in your local function. You will have to use the global keyword. By using a global keyword, you can either create a global variable in a local function, or link back to a global variable already created. 1234567x = &quot;h&quot;def myfunc(): global x x = &quot;fantastic&quot;myfunc() Change Variable in an Outer Scope: Similar to the global keyword, we have a nonlocal keyword for this purpose. 1234567def foo(): a = 1 def bar(): nonlocal a a = 2 bar() print(a) # Output: 2 Multiple number of arguments to a function: 123def foo(a, b, c, *others): print(a, b, c) print(&quot;And all the rest are &quot;, list(others)) Import a Custom Module: the same as import, but now the module name can be a variable instead of a static string 123package_name = &quot;numpy&quot;package = __import__(package_name) package.array() Class print a class like Javaâ€™s toString : 12345class Test: def __repr__(self): # what to display when looked at in an interactive prompt return &quot;Test()&quot; def __str__(self): # what to print when called print(Test) return &quot;member of Test&quot; Self-defined comparator: 12345678910111213class CustomNumber: def __init__(self, value): self.value = value def __lt__(self, obj): &quot;&quot;&quot;self &lt; obj&quot;&quot;&quot; return self.value &lt; obj.value def __le__(self, obj): &quot;&quot;&quot;self &lt;= obj&quot;&quot;&quot; def __eq__(self, obj): &quot;&quot;&quot;self == obj&quot;&quot;&quot; def __ne__(self, obj): &quot;&quot;&quot;self != obj&quot;&quot;&quot; def __gt__(self, obj): &quot;&quot;&quot;self &gt; obj&quot;&quot;&quot; def __ge__(self, obj): &quot;&quot;&quot;self &gt;= obj&quot;&quot;&quot; hash on a custom object: 12345678class Emp: def __init__(self, emp_name, id): self.emp_name = emp_name self.id = id def __hash__(self): # when you want to get the hash, use hash(instance_of_custom_object) return hash((self.emp_name, self.id)) Local variable in a class: Elements outside the __init__ method are static elements; they belong to the class. Elements inside the __init__ method are elements of the object (self); they donâ€™t belong to the class. 1234class MyClass: static_elem = 123 # static def __init__(self): self.object_elem = 456 # specific to eacy instance Exception Self-specified exception: 123456789101112class MyCustomError(Exception): def __init__(self, *args): if args: self.message = args[0] else: self.message = None def __str__(self): if self.message: return &#x27;MyCustomError, &#123;0&#125; &#x27;.format(self.message) else: return &#x27;MyCustomError has been raised&#x27; try catch clause in python: 1234try: print(x)except: print(&quot;Exception thrown. x does not exist.&quot;) String convert string to int: int(s) How to remove the leading and trailing spaces in Python: my_string.strip() åˆå¹¶ä¸€ä¸ª String List: \"\".join(str_lst) Join with seperator: \",\".join(str_lst) advanced split with re : re.split(\"split_on_what_in_regex\", str) Extract characters from a string: \"\".join(re.findall(\"[a-zA-Z]+\", str)) Convert String of Digits into a List of Digits: and just to characters 123456num = 2019# If you want a list of integersres = [int(x) for x in str(num)]# If you are good with a list of charactersres = list(str(num)) Format float to scientific computing: print(\"a = %.2e\" %(num)) String Format in General: f-string is a new feature since python 3.6 and you should use it as string formatting convention f\"iter: &#123;i&#125;\" to align signs: '+' indicates that a sign should be used for both positive as well as negative numbers. '-' indicates that a sign should be used only for negative numbers (this is the default behavior). ' ' indicates that a leading space should be used on positive numbers, and a minus sign on negative numbers (most used) 12345678# scientific format with f-stringf&#x27;&#123;num:.5e&#125;&#x27; # float number, use space to also align negative signf&#x27;&#123;num: .3f&#125;&#x27; # align integers to have a fixed lengthf&#x27;&#123;num:3d&#125;# f-string braced evaluation also supports everything (including functions)f&quot;&#123;&quot;Eric Idle&quot;.lower()&#125; is funny.&quot; Data Structures Queue: Python ç”¨çš„ä¸æ˜¯ enqueue dequeueï¼Œè€Œæ˜¯ put get 1234import queueq = queue.Queue()q.put(s)v = q.get() Priority Queue: 12from queue import priorityQueueq = PriorityQueue() å‡½æ•°å¼ç¼–ç¨‹ pythonçš„filteråŸºæœ¬ç”¨æ³•: lst = list(filter(func, lst)), dct = dict(filter(func, dct)) python3ä¸­map()å‡½æ•°ç”¨æ³•: map(func, list) Python reduce() å‡½æ•°: similar to fold_left reduce(lambda acc x : ..., list, init) IO è¯»å…¥å¤šè¡Œæ–‡ä»¶: lines = file1.readlines() 123456789file_path = os.getcwd() + &quot;\\\\&quot; + file_namef = open(file_path, &#x27;r&#x27;, encoding=&#x27;utf-8&#x27;)lines = f.readlines()f = open(file_path, &#x27;w&#x27;, encoding=&#x27;utf-8&#x27;)f.write(string)f.writelines(lst_of_strs)f.close() å†™å…¥csvæ–‡ä»¶çš„å‡ ç§æ–¹æ³• å†™å…¥csvæ–‡ä»¶çš„å‡ ç§æ–¹æ³•æ€»ç»“ è·å–å½“å‰æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰æ–‡ä»¶å¤¹å 1filenames = os.listdir(path) Get Parent Directory Name: os.path.dirname(os.getcwd()) Profiling Creating Profiling Data 123456import cProfileprofiler = cProfile.Profile()profiler.enable()# Code goes here profiler.disable()profiler.dump_stats(&quot;execution.stats&quot;) Inspecting Profiling Data 123import pstatsstats = pstats.Stats(&quot;example.stats&quot;)stats.print_stats() The following columns will be shown: ncalls: number of times function was called tottime: amount of time spent in the function (not counting any time spent in subfunctions) percall: tottime / ncalls cumtime: all the time spent in the function and subfunctions percall: cumtime / ncalls filename:lineno(function): name of function that was called and where it is defined A fairly common practice is to sort by one of the above attributes. Or to look at its callees to see where that function wound up spending time. You can also perform the inverse, and look up a functionâ€™s callers. This can be helpful if you have a function that is taking a lot of time, but you donâ€™t know who is calling it. 123stats.sort_stats(&quot;cumtime&quot;).print_stats(2) #print first 2 functions that spent highest cumulative timestats.print_callers(&quot;cprofile_example.py:7&quot;) # 7 is line7stats.print_callees(&quot;cprofile_example.py:3&quot;) You can also use the visualization tool snakeviz. Reference: Profiling Python Code with cProfile Profile Memory 123456import tracemalloctracemalloc.start()# Code goes here print(&quot;maximum memory usage is &quot; + str(tracemalloc.get_traced_memory()[1] / 1024 / 1024 / 1024) + &quot; Gb&quot;)tracemalloc.stop() Pip pip freeze to show all installed packages pip show &lt;package_name&gt; to show a specific package NumPy Difference between max and maximum: numpy.maximum(A,B) returns the element-wise bigger one of the two numpy.max(A) returns the maximum value inside A Matrix/Vector Multiplication: np.matmul(A, B): Returns matrix product of A and B np.multiply(A, B): Returns element-wise multiplication of A and B np.dot(A, B): Returns dot product of A and B numpy.diagonal(M): Returns the diagonal of a 2-D matrix M numpy.tile(A, reps): repeats A reps times numpy.where(cond, A, B): condition on array. Really useful function, so is just A if cond else B Solve TypeError: only integer scalar arrays can be converted to a scalar index when you execute a[a == b]: this happens because a is not an np array. It is a list and the message above comes from the list type. reference Convert sclacr to array or to any shape: np.reshape(scalar, (1,1)) When your matrix operations involve inverses Aâˆ’1, it is always better to use the inverse indirectly than to manifest it explicitly because manifesting it often involves intricate computation that may harm numerical stability. That is, use np.linalg.solve() instead of np.linalg.inv reference np.frompyfunc to more efficiently apply function on numpy arrays: This function is internally called when you apply a function to a np.array, but if the otuput doesnâ€™t meet your expectation, you can use this function to specify what it should do. 1234double = lambda x = 2xnpfunction = np.frompyfunc(f, &lt;input_number&gt;, &lt;output_number&gt;)npf = np.frompyfunc(double, 1, 1)# npf(arr) &lt;==&gt; f(arr) in this particular case For each row, extract the corresponding column: Qs = network(states)[np.arange(actions.shape[0]), actions] network(states) is B Ã— dimA representing for each sample, the value of taking a specific action. actions is vector of B storing which action we actually took. Using this command, we extract the value of taking a specific action at a specific state. Note There are a total B (state, action) pairs. Pandas 1234567891011121314# ç›´æ¥å¾ªç¯ df å¾ªç¯çš„æ˜¯ col åfor col in df: print(col)# æƒ³è¦å¾ªç¯æ¯ä¸€è¡Œçš„æ•°æ®åº”ä½¿ç”¨ iterrows()# row = (row_index: int, data: pd.Series)for row in df.iterrows(): print(row)# æƒ³è¦è¯»å–æŸä¸€è¡Œçš„æ•°æ®ä½¿ç”¨ loc[i]ï¼Œè¿”å› pd.Seriesrow0 = df.loc[0]# loc ç”¨æ¥è¿‡æ»¤æ—¶å¦‚æœæœ‰ä¸¤ä¸ªä»¥ä¸Šæ¡ä»¶ï¼šåªèƒ½ç”¨&amp;ï¼Œç”¨andä¼šæŠ¥é”™ï¼Œæ­¤å¤–ä¹Ÿè¦ç”¨åœ†æ‹¬å·æ‹¬èµ·æ¥ df.loc[ (df[&quot;att1&quot;] == &quot;012&quot;) &amp; (df[&quot;code&quot;] == &quot;2A&quot;) ] AttributeError: â€˜floatâ€™ object has no attribute â€˜splitâ€™ Mathplotlib import matplotlib.pyplot as plt Change where y range starts in matplotlib: plt.ylim(bottom = x) Rotate the labels in x-axis by 90 degrees: this trick helps you when you have too long x-axis labels. plt.xticks(rotation = 90 ) Output/Save Plot: plt.savefig('filename.png') Change labels, ticks, â€¦ Change ticks are applicable when your x-axis is discrete, like [1, 2, 5, 10] and you want any neighboring two only has unit distance instead of, say between 2 and 5 have 3 unit distance. 1234567plt.xlabel(&#x27;X axis&#x27;, fontsize=15)plt.ylabel(&#x27;Y axis&#x27;, fontsize=15) plt.xticks(lst_of_tick_position, labels, color=&#x27;blue&#x27;, rotation=60) # disabling yticks by setting yticks to an empty listplt.yticks([]) Different Kinds of Plot: scatter plot: plt.scatter(x,y) histogram: plt.hist(x,y) æ™®é€šæŠ˜çº¿å›¾: 123x = np.arange(-10,10,0.1)y = 2*xplt.plot(x,y) reset plot: plt.clf() Plot lines w/ custom line label: 123456#plot individual lines with custom colors, styles, and widthsplt.plot(df[&#x27;leads&#x27;], label=&#x27;Leads&#x27;, color=&#x27;green&#x27;)plt.plot(df[&#x27;prospects&#x27;], label=&#x27;Prospects&#x27;, color=&#x27;steelblue&#x27;, linewidth=4)plt.plot(df[&#x27;sales&#x27;], label=&#x27;Sales&#x27;, color=&#x27;purple&#x27;, linestyle=&#x27;dashed&#x27;)plt.legend() Json Json doesnâ€™t dump UTF-8: When you have json output like \\u2019, it may not be your fault. Note the json standard is to escape non-ascii characters even if itâ€™s not needed. You can override this with the following command: 12with open(&#x27;output.json&#x27;, &#x27;w&#x27;) as f: json.dump(posts, f, indent=4, ensure_ascii=False)","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"LaTeX Manual","slug":"2020-11-23-Latex-å®ç”¨æŠ€å·§æ‰‹å†Œ","date":"2020-11-23T05:00:00.000Z","updated":"2024-01-23T15:55:07.523Z","comments":true,"path":"2020-11-23-Latex-å®ç”¨æŠ€å·§æ‰‹å†Œ/","permalink":"https://yao-lirong.github.io/blog/2020-11-23-Latex-%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7%E6%89%8B%E5%86%8C/","excerpt":"","text":"Commands æ’ç‰ˆå¤§æ‹¬å· $f(x)=\\left\\{ \\begin{aligned} x &amp; = &amp; \\cos(t) \\\\ y &amp; = &amp; \\sin(t) \\\\ z &amp; = &amp; \\frac {x}{y} \\end{aligned} \\right.$ 1234567f(x)=\\left\\&#123;\\begin&#123;aligned&#125;x &amp; = &amp; \\cos(t) \\\\y &amp; = &amp; \\sin(t) \\\\z &amp; = &amp; \\frac xy\\end&#123;aligned&#125;\\right $f(x)= \\begin{cases} 0&amp; \\text{x=0}\\\\ 1&amp; \\text{x!=0} \\end{cases}$ 1234567\\[f(x)=\\begin&#123;cases&#125;0&amp; \\text&#123;x=0&#125;\\\\1&amp; \\text&#123;x!=0&#125;\\end&#123;cases&#125;\\]% note cases only support one align operator &amp;% and they need to stay in a math block Sections and Chapters: Usually, \\section is the top-level document command in most documents. However, in reports or books, and similar long documents, this would be \\chapter or \\part. To get an unnumbered chapter / section add an asterisk (*) at the end of the command, like \\section*. å¤§å†™å­—æ¯ åŒå†™ä½“: â„ - \\mathbb&#123;R&#125; ç²—ä½“: R - \\mathbf&#123;R&#125; èŠ±ä½“: â„› - \\mathcal&#123;R&#125; Text: Roman Font: \\textrm&#123;&#125; Typewriter Font: \\texttt&#123;&#125; Spacing: \\quad - equal to the current font size (= 18 math unit): between a mathematical symbol and text in displayed expressions 1\\[ E_n(t) \\to e^&#123;-t&#125;\\quad\\text&#123;as &#125;t\\to\\infty \\] \\qquad - double â€œquadâ€ (= 36 math unit) : between two separate equations 1\\[ x^2 + y^2 = a^2,\\qquad x-y=b \\] \\, (= 3 math unit) is the most commonly seen one with the thinnest space. \\; (= 5 math unit) is the spacing I always use. specify how many inches/cm - \\hspace&#123;0.1in&#125;; you can use \\vspace&#123;1cm&#125; for vertical space ~ inserts a non-breaking space, where you tell LaTeX not to insert a linebreak here Vector: pâƒ— - \\vec&#123;p&#125; Self-defined operators: \\operatorname*&#123;argmin&#125; Dot: horizontal dots on the line: â€¦ - \\ldots horizontal dots above the line: â‹¯ - \\cdots single horizontal dot on the line: â‹… \\cdot vertical dots: â‹® - \\vdots diagonal dots: â‹± - \\ddots Matrix: note this needs to be placed inside a math block $$ \\begin{bmatrix} \\sigma_{11} &amp; \\cdots &amp; \\sigma_{1n} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\sigma_{n1} &amp; \\cdots &amp; \\sigma_{nn} \\end{bmatrix} $$ 12345\\begin&#123;bmatrix&#125; \\sigma_&#123;11&#125; &amp; \\cdots &amp; \\sigma_&#123;1n&#125; \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\sigma_&#123;n1&#125; &amp; \\cdots &amp; \\sigma_&#123;nn&#125;\\end&#123;bmatrix&#125; proportional to: âˆ \\propto tilt / similar to: âˆ¼ \\sim Wrap formula with a box $$ \\boxed{h(\\mathbf{x}) = \\operatorname*{argmax}_y \\; \\hat\\pi_y \\prod_{\\alpha=1}^{d} P(x_\\alpha | y)} $$ 1\\boxed&#123; h(\\mathbf&#123;x&#125;) = \\operatorname*&#123;argmax&#125;_y \\; \\hat\\pi_y \\prod_&#123;\\alpha=1&#125;^&#123;d&#125; P(x_\\alpha | y) &#125; Comment in latex: use % Under or above any notation (also can do multiline): $$ \\underset{k\\in N}{E} \\overset{wow}{E} \\underset{\\substack{i \\in N \\\\ j \\in N}}{E} $$ 1234\\underset&#123;k\\in N&#125;&#123;E&#125;\\overset&#123;wow&#125;&#123;E&#125; % to write multi-line, use \\substack\\underset&#123;\\substack&#123;i \\in N \\\\ j \\in N&#125;&#125;&#123;E&#125; Under or above with braces: (For how to overlap multi braces, see the original answer) $$ \\underbrace{(x + 2)^3}_\\text{text 1} \\quad \\overbrace{(x - 3)}^\\text{text 2} $$ 12\\underbrace&#123;(x + 2)^3&#125;_\\text&#123;text 1&#125;\\overbrace&#123;(x - 3)&#125;^\\text&#123;text 2&#125; Multiple lines of subscript / under (There is no known multiple lines of superscript) $$ \\sum_{\\substack{a=b \\\\ b=c}} $$ 1\\sum_&#123;\\substack&#123;a=b \\\\ b=c&#125;&#125; Ceiling and floor: âŒŠxâŒ‹ âŒˆxâŒ‰ 12\\lfloor x \\rfloor \\lceil x \\rceil Make something to be centered even though its component has a non-zero width $$ \\int_{-\\infty}^{\\infty} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}} \\, dx \\\\ \\int_{-\\infty}^{\\infty} \\mathclap{e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}} \\, dx $$ 12\\int_&#123;-\\infty&#125;^&#123;\\infty&#125; e^&#123;-\\frac&#123;(x-\\mu)^2&#125;&#123;2\\sigma^2&#125;&#125; \\, dx \\\\\\int_&#123;-\\infty&#125;^&#123;\\infty&#125; \\mathclap&#123;e^&#123;-\\frac&#123;(x-\\mu)^2&#125;&#123;2\\sigma^2&#125;&#125;&#125; \\, dx Different types of alignment: align: numbers the equation (you can use \\nonumber after a specific line to suppress numbering) align*: doesnâ€™t number the equation alignat: doesnâ€™t add space between the columns (rl pairs), but you have to tell it how many columns you have (It works if you have fewer columns than you specified but doesnâ€™t if otherwise. So in theory you can just set a super big number to it) 123456\\begin&#123;alignat*&#125;&#123;3&#125;&amp; m \\quad &amp;&amp; \\text&#123;mÃ³dulo&#125; \\quad &amp;&amp; m&gt;0\\\\&amp; a \\quad &amp;&amp; \\text&#123;multiplicador&#125; \\quad &amp;&amp; 0&lt;a&lt;m\\\\&amp; c \\quad &amp;&amp; \\text&#123;constante aditiva&#125; \\quad &amp;&amp; 0\\leq c&lt;m\\\\&amp; x_0 \\quad &amp;&amp; \\text&#123;valor inicial&#125; \\quad &amp;&amp; 0\\leq x_0 &lt;m\\end&#123;alignat*&#125; $$ \\begin{alignat*}{3} &amp; m \\quad &amp;&amp; \\text{mÃ³dulo} \\quad &amp;&amp; m&gt;0\\\\ &amp; a \\quad &amp;&amp; \\text{multiplicador} \\quad &amp;&amp; 0&lt;a&lt;m\\\\ &amp; c \\quad &amp;&amp; \\text{constante aditiva} \\quad &amp;&amp; 0\\leq c&lt;m\\\\ &amp; x_0 \\quad &amp;&amp; \\text{valor inicial} \\quad &amp;&amp; 0\\leq x_0 &lt;m \\end{alignat*} $$ Basic Knowledge align with &amp; An align is a table-like structure, and &amp; is a column separator. The thing is that the columns in an align are rlrlrlrlrl..., that is, every other column is right aligned and left aligned. So, below the a is in a right aligned column, while =b is left aligned 1a &amp;= b In following, text will be in a right aligned column, 1a &amp;= b &amp; text We should note that &amp;&amp; is just &amp; &lt;no code here&gt; &amp;, Therefore, if you do the following, text will be in a left aligned column, as you basically just add an empty column between =b and text 1a &amp;= b &amp;&amp; text reference Best Practices \\[ \\] over $$ $$ for display math: $$ is TeX primitive syntax and itâ€™s pretty much deprecated. You should always use \\[ \\]. more detailed reasons \\( \\) over $ $ for inline math: similarly, $ is old TeX syntax whereas \\( \\) is LaTex syntax. People suggest choose at your own preference for this inline math one since the old TeX syntax does provide much more readability. more discussion here Helper TikzEdt: A â€œwhat you see is what you getâ€ Tikz editor. Tikz is a very powerful graph drawing package for LaTeX Reference Overleaf - Spacing in Math Mode Detailed Spacing Explanation Referring to Mathematics into Type","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"Pythonç½‘ç»œçˆ¬è™«ä¸ä¿¡æ¯æå–","slug":"2020-11-17-Pythonç½‘ç»œçˆ¬è™«ä¸ä¿¡æ¯æå–","date":"2020-11-17T05:00:00.000Z","updated":"2025-04-10T04:23:04.996Z","comments":true,"path":"2020-11-17-Pythonç½‘ç»œçˆ¬è™«ä¸ä¿¡æ¯æå–/","permalink":"https://yao-lirong.github.io/blog/2020-11-17-Python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B8%8E%E4%BF%A1%E6%81%AF%E6%8F%90%E5%8F%96/","excerpt":"Pythonç½‘ç»œçˆ¬è™«ä¸ä¿¡æ¯æå– - åµ©å¤©","text":"Pythonç½‘ç»œçˆ¬è™«ä¸ä¿¡æ¯æå– - åµ©å¤© è§„åˆ™ requests.get() r = requests.get(string url, timeout = n) r æ˜¯ä¸€ä¸ª response ç±»ï¼Œå®ƒåŒ…å«å¦‚ä¸‹å±æ€§ r.status_code: è¿”å›ç  r.text: HTTP ç›¸åº”å†…å®¹çš„å­—ç¬¦ä¸²å½¢å¼ r.encoding: ä» header ä¸­çŒœæµ‹çš„ç½‘é¡µç¼–ç æ–¹å¼ r.apparent_encoding: ä»å†…å®¹ä¸­åˆ†æå‡ºæ¥çš„ç¼–ç æ–¹å¼ r.content:HTTP ç›¸åº”å†…å®¹çš„äºŒè¿›åˆ¶å½¢å¼ å¦‚æœè¿‡ n ç§’åè¿˜æ²¡æœ‰æˆåŠŸå¾—åˆ°æœåŠ¡å™¨çš„ç›¸åº”/ä»æœåŠ¡å™¨è¯»å–æ•°æ®ï¼Œç¨‹åºä¼š throw TimeOutError requests åº“çš„å¼‚å¸¸ åœ¨ request ç½‘ç»œè¿æ¥æ—¶ï¼Œæˆ‘ä»¬ä¸€å®šè¦ç”¨ r.raise_for_status() æ¥åœ¨è¿”å›ç ä¸æ˜¯200æ­£å¸¸æ—¶ï¼Œraise exceptionï¼Œç„¶åç”¨ try ... catch ... è¯­å¥ä¿è¯å¼‚å¸¸è¢«æœ‰æ•ˆå¤„ç† requests.ConnectionError: ç½‘ç»œè¿æ¥é”™è¯¯å¼‚å¸¸ï¼Œå¦‚DNSæŸ¥è¯¢å¤±è´¥ã€æ‹’ç»è¿æ¥ç­‰ requests.HTTPError: HTTPé”™è¯¯å¼‚å¸¸ requests.URLRequired: URLç¼ºå¤±å¼‚å¸¸ requests.TooManyRedirects: è¶…è¿‡æœ€å¤§é‡å®šå‘æ¬¡æ•°ï¼Œäº§ç”Ÿé‡å®šå‘å¼‚ requests.ConnectTimeout: è¿æ¥è¿œç¨‹æœåŠ¡å™¨è¶…æ—¶å¼‚å¸¸ requests.Timeout: è¯·æ±‚URLè¶…æ—¶ï¼Œä»æ•´ä¸ªå‘èµ·URLè¯·æ±‚å¼€å§‹äº§ç”Ÿè¶…æ—¶å¼‚å¸¸ HTTP åè®®å¯¹èµ„æºçš„æ“ä½œ GET: è¯·æ±‚è·å–URLä½ç½®çš„èµ„æº HEAD: è¯·æ±‚è·å–URLä½ç½®èµ„æºçš„å“åº”æ¶ˆæ¯æŠ¥å‘Šï¼Œå³è·å¾—è¯¥èµ„æºçš„å¤´éƒ¨ä¿¡æ¯ï¼ŒèŠ‚çœå¸¦å®½ POST: è¯·æ±‚å‘URLä½ç½®çš„èµ„æºåé™„åŠ æ–°çš„æ•°æ®ï¼Œä¸æ”¹å˜ç°æœ‰å†…å®¹ï¼Œåªæ˜¯å¢åŠ  PUT: è¯·æ±‚å‘URLä½ç½®å­˜å‚¨ä¸€ä¸ªèµ„æºï¼Œè¦†ç›–åŸURLä½ç½®çš„èµ„æº PATCH: è¯·æ±‚å±€éƒ¨æ›´æ–°URLä½ç½®çš„èµ„æºï¼Œå³æ”¹å†™è¯¥å¤„èµ„æºçš„éƒ¨åˆ†å†…å®¹ ï¼ˆä¸ PUT ç›¸æ¯”èŠ‚çœå¸¦å®½ï¼‰ DELETE: è¯·æ±‚åˆ é™¤URLä½ç½®å­˜å‚¨çš„èµ„æº requests.request() r = requests.request(string method, string url, **kwargs) method å¯¹åº”ä¸Šæ–‡å…­ç§æ–¹å¼ Optional Arguments: params=kv: å…¶ä¸­ kv æ˜¯ä¸€ä¸ª dict å€¼ï¼Œåœ¨ url åä»£å…¥å‡ ä¸ªå‚æ•°ï¼Œå½¢å¦‚ ?k1=v1&amp;key2=v2&amp;... headers = hd: hd æ˜¯ä¸€ä¸ª dict å€¼ï¼Œå®šåˆ¶è®¿é—®æœåŠ¡å™¨æ—¶çš„ header å­—æ®µï¼Œæœ‰çš„æ—¶å€™ç½‘ç«™ä¼šä¿æŠ¤è‡ªå·±çš„æ•°æ®ä¸å…è®¸çˆ¬è™«è®¿é—®ï¼Œæˆ‘ä»¬æ”¹å˜ headers ä»¥åå°±å¯ä»¥ä¼ªè£…æˆæµè§ˆå™¨ data = dt, json = js: åœ¨ postæˆ–putæ—¶å°† dt æˆ– js ä¼ ç»™æœåŠ¡å™¨ Robots åè®® é€šè¿‡è¿™ä¸ªåè®®å¯¹ç½‘ç»œçˆ¬è™«èƒ½çˆ¬å–çš„ä¸œè¥¿è¿›è¡Œé™åˆ¶ï¼Œä¸€èˆ¬å°±åœ¨ç½‘ç»œçš„æ ¹ç›®å½•url/robots.txt ä¸‹ï¼Œä¸€ä¸ªä¾‹å­æ˜¯äº¬ä¸œçš„åè®® å¦‚æœä½ çš„çˆ¬è™«é€Ÿåº¦éå¸¸æ…¢ï¼Œè®¿é—®æ¬¡æ•°å¾ˆå°‘ï¼Œè®¿é—®é‡ä¸å¤§ï¼ˆè¿‘ä¼¼äººç±»è¡Œä¸ºï¼‰ï¼ŒåŸåˆ™ä¸Šå¯ä»¥ä¸éµå®ˆ robots åè®® æå– BeautifulSoup çš„åŸºæœ¬å…ƒç´  from bs4 import BeautifulSoup s = BeautifulSoup(r.text, \"html.parser\") returns the r.text restructured as html type. s.tag: æ ‡ç­¾ï¼Œæœ€åŸºæœ¬çš„ä¿¡æ¯ç»„æˆå•å…ƒï¼Œå¯¹åº” html ä¸­çš„ä¸€å¯¹å°–æ‹¬å·ï¼Œä¸‹æ–‡ä¸­ t = s.tag t.name: æ ‡ç­¾çš„åå­—ï¼Œæ¯”å¦‚ &lt;p&gt;&lt;/p&gt; çš„åå­—æ˜¯ p t.attrs: æ ‡ç­¾çš„å±æ€§ï¼Œä»¥å­—å…¸å½¢å¼å­˜å‚¨ã€‚&lt;p class=\"...\" id=\"...\"&gt;&lt;/p&gt; t.string: ä¸¤ä¸ªå°–æ‹¬å·é—´çš„å­—ç¬¦å†…å®¹ï¼Œå³&lt;p&gt;...&lt;/p&gt; ä¸­çš„ ... ä½¿ç”¨ BeautifulSoup éå† HTML h = s.head è¿”å› soup ä¸­çš„ç¬¬ä¸€ä¸ª head æ ‡ç­¾ BautifulSoup çš„æ¯ä¸ªç±»å‹éƒ½å¸¦æœ‰ pretify() å‡½æ•°ï¼Œä¼˜åŒ–æ‰“å°æ•ˆæœ: h.prettify(), s.prettify(), â€¦ ä¸‹è¡Œéå† h.contents: è¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«æ­¤ tag ä¸‹çš„æ‰€æœ‰å„¿å­èŠ‚ç‚¹ h.children: è¿”å›ä¸€ä¸ªæ‰€æœ‰å„¿å­èŠ‚ç‚¹çš„ iterator, å³å¯ä»¥ä½¿ç”¨ for c in h.children: ... éå†å„¿å­èŠ‚ç‚¹ h.descendant: è¿”å›æ‰€æœ‰å­å­™èŠ‚ç‚¹çš„ iterator ä¸Šè¡Œéå† h.parent: è¿”å› h çš„çˆ¶äº²æ ‡ç­¾ h.parents: è¿”å› h çš„ ascendant çš„ iteratorï¼Œå³ä¸€ç›´åˆ°æ ¹èŠ‚ç‚¹çš„æ‰€æœ‰èŠ‚ç‚¹ï¼Œç”¨æ¥å¾ªç¯éå† ascendant å¹³è¡Œéå† æ³¨æ„æ ‘ä¸­å¯èƒ½å­˜åœ¨ NavigableString, Tag, Comment ç§ç§ç±»å‹ï¼Œæˆ‘ä»¬éœ€è¦è¿›è¡Œåˆ¤æ–­ï¼Œä¸èƒ½å‡è®¾å¹³è¡Œéå†çš„ä¸‹ä¸€ä¸ªç»å¯¹æ˜¯ tag next_sibling: è¿”å›æŒ‰ç…§HTMLæ–‡æœ¬é¡ºåºçš„ä¸‹ä¸€ä¸ªå¹³è¡ŒèŠ‚ç‚¹æ ‡ç­¾ previous_sibling: è¿”å›æŒ‰ç…§HTMLæ–‡æœ¬é¡ºåºçš„ä¸Šä¸€ä¸ªå¹³è¡ŒèŠ‚ç‚¹æ ‡ç­¾ next_siblings: è¿”å›æŒ‰ç…§HTMLæ–‡æœ¬é¡ºåºçš„åç»­æ‰€æœ‰å¹³è¡ŒèŠ‚ç‚¹æ ‡ç­¾çš„ iterator previous_siblings: è¿”å›æŒ‰ç…§HTMLæ–‡æœ¬é¡ºåºçš„å‰ç»­æ‰€æœ‰å¹³è¡ŒèŠ‚ç‚¹æ ‡ç­¾çš„ iterator ä¿¡æ¯æ ‡è®°çš„å½¢å¼ XML (Extensible Markup Language): é€šè¿‡æ ‡ç­¾è¡¨è¾¾æ‰€æœ‰ä¿¡æ¯ï¼›å¯æ‰©å±•æ€§å¥½ï¼Œä½†æ¯”è¾ƒç¹çï¼›ç”¨äºäº’è”ç½‘ä¸Šçš„ä¿¡æ¯äº¤äº’å’Œè¡¨è¾¾ ç”¨ä¸€å¯¹æ ‡ç­¾è¡¨è¾¾å…¶ä¸­çš„ä¿¡æ¯&lt;tag&gt; ... &lt;/tag&gt;ï¼Œå¦‚æœæ²¡æœ‰å†…å®¹ï¼Œåˆ™åªç”¨ä¸€ä¸ªæ ‡ç­¾ï¼ˆå³ä¸€å¯¹å°–æ‹¬å·ï¼‰æ¥è¡¨è¾¾&lt;tag/&gt;. JSON (JavaScript Object Notation): æœ‰ç±»å‹çš„é”®å€¼å¯¹ï¼›é€‚åˆç¨‹åºå¤„ç†ç›´æ¥ä½¿ç”¨ï¼›ç”¨äºäº‘ç«¯å’Œå®¢æˆ·ç«¯çš„é€šä¿¡ï¼Œä¸€èˆ¬åœ¨æ¥å£å¤„ä½¿ç”¨ YAML (YAML Ainâ€™t Markup Language): æ— ç±»å‹çš„é”®å€¼å¯¹ï¼›æ–‡æœ¬ä¿¡æ¯æ¯”ä¾‹æœ€é«˜ï¼Œå¯è¯»æ€§é«˜ï¼›ç”¨äºç³»ç»Ÿé…ç½®æ–‡ä»¶ä¸­ ä½¿ç”¨ç¼©è¿›è¡¨è¾¾æ‰€å±å…³ç³» 123name : oldName: å»¶å®‰è‡ªç„¶ç§‘å­¦é™¢ newName: åŒ—äº¬ç†å·¥å¤§å­¦ - è¡¨ç¤ºå¹¶åˆ—å…³ç³» 123name: -å»¶å®‰è‡ªç„¶ç§‘å­¦é™¢-åŒ—äº¬ç†å·¥å¤§å­¦ | è¡¨è¾¾æ•´å—æ•°æ®ï¼ˆå¯ä»¥è·¨è¶Šå¤šè¡Œï¼‰ï¼Œ# è¡¨è¾¾æ³¨é‡Š 12text: | #å­¦æ ¡ä»‹ç»åŒ—äº¬ç†å·¥å¤§å­¦å¤©ä¸‹ç¬¬ä¸€bulabulabula ä½¿ç”¨ BeautifulSoup æå–ä¿¡æ¯ æˆ‘ä»¬ä½¿ç”¨find_all æ¥æå–HTMLé¡µé¢ä¸­çš„ä¿¡æ¯ï¼š s.find_all(name, attrs, recursive, string, ...) è¿”å›ä¸€ä¸ªå­˜å‚¨ç€æŸ¥è¯¢ç»“æœçš„åˆ—è¡¨ name: å¯¹æ ‡ç­¾åç§°çš„æ£€ç´¢å­—ç¬¦ä¸² å¯ä»¥æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼š å¯»æ‰¾æ‰€æœ‰ a æ ‡ç­¾ s.find_all(\"a\") ä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªåŒ…å«å­—ç¬¦ä¸²çš„åˆ—è¡¨ï¼šå¯»æ‰¾æ‰€æœ‰ a æ ‡ç­¾å’Œ b æ ‡ç­¾ s.find_all([\"a\",\"b\"]) å¯ä»¥æ˜¯ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ï¼šå¯»æ‰¾æ‰€æœ‰åå­—ä¸­åŒ…å« b çš„æ ‡ç­¾s.find_all(re.compile(\"b\")) ä¼šè¿”å› b æ ‡ç­¾å’Œ body æ ‡ç­¾ attrs: å¯¹æ ‡ç­¾å±æ€§å€¼çš„æ£€ç´¢å­—ç¬¦ä¸² æŸ¥æ‰¾åŒ…å«æŸä¸€å±æ€§çš„æ ‡ç­¾ï¼šs.find_all(\"p\", \"course\") è¿”å›æ‰€æœ‰å¸¦æœ‰ course è¿™ä¸ª attribute çš„ p tag æŸ¥æ‰¾åŒ…å«æŸä¸€å±æ€§ç­‰äºæŒ‡å®šå€¼çš„æ ‡ç­¾ï¼šs.find_all(id = \"link1\") è¿”å› [&lt;a class=\"py1\" href=\"http://www.icourse163.org/course/BIT-268001\" id=\"link1\"&gt;Basic Python&lt;/a&gt;] recursive: è¡¨ç¤ºæ˜¯å¦å¯¹å­å­™å…¨éƒ¨æ£€ç´¢çš„å¸ƒå°”å€¼ï¼Œé»˜è®¤True string: å¯¹æ ‡ç­¾ä¸­çš„å­—ç¬¦ä¸²è¿›è¡Œæœç´¢ï¼šs.find_all(string = re.compile(\"python\")) è¿”å›æ‰€æœ‰åŒ…å«æœ‰ python çš„æ ‡ç­¾å†…å®¹ ç®€æ˜“è¡¨ç¤ºæ–¹æ³•ï¼š&lt;tag&gt;(..)ç­‰ä»·äº &lt;tag&gt;.find_all(..); soup(..) ç­‰ä»·äº soup.find_all(..) å®æˆ˜ å¦‚æœæˆ‘ä»¬ä¸éœ€è¦é€šè¿‡åˆ†æé¡µé¢æ¶æ„ï¼Œåªæ˜¯é€šè¿‡åœ¨ html æ–‡ä»¶ä¸­æœç´¢å°±å¯ä»¥å¾—åˆ°æƒ³è¦çš„ä¿¡æ¯çš„è¯ï¼Œè¿™æ— ç–‘æ˜¯æœ€ç®€å•çš„ã€‚è¿™ç§æƒ…å†µå¯èƒ½å‘ç”Ÿäºä¿¡æ¯å­˜åœ¨é”®å€¼å¯¹ä¸­ï¼Œå¦‚æ­¤æœç´¢å˜å¾—å¾ˆæ–¹ä¾¿ raw string: r'[1-9]\\d&#123;5&#125; è½¬ä¹‰ç¬¦ escape character ä¸è½¬ä¹‰ï¼Œè¡¨è¾¾å…¶åœ¨å­—ç¬¦ä¸²ä¸­çš„åŸæ„ string: '[1-9]\\\\d&#123;5&#125;' è½¬ä¹‰ç¬¦ escape character æœ‰ Re åº“çš„åŸºæœ¬ä½¿ç”¨ re.search(pattern, string): åœ¨ string ä¸­æœç´¢åŒ¹é… pattern çš„ç¬¬ä¸€ä¸ªä½ç½®ï¼Œè¿”å› match ç±»å‹ re.match(p, s): ä» s çš„å¼€å§‹ä½ç½®èµ·åŒ¹é… pï¼Œè¿”å› match ç±»å‹ re.findall(p, s) : æœç´¢ s ï¼Œä»¥åˆ—è¡¨ç±»å‹è¿”å›å…¨éƒ¨ä¸ p åŒ¹é…çš„å­ä¸² re.split(p, s, maxsplit=n): å°† p æŒ‰ç…§ s åŒ¹é…ç»“æœè¿›è¡Œåˆ†å‰²ï¼Œå°†åŒ¹é…çš„éƒ¨åˆ†å»æ‰ï¼Œå…¶ä»–éƒ¨åˆ†åˆ†å‰²æˆå­ä¸²å­˜åœ¨åˆ—è¡¨ä¸­ï¼›å¯é€‰å‚æ•° maxsplit æœ€å¤šåˆ†ä¸º n ä¸ªéƒ¨åˆ† re.sub(p, repl, s, count=n): å°† n ä¸ª s ä¸­ä¸ p åŒ¹é…çš„å­ä¸²æ›¿æ¢æˆ replï¼Œnå¦‚æœæœªå®šä¹‰åˆ™é»˜è®¤æ›¿æ¢æ‰€æœ‰ é’ˆå¯¹å¯¹äºåŒä¸€æ­£åˆ™è¡¨è¾¾å¼çš„å¤šæ¬¡æ“ä½œï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ç¼–è¯‘ä¸ºä¸€ä¸ª pattern ç±»å‹ï¼Œä¹‹åå°±å¯ä»¥å¤šæ¬¡ä½¿ç”¨é’ˆå¯¹è¿™ä¸ªç±»å‹çš„ä»¥ä¸Šå‡½æ•°æ“ä½œ regex = re.compile(pattern) regex.search(s), regex.match(s), ... Re åº“çš„ match å¯¹è±¡ match å¯¹è±¡å°±æ˜¯ä¸€æ¬¡åŒ¹é…çš„ç»“æœï¼ŒåŒ…å«è®¸å¤šå…³äºè¿™æ¬¡åŒ¹é…çš„ä¿¡æ¯ .string: å¾…åŒ¹é…çš„æ–‡æœ¬ .re: åŒ¹é…æ—¶ä½¿ç”¨çš„patterå¯¹è±¡ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰ .pos: æ­£åˆ™è¡¨è¾¾å¼æœç´¢æ–‡æœ¬çš„å¼€å§‹ä½ç½® ï¼ˆå³åœ¨ string ä¸­æœç´¢çš„èŒƒå›´ï¼‰ .endpos: æ­£åˆ™è¡¨è¾¾å¼æœç´¢æ–‡æœ¬çš„ç»“æŸä½ç½® .group(0): è·å¾—åŒ¹é…åçš„å­—ç¬¦ä¸² .start(): åŒ¹é…ç»“æœåœ¨åŸå§‹å­—ç¬¦ä¸²çš„å¼€å§‹ä½ç½® .end(): åŒ¹é…ç»“æœåœ¨åŸå§‹å­—ç¬¦ä¸²çš„ç»“æŸä½ç½® .span(): è¿”å›(.start(), .end()) å…¶ä»–æŠ€å·§ ä¸­æ–‡çš„æ‰“å°ä¸å¯¹é½ æˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨ string.format() å‡½æ•°æ ¼å¼æˆ‘ä»¬çš„è¾“å‡ºï¼Œç”¨æ³•ï¼štheFormat.format(parameter1, parameter2, ...) formatter string ä¸­æœ‰å‡ ä¸ªå‚æ•°ï¼šï¼ˆæ³¨æ„å¿…é¡»ä¸¥æ ¼éµå®ˆè¿™ä¸ªé¡ºåºï¼‰ &#123;n&#125; è¡¨ç¤ºä½¿ç”¨ç¬¬ n ä¸ªå‚æ•°å¡«å……è¿™ä¸ªéƒ¨åˆ†ï¼Œä¸æŒ‡å®šåˆ™æŒ‰ç…§ä¸å‚æ•°çš„å¯¹åº”é¡ºåºæ¥ &#123;:p&#125; ä½¿ç”¨å‚æ•° p å¡«å……ï¼Œä¸æŒ‡å®šåˆ™é»˜è®¤ä¸ºç©ºæ ¼ &#123;:&lt;n&#125; &#123;:^n&#125; &#123;:&gt;n&#125; å·¦å¯¹é½ï¼Œå±…ä¸­å¯¹é½ï¼Œå³å¯¹é½ï¼Œå®½åº¦ä¸º n &#123;:,&#125; åœ¨åƒä½ç”¨é€—å·åˆ†éš”æ•°å­— &#123;:.n&#125; æµ®ç‚¹æ•°ä¿ç•™å°æ•°ç‚¹å n ä½ &#123;:&lt;type&gt;&#125; å¯ä»¥æ˜¯ d ä»£è¡¨æ•´å½¢ï¼Œf ä»£è¡¨æµ®ç‚¹å‹ï¼Œe ä»£è¡¨ç§‘å­¦è®¡æ•°æ³•æµ®ç‚¹å‹ï¼Œ% ä»£è¡¨ç™¾åˆ†å·æµ®ç‚¹å‹ \"&#123;0:^10&#125;\\t&#123;1:&#123;2&#125;^10&#125;\".format(\"æ’å\",\"å­¦æ ¡åç§°\",chr(12288)) æ‰“å° ç¬¬é›¶ä¸ªå‚æ•°(å±…ä¸­å¯¹é½å®½åº¦ä¸º10)ï¼Œæ‰“å° tabï¼Œæ‰“å°ç¬¬ä¸€ä¸ªå‚æ•°(ç”¨ç¬¬2ä¸ªå‚æ•°è¿›è¡Œå±…ä¸­å¡«å……å®½åº¦ä¸º10) ç¬¬äºŒä¸ªå‚æ•°æ˜¯ä¸­æ–‡ \"&#123;1:x&lt;20,.3f&#125;\".format(0,21031295.21413) æ‰“å° â€˜21,031,295.214xxxxxxâ€™ åœ¨ UTF-8 ç¼–ç ä¸­ï¼Œå¯¹åº”çš„ä¸­æ–‡ç©ºæ ¼å­—ç¬¦æ˜¯ chr(12288).","categories":[],"tags":[]},{"title":"CS4820 åŠ Algorithm Design ä¸€èˆ¬æ€§å†…å®¹æ€»ç»“","slug":"2020-10-13-Algorithm-Design-åŠ-CS4820-ä¸€èˆ¬æ€§å†…å®¹æ€»ç»“","date":"2020-10-13T04:00:00.000Z","updated":"2022-06-08T20:13:42.000Z","comments":true,"path":"2020-10-13-Algorithm-Design-åŠ-CS4820-ä¸€èˆ¬æ€§å†…å®¹æ€»ç»“/","permalink":"https://yao-lirong.github.io/blog/2020-10-13-Algorithm-Design-%E5%8F%8A-CS4820-%E4%B8%80%E8%88%AC%E6%80%A7%E5%86%85%E5%AE%B9%E6%80%BB%E7%BB%93/","excerpt":"CS 4820 develops techniques used in the design and analysis of algorithms, with an emphasis on problems arising in computing applications. Example applications are drawn from systems and networks, artificial intelligence, computer vision, data mining, and computational biology. This course covers four major algorithm design techniques (greedy algorithms, divide and conquer, dynamic programming, and network flow), computability theory focusing on undecidability, computational complexity focusing on NP-completeness, and algorithmic techniques for intractable problems, including identification of structured special cases, approximation algorithms, and randomization.","text":"CS 4820 develops techniques used in the design and analysis of algorithms, with an emphasis on problems arising in computing applications. Example applications are drawn from systems and networks, artificial intelligence, computer vision, data mining, and computational biology. This course covers four major algorithm design techniques (greedy algorithms, divide and conquer, dynamic programming, and network flow), computability theory focusing on undecidability, computational complexity focusing on NP-completeness, and algorithmic techniques for intractable problems, including identification of structured special cases, approximation algorithms, and randomization. Greedy Algorithm Greedy Stays Ahead Greedy is at least as good as the optimal solution in each step Exchange Argument Take any optimal solution, we can make it exactly the same as our greedy solution without having the optimal solution produce a worse result. There is some â€œstructureâ€ unique to this problem. All solutions have this â€œstructureâ€ give the same number of lateness. Our greedy solution has this â€œstructureâ€ We can exchange any optimal solution to have this â€œstructureâ€ without making this solution worse Divide and Conquer Master theorem says that for an algorithm with running time $T(n) = aT(\\frac{n}{b}) + f(n)$. f(n) is some polynomial of n, so we have $T(n) = aT(\\frac{n}{b}) + O(n^c)$. a = bc: T(n) = O(nc logn) - A balance between constant work at each level and number of subproblems at each level. a &lt; bc: T(n) = O(nc) - Time dominated by the constant work we do at upper levels: take a = 1 as an extreme example, all of the time will be spent on top level. a &gt; bc: T(n) = O(nlogba) - Time dominated by each subproblems we have as the recursion go deeper. A lot of branches of subproblems will be generated. Network Flow Max flow é—®é¢˜è½¬æ¢ä¸º Min Cut é—®é¢˜ï¼ŒMin Cut é—®é¢˜æ°¸è¿œå¯ä»¥ç»™è‡ªå·±ä¸æƒ³è¦çš„è¾¹ infinite capacity æ¥å°†å®ƒæ’é™¤åœ¨ min cut ä¹‹å¤–ã€‚ effectively infinite: ä»»ä½•ä¸€ä¸ªæ— æ³•è¾¾åˆ°çš„æ•°ï¼Œéƒ½å¯ä»¥è§†ä½œ infiniteï¼Œæ¯”å¦‚ infinite capacity å¯ä»¥æ˜¯ä¸€ä¸ªå·²çŸ¥çš„ cut å€¼+1 (max flow å¿…ç„¶å°äºä»»æ„ä¸€ä¸ª cutï¼Œæ‰€ä»¥æ²¡æœ‰ä»»ä½•ä¸€ä¸ª flow å¯ä»¥è¾¾åˆ° cut + 1) NP Proving Reduction Show that your reduction Ïƒ takes polynomial time. Show that x is a solution to the problem you are reducing from if and only if Ïƒ(x) is a solution to the problem you are trying to show is NP-hard. You need to show the implication in both directions. Proving NP, NP-Hard, NP-Completeness NP: prove you can verify a solution in polynomial time NP-hard: prove some known NP-Hard (or NP-complete) problem can be reduced to A in polynomial time (æ³¨æ„æ˜¯åˆ«çš„å·²çŸ¥é—®é¢˜å¯ä»¥è¢«è½¬æ¢æˆæˆ‘ä»¬è¦è¯æ˜çš„é—®é¢˜) NP-completeness: it is NP-hard and it is NP Important NP-Complete Problem satisfiability problems: Boolean satisfiability, CNFSAT (conjunctive normal form satisfiability) , 3CNFSAT (aka 3SAT) graph problems: Clique, Independent Set, Vertex Cover, Dominating Set, Colorability, Planar 3-colorability covering problems: Set Cover, 3-dimensional matching (3DM) tour problems: directed and undirected Hamiltonian circuit (HC), Traveling Salesperson (TSP) numerical problems: Subset Sum (SS), Partition, Knapsack, Bin Packing Tips If a problem asks you to decide if there exists a set of at least k objects satisfying some property, try reducing from another problem that involves picking at least k objects, e.g. Independent Set or Clique. Similarly, if a problem asks you to decide if there exists a set of at most k objects satisfying some property, try reducing from another problem that involves picking at most k objects, e.g. Vertex Cover or Set Cover. When reducing Independent Set / Vertex Cover to another graph-like problem. We find out adding a node representing edges is very useful. (Dominating Set, practicefsol 4, fakesol7 3) When a problem does not easily fit into either of the general categories listed above, usually the best thing to try first is 3CNFSAT. When do the reduction from A to B, try to reduce A to a special case of B. (hw5 P3 Clique -&gt; Submatrix Domination, hw6 P2 Vertex Cover -&gt; Dominating Set) Turing Machine Decidability Give a total Turing Machine (one that always halts) to accept any â€œyesâ€ instance and reject any â€œnoâ€ instance Undecidability Prove by Diagonalization Prove by Reduction: we usually reduce our problem to Halting Problem or the complement of it (Non-Halting Problem aka. Looping Problem). Note: Ïƒ in this case has to be computable instead of polynomial-time To prove some problem is undecidable within a certain time bound, use clocked diagonalization. Crucial Facts Minimum Spanning Tree cut property: Let A and B partitions vertices V, if e is the minimum edge connecting A and B, e must be in every minimum spanning tree. cycle property: Let C be any cycle in G, e be the maximum cost edge on that cycle, e is not in any minimum spanning tree Proof Techniques Loop Invariant and Recursion: ä¸€ä¸ªå¾ˆå¥½çš„ä¾‹å­æ˜¯ T7.42 çš„è¯æ˜ recursion = induction loop invariant = induction hypothesis termination condition = basis computation = logic â€“ Dexter Kozen","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"INFO1998 Intro to Machine Learning (sklearn, pandas)","slug":"2020-10-02-INFO1998-Intro-to-Machine-Learning","date":"2020-10-02T04:00:00.000Z","updated":"2022-06-08T19:30:54.000Z","comments":true,"path":"2020-10-02-INFO1998-Intro-to-Machine-Learning/","permalink":"https://yao-lirong.github.io/blog/2020-10-02-INFO1998-Intro-to-Machine-Learning/","excerpt":"The goal of this course is to provide you with a high-level exposure to a wide range of Data Science techniques and Machine Learning models. From the basics of getting your Jupyter environment setup, to manipulating and visualizing data, to building supervised and unsupervised models, this class aims to give you the base intuition and skillset to continue developing and working on ML projects. We hope you exit the course with an understanding of how models and optimization techniques work, as well as have the confidence and tools to solve future problems on your own.","text":"The goal of this course is to provide you with a high-level exposure to a wide range of Data Science techniques and Machine Learning models. From the basics of getting your Jupyter environment setup, to manipulating and visualizing data, to building supervised and unsupervised models, this class aims to give you the base intuition and skillset to continue developing and working on ML projects. We hope you exit the course with an understanding of how models and optimization techniques work, as well as have the confidence and tools to solve future problems on your own. Lec2 Data Manipulation Introduction to Pandas Series: one dimensional array DataFrame: 2-D table Filtering DataFrames: loc Cleaning-Up DataFrames: df.dropna(), df[df['Open'].notnull()] (These two methods both return a new DataFrame instead of modifying the existed one) View DataFrames: head, tail, â€¦ Summary Statistics: mean, median, â€¦ describe Dealing with missing data Fill in some random info of our choice: 12#if we there is no record about which cabin he is in, we assume he is on the Top Deckdf[&#x27;Cabin&#x27;]=df[&#x27;Cabin&#x27;].fillna(&#x27;Top Deck&#x27;) Using summary statistics: fill missing entries with median or mean works well with small set Use regression and clustering: will be covered later Lec3 Data Visualization Types of Graphs Heatmap Correlation Plots Coloring Graphs plt.scatter(Longitude, Latitude, c=Temp.values.ravel(),cmap=plt.cm.OrRd) color a scattered plot based on values of Temp with color scheme cm.OrRd. Find more color schemes from matplotlib manual. Lec4 Linear Regression Preparing Data 12345678910from sklearn.linear_model import LinearRegressionfrom sklearn.model_selection import train_test_split# X must be a table (in case there are multiple x in y = a1*x1 + a2*x2 + ... + k)X = data[[&#x27;cost&#x27;,&#x27;compl_4&#x27;]] # Y must be one columnY = data[&#x27;median_earnings&#x27;] from sklearn.model_selection import train_test_split# test is 20% of all datax_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2) Predicting and Fitting 12345678# creates Linear Regression model LR = LinearRegression()# note LR is an object by calling fit, we set all of its coefficientsLR.fit(x_train, y_train)# predict() returns the predicted valuey_predicted = LR.predict(x_test)# score(x,y&#x27;) first computes the predicted value y based on x and our model, then compare it with y&#x27;score = LR.score(x_test,y_test) Describing the Model 12345678# Gives a comprehensive view of Y = a1*x1 + a2*x2 + ... + kLR?# coefficients of x (a1, a2, ...)LR.coef_# intercept kLR.intercept_ Lec5 Measuring Modelâ€™s Accuracy When determining accuracy, usually want to compare our model to a baseline. Therefore, instead of comparing our modelâ€™s prediction to each specific y value, we compare it with the mean y value. 123456from sklearn.metrics import mean_squared_errorcelcius_MSE = mean_squared_error(y_test, celcius_predictions)test_goal_mean = y_test.mean()baseline = np.full((len(celcius_predictions),), test_goal_mean)baseline_MSE = mean_squared_error(baseline, celcius_predictions) overfitting: too specific to the data given, doesnâ€™t predict any other data underfitting: no matter what data you use to train this model, it gives the same curve, so it doesnâ€™t have prediction power either because it doesnâ€™t show any pattern of the data. Lec6 Classifiers Linear regression is used to predict the value of a continuous variable. Classifiers are used to predict categorical or binary variables. KNN 12345678from sklearn.model_selection import train_test_splitfrom sklearn.neighbors import KNeighborsClassifierx_train, x_test, y_train, y_test = train_test_split(X,Y, test_size=0.2)k = 10model = KNeighborsClassifier(k) # specify k nearest elementsmodel.fit(x_train,y_train)predictions = model.predict(x_test) Lec7 Other Supervised Learning Models Decision Trees 123from sklearn import treefrom sklearn.tree import DecisionTreeClassifiermodel = tree.DecisionTreeClassifier(max_depth=5) How to reduce overfitting? Reduce levels of trees Train multiple decision trees (maybe one for each training data) and take its average as final result Logistic Regression Value always between 0 and 1. Accept if value higher than threshold, reject if lower. K-fold Cross Validation Rather than doing test-train split only once, we do it k times: First separate our sample into k pieces and each time we take one of them as test set, the others as training set. Use from sklearn.model_selection import KFold to achieve this. Calculate a score for each of the split and take its average as the final score. This score is usually closer to real errors. 12345678910111213141516171819202122from sklearn.model_selection import KFoldfrom sklearn.metrics import mean_squared_error, accuracy_scoreincX = inc_data[[&#x27;education.num&#x27;]]incY = inc_data[&#x27;income&#x27;]kf = KFold(n_splits = 5)accuracy = 0for train_index, test_index in kf.split(incX): X_train = incX.iloc[train_index] Y_train = incY.iloc[train_index] X_test = incX.iloc[test_index] Y_test = incY.iloc[test_index] # best_depth æ˜¯æˆ‘ä»¬å‰ä¸€é¢˜æ‰¾åˆ°çš„ä½¿åˆ†æœ€é«˜çš„ depth level of decision tree model = tree.DecisionTreeClassifier (max_depth = best_depth) model.fit(X_train, Y_train) pred_test = model.predict(X_test) accuracy += accuracy_score(Y_test, pred_test) accuracy /= 5print(accuracy) Lec9 Unsupervised Learning Supervised Learning: The desired solution (target) is also included in the dataset Unsupervised Learning: The training data is unlabeled and algorithm tries to learn by itself Hierarchical Clustering Hierarchical clustering groups observations into multiple levels of sets; the top-level set includes all of the data, and the bottom-level sets contain individual observations. The levels in between contain sets of observations with similar features. 1234567891011from sklearn.preprocessing import StandardScalerfrom scipy.cluster.hierarchy import dendrogram, linkagefrom matplotlib import pyplot as plt# Standardize features by removing the mean and scaling to unit variancedata = StandardScaler().fit_transform(data)# build our model from dataclust = linkage(data) # draw the dendrogram visulizationdendrogram(clust)plt.show() K-Means Clustering We want to cluster the data into k groups. We first randomly choose k points in this dataset. Then we assign other data points to the group they are closest to. After assigning all data points to some group, we recompute the center of each group by taking the means of all points in that group. Repeat this process until no points change group assignment after one iteration. 1234from sklearn import clusterk = 3kmeans = cluster.KMeans(n_clusters = k) #cluster into k groupskmeans.fit(data)","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"Add \"Open with Windows Terminal\" to Right-Click Menu","slug":"2020-09-29-Add-Open-with-Windows-Terminalto-Right-Click-Menu","date":"2020-09-29T04:00:00.000Z","updated":"2022-06-08T19:34:22.000Z","comments":true,"path":"2020-09-29-Add-Open-with-Windows-Terminalto-Right-Click-Menu/","permalink":"https://yao-lirong.github.io/blog/2020-09-29-Add-Open-with-Windows-Terminalto-Right-Click-Menu/","excerpt":"Windows Terminal Preview now provides native support of this feature.","text":"Windows Terminal Preview now provides native support of this feature. Download the icon here Move the icon to directory C:\\Users\\&lt;your username&gt;\\AppData\\Local\\WindowsTerminal Create a .reg file and run it. 123456789Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\wt]@=&quot;Open with Windows Terminal&quot;&quot;Icon&quot;=&quot;C:\\\\Users\\\\&lt;your username&gt;\\\\AppData\\\\Local\\\\WindowsTerminal\\\\terminal.ico&quot;[HKEY_CLASSES_ROOT\\Directory\\Background\\shell\\wt\\command]@=&quot;C:\\\\Users\\\\harmo\\\\&lt;your username&gt;\\\\Local\\\\Microsoft\\\\WindowsApps\\\\wt.exe&quot; In Windows Terminalâ€™s settings, Add \"startingDirectory\" : \".\" into defaults list: 1234&quot;defaults&quot;: &#123; &quot;startingDirectory&quot; : &quot;.&quot; &#125;, Reference How to Add Open Windows Terminal Here Option to Right-click Menu Add â€œopen Windows terminal hereâ€ to right-click context menu å°†â€åœ¨æ­¤å¤„å¯åŠ¨Windows Terminalâ€æ·»åŠ åˆ°å³é”®èœå•","categories":[],"tags":[{"name":"Logistics","slug":"Logistics","permalink":"https://yao-lirong.github.io/blog/tags/Logistics/"}]},{"title":"CS2024 C++ Programming","slug":"2020-09-07-CS2024-C++-Programming","date":"2020-09-07T04:00:00.000Z","updated":"2022-06-08T19:30:10.000Z","comments":true,"path":"2020-09-07-CS2024-C++-Programming/","permalink":"https://yao-lirong.github.io/blog/2020-09-07-CS2024-C++-Programming/","excerpt":"The goal of CS2024 is to teach as much of the C++ language as possible with an eye towards your being able to use it effectively in future classes that may depend on it and/or in a professional setting. C++ is ever changing with new standards released every three years. We look to strike a balance between making sure you thoroughly understand â€œhistoricâ€ C++ as well as introducing you to new features enabled in the language in the past decade.","text":"The goal of CS2024 is to teach as much of the C++ language as possible with an eye towards your being able to use it effectively in future classes that may depend on it and/or in a professional setting. C++ is ever changing with new standards released every three years. We look to strike a balance between making sure you thoroughly understand â€œhistoricâ€ C++ as well as introducing you to new features enabled in the language in the past decade. Lec01 Introduction Explaining our First Program #include &lt;iostream&gt; Tells the compiler that we would like to load definitions from a header file named â€œiostreamâ€. The # (pound sign) indicates this is a preprocessor directive, it gets dealt with BEFORE your code is compiled std::cout &lt;&lt; â€œHello World!â€ &lt;&lt; std::endl; &lt;&lt; is an operator that directs content from the right to the left. In this case, we direct the string â€œHello Worldâ€ to std::cout, which is the console Compiling C++ Windows: use Visual Studio Linux: g++ -std=c++11 -lstdc++ -o demo1 demo1.cpp: -o specifies the name of the compiled file Compiler takes the text of the source code and converts it into a binary object so that it can execute it a bit more efficiently. Lec02 Input/Output and Operators Input and Output &gt;&gt; stream extraction operator std::cin &gt;&gt; k take a value from cin, which is the input stream keyboard, and assign it to k getline(cin,str): cin uses space as delimiter so it wonâ€™t read in a whole line. Use this to read a full line Using using is similar to import in java, so that you donâ€™t have to use the full name of a function when calling it. 1234567using std::cout;using std::endl;int main(int argc, char *argv[]) &#123; // No longer need to use the std:: prefix cout &lt;&lt; â€œHello Worldâ€ &lt;&lt; endl;&#125; Lec03 Introduction to Classes Struct C-Style structure definition: (Define a structure called Course, which has three fields ) 12345typedef struct &#123; string name; string instructor; int numStudents;&#125; Course; Classes Variables defined inside that class are called member variables. Functions defined inside the class are called member functions Public vs. Private public and private keywords can appear as many times as you want in the class definition. 1234567891011class Course &#123;public: // These can be seen outside the class // Define member functions int getStudentCount() &#123; return numStudents; &#125;private: // These can be seen inside the class only // Define member variables string name; string instructor; int numStudents;&#125; Declaration and Definition of Member Functions You donâ€™t have to define the functions where they are declared. Instead, you can define them outside of the class declaration. When you define them outside of the class declaration, you can still access the member variables inside that class. Thatâ€™s because you are telling the compiler that this is a member function. 12345678910111213141516class Course &#123;public: // These can be seen outside the class // Define member functions int getStudentCount(); void setStudentCount(int count); private: ...&#125;string Course::getCourseName()&#123;return name;&#125;int Course::getStudentCount()&#123;return numStudents;&#125; You usually want to define your getter and setter functions inside class definition. When other functions you are trying to define are too big, we usually define them outside the class definition and usually in a separate file. So we declare the functions in header file **.h and define them in another file **.cpp 123456789101112/* &lt;Courses.h&gt; */class Course &#123;private: void complexLogic();&#125;/* &lt;Courses.cpp&gt; */#incldue &quot;Courses.h&quot;void Courses::complexLogic()&#123; ...&#125;; Constructors Constructors have to have the same name as the class. Constructors have no return type. You can define Constructors outside of class definition too. Constructors are called when you declare an instance of that type: MyClass instance. Note defining a pointer of that class without allocating memory to that pointer MyClass *p will not call the constructor, but declaring a pointer and allocating memory will call the constructor, because thatâ€™s the real time an instance is created MyClass *p = new MyClass(). Lec5 Functions I Enum If you donâ€™t assign values to the ones following the first, they will all have value of previous increment 1. 12345678// Define error codesenum RonsError &#123; cNoError = 0, // Values are optional, default is 0 cBadArg, // If a value is not present, cBadResult, // assign previous value + 1 cUnknownErr&#125;; In C++11, we can use the class keyword to define sort of a â€œnamespaceâ€ for the enum. 12345678enum class Months &#123; JAN = 1, FEB, MAR, APR, MAY, JUN, JUL, AUG, SEP, OCT, NOV, DEC&#125;if ((month == Months::DEC) || (month &lt; Months::MAR)) ...Months get_march()&#123; return Months::MAR;&#125; Function Declaration and Definition Revisited 123456789101112// mymath.h -- header file for math functionslong squareIt(long);// mymath.cpp -- implementation of math functionslong squareIt(long x)&#123; return x * x;&#125;// main.cpp#include â€œmymath.hâ€void main()&#123; cout &lt;&lt; â€œ5 squared is â€œ &lt;&lt; squareIt(5) &lt;&lt; endl;&#125; You should never include a â€œ.c++â€ file in another c++ file. Lec6 Function II Inline Functions 12345inline int performAddition(int x,int y) &#123; return x+y;&#125; Wherever this function is called the compiler has the option of replacing the call with the body of the actual function, instead of creating a memory stack for that function call and etc. The compiler may not do that when itâ€™s a recursive call or that function is really long. Pass By Reference Why and when do you want to use pass by reference? You need to return multiple values. C++ only allows you to return one value. So you send those values as pass by reference parameters You are passing a large structure/class. When passing values, the compiler will make a copy of those structure/class and pass them, which takes up a lot of stack space. In the second case, maybe you donâ€™t want to change anything in the structure, but passing by reference makes such a mistake likely to happen. To fix this, you can declare this passed by value as const, so when you accidentally modify it, you will get a compile-time error. 12345bool isBusy(const BIGDataType &amp;arg1)&#123; if (arg1.busyField = 0) return true; return false;&#125; Default Argument When we declare a function, we can set a default value to its argument. (Donâ€™t set a default value in function definition) 12345678910class Counter &#123; â€¦ void increment(int incrementBy=1); â€¦ &#125;;void Counter::increment(int incrementBy);&#123; mycount += incrementBy;&#125; x.increment(); // increment x by 1 y.increment(2); // increment y by 2 Unary Scope Operator When you have 3 variables with the same name defined in global scope, local scope, and a nested scope inside local scope and you want to access the variable in the global scope inside some scope, you can use the :: before calling this variable. There is no way for you in the nested scope to access the variable with a same name in local scope (parent scope). 123456789int x=1; // in the global scopeint main(int argc, char *argv[]) &#123; int x = 6; // local variable to main() // cannot be accessed in the following nested scope &#123; int x = 5; // local variable in a sub-scope of main() cout &lt;&lt; â€œx is : â€œ &lt;&lt; ::x &lt;&lt; endl; // &quot;x is : 1&quot; &#125;&#125; Lec7 Function III Function Templates 1template &lt;typename a,typename b,â€¦&gt; return_type function_name (formal args) At compilation time the compiler will look at your code and generate a separate function for each type used throughout your code when calling template functions. For example, for this maximum below, when the compiler sees the call to maximum(3,5,8), it uses the function template to automatically generate an overloaded version of maximum() that takes three variables of type int as its arguments. 12345678910template &lt;class T&gt; T maximum(T val1, T val2, T val3)&#123; T maxValue = val1; if (val2 &gt; maxValue) maxValue = val2; if (val3 &gt; maxValue) maxValue = val3; return maxValue;&#125;return maximum(3,5,8); Lec8 Arrays and Vectors Arrays Arrays donâ€™t have boundary checking. 12345678910111213#include &lt;array&gt;// initializationconst int size = 5;array&lt;int,size&gt; myArray;// range based for-loopfor (int item : myArray) cout &lt;&lt; â€œNext item is: â€œ &lt;&lt; item;// sorting and searchingsort(myArray.begin(),myArray.end()); //ascending orderbool found = binary_search(myArray.begin(),myArray.end(),2); Vectors 123456#include&lt;vectors&gt;vector&lt;int&gt; primeVector&#123;2,3,5,7,11,13&#125;; primeVector[6] = 17; //valid syntax but can crash the programprimeVector.at(6) = 17; //involves boundary checking and throw an error Lec9 Pointers Dynamic Allocation 123int *iPtr; // declares a pointer to intiPtr = new int; // &quot;new int&quot; gives a dynamically allocated instance of int // then we assign this space to iPtr Note: in the above example, a memory in the heap is allocated to this pointer iPtr contains one of the following: A pointer to the newly allocated data type (in this case, an int) NULL (if the pointer could not be allocated due to insufficient memory) We should always check whether it is NULL before using a dynamically allocated pointer. We can use delete iPtr to dispose a dynamically allocated pointer. 12345int *iPtr; // iPtr points to some random memoryiPtr = new int; // iPtr points to some memory allocated to it in heap*iPtr = 5; // write 5 to the memory iPtr is allocated todelete iPtr; // release the memory assigned to iPtr / iPtr now no longer points to that memoryreturn 0; Pointers to Already Existing Values Existing values are in stack frame, so when our pointers point to something already existed, they point to something in the stack frame, but remember variables in stack frame can disappear when out of scope. 12345678int main()&#123; int *iPtr; if (true) &#123; int p = 5; iPtr = &amp;p; &#125; cout &lt;&lt; â€œ*iPtr is â€œ &lt;&lt; *iPtr &lt;&lt; endl;&#125; So the danger is you will have to know how long this stack frame will live, or you will lose track of what you are pointing to and end up pointing something totally irrelevant. Common Confusion with * int *p - declaring a pointer: The star is part of the type name, and says that we want a pointer to some other type (in our example, int * is the type of p). r = *p - dereferencing a pointer (RHS): The star is the dereference operator. This assignment gives the variable ra new value, namely the value inside the box that the pointer p points to. *p = r - dereferencing a pointer (LHS): The star is the dereference operator. This assignment changes the value inside the box that p points to be a new value, namely the value of the variable r. Pointer Chaos 12345678910111213141516int *a = 5, *b = 7;// dereference a, get the value stored in the memory a is pointing to,// and write a same value to the memory b is pointing to *b = *a; // let b point to the same address as a is pointing tob = a; // release the memory allocated to a, // also doing that for b since they are pointing at the same thingdelete a; // throw &quot;pointer being freed is not allocated&quot; error// since we already deleted it when we did that for adelete b; Pointers to User-Defined Types When we want to use member member (functions/ variables), we can use one of the following: 123Course *aCourse = new Course;(*aCourse).setStudentCount(45);aCourse-&gt;setStudentCount(45); Passing Pointers as Arguments 1234567int *a = new int;int x = 5;// store 0 in the memory location pointed at by intPtrvoid setToZero(int *intPtr) &#123; *intPtr = 0; &#125; setToZero(a); // pass to it a pointer whose value is some addresssetToZero(&amp;x); // pass the address of some variable to it Const with Pointers Principle of Least Privilege: Any operation you do should only be given the opptunity to happen if it absolutely needs to. Following this principle, we donâ€™t want to give writing privilege to functions doing reading. There are four possibilities between constant/non-constant pointers pointing to constant/non-constant data: 12345678910111213141516171819202122232425262728293031// Non-Constant Pointer, Non-Constant Data// Free for the pointer to point to something else,// Free for the data it is pointing to be written as something elseint *intPtr = new int;// Non-Constnat Pointer, Constant Data// We canâ€™t modify the data pointed at by coursePtr// We CAN set coursePtr to a different valuevoid printAllCourseData(const Course *coursePtr, const int size)&#123; // For this function, maybe we will direct pointer to some other course // once one course&#x27;s info has been printed, // while we don&#x27;t want to change that info // because this is just a reading function&#125;// Constant Pointer, Non-Consant Data// Pointer can only point to a specific memory// The data it is pointing to can be changedvoid setupCourse(Course *const coursePtr)&#123; // For this function, we only want to change information of this course passed in.&#125;// Constant Pointer, Constant Data// We canâ€™t modify the data pointed at by coursePtr// We canâ€™t set coursePtr to a different value eithervoid printCourseData(const Course *const coursePtr)&#123; // We only want to print out the info of this course passed in and do nothing else&#125; Lec10 Classic Arrays and Pointer Arithmetic Classic Array 12int *j[4]; == (int *) j[4]// array of 4 pointersint (*p)[4]; // a pointer to an array of 4 integers Arrays are somewhat pointers. For example, if we have int b[10], b always points to the first element in this array: b == &amp;b[0] Pointer Arithmetic For any array p[n] == *(p+n). In particular, *(p+n) gives the contents of we have after advancing n steps from p. In fact, we also have p[n] == n[p], because our a[m] is just a syntactic sugar for *(a+m) Dynamic Allocation of Arrays 123int a1[8] = new int; // WRONGint *a = new int[8]; // RIGHTdelete [] a; // Must use this, â€delete aâ€ is undefined There are more scope issues when you use arrays as pointers. For example, the following code returns a pointer to something inside current call stack frame. It will disappear when out of the scope. Therefore, the returned pointer from function MakeArray() actually points to something undefined. 123int *MakeArray() &#123; int iArray[50]; return iArray; &#125; The following code behaves differently. Instead of returning a pointer to something in the call stack, it returns something in the heap, which will not disappear after the function finishes execution. 123int *MakeArray(int size) &#123; int *anArray = new int[size]; return anArray; &#125; Passing Arrays as Parameters Since arrays are pointers, you can only pass the real array to a function. There is no concept of passing a copy of that array. These are standard ways of declaring a function taking in arrays as its parameters. 12void swap(int *A, int j, int k);void swap(int A[], int j, int k); Memory Allocation with malloc and sizeof malloc is a function for dynamic memory allocation and it only takes in byte. sizeof(SomeDataType) returns the number of bytes this data type needs. Say we want to declare an array of 6 Courses in heap here. 12Course *courseArray = malloc(sizeof(Course) * 6); // Old C way to initialize array in heapCourse *courseArray = new Course[6]; // The C++ way to do it Lec11 Classes â€“ A Deeper Look 1clang -std=c+11 -lstdc++ -c MyString.cpp Implicit Inline When you define a function right in the class definition, you make this function implicitly inline. Therefore, thereâ€™s no actual method/function created; the code of the method is substituted through the rest of the code wherever that method is called. Multiple Constructors You can use a delegate constructors to save yourself from writing duplicate code. It will just call that constructor, if the delegate constructors take in arguments, you can just pass in those arguments there. 123456789101112131415// older c++ styleMyString::MyString(string initValue) : MyString() &#123; if (growStorage(initValue.length())) &#123; strcpy(storagePtr, initValue.c_str()) stringLength = initValue.length(); &#125;&#125;// c++ 11 styleMyString::MyString(string initValue) : MyString&#123;&#125; &#123; ... &#125;&#125;// Another ExampleMenu::Menu(MenuItem* list[], int n, char prom, string title) : MenuItem(prom, title)&#123; for (int i = 0; i &lt; n; i++) items.push_back(list[i]);&#125;; Destructor The destructor is a special method (similar to constructor) that is called just before an object is destroyed. There is only one destructor per class (canâ€™t overload). It takes no arguments. A destructor should be used to clean up any dynamically allocated resources (memory, OS objects). You call the destructor when using delete keyword. Passing and Returning Reference Passing Reference If you modified a parameter passed by reference in a function, the change would persist in the calling function. Note that the way we call this function has not changed. We still pass in two strings instead of pointers. You donâ€™t have to do anything differently to specify that the string arguments are being passed â€œpass-by-referenceâ€ when I call the function; I only need to specify that I want to use pass-by-reference when I declare the getTimeAndTemp function. 12345678void getTimeAndTemp(string &amp;time,string &amp;temp)&#123; time = getTheREALTime(); temp = getTheREALTemp();&#125;int main() &#123; string theTime,theTemp; getTimeAndTemp(theTime,theTemp); // theTime and theTemp will be changed.&#125; Returning Reference When we add a &amp; before the function name, the function still returns whatever type it returns, but now the function call can appear on left side of assignment operator and we can write a new value to the memory address the returned value is stored in. For the following example, charAt still returns a char type. The only difference is that we can now directly change the returned value stored in the object by using the assignment operator. 123456789101112char &amp;MyString::charAt(int index) &#123; // boundary checking is omitted for clarity return storagePtr[index];&#125;int main() &#123; MyString str(â€œHello World!â€); char c =str.charAt(11); cout &lt;&lt; c; // &#x27;!&#x27; str.charAt(11) = â€˜?â€™; // legal because we are returning reference cout &lt;&lt; str.charAt(11); // &#x27;?&#x27; cout &lt;&lt; â€œstr is now: â€œ &lt;&lt; str.MakeString() &lt;&lt; endl; // Hello World?&#125; const in class As a qualifier to a member variable. It means that the member variable cannot be changed As a qualifier to a member function. It means that the member function cannot change anything in the class: 1string getName() const &#123; return mName; &#125; static in class There is ever only one copy of that variable that is shared among all the instances of the class. The storage for this variable must be declared in the global scope using the fully qualified name of the variable (classname::static_variable_name) The shared copy of the variable can be accessed either as a field of any instance or using the fully qualified name of the variable 123456789101112// &quot;Person.h&quot;class Person &#123; static int number_of_persons;&#125;// &quot;Person.cpp&quot;int Person::number_of_person = 0; // &quot;main.cpp&quot;cout &lt;&lt; Person::number_of_person; // 0Person p(&quot;Harmony&quot;); // increment number_of_person by 1 in the constructorcout &lt;&lt; p.number_of_person; // 1 this in class Its â€œtypeâ€ is pointer to class type. So, if we have a Person class, Person has an implicitly defined member variable named this that is of type Person * Any of the member variable and functions in the class can be referenced from this Lec12 Operator Overloads Unary Operator Overloads we just have to use the operator keyword. 1234567891011// &quot;MyString.h&quot;int operator~();std::string operator+();// &quot;MyString.cpp&quot;int MyString::operator~()&#123; return stringLength;&#125;string MyString::operator+()&#123; return MakeString(); // returns a std::string from our MyString instance&#125; Binary Operator Overloads We define most binary operator overloads globally when it doesnâ€™t make â€œsenseâ€ which of the two instances of the operands should â€œhostâ€ the overload. (Expressions on both ends are to some extent equal to the other) We use inline to allow us to place this in the header file without causing multiple definition errors, so we are never really â€œdefiningâ€ it, but just replace the code whenever it is called. 12345678inline MyString operator+(const MyString &amp;str1, const MyString &amp;str2) &#123; // use the overloaded unary + sign to return a std::string // then use the std::string overloaded binary + sign to concatenate two strings MyString temp( (+str1) + (+str2) ); return temp;&#125; Here we have an instance of binary overload not done globally. It is a â€œbinary operatorâ€ but only takes one argument. 123T &amp;operator[](int i) &#123; return *(mStoragePtr + i); // equivalent to return mStoragePtr[i];&#125; Copy Constructors Whenever we use the assignment operator to initialize a variable when it is declared, the compiler actually looks for a constructor that takes in a single argument that matches the type of the value you are assigning to the newly declared instance. If we have MyString str2 = 1;, the compiler would look for a constructor for MyString that took a single integer: MyString::MyString(int arg). If you copy constructors take in some object, it must be pass-by-reference! 123456789Point::Point(Point &amp;anotherPoint) &#123; // ...&#125;int main()&#123; Point p1(4,5); // will use our custom constructor Point p2(p1); // will use the copy constructor (just as a constructor function) Point p3 = p1; // will use the copy constructor&#125; Overloading Assignment = Rather than initialize some variable, we want now to assign a new value to an existing variable. Rather than a global function, we will define it as a member function in our class. 1234567MyString &amp;MyString::operator=(const MyString &amp;sourceStr)&#123; // convert sourceStr to a std::String with our predefined unary + // setValue takes a C++ string // return the address of this object setValue(+sourceStr); return *this;&#125; Overloading Stream Direction &lt;&lt; and &gt;&gt; 123456789101112131415inline ostream&amp; operator&lt;&lt;(ostream &amp;os, MyString &amp;str) &#123; os &lt;&lt; +str; // we must always return the stream that was passed in. That allows &quot;chaining&quot;(cout&lt;&lt;a&lt;&lt;&quot;good&quot;&lt;&lt;endl;) to work return os;&#125;inline istream&amp; operator&gt;&gt;(istream &amp;is, MyString &amp;str) &#123; int allocatedSpace = str.getAllocatedSpace(); char *tempBuf = new char[allocatedSpace]; // allocate temp is.get(tempBuf,allocatedSpace-1); // read from instream into location of tempBuf [tempBuf] up to [tempBuf + allocatedSpace - 1] string tempStr = tempBuf; // convert tempBuf to a std::string str.setValue(tempStr); // set str of MyString class to be tempStr delete [] tempBuf; // delete temp memory, realease space return is; // return stream&#125; Lec13 Inheritance Basic Syntax 12345678910class DerivedClass : public BaseClass&#123; &lt;member variables unique to Derived Class&gt; ...&#125;;class Student : public Person&#123; int studentID;&#125;; Override We can override a function by just reimplementing it in our derived class. To access the original implementation from the base class, we use its fully qualified name in the derived class. 123456789101112void Person::printInfo()&#123; cout &lt;&lt; â€œName: â€œ &lt;&lt; name &lt;&lt; endl; cout &lt;&lt; â€œAddr: â€œ &lt;&lt; address &lt;&lt; endl; cout &lt;&lt; â€œPhone: â€ &lt;&lt; phone &lt;&lt; endl; &#125;;void Student::printInfo()&#123; Person::printInfo(); cout &lt;&lt; â€œStudent ID: â€œ &lt;&lt; studentID &lt;&lt; endl;&#125;; Virtual Functions Say we overwrite the printInfo function in Person and define a global function that takes in a Person class and call the printInfo function on that class. When we pass a Student instance to it, it will actually use the printInfo function of Person instead of Student. Thatâ€™s because the compiler thinks the function just takes in a Person. 1234567void printPersonInfo(Person &amp;aPerson)&#123; aPerson.printInfo();&#125;;Student s;printPersonInfo(s); // prints out Name, Addr, Phone If you want to use the overridden version of the function, you will have to declare the function in base class as a virtual function. By defining a virtual function, we tell the compiler to call the overridden version no matter what type that instance may be cast to. However, to achieve this effect, we should also pass in an reference or pointer of instance of our derived class. Only in this way can the compiler knows what type our object was declared as. If we just pass by value (a copy of that instance), it will create a copy of our instance with whatever type specified in the function. More specifically, it calls the copy constructor of the specified class. It has no knowledge of what the original type of the argument was. 123456789class Person&#123; virtual void printInfo();&#125;void printPersonInfo(Person &amp;aPerson) // use overriden versionvoid printPersonInfo(Person *aPerson) // use overriden versionvoid printPersonInfo(Person aPerson) // use function in Person; //in fact in the last function, aPerson only has the &quot;Person&quot; part and doesn&#x27;t contain any information specific to the derived class Lec14 Polymorphism We can dynamically allocate an instance of the derived class and store it in a base class pointer variable. Since Instructor is derived from Person, this is legal. 12Person *aPerson = new Student(); // a pointer of base class(Person) pointing to its derived class(Student)aPerson-&gt;printInfo(); // calls the overridden method in derived class Abstract Class We can make a function to be pure virtual (abstract) by adding a = 0 after its declaration. Any new class derived from this class must implement pure virtual methods if the class is going to work. A class with pure virtual functions is an abstract class. Virtual Destructors If you have an abstract class, you would need to have an abstract/virtual destructor. That is because when a derived classâ€™s destructor is called, it will (implicitly) call destructors in all base classes it inherits from as well. 12345// Person.hvirtual ~Person() &#123;cout&lt;&lt;&quot;base class destructor called&quot;&lt;&lt;endl;&#125;// Student.h~Students() &#123;cout&lt;&lt;&quot;derived class Studenet destructor called&quot;&lt;&lt;endl;&#125; Lec15 Stream Simple Stream I/O put/get: For any stream, the simplest I/O routines let you input or output one character at a time. End of File eof: a special character (usually has value -1) that signals youâ€™ve reached an end of file state. When we reach eof, we cannot read any further from the file. (Ctrl+Z on Windows, Ctrl+D on other OS) getline: pass in a whole line of characters ( read in until encountering with a \\n) When you type in â€œThisâ€ while running the following code without hitting Enter, it will not print anything, because all characters you typed in have not been sent into the buffer yet. After you hit Enter, â€œThisâ€ will be echoed back. So everything got sent into the buffer, we get one out of it each time, and put it to the outstream, repeat the process until we encounter an eof (Ctrl+Z). 1234while (!cin.eof()) &#123; char c = cin.get(); cout.put(c);&#125; Error Handling Once an cin attempt failed, an error flag is set and future attempts to get input will fail. Failure happens when type entered doesnâ€™t match the type of the variable you are assigning value to. cin.fail(): returns true if the last cin assignment failed. cin.clear(): repairs the stream by clearing the error flag in cin. cin.ignore(n, c): ignores the following n characters or one c character. Therefore, cin.ignore(100,'\\n') ignore all input until youâ€™ve already ignored 100 of them or ignore 1 â€˜â€™ character. 123456cin &gt;&gt; id;while (cin.fail() || id&lt;0 || id&gt;99) &#123; cin.clear(); cin.ignore(99, &#x27;\\n&#x27;); cout &lt;&lt; &quot;invalid number, try again &gt; &quot;; cin &gt;&gt; id;&#125; Int Stream Manipulator dec: decimal, base 10 oct: octal, base 8 hex: hexadecimal, base 16 setbase(n): set to n base These stream manipulators are â€œstickyâ€. They will remain the format of your output (even though you start another sentence of cout), until you set another stream manipulator. 123cout &lt;&lt; oct &lt;&lt; 8; //10cout &lt;&lt; 9; // 11cout &lt;&lt; setbase(10) &lt;&lt; 16; // 16 Float Stream Manipulator fixed: print out float number in decimal/fixed point notation scientific: print out float number in scientific notation setprecision(n): always print out 3 digits after the decimal point They are all â€œstickyâ€. Youâ€™ll have to manually set it back to previous state. 123int curPrecision = cout.precision(); // current settingcout &lt;&lt; setprecision(2) &lt;&lt; 3.12545 &lt;&lt; endl; // 3.13cout.precision(curPrecision); // Restore original setting Fixed Width left: align to left, the output is padded to the field width appending fill characters at the end right: align to right, the output is padded to the field width by inserting fill characters at the beginning These two stream manipulators are sticky. We also use setw(n) to make sure at least n characters are printed. If the string to print has fewer than n characters, fill with space. If it has more than n characters, print everything. setw(n) is not sticky. Thatâ€™s because most output methods automatically calls setw(0) each time you call them. setw(n) is in the library #include &lt;iomanip&gt;. 123456789#include &lt;iomanip&gt;int n = -77, m = 13579;cout &lt;&lt; setw(6) &lt;&lt; left &lt;&lt; n &lt;&lt; endl;cout &lt;&lt; setw(6) &lt;&lt; right &lt;&lt; n &lt;&lt; endl;cout &lt;&lt; setw(2) &lt;&lt; m &lt;&lt; endl;//-77 // -77//13579 Custom Manipulator Manipulators are just globally defined functions that take an ostream reference and return an ostream reference. Following are some examples: 12345678ostream&amp; beep(ostream &amp;output)&#123; return output &lt;&lt; â€œ\\aâ€;&#125; // displaying \\a causes beepostream &amp;aReallyLongTokenForNewline(ostream &amp;output)&#123; return output &lt;&lt; â€œ\\nâ€;&#125;cout &lt;&lt; â€œThis will cause a beep: â€œ &lt;&lt; aReallyLongTokenForNewLine;cout &lt;&lt; beep; Lec16 Functional Programming auto keyword The auto keyword is used to declare a variable whose type is determined by the value it is initialized to. It must be initialized at the moment it is declared (or it will cause a static time compiler error). 12auto f = 3.14 // f is made a doubleauto k; // NO INITIALIZER â€“ This would be a compiler error Function Pointers When we define a function pointer, we need to define its return type and what type of arguments it takes in: return_type (* function_name) (argument_type1, argument_type2, ...). Note: All these parameters are required. We can declare a function pointer with no allocation. We can assign it to any function that matches the argument type and return type as we do to most pointers. We can also use the C++11 style function in STL functional: std::function&lt; return_type (argument_type1, argument_type2, ...) &gt; function_name, but this is much heavier. 123456789101112131415int SimpleAdd(int arg1,int arg2)&#123; return arg1 + arg2; &#125;int main(int argc, char *argv[])&#123; int (*f)(int start,int stop); // define a function pointer that takes in two ints and returns an int f = SimpleAdd; // f now points at the function â€œSimpleAddâ€ int x = (*f)(3,4); // dereference f, get the function it points to and applies it to 3,4 int y = f(3,4); // A syntactic sugar provided. Compiler will do the dereference cout &lt;&lt; &quot; x is: &quot; &lt;&lt; x &lt;&lt; &quot;, y is: &lt;&lt; y &lt;&lt; endl; function&lt;int(int,int)&gt; g; g = simpleAdd; cout &lt;&lt; g(3,4) &lt;&lt; endl; // also gives 7 // *g(3,4) doesn&#x27;t work because g here is an std::function, not a pointer to a C-style function&#125; Function as Parameter When we want to pass a function as a parameter of another function, we can pass it as a C-style pointer or C++11 std::funciton. We can also use a template and let the compiler to figure it out. 12345678910void OldCallMe(int (*f)(int), int x) &#123;...&#125;void NewCallMe(std::function&lt;int(int)&gt; f, int x) &#123;...&#125;template&lt;typename T&gt;void CallMe(T fn, int x)&#123; // a syntax error will result if the fn passed in of type T doesn&#x27;t support the following line int newValue = fn(x); cout &lt;&lt; &quot;CallMe-newValue is: &quot; &lt;&lt; newValue &lt;&lt; endl;&#125; Lambda Expressions A lambda expression evaluates to a function pointer. It takes the following format: [vars](args) -&gt; returntype &#123; // body of function &#125;;, where return type and arrow can be omitted. 12345678910111213// Declare a lambda with the auto keyword (we don&#x27;t know what type of a function that is)// func is a function that takes no variables or arguments and simply prints out Hello Worldauto func = []() &#123; cout &lt;&lt; &quot;Hello world!&quot; &lt;&lt; endl; &#125;;// Declare a lambda with a function pointer:// func2 is a pointer to a function that takes in a string as parameter// More specifically, that function takes in a string and prints it outvoid (*func2)(string) = [](string s) &#123; cout &lt;&lt; â€œHello â€œ &lt;&lt; s &lt;&lt; endl; &#125;;// Use function template (C++11) to store lambdastd::function&lt;void(string)&gt; func3 = [](string s) &#123; cout &lt;&lt; â€œHello â€œ &lt;&lt; s &lt;&lt; endl; &#125;; Capture Local Variables We can use lambda expressions to capture local variables. This will be an important way to still be able to use variables in a function that no longer exists when the lambda finally gets executed. If you want to capture local variables, always use C++11 std::function when defining either the lambda expression or the function you want to take this lambda expression. 12345678void CallMe(std::function&lt;int()&gt; fn) &#123;...&#125;;// template also works because it will automatically identify fn as an std::functiontemplate&lt;typename T&gt;void CallMe(T fn) &#123;...&#125;;int myX = 300;CallMe([myX]()-&gt;int&#123; return myX*2; &#125;); You also have the option of capturing local variables by reference. That means if the lambda expression modifies them, the modifications persist back into the â€œhostingâ€ function where these variables were defined. (Just like any pass by reference function call). Pass by reference or pass a pointer will do. 12345int myX = 300; int *myY = new int; *myY = 3;CallMe([&amp;myX]()&#123; myX *= 2; &#125;);CallMe([myY]()&#123; *myY *= 2; &#125;);cout &lt;&lt; &quot;myX is &quot; &lt;&lt; myX &lt;&lt; endl &lt;&lt; &quot;myY is &quot; &lt;&lt; *myY &lt;&lt; endl; // 600 Lec17 Files I/O ofstream We use ofstream to write to file. A constructor of ofstream takes in two arguments name of the file to open specifies which mode to use: ios::out open file for writing, overwrite existing file ios::app open file for writing, append to existing file We donâ€™t have to close the stream after writing, ofstream has a destructor that is automatically called at the end of the program. That being said, we can still call out.close() manually. We use out.is_open() to make sure the file is indeed successfully opened and ready to be written in. Directly evaluating the stream variable out itself as a boolean also does the check. 123456#include&lt;fstream&gt;ofstream out(â€œmyFileâ€,ios::out); // create an ofstream, pass in name of the file and ios::out to indicate you want to use it for outputif (out.is_open()) // make sure we successfully opend the file out &lt;&lt; â€œHello world!â€ &lt;&lt; endl;out.close(); ifstream We use ifstream to read from a file. 1234ifstream in(â€œmyFileâ€,ios::in);string str = &quot;Hello&quot;;if (in.is_open()) in &gt;&gt; str; Sequential Files Suppose we have a csv file that uses comma as the delimiter and space as a record separator. If we want to change only a specific record, how are we supposed to move around in that file? tellg(): returns the offset from the beginning of the file where the next read operation will get data from. tellp(): returns the offset from the beginning of the file where the next write operation will put data to. seekg(n): sets the â€œgetâ€ offset to the nth character in the file seekp(n): sets the â€œputâ€ offset to the nth character in the file Reading and Writing at the Same Time When declare an fstream variable, we can specify using multiple â€œmodesâ€ at the same time by putting the or operator | between different modes. We can then use whatever function those modes give 123fstream file(â€œages.datâ€, ios::in | ios::out) //reads and write to &quot;ages.dat&quot; at the same timestring str; file &gt;&gt; str; // read worksfile &lt;&lt; &quot;That&#x27;s good&quot;; // write also works Lec18 Standard Template Library Iterator begin() points to the first element in the object. end() points to one after the last element. Common operators like + &lt; &gt; are all overloaded for iterators. 123for (vector&lt;string&gt;::iterator p = stringVector.begin(); p &lt; stringVector.end(); ++p) cout &lt;&lt; â€œNext Vector Element is: â€œ &lt;&lt; *p &lt;&lt; endl; Vector 123vector&lt;string&gt;::iterator q = stringVector.begin();stringVector.erase(q+5); // erase the 6th elementstringVector.erase(q,q+5); // erase [q, q+5), so erase 1st to the 5th element Map Map is based on valuetype, which has type &lt;key, value&gt;. All operations come from this pair. We can use typedef to name some very complicated data type that is frequently used. 12345678910111213141516typedef map&lt;int,string&gt;::value_type IDRecord; // IDRecord is in fact of &quot;pair&lt;int,string&gt;&quot; typetypedef map&lt;int,string&gt;::iterator IDRecordIterator;int main()&#123; map&lt;int,string&gt; ids; IDRecord rec1(12345,&quot;Ron DiNapoli&quot;); IDRecord rec2(34564,&quot;Darpan Kaplan&quot;); ids.insert(rec1); // alway insert a key-value pair ids.insert(rec2); cout &lt;&lt; &quot;ID 34564 belongs to: &quot; &lt;&lt; ids[34564] &lt;&lt; endl; // use array-like way to access map IDRecordIterator p = ids.find(12345); // find returns the address of that entry with a matched key , returns map::end() if key doesn&#x27;t exist IDRecordIterator q = ++p; cout &lt;&lt; &quot;Next entry of ID 12345 is: &quot; &lt;&lt; (*q).second &lt;&lt; endl;&#125; Lec19 Exceptions Basic Syntax Exceptions can be of any type. We can do throw 3.14, throw \"Unexpected\", or throw some object. 1234567891011enum MathErr &#123; noErr, divByZero, genericOverflow &#125;;throw divByZero;try &#123; ...&#125; catch(MathErr e) &#123; ...&#125;// Orcatch(...) &#123;&#125; // catches all kinds of Exceptions Exception Object and Inheritance As said in previous section, we can throw an object. 1234567891011121314151617181920212223242526272829class MyIndexError &#123; MyIndexError(int i,char *msg):badIndex(i),theMsg(msg)&#123;&#125; int getBadIndex() &#123; return badIndex; &#125; string getMessage() &#123; return theMsg; &#125;private: int badIndex; string theMsg;&#125;;char &amp;MyString::operator[](int index)&#123; if ((index &lt; 0) || (index &gt;= stringLength)) throw MyIndexError(index,â€Index out of boundsâ€); return storagePtr[index];&#125;class BaseException&#123;public: BaseException(string msg,int err=0):message(msg), errorCode(err)&#123;&#125; virtual string getMessage() &#123; return â€œBASE EXCEPTION: â€œ + message; &#125; int getErrorCode() &#123; return errorCode; &#125;protected: string message; int errorCode;&#125;; Lec20 Custom Templates Basic Syntax 1234567891011template &lt;class placeholder&gt; // declare placeholdersclass SimpleClass // regular class definition&#123;public:â€¦&#125;;// define a function outside of template classvoid SimpleClass&lt;placeholder&gt;::FunctionName() &#123;...&#125;// define constructor/destructor outside of template classvoid SimpleClass&lt;placeholder&gt;::SimpleClass() â€œDefinitionâ€ template class should also be in the same .h file. Because the compiler needs to generate a separate set of member functions for each type used to create an instance of this class at compile time. That means that these definitions are needed at compile time and not at link time, so .cpp wonâ€™t enable us to actually call those functions. Non-Type Parameters We specified a data type calls placeholder in the template class. We can also specify a constant expression when we declare a template class. This will have the same effect as setting a const value specific for that instance, except previously we couldnâ€™t assign values to const variable. 12template &lt;class storageType,int size&gt; class MyArray &#123;...&#125;template &lt;class storageType=int,int size=5&gt; class MyArray &#123;...&#125; // give a default value Lec22 STL Algorithms #include&lt;algorithm&gt; for all functions below. fill(iterator begin, iterator end, T value): take two iterators/pointers and one value. Fill every position in between with that value.: 12char *ptr = new char[10] // An array of 10 charsfill(ptr,ptr+9,â€™Aâ€™); generate(iterator begin, iterator end, function g): assigns every position in between the two iterators/pointers according to the generating function g. 1234567int nextVal() &#123; static int number = 0; return number++;&#125;int main(int argc,char *argv[]) &#123; std::vector&lt;int&gt; intVector(10); // A vector of integers std::generate(intVector.begin(),intVector.end(),nextVal);&#125; fill_n(begin,count,value): fill from begin to begin+count with specified value generate_n(begin,count,function): fill from begin to begin+count with generated value remove(begin,end,value): remove all elements == value in range from begin to end replace(begin,end,value,replaceWith): replace all elements == value in range from begin to end WITH replaceWith Lec23 Smart Pointers Shared Pointer You can declare multiple pointers pointing to the same thing using shared pointer and they will all be released when you release one of them, so itâ€™s safer than the classic pointer, where the pointer will hang over there. You can call the use_count() method to get how many shared pointers are out there pointing to this same thing. 123456int main(int argc,char *argv[]) &#123; shared_ptr&lt;Point&gt; pointPtr(new Point(1,2)); shared_ptr&lt;Point&gt; pointPtr2(pointPtr); cout &lt;&lt; â€œx coordinate is: â€œ &lt;&lt; (*pointPtr).x &lt;&lt; endl; cout &lt;&lt; â€œreference count is: â€œ &lt;&lt; pointPtr.use_count();&#125; Unique Pointer There is only this one pointer pointing to that thing. No other shared pointers can be created pointing to the same thing. For the same reason, use_count() is not available either. Lec24 Namespaces and C/C++ Differences Namespace Declaring Namespace We define a namespace by putting it inside a namespace declaration and its corresponding scope, just like what we do to a class. Whatâ€™s different is that a single namespace may span multiple files. Therefore, we can declare/define a single namespace in multiple files. 123456namespace CornellCS2024 &#123; // Defines a namespace named CornellCS2024 class MyString &#123; public: ...&#125;; class AnotherClass &#123;...&#125;&#125; Using Namespace We can use anything declared in the namespace by quoting the fully qualified name 1CornellCS2024::MyString aString; We can designate a specific class to use in the rest of the file. 12using CornellCS2024::MyString;MyString aString; We can simply state that we want to use everything declared in this namespace. Thatâ€™s what we usually do to std in small file. 12using namespace CornellCS2024;MyString aString; C/C++ Difference only supports /* block comments */ variable declarations had to appear the beginning of a scope before any other statements were encountered only has struct, no class no overloads, Namespaces, Declaring a counter variable in a loop, String type, Exceptions, Templates does not use new/delete for dynamic memory allocation/deallocation. Instead, C uses malloc() allocates memory. It needs to be given the exact number of bytes you want to dynamically allocate calloc() is the same as malloc() but initializes all allocated memory to 0 realloc() â€œgrowâ€ a dynamic allocation: basically allocates new space and copies all original memory to new space. free() releases allocated memory Lec99 From Assignments new keyword returns a pointer to an object. You donâ€™t have to use new when creating a new object. Reference 123test t = test(&quot;rrr&quot;, 8);test t(&quot;rrr&quot;, 8);test *t = new test(&quot;rrr&quot;, 8);","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"Windowsä¸‹é…ç½®PostgreSQL","slug":"2020-09-05-Windowsä¸‹é…ç½®PostgreSQL","date":"2020-09-05T04:00:00.000Z","updated":"2022-06-08T19:34:22.000Z","comments":true,"path":"2020-09-05-Windowsä¸‹é…ç½®PostgreSQL/","permalink":"https://yao-lirong.github.io/blog/2020-09-05-Windows%E4%B8%8B%E9%85%8D%E7%BD%AEPostgreSQL/","excerpt":"å¦‚æœä½ åœ¨çº ç»“è¦ä¸è¦è£…ï¼Œåˆ«è£…äº†å§ï¼Œå¯¹è‡ªå·±å¥½ä¸€ç‚¹","text":"å¦‚æœä½ åœ¨çº ç»“è¦ä¸è¦è£…ï¼Œåˆ«è£…äº†å§ï¼Œå¯¹è‡ªå·±å¥½ä¸€ç‚¹ Download and Install PostgreSQL. During the process, PostgreSQL will ask you to create a username and password, the default username is â€œpostgresâ€ and password is up to you. Run the pg_env.bat under installation folder or the following env.vbs file if that bat doesnâ€™t work 1234567891011on error resume nextset sysenv=CreateObject(&quot;WScript.Shell&quot;).Environment(&quot;system&quot;) &#x27;ç³»ç»Ÿç¯å¢ƒå˜é‡çš„æ•°ç»„å¯¹è±¡Path = CreateObject(&quot;Scripting.FileSystemObject&quot;).GetFolder(&quot;.&quot;).Path&#x27;æ·»åŠ å˜é‡sysenv(&quot;PGHOME&quot;)=&quot;C:\\Hacking\\PostgreSQL&quot; &#x27;!!!change to your own directory!!!&#x27;sysenv(&quot;PGHOST&quot;)=&quot;localhost&quot;sysenv(&quot;Path&quot;)=sysenv(&quot;PGHOME&quot;)+&quot;\\bin;&quot;+sysenv(&quot;Path&quot;)sysenv(&quot;PGLIB&quot;)=sysenv(&quot;PGHOME&quot;)+&quot;\\lib&quot;sysenv(&quot;PGDATA&quot;)=sysenv(&quot;PGHOME&quot;)+&quot;\\data&quot; wscript.echo &quot;PostgreSQL Environment Variable Successfully set&quot; Initialize database by running initdb -D C:\\Hacking\\PostgreSQL\\data Start Server by running pg_ctl -D C:\\Hacking\\PostgreSQL\\data start Register a server service by running pg_ctl register -N \"PostgreSQL\" -D C:\\Hacking\\PostgreSQL\\data (If not working, run terminal as administrator) You should then be able to see a service called â€œPostgreSQLâ€ in Windows Services (Win+R services.msc) Create Database by running createdb -U postgres &lt;DatabaseName&gt; and entering the password you entered in step 1. Note it will give a â€œPassword Authentication Failureâ€ if you try createdb &lt;DatabaseName&gt; and enter the password that way. That is because PostgreSQL uses your computer username as default and no such use is registered in PostgreSQL in the first place. You have to use -U option to specify the user you want to log in as. Allow operations on database without password by changing authentication method in PostgreSQL\\data\\pg_hba.conf all from md5 to trust: (might take effect after a reboot) 12345678910# TYPE DATABASE USER ADDRESS METHOD# IPv4 local connections:host all all 127.0.0.1/32 trust (was md5)# IPv6 local connections:host all all ::1/128 trust# Allow replication connections from localhost, by a user with the# replication privilege.host replication all 127.0.0.1/32 trusthost replication all ::1/128 trust Now when we run command createdb db, we may get a message Fatel Error: User \"harmo\" does not exist. This is a similar problem as in step 6. We want to create a user called â€œharmoâ€ by running createuser -s -r -U postgres harmo. Note simply creatuser -s -r harmo will not work because the default user to use to create such a user harmo is also harmo, which doesnâ€™t exist in the first place. What a stupid logic PostgreSQL applies. Now PostgreSQL is ready to use. è¿‡äº†ä¸€å¤©æœåŠ¡å¯åŠ¨ä¸èµ·æ¥äº†ï¼ŒæŸ¥äº†ä¸€å †æ²¡æœ‰ç»“æœï¼Œæˆ‘è¿˜ç”¨ä½ å¦ˆäº†ä¸ªå—¨ï¼Œå°çˆ·ä¸€ä¸ªå‘¨æœ«å°±æ•´ä½ è¿™å‚»é€¼ç©æ„ï¼Œè‰äº†çœŸçš„æ˜¯ å¥½åƒæ˜¯å¯åŠ¨ pgAdmin ä¹‹åï¼Œåˆå¯ä»¥ç”¨äº†ã€‚åˆšåˆšå¯åŠ¨çš„æœåŠ¡æœ¬èº«å°±æ˜¯ä¸ºäº†è®© local server è¿ä½œçš„ï¼Œè€Œ pgAdmin å¯ä»¥å¸®æˆ‘ä»¬å®Œæˆè¿™ä¸ªä»»åŠ¡ã€‚äºæ˜¯æˆ‘ä»¬ç™»å½•è¿› pgAdmin å°±ç›¸å½“äºè®©é‚£ä¸ªæœåŠ¡è¿ä½œèµ·æ¥äº†ï¼Œä¹Ÿå°±å¯ä»¥æ­£å¸¸åœ¨ç»ˆç«¯ä¸­ä½¿ç”¨å‘½ä»¤äº† Reference ä¸»è¦ï¼šWindowsä¸‹åœ¨å‘½ä»¤è¡Œå®‰è£…postgresqlï¼Œå¹¶æ³¨å†ŒæˆwindowæœåŠ¡ Windowsä¸ŠPostgreSQLå®‰è£…é…ç½®æ•™ç¨‹ Windowsä¸‹Postgresqlä¸‹è½½ä¸é…ç½®æ–¹æ³• postgresql å£ä»¤ï¼š psql: è‡´å‘½é”™è¯¯: ç”¨æˆ· è®¤è¯å¤±è´¥ æœ¬æœºpsqlè®¾ç½®éœ€è¦/ä¸éœ€è¦å¯†ç  Postgres psql: è‡´å‘½é”™è¯¯: è§’è‰² â€œpostgresâ€ ä¸å­˜åœ¨","categories":[],"tags":[{"name":"Logistics","slug":"Logistics","permalink":"https://yao-lirong.github.io/blog/tags/Logistics/"}]},{"title":"Kinect as Web Cam","slug":"2020-06-24-Kinekt-as-Web-Cam","date":"2020-06-24T04:00:00.000Z","updated":"2022-06-08T19:34:22.000Z","comments":true,"path":"2020-06-24-Kinekt-as-Web-Cam/","permalink":"https://yao-lirong.github.io/blog/2020-06-24-Kinekt-as-Web-Cam/","excerpt":"é«˜äºŒå‡é«˜ä¸‰æš‘å‡å‚åŠ å¤ä»¤è¥è®©æˆ‘ç™½å«–çš„ Kinect2ï¼Œå¤§æå°ç”¨å½“åšç½‘ç»œæ‘„åƒå¤´æ¥ç”¨","text":"é«˜äºŒå‡é«˜ä¸‰æš‘å‡å‚åŠ å¤ä»¤è¥è®©æˆ‘ç™½å«–çš„ Kinect2ï¼Œå¤§æå°ç”¨å½“åšç½‘ç»œæ‘„åƒå¤´æ¥ç”¨ ä¸‹è½½ Kinect For Windows SDK 2.0ï¼Œä¸‹è½½åˆ«äººå¼€å‘çš„ FullFastKinectCamV2 ver. 2.2ï¼Œç”¨å°±å®Œäº‹äº† Reference KinectCamV2 for Kinect V2","categories":[],"tags":[{"name":"Logistics","slug":"Logistics","permalink":"https://yao-lirong.github.io/blog/tags/Logistics/"}]},{"title":"Look Back on Cornell 20SP","slug":"2020-05-27-Cornell-20SP-æ€»ç»“","date":"2020-05-27T04:00:00.000Z","updated":"2022-06-08T19:56:48.000Z","comments":true,"path":"2020-05-27-Cornell-20SP-æ€»ç»“/","permalink":"https://yao-lirong.github.io/blog/2020-05-27-Cornell-20SP-%E6%80%BB%E7%BB%93/","excerpt":"CS3110 Data Struct &amp; Functional Programming Ranting When you find yourself saying, â€œI donâ€™t know,â€ be sure to follow it up with â€ - but Iâ€™ll find out.â€ Itâ€™s a great way to admit what you donâ€™t know, but then take responsibility like a pro. â€“ The Pragmatic Programmer, Ch2. The Cat Ate My Source Code","text":"CS3110 Data Struct &amp; Functional Programming Ranting When you find yourself saying, â€œI donâ€™t know,â€ be sure to follow it up with â€ - but Iâ€™ll find out.â€ Itâ€™s a great way to admit what you donâ€™t know, but then take responsibility like a pro. â€“ The Pragmatic Programmer, Ch2. The Cat Ate My Source Code â€‹ Nate Foster å®Œç¾è¯ é‡Šäº†å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ï¼Œå½“ä½ é—®ä»– XXX ä»€ä¹ˆæ—¶å€™æå®Œï¼Œ XXX ä¸ºä»€ä¹ˆè¿˜æ²¡ä¸Šä¼ ï¼ŒXXX æ˜¯ä¸æ˜¯å‡ºé”™äº†çš„æ—¶å€™ï¼Œä»–æ€»èƒ½å‘Šè¯‰ä½  â€œIâ€™ll look into itâ€, â€œI donâ€™t know but Iâ€™ll get it done by todayâ€, â€œI have another meeting coming up, but you can come to my office hour to talk about thatâ€ (å½“ä½ çœŸå»äº†çš„è¯ä»–ä¼šå’Œä½ è¯´ä»–æ¥ä¸‹æ¥åˆæœ‰å¦ä¸€ä¸ªäº‹è¦å¤„ç†å¹¶éå¸¸ç¤¼è²Œåœ°è¯·ä½ æ»š)ã€‚ç½‘ä¸Šçš„æ‰€æœ‰è¯„ä»·éƒ½æ˜¯ Both 3110 professors are amazingï¼Œå¹¶ä¸” reddit ä¸Šç»å¸¸æœ‰äººæ„Ÿè°¢ Fosterï¼Œå°±å·®èµç¾ Foster èƒœè¿‡ä»–äº²çˆ·çˆ·äº†ã€‚ä¸çŸ¥é“æ˜¯ Foster ç»™äº†è¿™äº›äººå¥½å¤„ï¼Œè¿˜æ˜¯ Foster è‡ªå¯¼è‡ªæ¼”ï¼Œæˆ‘å’Œ 19FA å’¨è¯¢çš„ä¸€å TA æ„è§æ˜¯ç›¸åŒçš„ï¼šâ€œClarkson is more organized than Fosterâ€. æˆ‘è™½ç„¶æ²¡æœ‰ä¸Šè¿‡ Clarkson çš„3110ï¼Œä½†æ˜¯æˆ‘è§‰å¾—å†å·®ä¹Ÿä¸ä¼šå·®åˆ°å“ªé‡Œå»äº†ã€‚è¦ä¸æ˜¯ SP çš„ 3410 è®²å¸ˆå¤©æ°”å‹ºè¯„ä»·æ›´å·®ï¼Œæˆ‘ç»ä¸é€‰ SP ä¸Š 3110ã€‚ â€‹ ä¸çŸ¥é“æ˜¯ä¸æ˜¯è®¡ç®—æœºé™¢éƒ½æœ‰çš„é—®é¢˜ï¼šè®²ä¹‰å†™çš„å®åœ¨å¤ªå¥½äº†ä»¥è‡³äºä¸Šè¯¾ä¸å¦‚è‡ªå·±çœ‹è®²ä¹‰ã€‚ä½†æ˜¯ Myers è®²çš„ç¯ç¯ç›¸æ‰£ï¼ŒFoster åˆ™æ˜¯å¼•å…¥äº† iclicker ä»¥å¼ºåˆ¶ä½ åœ¨ä¸€ä¸ªå¯ä»¥å®¹çº³ 300 ä¸ªäººçš„æ•™å®¤é‡Œä¸Šè®¡ç®—æœºè¯¾æ—¶ç¦æ­¢ä½¿ç”¨è®¡ç®—æœºï¼Œè€Œæ˜¯çœ‹ç€ä»–ç°åœº debug è‡ªå·±æœ¬åº”åœ¨è¯¾å‰ debug å¥½çš„ demo ä»£ç ã€‚Foster è¿™å­¦æœŸå”¯ä¸€çš„ç”¨å¤„å¤§æ¦‚å°±æ˜¯è§£ç­”äº†æˆ‘å…³äºçº¢é»‘æ ‘çš„é—®é¢˜ (å½“ç„¶äº†ä¸¥æ ¼æ¥è¯´ä¸æ˜¯ä»–è§£ç­”çš„ï¼Œè¿™ä¸ªæˆ‘å£ä¸­çš„æœ€å¤§ç”¨å¤„å…¶å®å°±æ˜¯æˆ‘é—® â€œä¸ºä»€ä¹ˆ OCaml å¯ä»¥å‡ åè¡Œå®ç°å…¶ä»–è¯­è¨€å‡ ç™¾è¡Œçš„ä»£ç ï¼Œæ˜¯ä¸æ˜¯å› ä¸º OCaml çš„ pattern matching å‡å°‘äº†å¾ˆå¤šæŒ‡é’ˆæ“ä½œâ€ï¼Œä»–å›ç­”äº†ä¸ª â€œYes, you can say thatâ€ è€Œå·²) Assignment A0: æŸä¸€ä¸ª Consultant è¯´æˆ‘æŠŠæœ€åä¸€ä¸ªå‡½æ•° tail-recursive Fibonacci çš„ä¸¤ä¸ªå˜é‡æå€’å·´äº†ï¼Œäºæ˜¯æˆ‘æŠŠå®ƒæ­£äº†è¿‡æ¥ï¼Œè¿™é¢˜0åˆ†ã€‚ä¸€ä¸ªmedianä¸ºæ»¡åˆ†çš„å°çƒ­èº«ï¼Œæˆ‘å¾—äº†å‡ ä¹ä¸¤ä¸ª deviation ä½äº medianã€‚appealçš„ç»“æœä¹Ÿæ˜¯ä¸ç»™æˆ‘åˆ†ï¼ŒåŸå› æ˜¯æˆ‘çš„ spec é‡Œé¢ä¸¤ä¸ªå˜é‡çš„é¡ºåºæ˜¯æ­£ç¡®çš„ã€‚ä½ è¯´è¿™TMä¸æ˜¯åºŸè¯å—ï¼Œå› ä¸ºå½“æ—¶æ”¹çš„æ—¶å€™å¿˜æ”¹specäº†å‘—ã€‚å°±å› ä¸ºè¿™ä¸ªä½œä¸šæäº†æˆ‘çš„å¿ƒæ€æ‰€ä»¥æˆ‘åé¢å¯¹ Foster å’Œè¿™é—¨è¯¾ä¸€ç›´å°è±¡ä¸å¥½ã€‚ A3: å†™äº†Maplewoodâ€¦ A5: sxyåˆæ•‘äº†æˆ‘ä¸€å‘½ï¼Œè¯´å®è¯æˆ‘ä¸€ç›´åˆ°å†™å®Œéƒ½ä¸çŸ¥é“è‡ªå·±åœ¨å†™ä»€ä¹ˆã€‚è¿™ä¸ªä½œä¸šå®Œå…¨æ˜¯è¢«sxyå¸¦çš„ Project åšäº†ä¸€ä¸ªè¿˜è›®å¥½ç©çš„äºŒåˆ†æ³•è§£ä»»æ„ä¸€å…ƒå‡½æ•°çš„å¯ç¼–ç¨‹è®¡ç®—å™¨ã€‚ CS2802 Discrete Structures (Honors) - So letâ€™s think about some applications of graph in real life. Say who is the most influential person in this class. - You, professor! - â€¦ Yeah, of course. â€‹ Joe Halpern æ˜¯ä¸ªéå¸¸å¥½ç©çš„è€å¤´ï¼Œé™¤äº†æœ‰çš„æ—¶å€™è¯¾ä¸Šæ‰¯å¤ªå¤šçš„ä¾‹å­ä»¥è‡³äºè®²ä¸å®Œè¯¾ä»¥å¤–ï¼Œè¿™æ˜¯ä¸€å ‚è¦æ˜¯æœ‰æ—¶é—´è®²å®Œå›¾è®ºå°±å®Œç¾äº†çš„è¯¾ã€‚ä»ä¸€å¼€å§‹çš„æ—¶å€™å¿…é¡»æ¯æ¬¡éƒ½å» OH å†™å‡ºæ¥è¯æ˜ (å°¤å…¶æ˜¯æŸä¸€æ¬¡çš„ inductive definition of transitive closure)ï¼Œåˆ°æœ€åæŸä¸ªä½œä¸šè‡ªå·±ç‹¬ç«‹å®Œæˆäº† â€œWe know M accepts A, WTS A* is regular (accepted by some automata)â€ ç„¶åè¿™ä¸ªé¢˜è¿˜æ‹¿äº†æ»¡åˆ†ï¼Œåˆ‡å®çš„æ„Ÿè§‰åˆ°è‡ªå·±è¿˜æ˜¯å­¦äº†äº›æœ‰ä¸€èˆ¬é€‚ç”¨æ€§çš„ä¸œè¥¿çš„ã€‚ MATH3110 Introduction To Analysis â€‹ å› ä¸ºæŸäººé€‰çš„è¿™è¯¾ï¼Œä¸´èµ°å‰è¯·æ•™äº†åˆ˜æ™“ä¸œï¼Œä»–å®³æ€•è¿™èŠ‚è¯¾ä¼šéš¾æ‰€ä»¥å»ºè®®æˆ‘åªæ˜¯æ—å¬ä½†ä¸è¦ä¸Šï¼Œå“å¾—æˆ‘è¿™å­¦æœŸæ²¡å†å¤šé€‰è¯¾ï¼Œç»“æœä¸èƒ½è¯´å®Œå…¨ä¸éš¾ï¼Œä½†æ˜¯æ¯” 2802 è¿™ä¸ª 3 å­¦åˆ†çš„è¯¾æ•´ä½“æ¥è¯´èŠ±çš„æ—¶é—´å°‘ã€‚å†ä¹Ÿä¸ä¿¡åˆ˜æ™“ä¸œäº†ï¼Œç¬¬ä¸€å­¦æœŸä¸´èµ°å‰è¿˜è·Ÿæˆ‘è¯´åˆ«æŠŠå¤šå…ƒå¾®ç§¯åˆ†è€ƒæ‰ï¼Œæœ€åæˆ‘è¿˜æ˜¯è€ƒæ‰äº†( â€‹ åšå®šä¸‹æ¥é€‰è¿™é—¨è¯¾è¿˜æœ‰ä¸€ä¸ªåŸå› æ˜¯ä¸Šå­¦æœŸçš„çº¿æ€§ä»£æ•°é‡‘ç‰Œè®²å¸ˆ Meyer åœ¨è®²ï¼Œè¿™å­¦æœŸè·Ÿå¥¹ä¸Šäº†ä¸€ä¸ªå­¦æœŸæ„Ÿè§‰è™½ç„¶æœ‰çš„æ—¶å€™è¯¾ä¸Šè®²ä¸å¤ªåˆ°ç‚¹å­ä¸Š (Meyer ä¸‹å­¦æœŸè¦å» Carleton äº†ï¼Œå“­å“­)ã€‚è§£é‡Šçš„ä¸æ˜¯å¾ˆæ˜ç™½ä»¥å¤–ï¼Œæ•´ä¸ªè¯¾ä¸‹æ¥éå¸¸æœ‰ç»„ç»‡æ€§ã€‚å¦ä¸€åè®²å¸ˆæ³•å›½ä½¬ Saloff-Coste è™½ç„¶è¯¾è®²å¾—çœŸä¸æ€ä¹ˆæ ·ï¼Œä½†æ˜¯ OH ç‰¹åˆ«æœ‰ç”¨ï¼Œè®©äººä¸ç¦ç–‘æƒ‘ OH çš„æ—¶å€™è®²å¾—è¿™ä¹ˆå¥½ä¸ºä»€ä¹ˆè¯¾èƒ½è®²å¾—è¿™ä¹ˆçƒ‚ã€‚ CS2043 UNIX Tools and Scripting â€‹ è®²çš„ä¸œè¥¿éƒ½å¾ˆæœ‰ç”¨å¾ˆæœ‰æ„æ€ï¼Œä½†æ˜¯è¿™è€å¸ˆå®å±ä¸è¡Œï¼Œå°±çº¯å¿µ PPT WRIT1380 FWS: Elements of Acad Wtg â€‹ ä¸ºäº†æˆç»©èƒ½é«˜ç‚¹åˆæ°´äº†ä¸€å¹´ FWSï¼Œæ¯”å»å¹´å·®è¿œäº†ï¼Œè¿™è€å¸ˆæ²¡æœ‰Brad èƒ½æ‰¯çš®ä¹Ÿæ²¡ä»–æœ‰æ„æ€ï¼Œä½œä¸šè¿˜æ¯” Brad å¤šã€‚ä¸è¿‡ç¡®å®æ•™äº†ç‚¹æœ‰ç”¨çš„å†™ä½œæŠ€å·§","categories":[],"tags":[{"name":"Cornell","slug":"Cornell","permalink":"https://yao-lirong.github.io/blog/tags/Cornell/"},{"name":"Review","slug":"Review","permalink":"https://yao-lirong.github.io/blog/tags/Review/"}]},{"title":"Introduction to Vim","slug":"2020-03-15-Introduction-to-Vim","date":"2020-03-15T04:00:00.000Z","updated":"2020-04-02T22:54:56.000Z","comments":true,"path":"2020-03-15-Introduction-to-Vim/","permalink":"https://yao-lirong.github.io/blog/2020-03-15-Introduction-to-Vim/","excerpt":"","text":"First Steps in Vim Editing h j k l: huang he (W), Java (S), Kosovo (N), Los Angeles (E) i: begin insertion at current cursor a: begin insertion after current cursor o: creates a new line after this line and begin insertion O: opens a line above the cursor Deleting Characters x: delete one character forward dl X: deletes one character backward dh dd: delete a whole line J: delete the line break in this line. Undo and Redo u: undo your last edit ctrl-R: redo changes Moving Around Move by Words a string of English characters â€œthisIsAWordâ€ or symbols â€œ^&amp;%â€ is considered a word* in vim. A mix of both is not. w: move to the start of next word (forward) b: move to the start of last word (back) e: move to the next end of a word (end) ge: move to the previous end of a word These lowercases command consider the appearance of different kinds of characters as separation of word. There uppercases version W B E gE consider only whitespaces to be delimiter. Using Counts and Combination of Commands You can add numbers before commands to perform this command multiple times. e.g. 3w moves you to the start of the third next word. 5gE moves you to the end of the fifth previous word delimited by whitespaces. 4a!&lt;esc&gt; appends ! four times after the position of our cursor. dw: delete the word forward d$: delete from the cursor to the end of the line d2e: delete two words from the cursor to the end of the second end of word ahead Search Characters f&lt;character&gt;: move to the position of characterâ€™s first occurrence on right (forward) F&lt;character&gt;: move to the position of characterâ€™s first occurrence on left (backward) Move by Lines &lt;number&gt;G: go to specific line in file G: go to the end of the file gg: go to the top of the file &lt;number0~100&gt;%: go to some percentage of the file H: go to the top line of whatâ€™s visible (home) M: go to the middle part of whatâ€™s visible (middle) L: go to the last line of whatâ€™s visible (last) Scrolling ??? â€œ``â€: jumps back to the position you just came from (a jump is a move by lines) Searching Words /xxx search for xxx in our â€œfileâ€ searching has history, you can use arrow key up and down to go through histories *: use asterisk on a word to search this word in a file match whole words /the: matches â€œtheâ€, â€œthereâ€, â€œsootheâ€ /\\&lt;the: matches â€œtheâ€, â€œthereâ€ /the\\&gt; matches â€œtheâ€, â€œsootheâ€ /\\&lt;the\\&gt; matches only â€œtheâ€ You can also use regular expressions in searching Making Small Changes Changing Text c works just like d except it leaves you in the editing mode after deletion. c2wbe: deletes two words forward and then insert â€œbeâ€ cc: changes (deletes and leaves you in editing mode) a whole line (as dd does) c$: deletes to the end of the line and leaves user in editing mode r&lt;single character&gt; replaces the character under our cursor with the &lt;single character&gt; we typed in. e.g. rw replaces the character with â€œwâ€. Repeating a Change . repeats the last change we made (edit of the file) e.g. we want to delete all occurrences of â€œâ€ 123456f&lt; find first &lt; df&gt; delete to &gt;f&lt; find next &lt;. repeat df&gt; f&lt; find next &lt; . repeat df&gt; e.g. We want to change all occurrences of â€œfourâ€ to â€œfiveâ€ 123456789/four&lt;Enter&gt; find the first string &quot;four&quot;cwfive&lt;Esc&gt; change the word to &quot;five&quot;n find the next &quot;four&quot;. repeat the change to &quot;five&#x27;n find the next &quot;four&quot;. repeat the change etc. Visual Mode å…¶å®å°±æ˜¯ä¸€ä¸ªå¯ä»¥é€‰ä¸­æ–‡å­—çš„æ¨¡å¼ã€‚ vllld selects three characters right to the cursor and deletes them. V selects whole line (commands like hl move the cursor but donâ€™t change the selected area) Vjjd selects and deletes this line and two lines below it o: gets you to the other side of selected area in visual mode Moving Text When you delete something with the d, x, or another command, the text is saved. You can paste it back by using the p command. (The Vim name for this is put). p: puts the word deleted after the cursor P: puts the word deleted before the cursor xp: a combination of command to swap two characters if you typed them wrong (e.g. teh -&gt; the) Copying Text y: copy selected word (use p to paste it) yy: copy the whole line Y: also copy the whole line (not like D, which deletes until the end of the line) Clipboard use the \"* to use Vim clipboard \"*yy: copy a whole line to the clipboard \"*p: puts a line from the clipboard Text Objects daw: delete the word your cursor is at (aw: a word) das: deletes a sentence, including any trailing whitespace (as: a sentence) dis: deletes a sentence until the period, not including the trailing whitespaces (is: interior sentence) Set Your Settings Vimrc find .vimrc by :scriptnames and add the following commands at the end of the file :set incsearch: makes Vim display the match for the string while you are still typing it :set ruler: This will display the cursor position in the lower right corner of the Vim window :set autoindent: use the indent of previous line for a newly created line Mapping map a shorter combination of commands to a complicated function :map &lt;F5&gt; i&#123;&lt;Esc&gt;ea&#125;&lt;Esc&gt;: insert curly brackets around the current word by pressing function key F5 One key commonly used in mapping is the backslash \\ For example, :map \\p i(&lt;Esc&gt;ea)&lt;Esc&gt;: press \\p to insert parenthesis :map \\c i&#123;&lt;Esc&gt;ea&#125;&lt;Esc&gt;: press \\c to insert curly brackets Plugin Global Plugins You can just add global plugins under ~/.vim/plugin/ directory and Vim will load them automatically when it starts. Donâ€™t forget you can organize these plugins by putting them into different folders: ~/.vim/plugin/perl/ or ~/.vim/plugin/cpp/ Filetype Plugins Start these plugins by :filetype plugin on Filetype plugins are stored under ~/.vim/ftplugin/. When name your plugin, you have to name them according to the file type (extension names). e.g. ~/.vim/ftplugin/stuff.vim works only for file of type â€œstuffâ€. When you have two plugins for stuff and want to distinguish these two, you should use underscore to separate filetypes and the names of plugin. e.g. stuff_too.vim is an extension for filetype stuff with name â€œtooâ€. More Options :set nowrap: let the text continue right after the window :set &lt;option&gt;&amp;: set the value of this option back to default e.g. :set iskeyword&amp; :set list: display tab as ^I, end of line as $ :set listchars=tab:&gt;-,trail:-: set tabs to be displayed as &gt;---, trailing whitespaces as ----. :set iskeyword+=_: â€œ_â€ now also becomes a part of keyword (e.g. stuff_abc is now a single word, w or b will not stop at the â€œaâ€ when they move) :set cmdheight=3: set the command line height at the bottom to be 3 (more space for command line)","categories":[],"tags":[{"name":"Logistics","slug":"Logistics","permalink":"https://yao-lirong.github.io/blog/tags/Logistics/"},{"name":"Vim","slug":"Vim","permalink":"https://yao-lirong.github.io/blog/tags/Vim/"}]},{"title":"CS2043 Unix Tools and Scripting","slug":"2020-01-24-CS2043-Unix-Tools-and-Scripting","date":"2020-01-24T05:00:00.000Z","updated":"2023-05-18T03:26:44.000Z","comments":true,"path":"2020-01-24-CS2043-Unix-Tools-and-Scripting/","permalink":"https://yao-lirong.github.io/blog/2020-01-24-CS2043-Unix-Tools-and-Scripting/","excerpt":"About The goal of CS2043 is to introduce you to the UNIX/Linux â€œcommand lineâ€ and its accompanying tools. When done with this class you should feel comfortable navigating any UNIX shell prompt, installing UNIX/Linux systems and understanding any shell script that you may encounter down the road. Weâ€™ll cover basic commands through script writing and visit some of the more common tools used today!","text":"About The goal of CS2043 is to introduce you to the UNIX/Linux â€œcommand lineâ€ and its accompanying tools. When done with this class you should feel comfortable navigating any UNIX shell prompt, installing UNIX/Linux systems and understanding any shell script that you may encounter down the road. Weâ€™ll cover basic commands through script writing and visit some of the more common tools used today! LEC02 File System (01/24) Root Directory Unlike Windows, UNIX has a single global â€œrootâ€ directory (instead of a root directory for each disk or volume). The root directory is just /. Absolute paths start with a /, and always refer to the root directory. cat: concatenate and print a file cat &gt;&gt; &lt;filename&gt;: concatenate your following input in shell to the file specified wc -l &lt;filename&gt;: count the number of lines in a file wc -w &lt;filename&gt;: count the number of words in a file touch: create a file if not existed mkdir -p test/a/b: make directory and all its parent directory if they do not exist cp â€“r &lt;src&gt; &lt;dest&gt;: To copy a complete directory cp â€“f &lt;src&gt; &lt;dest&gt;: To overwrite more aggressively LEC03 Permission (01/27) Reading permission: Linux Representation Permission by user type -rwxâ€”â€” User permissions â€”-rwxâ€” Group permissions â€”â€”-rwx Other permissions r- read, w- write, x - execute groups &lt;username&gt;: check which group this user is in and you can manage permission by groups chmod &lt;mode&gt; &lt;filename&gt;: change permissions: &lt;mode&gt;: +774: add user and group all rwx permissions, give others only r permission to the file -222: deprive user, group, and otherâ€™s permissions to write the file =111: change user, group, and otherâ€™s permissions to only execute the file. They will lose permissions to read or write if they previously had su: makes you the super user sudo: grants you the super power temporarily LEC04 More Commands (01/29) more | less: to view file man: \\something to search for â€œsomethingâ€, n to go to its next occurrence find &lt;directory&gt; -&lt;criteria&gt; &lt;specification&gt;: Search is recursive (will search all subdirectories too), so sometimes you may need to limit the depth with -maxdepth &lt;int&gt; Modifiers for find are evaluated in conjunction (a.k.a AND). But you can condition your arguments with an OR using the â€“o flag find can also execute command on found files / directories by using the â€“exec modifier, and find will execute the command for you The variable name is {} You have to end the command with either a : Semicolon (;): execute command on each result as you find them- Plus (+): find all the results first, then execute command arguments for &lt;criteria&gt;: -name: the fileâ€™s name -amin n: file last access was n minutes ago -atime n: file last access was n days ago examples: find ./ -name *.sh: find under the current directory all files containing the extension name â€œ.shâ€ find . â€“amin -10 â€“exec cat &#123;&#125; \\+: Display all the contents of files accessed in the last 10 minutes find . â€“type f â€“readable â€“executable: All files that are readable and executable find . â€“type f â€“readable â€“o â€“executable: All files that are readable or executable find . â€“amin +10: Find all files accessed at least 10 minutes ago find . â€“amin -10: Find all files accessed at most 10 minutes ago LEC05 Zipping (01/31) Zipping tar -c -v -f &lt;zipped_filename&gt; &lt;files_to_zip&gt;: tar files only create a bundle of file,s it doesnâ€™t compress Remember to put -f as the last one, or at least -f must come right before &lt;zipped_filename&gt; -c : create a new bundle -v : verbose (output information about whatâ€™s going on) -f : save in file tar -xvf &lt;archived_filename&gt; &lt;files_to_zip&gt;: -x: extract files zip archive.zip file1 file2 ...: zip files zip -r archive.zip folder/: zip folder recursively unzip -Z &lt;zip_filename&gt;: show whatâ€™s inside the zip file unzip &lt;zip_filename&gt;: unzip the file Piping 1&lt;command1&gt; | &lt;command2&gt; ls -al /bin | less: show everything in directory /bin as scrollable history | tail -20 | head -10 : the most recent 10th - 19th file Redirection If you donâ€™t specify, the output or input of a command comes from the terminal command &gt; file: write the output of the command into file (overwrite) command &lt; file: take the file as input of a command line command 2&gt; file: outputs the error message to a file (stderr(2) in C) command &gt;&gt; file: append the output of the command into file (doesnâ€™t overwrite) LEC06 Loops and Variables (02/03) Environment and Variables environment variables: in the computer local variables: only in current shell Shebang #!/bin/sh: execute the file using Bourne shell (sh): describes the shell programming language, usually its implementation points to /bin/bash #!/bin/bash: execute the file using bash shell (bash): an sh-compatible implementation with modern implementation exit code returned value of main will be printed out if executing the script in Linux exit N: exit with status N executing multiple commands in a row cmd1; cmd2: execute cmd 1 first, then cmd 2 cmd1 &amp;&amp; cmd2: execute cmd2 only if cmd 1 returns 0 (exited normally) cmd1 || cmd2: execute cmd2 only if cmd 1 doesnâ€™t return 0 (failed) Scripting We mostly use bash in our scripting. So remember to include #!/bin/bash in the top Variables storing command output: var = \"$(echo hello world)\" if statement 123456789if [ CONDITION_1 ] then # statementselif [ CONDITION_2 ]then # statementselse # statementsfi if...then...fi part is necessary. elif and else are allowed, but not necessary. Shorten codes with ; to write them in one line, like if [[ 0 â€“eq 0]]; then echo â€œHiyaâ€; fi for loop 123for (( i = 0; i &lt;= 11; ++i )); do echo â€œi: $iâ€; done while loop 1234567891011121314151617s=â€œsâ€ while [[ &quot;$s&quot; != &quot;ssss&quot; ]]; do echo &quot;$s&quot; s=&quot;s$s&quot;donex=0 while (( x &lt;= 11 )); do echo &quot;x: $x&quot; (( ++x ))done# Loop through lines in a filefile=â€œfilename.txtâ€while read -r line; do echo &quot;Line: $line&quot;done &lt; &quot;$file&quot; Comparing Values Numbers $n1 â€“eq $n2 tests if n1 == n2 $n1 â€“ne $n2 tests if n1 != n2 $n1 â€“lt $n2 tests if n1 &lt; n2 $n1 â€“le $n2 tests if n1 &lt;= n2 $n1 â€“gt $n2 tests if n1 &gt; n2 $n1 â€“ge $n2 tests if n1 &gt;= n2 Strings â€œ$s1â€ == â€œ$s2â€ tests if s1 and s2 are identical â€œ$s1â€ != â€œ$s2â€ tests if s1 and s2 are different Path Testing Test if /some/path exists: -e /some/path Test if /some/path is a file: -f /some/path Test if /some/path is a directory: -d /some/path Test if /some/path can be read/written/execute: -r/-w/-x /some/path Arithmetic Expression Put expressions inside (( )) . In script, you need to put $ before expressions to read values. Below are some examples 123echo $(( 2 + 3 )) #5x=10; sum=$(( $x+10 ))echo $sum #20 Passing Arguments $1, $2, â€¦, $10: values of the first, second, etc. arguments If 3 arguments are given, $4, $5, â€¦ higher are empty $0 is the name of the script $# is the number of arguments (argc in C) $? Is the exit code of the last program executed You can have your script set this with exit &lt;number&gt; (read man exit) No explicit call to exit is the same as exit 0 (a.k.a, success!) $* expands \\$1 .. \\$n into one string, has the same effect as â€œ\\$1 \\$2 â€¦ \\$nâ€ (one string) $@ expands $1 .. $n into individual strings, same as â€œ$1â€ â€œ$2â€ .. â€œ$nâ€ (n strings) Be careful with spacing comparing two variables Lec07 Your Shell, Job, and Processes (02/05) Resource Monitoring Commands ps &lt;PID&gt; (process snapshot): report the current running processes, including PID ps -C &lt;command_name&gt;: report the current process using its corresponding shell command top: displays CPU usage of current processes htop: better version of top, though not pre-installed in many Linux distributions free -h: display available memory in human-readable format nvidia-smi: display Nvidia GPU information Examples 1234ps â€“C firefox #find firefox&#x27;s pid through its command name61860 ... firefoxhtop -p 61860 #display usage of this specific process Modifying Processes nice -n &lt;priority:int&gt; &lt;command name&gt;: initialize command with non-default priority renice -n &lt;priority&gt; -p &lt;PID&gt;: readjust the priority of a running process kill &lt;PID&gt;: kill this process killall &lt;command name&gt;: kill processes by name, kill all processes related to this program Jobs When we are executing ping or installing big packages, we may lose control of our command line temporarily. And we may want to run these commands in the background. &lt;command&gt; &amp;: run the command in background, but will still print output in the terminal jobs: report jobs working in background bg &lt;job_id&gt;: resumes the job in background (note: job id should come after %, like %1, or the command will take it as the PID) fg &lt;job_id&gt;: resume job in the foreground Lec08 Your Shell (02/10) source &lt;script_name&gt;: the command runs script in the current shell, not as usual in a spawned shell exec $shell: restart the current shell (source) alias &lt;new_name&gt;=&lt;old_name&gt;: e.g. x = 'cd /Desktop' ssh -X: allows X11 rendering (allows graphic interface through remote server) scp [flags] &lt;from&gt; &lt;to&gt; (secure copy): copy files from the internet (remote host): Must specify the user on the remote host. Syntax for remote client: user@host:/path (Note You need the : to start the path) ctrl + r reverse search your history for the most recent command that has the string you just typed in. Lec10 Shell Expansions and Search (02/14) Grammar of Shell Expansions *: multiple character wildcard: match any string, including the empty string ?: single character wildcard: match a single character: matches exactly one but what that character is doesnâ€™t matter [brackets]: [a-z, A-Z] matches one character in the range [^ ...]: not, [^abc] matches any character that is not a, b, or c &#123;... , ...&#125;: matches any pattern inside the comma separated braces. &#123;Hello,World&#125; matches either â€œHelloâ€ or â€œWorldâ€ \\ : escape space: &#123;Hello, Goodbye&#125; World = Hello Goodbye World &#123;Hello, Goodbye&#125;\\ World = Hello World Goodbye World (the space is escaped, so â€œWorldâ€ is now taken as a part of the set of words) $: to read values (echo $PWD reads the PWD variable and then echo its value) &lt;: create instream from file &gt; &gt;&gt;: direct output to a file (overwrite or append) GREP grep &lt;pattern&gt; [input] Globally search a Regular Expression and Print. GREP can be used to search or filter large amounts of data. grep -r &lt;pattern&gt; ./ search current directory and all its subdirectories for the pattern specified grep -i &lt;p&gt; ./ ignore upper/lower case distinctions -v display those lines that do NOT match -n precede each matching line with the line number -c print only the total count of matched lines Regular Expressions a?: search for a with 0 or 1 appearance a*: search for a with 0 or multiple appearance a+: search for a with 1 or multiple appearance .: wildcard Lec11 Sed, Cut, and Paste cut cut -c M-N file: print out the Mth to Nth characters (-c) in file cut -d \" \" -f 1 t.txt: print out the first field of each line in file t.txt, field is determined by delimiter space sed sed is the Stream EDitor. It goes line by line searching for the regular expression Print sed '/pattern/p': print out all occurrences that meet pattern. Replace sed 's/pattern1/pattern2/': sed 's/no spoon /a fork/g' no_spoon.txt: replace every occurrence in the whole document (globally: /g) of â€œno spoonâ€ with â€œa forkâ€ Delete sed '/pattern/d': sed '/[Dd]avid/d' david.txt: executes delete command (/d) Extended regular expression sed -E '...': let sed to use the more usual version of regex, where + ? () have special meanings. See here for an explanation of Extended Syntax xargs xargs: can read from stdin, so it can pass output from other commands to scripts that only take in arguments, not from stdin. xargs -n 1 &lt;command&gt;: only feeds 1 arguments to the next command. See the next grep 688 for an example xargs -I '&#123;&#125;' &lt;command&gt; '&#123;&#125;': -I specify where to use the the argument read in by xargs. Specifically, for the results fed into xargs, we give them a name &#123;&#125;, when we later run the next command, replace occurrence of &#123;&#125; in that command with those results. e.g. grep 688 ./ | xargs -n 1 -I '&#123;&#125;' mv '&#123;&#125;' ./results/ for each of the file that was found to contain 688 in their name, move that file to results/ we can also use a token other than &#123;&#125;, for example cat directories.txt | xargs -I % sh -c 'echo %; mkdir %' shift &amp; paste shift &lt;number&gt;: drop the first &lt;number&gt; arguments paste: merge multiple files paste â€“d , names.txt phones.txt &gt; result.csv: merge names and phones together, -ddelimit them with â€˜,â€™ paste â€“d , -s names.txt phones.txt &gt; result.csv: merge file serially (-s) instead of in parallel LEC12 awk, gawk, and Process Substitution awk Use awk on delimited fields on a per-line basis The basic structure of an awk program is: 1234BEGIN &#123;commands&#125;pattern1 &#123; commands1 &#125;pattern2 &#123; commands2 &#125;END &#123;commands&#125; awk '/[Mm]onster/ &#123;print&#125;' frankenstein.txt: find regex [Mm]onste and print the lines out. awk '/[Mm]onster/' frankenstein.txt: if not specified, the default action is to print the whole line awk '/[Mm]onster/ &#123;print $0&#125;' frankenstein.txt: $0 refers the whole line awk '/[Mm]onster/ &#123;print $1&#125;' frankenstein.txt: prints the first word of the line contains our pattern awk '/Ron/&#123;print $3&#125;' marks.txt: prints the third column of the line containing â€˜Ronâ€™ in the file â€˜marks.txtâ€™ You can also use awk without specifying a pattern: awk 'BEGIN&#123;x=5; y=10; z=x+y; print z&#125;': arithmetic in awk awk '&#123;print $1 \",\"&#125;' t.txt: print out the first field of each line plus a colon in file t.txt, field is determined by delimiter space &amp;&amp; || a?b:c !(a&amp;&amp;b): also work in awk. If you want to do regular expression, you need to enclose them with /regular expression/ awk '/s/?/8./:/9./ &#123;print&#125;' marks.txt: If thereâ€™s an â€˜sâ€™, look for grade in 80s, otherwise grade in 90s awk '!/s/ &#123;print&#125;' marks.txt: Look for all lines that do not contain an â€˜sâ€™ Process Substitution We can treat a command of series of commands as if they were a file &lt; (list): treat the list of commands as input e.g. echo \"This is a test\" &gt; &gt;(wc â€“w) &gt; (list): treat the list of commands as output file e.g. while read x; do echo $x; done &lt; &lt;(git log) LEC13 Advanced Bash Scripting Condition Statements: case case employs a patter match, using shell expansion 123456789case &quot;$var&quot; in&quot;A&quot; ) #commands to execute if [[ $var == &quot;A&quot; ]]2 ) #commands to execute if [[ $var -eq 2 ]][2-4] ) ##commands to execute if [[ $var -ge 2 ]] &amp;&amp; [[ $var -le 4 ]]* ) #default commands Arrays 1234567891011121314151617arr = ( use parentheses and seperate items by space )my_arr = ( &quot;a string&quot; 1 ) % can be of multiple types# You can also customize the indexes inside the array (so its more like a dictionary instead of a traditional array)my_arr[44] = &quot;string&quot;# perform an array operation by $&#123;expr&#125;echo &quot;Index 51: $&#123;arr[51]&#125;&quot;#iterate through the array as individual itemsfor x in &quot;$&#123;arr[@]&#125;&quot;; do echo &quot;$x&quot;; done#iterate through the array as a joined long seriesfor x in &quot;$&#123;arr[*]&#125;&quot;; do echo &quot;$x&quot;; done#iterate through the list of indexesfor idx in &quot;$&#123;!new_arr[@]&#125;&quot;; do echo â€œ$idxâ€; done Lec99 Practical Tasks find . -name \"*.png\" -type f -print0 | xargs -0 rm -v -rf \"&#123;&#125;\" reference find . -name \"*.png\" -type f: search files (type -f) with this name -print0: names will be terminated by a null character, and spaces and strange characters will be catered for. xargs -0: xargs is also going to consider filenames to be null-terminated, and spaces and strange characters will not cause problems. rm -v -rf \"&#123;&#125;\": The â€œ{}â€ is replaced by each filename.","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"Installing and Configuring Ocaml on Linux","slug":"2020-01-20-Installing-Ocaml-on-Linux","date":"2020-01-20T05:00:00.000Z","updated":"2022-06-08T19:25:40.000Z","comments":true,"path":"2020-01-20-Installing-Ocaml-on-Linux/","permalink":"https://yao-lirong.github.io/blog/2020-01-20-Installing-Ocaml-on-Linux/","excerpt":"Install Ocaml run sh &lt;(curl -sL https://raw.githubusercontent.com/ocaml/opam/master/shell/install.sh) and install opam at /usr/bin (Caution: install it under this directory to ensure you can also access opam at userâ€™s directory)","text":"Install Ocaml run sh &lt;(curl -sL https://raw.githubusercontent.com/ocaml/opam/master/shell/install.sh) and install opam at /usr/bin (Caution: install it under this directory to ensure you can also access opam at userâ€™s directory) Configure Ocaml and VSCode initiate with sandbox (bubblewrap) disabled opam init --bare -a -y --disable-sandboxing switch OPAM to the OCaml 4.09.0 compiler: 123# Note: do NOT prefix these commands with sudoopam switch create 4.09.0 ocaml-base-compiler.4.09.0eval $(opam env) install OPAM packages needed 12opam install -y utop ounit qtest yojson lwt lwt_ppx menhir ansiterminal lambda-term merlin ocp-indent user-setup bisect_ppx-ocamlbuildopam user-setup install install â€œOCaml and Reason IDEâ€ and configure settings.json in vscode as such: 12345678910&#123; &quot;workbench.colorTheme&quot;: &quot;Solarized Light&quot;, &quot;editor.tabSize&quot;: 2, &quot;editor.rulers&quot;: [ 80 ], &quot;editor.formatOnSave&quot;: true, &quot;reason.path.ocamlmerlin&quot;: &quot;/home/mint/.opam/4.09.0/bin/ocamlmerlin&quot;, &quot;reason.path.ocamlfind&quot;: &quot;/home/mint/.opam/4.09.0/bin/ocamlfind&quot;&#125; note that it first showed that â€œcannot locate ocamlmerlin binary.â€ I fixed the problem by changing directory of â€œocamlmerlinâ€ and â€œocamlfindâ€ in the settings. (Find their path with which ocamlmerlin)","categories":[],"tags":[{"name":"CS3110","slug":"CS3110","permalink":"https://yao-lirong.github.io/blog/tags/CS3110/"}]},{"title":"Look Back on Cornell 19FA","slug":"2019-12-22-Cornell-19FA-æ€»ç»“","date":"2019-12-22T05:00:00.000Z","updated":"2025-09-03T01:42:46.384Z","comments":true,"path":"2019-12-22-Cornell-19FA-æ€»ç»“/","permalink":"https://yao-lirong.github.io/blog/2019-12-22-Cornell-19FA-%E6%80%BB%E7%BB%93/","excerpt":"CS2112 OO Design Data Structs (Honors) My goal in teaching this course has been to make you guys fearless about taking ideas and turning them into systems of codes that work â€“ Andrew Myers, 2019/12/10","text":"CS2112 OO Design Data Structs (Honors) My goal in teaching this course has been to make you guys fearless about taking ideas and turning them into systems of codes that work â€“ Andrew Myers, 2019/12/10 ä»A1åˆ°A7è‚‰çœ¼å¯è§è‡ªå·±çš„æˆé•¿ï¼ŒçœŸçš„æƒ³å­¦CSçš„è¯ä¸€å®šè¦ä¸Šè¿™ä¸ªè¯¾ï¼Œå› ä¸ºè¿™ä¸ªè¯¾æ‰€ä»¥æˆ‘è§‰å¾—è¿™ä¸€å­¦æœŸè¿‡å¾—ç‰¹åˆ«å¿«ï¼Œä¸¤å‘¨ä¸€ä¸ªprojectï¼Œä¸€å­¦æœŸå°±è¿™æ ·è¿‡å»äº†ã€‚ A4-A7 Git Commit History A1: ä»€ä¹ˆå˜›ï¼Œè¿˜æ˜¯æŒºç®€å•çš„å—ï¼ˆç»“æœæ‹¿äº†ä½äºä¸€ä¸ªdeviationï¼‰ A2(Isaac)ï¼šå› ä¸ºäº²çˆ±çš„ä¸­å›½æœ‹å‹ä»¬è‡ªå·±æœ‰è‡ªå·±çš„é˜Ÿå‹ï¼Œåªæœ‰ä¸€ä¸ªé»‘å“¥æ‰¾æˆ‘å½“é˜Ÿå‹ã€‚è¿™ä¸ªé»‘å“¥å¥½åƒæ˜¯è¯¾ä¸Šå”¯ä¸€ä¸€ä¸ªé»‘å“¥ï¼ŒçœŸçš„éå¸¸åŠªåŠ›ã€‚ä½†æ˜¯è¯´å®è¯æœ‰çš„æ—¶å€™å¿™ä¸åˆ°ç‚¹ä¸Šå»ï¼Œå¿™äº†ç™½å¿™ã€‚æœ€åRSAå› ä¸ºä¸€ä¸ªè«åå…¶å¦™çš„bugï¼Œåˆæ˜¯ä½äºä¸€ä¸ªmedian (128 commits) A3(Ralph)ï¼šæˆ‘æœ€çˆ±çš„æ•°æ®ç»“æ„ï¼ŒChinese American é˜Ÿå‹ï¼Œå¼ºæ˜¯çœŸçš„å¼ºã€‚å¯ä»¥ç›´æ¥æ— éšœç¢è¯»Javaæºç ï¼Œä»–çš„hashTableä¼°è®¡å°±æ˜¯è¿™æ ·å†™å‡ºæ¥çš„ï¼Œä¸ç„¶æ›´å¼ºï¼Œå› ä¸ºä»–çš„hashTableå†™å¾—å®åœ¨å¤ªå¥½äº†ã€‚åŸºæœ¬ä¸Šè¢«ä»–å¸¦äº†ï¼Œæˆ‘å°±å†™äº†ä¸ªtrieè€Œå·²ã€‚ä½†æœ‰å¯èƒ½æ˜¯å› ä¸ºè¿™æ¬¡ä½œä¸šå¤ªç®€å•ï¼Œè€Œä¸”ç›¸å¯¹ç‹¬ç«‹ï¼Œæˆ‘ä¿©éƒ½è§‰å¾—ä¸éœ€è¦å’Œå¯¹æ–¹äº¤æµï¼Œç»“æœæ²¡ä»€ä¹ˆå›¢é˜Ÿåˆä½œçš„æ„Ÿè§‰ï¼Œåšçš„è¿˜ä¸å¦‚A2å¸¦æ„Ÿ (152 commits) A4(Xinyu &amp; Faizaan)ï¼šç»ˆäºæœ‰ä¸­å›½äººæ²¡æœ‰é˜Ÿå‹äº†ï¼ˆï¼Œæ‰€ä»¥æ˜¯ä¸€ä¸ªä¸­å›½å¦¹å­å’Œä¸€ä¸ªç¾å›½äººåšå¾—é˜Ÿå‹ã€‚è¿™ä¸ªç¾å›½äººï¼ŒçœŸçš„ä¸æ­£ç»ï¼Œæ˜æ˜èƒ½æå‰åšå®Œéè¦æ‹–åˆ°æœ€åä¸€ç§’å†™ã€‚å¹¸äºå› ä¸ºA4æ•´ä¸ªç»“æ„æ˜¯æˆ‘å†™çš„ï¼Œæˆ‘å‡ ä¹å¯¹å®ƒæœ‰ç»å¯¹äº†è§£å’ŒæŒæ§ï¼Œè¿›è¡Œå¾—è¿˜æ˜¯å¾ˆé¡ºåˆ©çš„ã€‚è¿™ä¸ªä¸­å›½å°å§‘å¨˜æ˜¯çœŸçš„å¼ºï¼Œç»™å¥¹è®²æ˜ç™½äº†å°±èƒ½å†™ï¼Œå†™å‡ºæ¥è¿˜ä¸€ç‚¹éƒ½æ²¡bug A5(Xinyu &amp; Faizaan)ï¼šå› ä¸ºA4æˆ‘è¦å…³å¿ƒçš„ä¸œè¥¿å¤ªå¤šï¼Œæ•´ä¸ªç»™æˆ‘æ•´è™šè„±äº†ï¼Œäºæ˜¯æˆ‘æŠŠA5å…¨æƒäº¤ç»™äº†ç¾å›½äººï¼Œç»“æœä½œä¸ºä»£ç é‡æœ€å¤§çš„projectä¹‹ä¸€ï¼Œä»–åˆæ²¡å†™å®Œï¼Œåº”è¯¥æ˜¯æˆ‘åšçš„æœ€å·®çš„ä¸€æ¬¡ä½œä¸šã€‚ä½†æ˜¯æœ€åæˆç»©æ²¡æœ‰æƒ³è±¡çš„é‚£ä¹ˆå·®ï¼Œä¸»è¦æ‰¹çš„æ¾ã€‚ A6(Xinyu &amp; Faizaan)ï¼šå› ä¸ºæˆ‘æ‡’å¾—å­¦ä¹ JavaFxä¸€å †ä¹±ä¸ƒå…«ç³Ÿçš„è¯­æ³•ï¼Œæ‰€ä»¥æˆ‘åˆå…¨æƒäº¤ç»™äº†ç¾å›½äººï¼Œè¿™ä¸ªæ—¶å€™å…¶å®æœ‰ç‚¹ç ´ç½å­ç ´æ‘”çš„æ„Ÿè§‰ã€‚åŒæ—¶æˆ‘æŠŠA5ç”¨ä¸äº†çš„åœ°æ–¹æ•´ä¸ªé‡å†™äº†ä¸€éã€‚æœ€åä¸€æ™šä¸Šéå¸¸åˆºæ¿€ï¼Œè™½ç„¶æˆ‘ä»¬deadlineä¹‹å‰ä¸€ä¸ªå°æ—¶åšå®Œäº†ï¼Œä½†æ˜¯æœ€åä¸€åˆ»æˆ‘æ”¹äº†æ”¹ä¸€äº›é”™è¯¯ä¿¡æ¯å±•ç¤ºçš„ä»£ç è®©æ•´ä¸ªGUIæ›´å¥½çœ‹ï¼Œç»“æœåœ¨æµ‹è¯•çš„æ—¶å€™å‘ç°äº†ä¸€ä¸ªbugã€‚æˆ‘ä»¥ä¸ºæ˜¯æˆ‘çš„é”™è¯¯ï¼Œäºæ˜¯git resetå›å»ï¼Œäº¤ä¸Šäº†ä»¥å‰çš„ç‰ˆæœ¬ã€‚åˆºæ¿€åœ¨äºæˆ‘å¡ç€deadlineäº¤ä¸Šçš„ï¼Œæ›´åˆºæ¿€çš„æ˜¯æˆ‘äº¤å®Œä»¥åå‘ç°æˆ‘äº¤çš„ä»ç„¶æ˜¯æœ€æ–°ç‰ˆæœ¬ï¼Œæ‰€ä»¥bugä»ç„¶å­˜åœ¨ï¼Œå¿ƒæƒ…èµ·ä¼æœ€å¤§çš„ä¸€æ™šä¸Šã€‚ï¼ˆä¸è¿‡æœ€åå‘ç°å’Œæˆ‘é‚£ä¸€ä¸ªå°æ—¶çš„æ”¹åŠ¨æ²¡å…³ç³»ï¼Œæ˜¯modelä¸æ˜¯GUIå‡ºäº†é—®é¢˜ï¼‰ A7(Xinyu &amp; Faizaan)ï¼šserveræˆ‘è§‰å¾—è¿˜æ˜¯è¦å­¦ä¸€ä¸‹çš„ï¼Œå’ŒA4ä¸€æ ·è¯•ç€å†™äº†ä¸ªç»“æ„ã€‚å°å§‘å¨˜å¸®æˆ‘æŠŠserverå…¨å†™å®Œäº†ï¼Œæœ€å¯æ€•çš„æ˜¯ä¸€ä¸ªbugéƒ½æ²¡æœ‰ï¼ŒçœŸçš„å“äººã€‚ç¾å›½äººå¯èƒ½å› ä¸ºè¦å‡†å¤‡è‡ªå·±çš„Finalï¼Œæ‰€ä»¥è¿™ä¸€æ¬¡ç«Ÿç„¶åœ¨deadlineä¹‹å‰å…­ä¸ƒä¸ªå°æ—¶å°±å†™å®Œäº†ï¼Œç„¶åæ—©æ—©æäº¤ä¸Šå»äº†ã€‚éå¸¸æ»¡æ„çš„ä¸€æ¬¡ä½œä¸šï¼ˆä¹Ÿæ˜¯é™¤A3å¤–å”¯ä¸€çš„é«˜äºmediançš„ä½œä¸šï¼‰(475 commits in total) æœ¬æ¥æŒ‡ç€Finalé‡Œé¢æ“…é•¿çš„ç®—æ³•å’Œæ•°æ®ç»“æ„ææåˆ†ï¼Œç»“æœFinalå‡ºç‚¹è¿‡äºç®€å•ï¼Œå¹¶æ‹‰ä¸å¼€åˆ†å·®ã€‚è¦æ˜¯å‡ºåˆ°å’Œç»™çš„exampleåŒä¸€ä¸ªéš¾åº¦ï¼Œæˆ‘æ˜¯æœ‰ä¿¡å¿ƒè¿™èŠ‚è¯¾æ‹¿Açš„ã€‚ MATH 2210 Linear Algebra æˆ‘çš„æ•™æˆæ˜¯ä¸ªè€çˆ·å­(James West) ï¼Œè€çˆ·å­å¿«ä¹åäº†å§ï¼Œä¸€å¥è¯è¯´åˆ°æœ€åä¸€ä¸ªè¯çš„æ—¶å€™æˆ‘å·²ç»å¿˜äº†ä»–ç¬¬ä¸€ä¸ªè¯´çš„è¯æ˜¯ä»€ä¹ˆäº†ï¼ŒäººçœŸçš„å¾ˆå¥½ï¼Œå¯æ˜¯è„‘å­ç¡®å®è€åŒ–äº†ï¼Œå¹¶ä¸æ˜¯é‚£ä¸ªæœ€å¥½çš„è®²å¸ˆã€‚ åæ¥æ¢åˆ° Myer çš„ sessionï¼Œè®²å¾—ç¡®å®ä¸é”™ï¼ˆWest é‚£é‡Œçš„äººå…¨è·‘å¥¹é‚£å»äº†ï¼‰ï¼Œæœ€åä¸€ä¸ª OH è¿˜å¤šç•™äº†ä¸‰ååˆ†é’Ÿä¸“é—¨ç»™æˆ‘æŠŠ Inner Product Space è®²æ˜ç™½äº†ï¼Œä¸€ä½ä¼˜é›…åˆå–„è‰¯çš„å¥³è€å¸ˆã€‚ DEA 1500 Intro to Environ. Psychology æœ¬ä¸“ä¸šå”¯ä¸€ä¸€èŠ‚æˆ‘è§‰å¾—å¯ä»¥ä¸Šçš„è¯¾ï¼Œè€Œä¸”è¯„ä»·ä¹Ÿå¾ˆå¥½ï¼Œäºæ˜¯å°±ä¸Šäº†ã€‚Gary Evans ç»å¯¹æ˜¯æ•°ä¸€æ•°äºŒçš„è®²å¸ˆï¼Œæ¸…æ™°æœ‰æ¡ç†ï¼Œè¯¾ç¨‹å†…å®¹ä¹Ÿå¾ˆæœ‰è¶£ï¼ˆè™½ç„¶åæœŸæœ‰äº›åŒè´¨åŒ–ï¼‰ã€‚å¦‚æœè¯´ç¾å›½1%çš„äººæŒæ¡ç€99%çš„è´¢å¯Œï¼Œé‚£æˆ‘ä¹Ÿè¦è¯´ç¾å›½1%çš„èªæ˜å¹¶çœŸæ­£æœ‰ç€äººæ–‡æƒ…æ€€çš„äººé¢†åˆ°äº†99%çš„å‚»å­ï¼Œå°±æ˜¯è¿™1%çš„äººæ„å»ºäº†éƒ¨åˆ†äººå¿ƒç›®ä¸­çš„äººç±»æ–‡æ˜ç¯å¡”ã€‚Gary å°±æ˜¯é‚£ä¸ª1%ã€‚èƒ½ä»ä»–çš„è¯¾ä¸­æ„Ÿå—åˆ°ä»–å¯¹è¿™ä¸ªæ˜Ÿçƒç”šè‡³æ•´ä¸ªäººç±»çš„çˆ±ã€‚ Sometimes we focus on Chinaâ€™s carbon footprint and says it should regulate more. However, look at the data of the United States per capita. Iâ€™m not saying China shouldnâ€™t regulate more, but isnâ€™t it a little hypocritical to ask China to do more regulations while we are producing more than them? è™½ç„¶ä¸æƒ³æ§ä¸€è¸©ä¸€ï¼Œä½†æ˜¯Garyå…¶å®åº”è¯¥ä¹Ÿå¾ˆè€äº†ã€‚å³ä½¿å¦‚æ­¤å´ä¸€ç›´ç”¨é¥±æ»¡çš„ç²¾ç¥ä¸ºå¤§å®¶å‘ˆç°è¿™é—¨è¯¾ï¼Œæœ€åå‡ ä¸ªlectureä¸çŸ¥é“ä»–æ€ä¹ˆäº†ï¼Œæœ‰çš„æ—¶å€™ä¼šå¤±æ‰è‡ªå·±çš„å£°éŸ³ï¼Œæ•´ä¸ªå£°éŸ³çªç„¶å°±å˜å“‘äº†ï¼Œé‚£ä¸ªæ—¶å€™çœŸçš„æ˜¯å¿ƒç–¼ä»–ã€‚ä»–çš„æœ€åä¸€è¯¾æˆ‘ä¼šæ°¸è¿œè®°åœ¨å¿ƒé‡Œã€‚ æˆ‘çŸ¥é“ä½ ä»¬ä¸­æœ‰å¾ˆå¤šäººæ˜¯å„æ–¹é¢çš„ç§¯æåˆ†å­ï¼Œæ¯”å¦‚ç¯ä¿ä¸»ä¹‰è€…ï¼Œä½ æœ‰çš„æ—¶å€™ä¹Ÿè§‰å¾—ä¸ºä»€ä¹ˆå¤§å®¶éƒ½ä¸ç†è§£æˆ‘åœ¨åšçš„äº‹éƒ½æ˜¯ä¸ºäº†ä»–ä»¬å¥½ï¼Œä½ æœ‰çš„æ—¶å€™ä¹Ÿä¼šè§‰å¾—è‡ªå·±éå¸¸æ— åŠ©ã€‚æˆ‘è¦å‘å¤§å®¶å±•ç¤ºè¿™ä¸€å¥è¯ï¼šè¿™äº›åšå‡ºå·¨å¤§æ”¹å˜çš„è¿åŠ¨ï¼Œå¾€å¾€æ˜¯ç”±ä¸€å°ç¾¤äººé¢†å¯¼çš„ã€‚å›æƒ³ä¸€ä¸‹ï¼Œä»–ï¼ˆç”˜åœ°ï¼‰å½“æ—¶æ˜¯å¤§å¤šæ•°å—ï¼Ÿä»–ï¼ˆé©¬ä¸è·¯å¾·é‡‘ï¼‰ä¹Ÿä¸æ˜¯ã€‚ä½ å¯èƒ½è§‰å¾—è¿™äº›äººéƒ½æ˜¯ä¸€å¼€å§‹å°±éå¸¸ä¼Ÿå¤§çš„ â€¦ è¿™ä¸ªå½“æ—¶åªæœ‰åäºŒå²çš„å°å¥³å­©ï¼Œå‘ä¸–ç•Œæ­éœ²äº†çº³ç²¹çš„ç½ªè¡Œï¼Œå¥¹å½“æ—¶æœ‰å¤šä¹ˆå¼ºå¤§çš„èƒ½åŠ›å—ï¼Ÿâ€¦ æœ‰æ—¶ä½ å¯èƒ½ä¼šè§‰å¾—å¾ˆæ— åŠ›ï¼Œä½†æ˜¯è®°ä½Margaretè¯´äº†ä»€ä¹ˆï¼šæ°¸è¿œéƒ½æ˜¯é‚£ä¸€å°éƒ¨åˆ†äººã€‚ â€“ Gary Evans, 2019/12/09 Donâ€™t Feel Helpless WRIT 1370 FWS: Elements of Acad Wtg Bradæ˜¯ä¸ªç¨å¾®å¸¦ç‚¹ç—æ°”çš„ä¸é”™çš„äººï¼Œè™½ç„¶è¿™è¯¾å«åš Metaphor in Art, Science and Culture ä½†æˆ‘å®é™…ä¸Šè§‰å¾—ä»–å…¶å®è¿™ä¸‰ä¸ªéƒ½å¹¶ä¸å¾ˆæ‡‚â€¦ Donâ€™t be Strangers. â€“ Brad Zukovic, 2019/12/06 CS5199 Comp Program &amp; Problem Solving ç‹—å±è¯¾ï¼Œè¯¾ç¨‹éƒ½è¿›è¡Œäº†ä¸€å¤§åŠäº†æ‰å‘Šè¯‰åˆ«äººç”¨ä»€ä¹ˆæ–¹å¼è®¡ç®—attendanceï¼Œå¹¸äºæœ€åè¿æ°”å¥½åˆšåˆšå¥½åˆ°äº†passçš„çº¿ï¼Œä¸ç„¶è¦æ˜¯ç¬¬ä¸€å­¦æœŸæˆç»©å•ä¸Šå°±æœ‰ä¸ªfailæˆ–è€…withdrawï¼Œé‚£æ˜¯çœŸçš„éš¾çœ‹ã€‚ PE1395 Self Defense æŒºå¥½ç©çš„","categories":[],"tags":[{"name":"Cornell","slug":"Cornell","permalink":"https://yao-lirong.github.io/blog/tags/Cornell/"},{"name":"Review","slug":"Review","permalink":"https://yao-lirong.github.io/blog/tags/Review/"}]},{"title":"Add pdf file to hexo","slug":"2019-12-17-add-pdf-file-to-hexo","date":"2019-12-17T05:00:00.000Z","updated":"2022-06-08T19:34:22.000Z","comments":true,"path":"2019-12-17-add-pdf-file-to-hexo/","permalink":"https://yao-lirong.github.io/blog/2019-12-17-add-pdf-file-to-hexo/","excerpt":"Say youâ€™ve put book.pdf in ./source/books/, then put something like [Download my book!](/books/book.pdf) anywhere in the article and it will create the link for you. Cited From hexo","text":"Say youâ€™ve put book.pdf in ./source/books/, then put something like [Download my book!](/books/book.pdf) anywhere in the article and it will create the link for you. Cited From hexo","categories":[],"tags":[{"name":"Logistics","slug":"Logistics","permalink":"https://yao-lirong.github.io/blog/tags/Logistics/"}]},{"title":"Import Junit and JavaFx into VSCode","slug":"2019-11-21-import-Junit-and-JavaFx-into-VSCode","date":"2019-11-21T05:00:00.000Z","updated":"2022-07-17T05:37:34.000Z","comments":true,"path":"2019-11-21-import-Junit-and-JavaFx-into-VSCode/","permalink":"https://yao-lirong.github.io/blog/2019-11-21-import-Junit-and-JavaFx-into-VSCode/","excerpt":"The import javafx cannot be resolved I have java 11 installed on my computer. JavaFx was not bundled with Java 11 so I have to first download it from here and put it at the same directory as Java jdk. But VScode still gives me the error â€œThe import javafx cannot be resolvedâ€. This was resolved after I ran Java: Clean the Java Language Server workspace, though I have no idea how VSCode magically found the directory of JavaFx.","text":"The import javafx cannot be resolved I have java 11 installed on my computer. JavaFx was not bundled with Java 11 so I have to first download it from here and put it at the same directory as Java jdk. But VScode still gives me the error â€œThe import javafx cannot be resolvedâ€. This was resolved after I ran Java: Clean the Java Language Server workspace, though I have no idea how VSCode magically found the directory of JavaFx. The import Junit.Jupiter cannot be resolved I downloaded Junit.Jupiter.api (the package I used for my tests) from here and put the jar file under workspace\\lib. Then problem was solved. Tests are now runnable.","categories":[],"tags":[{"name":"Logistics","slug":"Logistics","permalink":"https://yao-lirong.github.io/blog/tags/Logistics/"}]},{"title":"P1162 å¡«æ¶‚é¢œè‰²","slug":"2019-07-07-P1162-å¡«æ¶‚é¢œè‰²","date":"2019-07-07T04:00:00.000Z","updated":"2019-10-06T21:02:30.000Z","comments":true,"path":"2019-07-07-P1162-å¡«æ¶‚é¢œè‰²/","permalink":"https://yao-lirong.github.io/blog/2019-07-07-P1162-%E5%A1%AB%E6%B6%82%E9%A2%9C%E8%89%B2/","excerpt":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1162 å¡«æ¶‚é¢œè‰² å¦‚æœè¢«åŒ…å›´çš„éƒ¨åˆ†æ²¡ä»€ä¹ˆç‰¹ç‚¹ï¼Œé‚£ä¹ˆå°±å¯ä»¥çœ‹çœ‹å…¶ä»–éƒ¨åˆ†æœ‰æ²¡æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Œæœ¬é¢˜ä¸­å°±æ˜¯å¯ä»¥ä»å¤–å›´å¼€å§‹æœç´¢ï¼Œæœåˆ°å¢™å°±åœä¸‹ï¼Œæœ€åæ²¡è¢«æœåˆ°çš„éƒ¨åˆ†å°±æ˜¯è¢«å¢™åŒ…å›´çš„éƒ¨åˆ† ä¸ºäº†é˜²æ­¢å¤–å›´èµ·ç‚¹å°±æ˜¯å¢™ï¼Œæˆ–è€…æ˜¯å¤–å›´çš„0è¢«å¢™åˆ†ä¸ºå¥½å‡ éƒ¨åˆ†å¯¼è‡´æˆ‘ä»¬æ— æ³•æœç´¢åˆ°è¢«åˆ†å‰²çš„éƒ¨åˆ†ï¼Œå¯ä»¥å¤šå¼€ä¸€åœˆæ•°ç»„ï¼Œä½¿å¾—å¤–å›´ç›¸äº’è¿æ¥èµ·æ¥ï¼Œç¡®ä¿ä¸è¢«åŒ…å›´çš„0ä¸€å®šå¯ä»¥è¢«æœåˆ°","text":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1162 å¡«æ¶‚é¢œè‰² å¦‚æœè¢«åŒ…å›´çš„éƒ¨åˆ†æ²¡ä»€ä¹ˆç‰¹ç‚¹ï¼Œé‚£ä¹ˆå°±å¯ä»¥çœ‹çœ‹å…¶ä»–éƒ¨åˆ†æœ‰æ²¡æœ‰ä»€ä¹ˆç‰¹ç‚¹ï¼Œæœ¬é¢˜ä¸­å°±æ˜¯å¯ä»¥ä»å¤–å›´å¼€å§‹æœç´¢ï¼Œæœåˆ°å¢™å°±åœä¸‹ï¼Œæœ€åæ²¡è¢«æœåˆ°çš„éƒ¨åˆ†å°±æ˜¯è¢«å¢™åŒ…å›´çš„éƒ¨åˆ† ä¸ºäº†é˜²æ­¢å¤–å›´èµ·ç‚¹å°±æ˜¯å¢™ï¼Œæˆ–è€…æ˜¯å¤–å›´çš„0è¢«å¢™åˆ†ä¸ºå¥½å‡ éƒ¨åˆ†å¯¼è‡´æˆ‘ä»¬æ— æ³•æœç´¢åˆ°è¢«åˆ†å‰²çš„éƒ¨åˆ†ï¼Œå¯ä»¥å¤šå¼€ä¸€åœˆæ•°ç»„ï¼Œä½¿å¾—å¤–å›´ç›¸äº’è¿æ¥èµ·æ¥ï¼Œç¡®ä¿ä¸è¢«åŒ…å›´çš„0ä¸€å®šå¯ä»¥è¢«æœåˆ° 1234567891011121314151617181920212223242526272829303132333435363738#include&lt;iostream&gt;#include&lt;cstdio&gt;using namespace std;int n,dir[4][2]=&#123;&#123;1,0&#125;,&#123;-1,0&#125;,&#123;0,1&#125;,&#123;0,-1&#125;&#125;;bool graph[32][32],vis[32][32];///graph è®°å½•è¿™ä¸ªå›¾åŸæ¥æ˜¯0è¿˜æ˜¯1ï¼ˆç©ºè¿˜æ˜¯å¢™ï¼‰ï¼Œvisè®°å½•è¢«æ²¡è¢«è®¿é—®è¿‡///æ³¨æ„è¿™ä¸¤ä¸ªæ•°ç»„éƒ½æ˜¯å¼€çš„32ï¼ˆæ•°æ®æ˜¯1~30ï¼Œæœ¬æ¥å¼€31å°±å¤Ÿäº†ï¼‰ä¿è¯äº†å¤–é¢åˆä¸€åœˆ0ï¼Œä¹Ÿå°±æ˜¯æœ€å¤–é¢çš„ä¸€åœˆéƒ½æ˜¯è”é€šçš„ï¼Œé¿å…äº†ç¬¬ä¸€ä¸ªç‚¹1,1å°±æ˜¯å¢™å¯¼è‡´å¾ªç¯å¾ªç¯ä¸ä¸‹å»çš„æƒ…å†µï¼Œä¹Ÿé¿å…äº†ä¸€å µå¢™æŠŠä¸­é—´å…¨éƒ¨å µæ­»ï¼Œåªæ‰«äº†å¢™å·¦è¾¹çš„0ï¼Œæ²¡æ‰«åŒåœ¨å¢™å¤–ä½†åœ¨å¢™å³è¾¹çš„0çš„æƒ…å†µvoid dfs(int, int);int main()&#123; cin&gt;&gt;n; for(int i=1;i&lt;=n;i++) for(int j=1;j&lt;=n;j++) cin&gt;&gt;graph[i][j]; dfs(0,0); for(int i=1;i&lt;=n;i++)&#123; for(int j=1;j&lt;=n;j++)&#123; if(vis[i][j]) cout&lt;&lt;&quot;0 &quot;;///å¦‚æœè®¿é—®è¿‡ï¼Œé‚£ä¹ˆä¸€å®šæ˜¯å¢™å¤–çš„0 else if(graph[i][j]) cout&lt;&lt;&quot;1 &quot;;///è¾“å…¥æ—¶åŸæœ¬æ˜¯å¢™ï¼Œé‚£ä¹ˆå®ƒè¿˜æ˜¯å¢™ï¼ˆè¿™ä¸€å¥å¯ä»¥å’Œä¸Šé¢é‚£ä¸€å¥äº’æ¢ä½ç½®ï¼‰ else cout&lt;&lt;&quot;2 &quot;;///åŠæ²¡è¢«è®¿é—®è¿‡ï¼Œè¾“å…¥æ—¶ä¹Ÿä¸æ˜¯å¢™ï¼Œé‚£ä¹ˆè‚¯å®šæ˜¯è¢«åŒ…å›´åœ¨é‡Œé¢çš„0 &#125; cout&lt;&lt;endl; &#125; return 0;&#125;void dfs(int x, int y)&#123; if( x&lt;0 | x&gt;n+1 | y&lt;0 | y&gt;n+1 | graph[x][y] | vis[x][y] ) ///å¦‚æœ1.è¶Šç•Œï¼ˆæ³¨æ„æ˜¯ &lt;0|&gt;n+1 è¿™é‡Œå¯ä»¥çœ‹å‡ºæ¥æˆ‘ä»¬å¤šå¼€äº†ä¸€åœˆ0åœ¨åŸè¾“å…¥å¤–é¢ï¼‰ ///2.æ˜¯å¢™|è¢«è®¿é—®è¿‡ é‚£ä¹ˆä¸åšæ“ä½œ return; vis[x][y]=true; for(int i=0;i&lt;4;i++) dfs(x+dir[i][0],y+dir[i][1]);&#125;","categories":[],"tags":[{"name":"NOI","slug":"NOI","permalink":"https://yao-lirong.github.io/blog/tags/NOI/"}]},{"title":"P1141 01è¿·å®«","slug":"2019-07-04-P1141-01è¿·å®«","date":"2019-07-04T04:00:00.000Z","updated":"2019-10-06T21:02:22.000Z","comments":true,"path":"2019-07-04-P1141-01è¿·å®«/","permalink":"https://yao-lirong.github.io/blog/2019-07-04-P1141-01%E8%BF%B7%E5%AE%AB/","excerpt":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1141 01è¿·å®« BFSæ‰¾è¿é€šå— è¿é€šå—è‚¯å®šè¿˜æ˜¯DFSæ‰¾å¾—å¿«ï¼Œå› ä¸ºä¸€å¼€å§‹ä¸çŸ¥é“ä»€ä¹ˆæ˜¯è¿é€šå—æ‰€ä»¥å†™äº†ä¸ªBFS æœç´¢è¿é€šå—ä¸éœ€è¦è®°å½•ä»æŸä¸€ä¸ªç‚¹å‡ºå‘æœ€è¿œèƒ½åˆ°è¾¾å“ªä¸ªç‚¹ï¼ˆBFSæœç´¢æœ€çŸ­è·ç¦»ï¼‰ï¼Œåªéœ€è¦è®°å½•ä»æŸä¸€ä¸ªç‚¹å‡ºå‘ä¸€å…±ç»è¿‡äº†å¤šå°‘ä¸ªç¬¦åˆæ¡ä»¶çš„ç‚¹å°±è¡Œäº†ï¼ˆBFSæœç´¢è¿é€šå—ï¼‰ï¼Œå› ä¸ºå¦‚æœAå’ŒBè”é€šï¼ŒBå’ŒCè”é€šï¼Œé‚£ä¹ˆAå’ŒCå¿…ç„¶è”é€šï¼Œæ‰€ä»¥ä¸€æ¬¡æœç´¢èƒ½è¾¾åˆ°çš„æ‰€æœ‰ç‚¹å¿…å®šåœ¨åŒä¸€ä¸ªè¿é€šå—å†…","text":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1141 01è¿·å®« BFSæ‰¾è¿é€šå— è¿é€šå—è‚¯å®šè¿˜æ˜¯DFSæ‰¾å¾—å¿«ï¼Œå› ä¸ºä¸€å¼€å§‹ä¸çŸ¥é“ä»€ä¹ˆæ˜¯è¿é€šå—æ‰€ä»¥å†™äº†ä¸ªBFS æœç´¢è¿é€šå—ä¸éœ€è¦è®°å½•ä»æŸä¸€ä¸ªç‚¹å‡ºå‘æœ€è¿œèƒ½åˆ°è¾¾å“ªä¸ªç‚¹ï¼ˆBFSæœç´¢æœ€çŸ­è·ç¦»ï¼‰ï¼Œåªéœ€è¦è®°å½•ä»æŸä¸€ä¸ªç‚¹å‡ºå‘ä¸€å…±ç»è¿‡äº†å¤šå°‘ä¸ªç¬¦åˆæ¡ä»¶çš„ç‚¹å°±è¡Œäº†ï¼ˆBFSæœç´¢è¿é€šå—ï¼‰ï¼Œå› ä¸ºå¦‚æœAå’ŒBè”é€šï¼ŒBå’ŒCè”é€šï¼Œé‚£ä¹ˆAå’ŒCå¿…ç„¶è”é€šï¼Œæ‰€ä»¥ä¸€æ¬¡æœç´¢èƒ½è¾¾åˆ°çš„æ‰€æœ‰ç‚¹å¿…å®šåœ¨åŒä¸€ä¸ªè¿é€šå—å†… å¦‚æœå¯¹äºæ¯ä¸ªæŸ¥è¯¢æˆ‘ä»¬éƒ½æœç´¢ä¸€éçš„è¯è‚¯å®šä¼šè¶…æ—¶ï¼Œæ‰€ä»¥æˆ‘ä»¬ç”¨visæ•°ç»„è®°å½•ä¸‹æ¥ä¸€æ¬¡æœç´¢ä¸­æ‰€æœ‰ç»è¿‡çš„ç‚¹æ‰€åœ¨çš„ï¼ˆå¿…å®šæ˜¯åŒä¸€ä¸ªï¼‰è¿é€šå—çš„åºå·ï¼Œansæ•°ç»„è®°å½•ç›¸åº”åºå·çš„è¿é€šå—ä¸­å…±æœ‰å‡ ä¸ªç‚¹ï¼Œä¸‹æ¬¡å¦‚æœè¯¢é—®çš„ç‚¹å·²ç»è¢«æœç´¢è¿‡å°±å¯ä»¥å…å»æœç´¢ç›´æ¥è¾“å‡ºç­”æ¡ˆäº†ã€‚ ç¨‹åºå‘æœ¬æ¥è¢«å°æ­»çš„åœ°æ–¹èµ°äº†ä¸€æ­¥ï¼Œå¯èƒ½æ˜¯åˆå§‹åŒ–çš„é—®é¢˜ã€‚åˆå§‹åŒ–å°±åˆ«ç”¨é‚£äº›èŠ±é‡Œèƒ¡å“¨çš„å¥å­äº†ï¼Œè¿˜æ˜¯è€è€å®å®å†™forå¾ªç¯å§ï¼Œåæ­£æ—¶é—´ç©ºé—´å¤Ÿç”¨ï¼Œåˆ«çš„å¥å­å¤ªå®¹æ˜“å‡ºé”™ è«åå…¶å¦™è¾“å‡ºæ¥å‡ åä¸‡çš„æ•°æ®ï¼Œä¼°è®¡æ˜¯çˆ†å†…å­˜äº†ï¼Œæ•°ç»„ä¸€å®šè¦æ ¹æ®é¢˜ç›®è¦æ±‚å¼€å¾—è¶³å¤Ÿå¤§ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include&lt;cstring&gt;#include&lt;cstdio&gt;#include&lt;iostream&gt;#include&lt;queue&gt;#include&lt;algorithm&gt;using namespace std;struct node&#123; int x,y;&#125;;int m,n,question[100005][2],dir[4][2]=&#123;&#123;1,0&#125;,&#123;-1,0&#125;,&#123;0,1&#125;,&#123;0,-1&#125;&#125;,vis[1003][1003],ans[100005],connect=1; bool maze[1003][1003];///question å­˜å‚¨äº†æ¯ç»„è¯¢é—®çš„èµ·ç‚¹åæ ‡///vis = 0 ä»£è¡¨è¿™ä¸ªç‚¹æ²¡èµ°è¿‡ï¼Œç°åœ¨ä¸åœ¨ä»»ä½•ä¸€ä¸ªè¿é€šå—é‡Œé¢ï¼›vis = x (x&gt;0) ä»£è¡¨è¿™ä¸ªç‚¹èµ°è¿‡äº†ï¼Œå¹¶ä¸”åœ¨xå·è¿é€šå—é‡Œé¢ï¼›è¿™ä¸ªæ•°ç»„ä¸€å®šè¦å¼€å¤§ï¼Œåªå¼€åˆ°1003æ˜¯ä¸è¡Œçš„ï¼Œå¿…é¡»è¦å¼€åˆ°å’Œquestionä¸€ä¸ªæ•°é‡çº§///ans å­˜å‚¨æ¯ä¸ªè¿é€šå—é‡Œé¢å…±æœ‰å‡ ä¸ªç‚¹///maze å­˜å‚¨è¿™ä¸ªè¿·å®«///connect ä»£è¡¨å„ä¸ªè¿é€šå—çš„åºå·int bfs(int, int); bool legal(node, node);int main()&#123; cin&gt;&gt;n&gt;&gt;m; for(int i=1;i&lt;=n;i++) for(int j=1;j&lt;=n;j++)&#123; char a; cin&gt;&gt;a; if(a==&#x27;0&#x27;) maze[i][j]=0; else if(a==&#x27;1&#x27;) maze[i][j]=1; &#125;///å› ä¸ºæ¯ä¸ªè¾“å…¥ä¹‹é—´æ˜¯ä¸ç©ºæ ¼çš„ï¼Œæ‰€ä»¥ç”¨charæ¥è¾“å…¥åšä¸€ä¸ªå·§å¦™çš„å¤„ç† for(int i=1;i&lt;=m;i++) cin&gt;&gt;question[i][0]&gt;&gt;question[i][1]; ///åˆå§‹åŒ–æœ€åå‡ºäº†å¾ˆå¤§é—®é¢˜ï¼Œè¿˜æ˜¯ç”¨æœ€ä¿é™©çš„forå¾ªç¯ for(int i=0;i&lt;100005;i++) ans[i]=1; for(int i=0;i&lt;1003;i++) for(int j=0;j&lt;1003;j++) vis[i][j]=0; for(int i=1;i&lt;=m;i++) cout&lt;&lt;bfs(question[i][0],question[i][1])&lt;&lt;endl; return 0;&#125;bool legal(node now, node next)&#123; ///è¿™é‡Œä¸éœ€è¦åˆ†æƒ…å†µè®¨è®ºâ€œå¦‚æœ now==0 åˆ™å¿…é¡» next==1â€ æˆ–ç›¸åï¼Œåªéœ€è¦ç¡®ä¿nowå’Œnextçš„å€¼ä¸åŒå°±è¡Œäº† return maze[now.x][now.y]!=maze[next.x][next.y] &amp;&amp; next.x&gt;=1 &amp;&amp; next.x&lt;=n &amp;&amp; next.y&gt;=1 &amp;&amp; next.y&lt;=n &amp;&amp; vis[next.x][next.y]==0;&#125;int bfs(int x, int y)&#123; queue &lt;node&gt; q; node start; start.x = x; start.y = y; if(vis[start.x][start.y]==0)&#123;///å¦‚æœè¿™ä¸ªç‚¹ä¸åœ¨ç°æœ‰çš„ä»»ä½•ä¸€ä¸ªè¿é€šå—å†…ï¼Œåˆ™è¿›å…¥é˜Ÿåˆ—ï¼Œå¼€å§‹bfs vis[start.x][start.y] = connect; q.push(start); &#125; else return ans[vis[start.x][start.y]];///å¦‚æœè¿™ä¸ªç‚¹åœ¨æŸä¸ªè¿é€šå—å†…ï¼Œåˆ™ç›´æ¥è¾“å‡ºæ­¤è¿é€šå—å¯¹åº”çš„ç»“æœ while(!q.empty())&#123; node now = q.front(); q.pop(); for(int i=0;i&lt;4;i++)&#123; node next; next.x = now.x + dir[i][0]; next.y = now.y + dir[i][1]; if(legal(now,next))&#123; vis[next.x][next.y] = connect;///è®°å½•ä¸‹æ¥ç‚¹nextå±äºè¿é€šå—connect ans[connect]++;///è¿é€šå—connectä¸­æ€»ç‚¹æ•°+1 q.push(next); &#125; &#125; &#125; return ans[connect++];///æ‰€æœ‰å±äºconnectçš„ç‚¹éƒ½æœå®Œäº†ï¼Œè¿”å›ç­”æ¡ˆï¼Œå¹¶ä½¿connect++ï¼Œè¡¨ç¤ºæ¥ä¸‹æ¥è¦æ‰«çš„æ˜¯æ–°çš„è¿é€šå—&#125;","categories":[],"tags":[{"name":"NOI","slug":"NOI","permalink":"https://yao-lirong.github.io/blog/tags/NOI/"}]},{"title":"P1118 Backward Digital Sums","slug":"2019-07-02-P1118-Backward-Digital-Sums","date":"2019-07-02T04:00:00.000Z","updated":"2019-10-06T21:02:08.000Z","comments":true,"path":"2019-07-02-P1118-Backward-Digital-Sums/","permalink":"https://yao-lirong.github.io/blog/2019-07-02-P1118-Backward-Digital-Sums/","excerpt":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1118 æ•°å­—ä¸‰è§’å½¢ æš´åŠ›æœç´¢ çœ‹åˆ°é¢˜ç›®çš„ç¬¬ä¸€çœ¼æƒ³çš„å°±æ˜¯ç›´æ¥æœï¼Œå‘ç°ä¸å°‘TLEï¼Œæˆ‘è¿˜å‡äº†ä¸å°‘æâ€¦ è¶…æ—¶ï¼Œåªæœ‰20åˆ†ï¼Œé€šè¿‡å‡ ä¸ªè¿è¡Œç»“æœæ¥çœ‹ï¼Œå†™æ³•åº”è¯¥å¯¹äº†ï¼Œåªæ˜¯å…¨éƒ½TLEè€Œå·²","text":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1118 æ•°å­—ä¸‰è§’å½¢ æš´åŠ›æœç´¢ çœ‹åˆ°é¢˜ç›®çš„ç¬¬ä¸€çœ¼æƒ³çš„å°±æ˜¯ç›´æ¥æœï¼Œå‘ç°ä¸å°‘TLEï¼Œæˆ‘è¿˜å‡äº†ä¸å°‘æâ€¦ è¶…æ—¶ï¼Œåªæœ‰20åˆ†ï¼Œé€šè¿‡å‡ ä¸ªè¿è¡Œç»“æœæ¥çœ‹ï¼Œå†™æ³•åº”è¯¥å¯¹äº†ï¼Œåªæ˜¯å…¨éƒ½TLEè€Œå·² ^åœ¨c++ä¸­ä¸æ˜¯å¹‚è¿ç®—ï¼Œæ˜¯å¼‚æˆ–ï¼ˆå¦‚æœä¸¤ä¸ªç›¸åº”ä½ä¸ºâ€œå¼‚â€ï¼ˆå€¼ä¸åŒï¼‰ï¼Œåˆ™è¯¥ä½ç»“æœä¸º1ï¼Œå¦åˆ™ä¸º0ã€‚0^0=0; 0^1=1; 1^0=1; 1^1=0ï¼‰ã€‚å¹‚è¿ç®—ç”¨pow(base,power) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;cmath&gt;using namespace std;int n,tri[13][13],ans[13]; bool flag=true;void dfs(int);int main()&#123; int start; cin&gt;&gt;n&gt;&gt;start; tri[n][1]=start; dfs(n-1); if(!flag) for(int i=1;i&lt;=n;i++) cout&lt;&lt;ans[i]&lt;&lt;&quot; &quot;; return 0;&#125;void dfs(int level)&#123; if(flag)&#123; int lbound=pow(2,level-1),ubound=tri[level+1][1]-lbound;///lbound(lower_bound)æ˜¯å‡è®¾ç¬¬ä¸€è¡Œå…¨æ˜¯1ï¼Œå¾—å‡ºçš„åç»­å‡ è¡Œçš„æœ€å°å€¼ for(int i=lbound;i&lt;=ubound;i++)&#123; if(!flag) continue; tri[level][1]=i; bool jump=false; for(int j=1;j&lt;=n-level;j++)&#123; tri[level][j+1]=tri[level+1][j]-tri[level][j]; ///å¯ä»¥åŠ ä¸€ä¸ªåˆ¤å®šæ¡ä»¶ï¼Œå¦‚æœå°äºXXXï¼Œå°±åœæ­¢æœ¬æ¬¡æœç´¢ if(tri[level][j+1]&lt;lbound) &#123;jump=true; break;&#125;///ä¸å‰é¢çš„lboundå®šä¹‰ä¸€æ ·ï¼Œå¦‚æœä¸€ä¸ä¸‹å¿ƒæœå‡ºæ¥0æˆ–è€…-1é‚£ä¹ˆè‚¯å®šä¸å¯¹ if(tri[level][j+1]==tri[level][j]) &#123;jump=true; break;&#125;///è‡ªå·±å‘ç°çš„è§„å¾‹ï¼Œç›¸é‚»ä¸¤é¡¹ä¸å¯èƒ½ç›¸ç­‰ï¼Œå› ä¸ºç›¸é‚»çš„ä¸¤é¡¹ç›¸ç­‰ä¼šå¯¼è‡´å†ä¸Šé¢ä¸€å±‚ä¹Ÿæœ‰ä¸¤é¡¹ç›¸ç­‰ï¼Œç›´åˆ°ç¬¬ä¸€å±‚æœ‰ä¸¤é¡¹ç›¸ç­‰ï¼Œæ„å‘³ç€ç­”æ¡ˆä¸ç¬¦åˆæ¡ä»¶ &#125; if(jump) continue; for(int j=1;j&lt;=n-level+1;j++)&#123; cout&lt;&lt;tri[level][j]&lt;&lt;&quot; &quot;; &#125; cout&lt;&lt;endl; if(level==1)&#123; int sum=0; for(int i=1;i&lt;=n;i++)&#123; sum+=pow(2,tri[1][i]); sum-=pow(2,i); &#125;///è¿™ä¸ªåœ°æ–¹ç”¨äº†ä¸€ä¸ªäºŒè¿›åˆ¶çš„æ€§è´¨ç®—æˆ‘ä»¬çš„ç­”æ¡ˆç¬¬ä¸€è¡Œæ˜¯å¦æ˜¯1~Nçš„æ•°å­—ä¸”äº’ä¸ç›¸åŒ(æ¯ä¸ª1~Nçš„æ•°éƒ½æœ‰ä¸¤ç§çŠ¶æ€ï¼Œåœ¨ç­”æ¡ˆé‡Œæœ‰æˆ–è€…æ²¡æœ‰) if(sum==0)&#123;///sum==0 ä»£è¡¨sum(pow(2,tri[1][i]))==sum(pow(2,i)) for(int i=1;i&lt;=n;i++) ans[i]=tri[1][i]; flag=false; &#125; /// åœæ­¢æ‰€æœ‰æœç´¢ï¼Œå·²æ‰¾åˆ°ç­”æ¡ˆ &#125; if(level&gt;1&amp;&amp;flag==true) dfs(level-1); &#125; &#125;&#125; æ¨è¾‰ä¸‰è§’ ä»¥ä¸‹ä¸ºæ¨è¾‰ä¸‰è§’ä¸€ç»´dfsï¼Œåªæœ‰70åˆ†ï¼Œè¿˜æ˜¯éœ€è¦å‰ªæ é¦–å…ˆè¦ææ¸…æ¥šè¿™ä¸ªæ•°å­—ä¸‰è§’å½¢ç©¶ç«Ÿæ˜¯ä»€ä¹ˆå§ã€‚å¤§å®¶å¯ä»¥è‡ªå·±åœ¨è‰ç¨¿çº¸ä¸Šå†™ä¸€ä¸‹ï¼Œå‡è®¾nä¸ºä¸€ä¸ªæ¯”è¾ƒå°çš„æ•°(æ¯”å¦‚ï¼ŒæŒ‰æ ·ä¾‹ï¼Œ4)ï¼Œè®¾ç¬¬ä¸€è¡Œçš„nä¸ªæ•°åˆ†åˆ«ä¸ºa,b,c,â€¦(æˆ‘è¿™é‡Œæ˜¯a,b,c,d)ï¼Œç„¶åæ¨¡æ‹ŸåŠ ä¸€ä¸‹ï¼Œå°±ä¼šå‘ç°sumæ˜¯â€¦â€¦ å¦‚æœnä¸º4ï¼Œé‚£ä¹ˆsumæ˜¯a+3b+3c+dã€‚ å¦‚æœnä¸º5ï¼Œé‚£ä¹ˆsumæ˜¯a+4b+6c+4d+eã€‚ å¦‚æœnä¸º6ï¼Œé‚£ä¹ˆsumæ˜¯a+5b+10c+10d+5e+fã€‚ è§‚å¯Ÿå„é¡¹çš„ç³»æ•°ï¼Œä½ å‘ç°äº†ä»€ä¹ˆï¼Ÿ å¦‚æœä½ æœ‰æ•é”çš„æ•°å­¦çœ¼å…‰ï¼Œä½ ä¼šå‘ç°ï¼Œå„é¡¹ç³»æ•°æ°ä¸æ¨è¾‰ä¸‰è§’æœ‰å…³ï¼ é‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥æšä¸¾æ¯ä¸ªa,b,c,â€¦ï¼Œé€ä¸€ä¸sumæ¯”è¾ƒï¼Œå°±å¯ä»¥å¾—å‡ºç­”æ¡ˆäº†ã€‚~ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include&lt;iostream&gt;#include&lt;cmath&gt;#include&lt;cstring&gt;#include&lt;cstdio&gt;using namespace std;int yanghui[13][13],ans[13],n,sum; bool vis[13];int compute();void dfs(int);int main()&#123; cin&gt;&gt;n&gt;&gt;sum; memset(vis,true,sizeof(vis)); ///åˆå§‹åŒ–æ¨è¾‰ä¸‰è§’ yanghui[1][1]=1;yanghui[2][1]=1;yanghui[2][2]=1; for(int i=3;i&lt;=n;i++)&#123; yanghui[i][1]=1; for(int j=2;j&lt;=i;j++) yanghui[i][j]=yanghui[i-1][j-1]+yanghui[i-1][j]; &#125; dfs(1);///ä»ç¬¬ä¸€ä¸ªä½ç½®å¼€å§‹æœç´¢ return 0;&#125;int compute()///å½“å·²ç»æšä¸¾åˆ°äº†æœ€åä¸€ä½æ—¶ï¼Œå¯ä»¥è®¡ç®—ç°åœ¨ç­”æ¡ˆçš„å€¼æ˜¯å¦çœŸçš„ç­‰äºæˆ‘ä»¬è¾“å…¥çš„sum&#123; int temp=0; for(int i=1;i&lt;=n;i++) temp+=ans[i]*yanghui[n][i]; return temp;&#125;void dfs(int pointer)&#123; for(int i=1;i&lt;=n;i++)&#123; if(vis[i])&#123; ans[pointer]=i; vis[i]=false; if(pointer==n&amp;&amp;compute()==sum) &#123; for(int i=1;i&lt;=n;i++) cout&lt;&lt;ans[i]&lt;&lt;&quot; &quot;; break; &#125; if(pointer&lt;n) dfs(pointer+1); ans[pointer]=0; vis[i]=true; &#125; &#125;&#125; äºŒç»´DFS ä¸Šé¢æ–¹æ³•çš„é—®é¢˜åœ¨äºï¼šåªåœ¨æ‰€æœ‰ä½ç½®éƒ½é€‰å®Œçš„æ—¶å€™æ‰åˆ¤å®šæ˜¯å¦ç¬¦åˆæ¡ä»¶(sum=sum_to_find|(åœ¨è¿™ä¸ªç¨‹åºä¸­)sum=compute())ï¼Œä½†æ˜¯æœ‰å¾ˆå¤šæƒ…å†µä¸‹åœ¨æˆ‘ä»¬æ²¡é€‰å®Œçš„æ—¶å€™å°±å·²ç»ä¸ç¬¦åˆæ¡ä»¶äº†(sum&gt;sum_to_find)ã€‚æˆ‘ä»¬å¿…é¡»è¦æ’é™¤è¿™ç§æƒ…å†µï¼Œè¿™æ ·çš„è¯å°±å¿…é¡»åœ¨æœç´¢çš„åŒæ—¶è®°å½•ç°åœ¨çŠ¶æ€ä¸‹åˆ(sum)çš„å¤§å°ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±éœ€è¦å†™ä¸€ä¸ªäºŒç»´çš„dfs ~~å®åœ¨å¤ªè ¢äº†ï¼ŒæŠŠæ‰€æœ‰è¦åˆ¤å®šçš„åœ°æ–¹éƒ½åŠ ä¸Š&amp;flagè¿è¡Œæ—¶é—´ç›´æ¥ä»1500msæåˆ°äº†101ms ~~ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include&lt;iostream&gt;#include&lt;cmath&gt;#include&lt;cstring&gt;#include&lt;cstdio&gt;using namespace std;int yanghui[13][13],ans[13],n,sum_to_find; bool vis[13],flag=true;int compute();void dfs(int,int);int main()&#123; cin&gt;&gt;n&gt;&gt;sum_to_find; memset(vis,true,sizeof(vis)); ///åˆå§‹åŒ–æ¨è¾‰ä¸‰è§’ yanghui[1][1]=1;yanghui[2][1]=1;yanghui[2][2]=1; for(int i=3;i&lt;=n;i++)&#123; yanghui[i][1]=1; for(int j=2;j&lt;=i;j++) yanghui[i][j]=yanghui[i-1][j-1]+yanghui[i-1][j]; &#125; dfs(1,0); return 0;&#125;void dfs(int pointer,int sum)&#123; if(flag)&#123;///è¿™ä¸ªåœ°æ–¹ä»£ç è¿™ä¹ˆä¸‘æ˜¯å› ä¸ºæˆ‘æŠŠæ‰€æœ‰è¦åˆ¤å®šçš„åœ°æ–¹éƒ½åŠ ä¸Š&amp;flagï¼Œä¸ç„¶TLE for(int i=1;i&lt;=n;i++)&#123; if(vis[i]&amp;&amp;flag)&#123; ans[pointer]=i; vis[i]=false; sum+=ans[pointer]*yanghui[n][pointer]; if(pointer==n&amp;&amp;sum==sum_to_find&amp;&amp;flag) &#123; for(int i=1;i&lt;=n;i++) &#123;cout&lt;&lt;ans[i]&lt;&lt;&quot; &quot;; flag=false;&#125; break; &#125; if(pointer&lt;n&amp;&amp;sum&lt;sum_to_find&amp;&amp;flag) dfs(pointer+1,sum); sum-=ans[pointer]*yanghui[n][pointer]; ans[pointer]=0;///è¿™ä¸¤å¥çš„é¡ºåºå¯ä¸èƒ½ææ··äº†ï¼Œè¦å…ˆè¿˜åŸsumå€¼ï¼Œå†è¿˜åŸanså€¼ï¼Œå› ä¸ºsumå€¼å’Œanså€¼æœ‰å…³ vis[i]=true; &#125; &#125;&#125;&#125;","categories":[],"tags":[{"name":"NOI","slug":"NOI","permalink":"https://yao-lirong.github.io/blog/tags/NOI/"}]},{"title":"P1019 å•è¯æ¥é¾™","slug":"P1019 å•è¯æ¥é¾™","date":"2019-06-26T04:00:00.000Z","updated":"2019-06-27T12:39:42.000Z","comments":true,"path":"P1019 å•è¯æ¥é¾™/","permalink":"https://yao-lirong.github.io/blog/P1019%20%E5%8D%95%E8%AF%8D%E6%8E%A5%E9%BE%99/","excerpt":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1019 å•è¯æ¥é¾™ è°ƒäº†å¥½å‡ å¤©ï¼Œæœ€åè¯·æ•™äº†é†‰ç¥(@magolor)ï¼Œååˆ†é’Ÿç»™æˆ‘è°ƒå¥½äº†â€¦ è¿™ä¸ªç¨‹åºä¸€ä¸ªé—®é¢˜å°±æ˜¯å¾ªç¯æ ¹æœ¬å°±ä¸ä¼šå§dictå…¨å¾ªç¯ä¸€éï¼Œé‚£å¯èƒ½å°±æ˜¯åˆå§‹åŒ–å‡ºäº†é—®é¢˜ï¼š m=pointer çš„ä½ç½®ï¼Œå½“æ—¶è®°å¾—åº”è¯¥å†™ä¸€ä¸ªå‰¯æœ¬ m ä»£æ›¿ pointer è¢«æ”¹å˜ï¼Œä½†æ˜¯å†™ç€å†™ç€å¿˜äº† m å…·ä½“åº”è¯¥åœ¨å“ªè¢«åˆå§‹åŒ–äº†ï¼Œé—®é¢˜å°±å‡ºç°åœ¨è¿™ å›æº¯çš„çŠ¶æ€ï¼šä¸€å®šè¦æ˜ç¡®å›æº¯åº”å½“å›æº¯åˆ°å…·ä½“é‚£ä¸ªçŠ¶æ€ï¼Œæ˜¯ans_tempå·²ç»è¢«æ”¹å˜çš„çŠ¶æ€å—ï¼Ÿè¿˜æ˜¯æœªæ”¹å˜çš„çŠ¶æ€ï¼Ÿæœ¬é¢˜ä¸­æ˜¯ans_tempæœªæ”¹å˜çš„çŠ¶æ€","text":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1019 å•è¯æ¥é¾™ è°ƒäº†å¥½å‡ å¤©ï¼Œæœ€åè¯·æ•™äº†é†‰ç¥(@magolor)ï¼Œååˆ†é’Ÿç»™æˆ‘è°ƒå¥½äº†â€¦ è¿™ä¸ªç¨‹åºä¸€ä¸ªé—®é¢˜å°±æ˜¯å¾ªç¯æ ¹æœ¬å°±ä¸ä¼šå§dictå…¨å¾ªç¯ä¸€éï¼Œé‚£å¯èƒ½å°±æ˜¯åˆå§‹åŒ–å‡ºäº†é—®é¢˜ï¼š m=pointer çš„ä½ç½®ï¼Œå½“æ—¶è®°å¾—åº”è¯¥å†™ä¸€ä¸ªå‰¯æœ¬ m ä»£æ›¿ pointer è¢«æ”¹å˜ï¼Œä½†æ˜¯å†™ç€å†™ç€å¿˜äº† m å…·ä½“åº”è¯¥åœ¨å“ªè¢«åˆå§‹åŒ–äº†ï¼Œé—®é¢˜å°±å‡ºç°åœ¨è¿™ å›æº¯çš„çŠ¶æ€ï¼šä¸€å®šè¦æ˜ç¡®å›æº¯åº”å½“å›æº¯åˆ°å…·ä½“é‚£ä¸ªçŠ¶æ€ï¼Œæ˜¯ans_tempå·²ç»è¢«æ”¹å˜çš„çŠ¶æ€å—ï¼Ÿè¿˜æ˜¯æœªæ”¹å˜çš„çŠ¶æ€ï¼Ÿæœ¬é¢˜ä¸­æ˜¯ans_tempæœªæ”¹å˜çš„çŠ¶æ€ æˆ‘çš„è§£ä¸æ ‡è§£ è·Ÿæˆ‘çš„åšæ³•ä¸€æ ·ï¼ŒåŒºåˆ«åªæ˜¯æ ‡è§£ç”¨forå¾ªç¯æšä¸¾jè€Œä¸æ˜¯è·Ÿæˆ‘ä¸€æ ·ç”¨ç›´æ¥ç”¨dfså‡½æ•° ä¸‹é¢æ˜¯æˆ‘çš„ä»£ç ï¼š 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;cmath&gt;#include&lt;cstring&gt;using namespace std;char dict[21][30],ans[500]; int n,vis[21],ans_max=0,ans_temp=0;void dfs(int,int);int main()&#123; cin&gt;&gt;n; for(int i=1;i&lt;=n;i++) cin&gt;&gt;dict[i]; for(int i=1;i&lt;=n;i++) vis[i]=2; cin&gt;&gt;dict[0][0];///å¼€å¤´çš„å­—æ¯ dfs(0,0); cout&lt;&lt;ans_max; return 0;&#125;void dfs(int word,int pointer)&#123; if(pointer&lt;strlen(dict[word]))&#123; ans_temp++; int ans_mark=ans_temp; ans_max=max(ans_max,ans_temp); dfs(word,pointer+1);///è¿™å¥è¯ä»¥ä¸Šæ˜¯å°†æœ¬å•è¯ä¸­çš„ä¸‹ä¸€ä¸ªå­—æ¯åŠ å…¥ç­”æ¡ˆå­—ç¬¦ä¸²ä¸­ï¼Œä»¥ä¸‹æ˜¯å°†æŸ¥çœ‹ä»¥è¿™ä¸ªå­—æ¯ä¸ºåŸºå‡†ï¼Œèƒ½ä¸èƒ½æ¥ä¸Šå…¶ä»–å•è¯çš„é¾™ ans_temp=ans_mark; &#125; int m; for(int i=1;i&lt;=n;i++)&#123;///æšä¸¾nä¸ªè¯ä¸­å“ªä¸ªè¯çš„é¦–å­—æ¯å¯ä»¥å’Œç°åœ¨å­—ç¬¦ä¸²çš„æœ€åä¸€ä¸ªç›¸åŒ if(vis[i]&gt;0)&#123; int j=0; ///!!! m=pointer; ///!!!å…¶ä»–äººçš„åšæ³•æ˜¯ç›´æ¥æšä¸¾å•è¯ word ä¸­çš„æ‰€æœ‰å­—æ¯ï¼Œä¸åƒæˆ‘æ˜¯é€šè¿‡ dfs(word,pointer+1)æ¥æšä¸¾ï¼Œæ‰€ä»¥ä¸éœ€è¦è€ƒè™‘pointerå¦‚ä½•å¦‚ä½•ï¼Œæˆ‘ä»¬è¿™é‡Œå¦‚æœå¯¹ pointer åé¢çš„å­—æ¯(pointer+1,pointer+2,...)ä¸€ä¸ªä¸ªè¿›è¡Œæ¯”å¯¹ï¼Œå¿…ç„¶ä¼šæ”¹å˜pointerçš„å€¼ï¼Œæ‰€ä»¥ç”¨äº†ä¸€ä¸ªå‰¯æœ¬ m è¿›è¡Œæ¯”å¯¹ï¼Œä¿è¯pointerå€¼ä¸å˜ if(dict[word][m]==dict[i][j])&#123;///å¦‚æœå¤´ä¸€ä¸ªå­—æ¯ç›¸åŒ bool flag=true; while(m&lt;strlen(dict[word]))&#123;///ä¸€ç›´æ¯”å¯¹åˆ°æœ€åä¸€ä¸ªå­—æ¯ï¼Œå¹¶ä¸”è¿™é‡Œåˆ¤æ–­äº†â€œç›¸é‚»çš„ä¸¤éƒ¨åˆ†ä¸èƒ½å­˜åœ¨åŒ…å«å…³ç³»â€è¿™ä¸€æ¡ä»¶ if(dict[word][m]!=dict[i][j]) flag=false; m++; j++; &#125; if(flag)&#123;///å¦‚æœæ¯ä¸ªå­—æ¯éƒ½ä¸€æ · ///!!! int ans_mark=ans_temp;///è®°å½•ä¸€ä¸‹ç°åœ¨çš„é•¿åº¦ï¼Œå› ä¸ºå†è¿›è¡Œå…¶ä»–çš„dfsï¼Œans_tempä¼šè¢«æ›´æ–° ans_temp+=j-1;///ç­”æ¡ˆå­—ç¬¦ä¸²çš„é•¿åº¦å°±å¯ä»¥åŠ ä¸Šæ–°åŠ å…¥çš„å•è¯çš„é•¿åº¦ ///!!!æ³¨æ„è¿™ä¸ªåœ°æ–¹è¿™ä¸¤å¥è¯åº”è¯¥æ˜¯å…ˆè®°å½• ans_temp å†æ›´æ–° ans_temp ï¼Œå› ä¸ºæˆ‘ä»¬æœ€åå›æº¯çš„æ—¶å€™æ˜¯è¦å›æº¯åˆ°æ²¡æœ‰æ¥é¾™æ¥ä¸Šå½“å‰å•è¯çš„çŠ¶æ€ï¼Œæ‰€ä»¥åº”è¯¥æ˜¯å…ˆè®°å½•ï¼Œåæ›´æ–° ans_max=max(ans_max,ans_temp); vis[i]--; dfs(i,j); vis[i]++; ans_temp=ans_mark;///æŠŠans_tempæ›´æ–°å›æ¥ &#125; &#125; &#125; &#125;&#125; å…ˆé¢„å¤„ç†å¾—åˆ°ä¸¤ä¸¤å•è¯é—´çš„æœ€çŸ­é‡åˆéƒ¨åˆ†ï¼Œç„¶åæœç´¢å¾—åˆ°ç­”æ¡ˆ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include&lt;cstring&gt;#include&lt;iostream&gt;#include&lt;cstdio&gt;using namespace std;string dict[31]; int ans_now=1,ans_max=0,n,vis[31],overlap[31][31];///è¿™ä¸ªåœ°æ–¹æŠŠ ans_now è®¾ä¸º1ï¼Œæ˜¯å› ä¸ºç¬¬ä¸€ä¸ªå¼€å¤´çš„å­—æ¯ä¸ä¼šè¢«ç®—åœ¨é•¿åº¦å†…ï¼Œä¸ºäº†æŠŠè¿™ä¸ªå¼€å¤´çš„å­—æ¯ç®—è¿›å»ï¼Œans_now ä»1å¼€å§‹int find_overlap(string,string);///å¯»æ‰¾ä¸¤ä¸ªå•è¯çš„æœ€å°é‡åˆéƒ¨åˆ†void dfs(int);int main()&#123; cin&gt;&gt;n; for(int i=1;i&lt;=n;i++) cin&gt;&gt;dict[i]; for(int i=1;i&lt;=n;i++) vis[i]=2; cin&gt;&gt;dict[0];///å¼€å¤´çš„å­—æ¯ memset(overlap,0,sizeof(overlap)); for(int i=0;i&lt;=n;i++) for(int j=1;j&lt;=n;j++) overlap[i][j]=find_overlap(dict[i],dict[j]); dfs(0); cout&lt;&lt;ans_max; return 0;&#125;int find_overlap(string a, string b)///å…¶ä¸­ï¼Œaæ˜¯å°†è¦è¢«åˆ«äººæ¥ä¸Šå»çš„å­—ç¬¦ä¸²ï¼Œbæ˜¯æƒ³è¦æ¥ä¸Šå»çš„å­—ç¬¦ä¸²&#123; for(int i=a.size()-1;i&gt;=0;i--)&#123;///å€’åºå¯»æ‰¾æœ€å°é‡åˆéƒ¨åˆ†çš„å¤§å° int ja=i,jb=0; bool flag=true; while(ja&lt;a.size())&#123;///æ­£åºçœ‹çœ‹è¿™ä¸ªéƒ¨åˆ†æ˜¯å¦é‡åˆ if(a[ja]!=b[jb]) &#123;flag=false; break;&#125; ja++; jb++; &#125; if(flag)&#123; int ans_overlap=a.size()-i; ///å¾—åˆ°é‡å éƒ¨åˆ†çš„å¤§å° if(ans_overlap!=a.size()&amp;&amp;ans_overlap!=b.size()) return ans_overlap; ///åˆ¤æ–­é‡å éƒ¨åˆ†æ˜¯ä¸æ˜¯åŒ…å«éƒ¨åˆ†ï¼Œå¦‚æœä¸æ˜¯å°±è¿”å›ç­”æ¡ˆ else if(a.size()==1) return ans_overlap; ///å¦‚æœæ˜¯å¼€å¤´çš„å­—æ¯(cin&gt;&gt;dict[0])ï¼Œæ°¸è¿œæœ‰ ans_overlap==a.size()==0 é‚£ä¹ˆä¸ç®¡ans_overlap!=a.size()æ˜¯å¦æˆç«‹ï¼Œæˆ‘ä»¬éƒ½è¦è¿”å›ç­”æ¡ˆ else return 0;///å…¶ä»–çš„æƒ…å†µä¸‹ï¼Œé‡å éƒ¨åˆ†æ˜¯åŒ…å«éƒ¨åˆ†ï¼Œä¸èƒ½æ¥é¾™ï¼Œæ‰€ä»¥è¿”å›0 &#125; &#125; return 0;///æ²¡æ‰¾åˆ°é‡å éƒ¨åˆ†&#125;void dfs(int word)&#123; for(int i=1;i&lt;=n;i++)&#123; if(overlap[word][i]&gt;0 &amp;&amp; vis[i]&gt;0)&#123; ans_now+=dict[i].size()-overlap[word][i];///æ¥ä¸Šçš„å­—ç¬¦ä¸²çš„é•¿åº¦ ans_max=max(ans_max,ans_now); vis[i]--; dfs(i); vis[i]++; ans_now-=dict[i].size()-overlap[word][i]; &#125; &#125;&#125;","categories":[],"tags":[{"name":"NOI","slug":"NOI","permalink":"https://yao-lirong.github.io/blog/tags/NOI/"}]},{"title":"P1101 å•è¯æ–¹é˜µ","slug":"P1101 å•è¯æ–¹é˜µ","date":"2019-06-17T04:00:00.000Z","updated":"2019-06-27T12:38:12.000Z","comments":true,"path":"P1101 å•è¯æ–¹é˜µ/","permalink":"https://yao-lirong.github.io/blog/P1101%20%E5%8D%95%E8%AF%8D%E6%96%B9%E9%98%B5/","excerpt":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1101 å•è¯æ–¹é˜µ dir è¿™ä¸ªæ•°ç»„æ˜¯å¾ˆå¥½ç”¨çš„ï¼Œä¸éœ€è¦ä¸º8ä¸ªæ–¹å‘ç‰¹æ„å†™8ä¸ªä¸åŒçš„å‡½æ•°ï¼Œåªéœ€è¦å†™ä¸€ä¸ªå‡½æ•°ä½†æ˜¯æ”¹å˜å–å“ªä¸€ä¸ªdir[i]æ¥åˆ¤å®šå“ªä¸€ä¸ªæ–¹å‘ç¬¦åˆæ¡ä»¶å°±è¡Œäº†","text":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1101 å•è¯æ–¹é˜µ dir è¿™ä¸ªæ•°ç»„æ˜¯å¾ˆå¥½ç”¨çš„ï¼Œä¸éœ€è¦ä¸º8ä¸ªæ–¹å‘ç‰¹æ„å†™8ä¸ªä¸åŒçš„å‡½æ•°ï¼Œåªéœ€è¦å†™ä¸€ä¸ªå‡½æ•°ä½†æ˜¯æ”¹å˜å–å“ªä¸€ä¸ªdir[i]æ¥åˆ¤å®šå“ªä¸€ä¸ªæ–¹å‘ç¬¦åˆæ¡ä»¶å°±è¡Œäº† 123456789101112131415161718192021222324252627282930313233343536373839404142#include&lt;iostream&gt;#include&lt;cstdio&gt;using namespace std;char matrix[103][103], yizhong[8]=&quot;yizhong&quot;; bool mark[103][103];/// matrix å­˜å‚¨æ¯ä¸ªä½ç½®çš„å­—æ¯ï¼Œyizhong å­˜å‚¨æˆ‘ä»¬è¦æ‰¾çš„å­—ç¬¦ä¸² &quot;yizhong&quot;ï¼Œmarkå­˜å‚¨è¿™ä¸ªä½ç½®ç¬¦ä¸ç¬¦åˆè¦æ±‚ï¼Œæœ€åè¦ä¸è¦è¢«å˜æˆ &quot;*&quot; è¾“å‡ºint dir[8][2]=&#123;&#123;0,1&#125;,&#123;1,1&#125;,&#123;1,0&#125;,&#123;1,-1&#125;,&#123;0,-1&#125;,&#123;-1,-1&#125;,&#123;-1,0&#125;,&#123;-1,1&#125;&#125;;/// dir[8] å­˜å‚¨äº†8ä¸ªæ–¹å‘ï¼Œdir[i][0] æ˜¯xè½´åæ ‡ï¼Œdir[i][1] æ˜¯yè½´åæ ‡void dfs(int,int); /// è¿™ä¸ªé¢˜è™½ç„¶æ”¾åœ¨dfsé‡Œé¢ä½†æ˜¯å› ä¸ºè¿™ä¸ªå­—ç¬¦ä¸²çš„æ–¹å‘æ˜¯å›ºå®šçš„ï¼Œä¸ä¼šæ‹å¼¯æŠ¹è§’ï¼Œæ‰€ä»¥å¥½åƒå’Œdfsæ²¡ä»€ä¹ˆå…³ç³»int main()&#123; int n; cin&gt;&gt;n; for(int i=1;i&lt;=n;i++) for(int j=1;j&lt;=n;j++) cin&gt;&gt;matrix[i][j]; for(int i=1;i&lt;=n;i++) for(int j=1;j&lt;=n;j++) dfs(i,j); for(int i=1;i&lt;=n;i++)&#123; for(int j=1;j&lt;=n;j++)&#123; if(mark[i][j]) cout&lt;&lt;matrix[i][j]; else cout&lt;&lt;&quot;*&quot;; &#125; cout&lt;&lt;endl; &#125; return 0;&#125;void dfs(int x, int y)&#123; for(int i=0;i&lt;8;i++)&#123; ///å¯¹äºä»»æ„ä¸€ä¸ªç‚¹ï¼Œæˆ‘ä»¬éƒ½çœ‹çœ‹å®ƒå‘¨å›´å…«ä¸ªæ–¹å‘å„è‡ªç¬¦ä¸ç¬¦åˆæ¡ä»¶ int j=0;bool flag=true; while(j&lt;7)&#123; ///åˆ†åˆ«æ£€è§†æ¯ä¸€ä¸ªå­—ç¬¦ ä¸ yizhong æ˜¯å¦åŒ¹é… if(matrix[x+j*dir[i][0]][y+j*dir[i][1]] != yizhong[j])&#123; ///éå¸¸ç²¾é«“ flag=false; break; /// ä¸åŒ¹é…ï¼Œflag=false &#125; j++; &#125; if(flag)&#123; ///åŒ¹é…çš„è¯å°±è®°å½•ä¸‹æ¥å®ƒä»¬æ˜¯ç¬¦åˆè¦æ±‚çš„ï¼Œæœ€åç›´æ¥è¾“å‡ºå½“å‰ä½ç½®çš„å­—ç¬¦ for(int j=0;j&lt;7;j++) mark[x+j*dir[i][0]][y+j*dir[i][1]]=true; &#125; &#125;&#125;","categories":[],"tags":[{"name":"NOI","slug":"NOI","permalink":"https://yao-lirong.github.io/blog/tags/NOI/"}]},{"title":"P1219 å…«çš‡å","slug":"P1219 å…«çš‡å","date":"2019-06-16T04:00:00.000Z","updated":"2019-06-27T12:35:52.000Z","comments":true,"path":"P1219 å…«çš‡å/","permalink":"https://yao-lirong.github.io/blog/P1219%20%E5%85%AB%E7%9A%87%E5%90%8E/","excerpt":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1219 å…«çš‡å æˆ‘çš„è§£æ³• è‡ªå·±çš„ç¨‹åºå‡ºç°çš„å‡ ä¸ªé—®é¢˜ï¼š å¯¹è§’çº¿è¡¨è¾¾å¼å¤ªè¿‡å¤æ‚ï¼Œå„å±‚ç»å¯¹å€¼éƒ½å¯ä»¥ç®€åŒ–ï¼Œåº”è¯¥ç›¸ä¿¡å¤§éƒ¨åˆ†æƒ…å†µä¸‹å¤æ‚çš„éƒ½æ˜¯é”™è¯¯çš„ ä¸éœ€è¦è®°å½•è¿™ä¸€è¡Œæ”¾æ²¡æ”¾è¿‡æ£‹å­ï¼Œå› ä¸ºæˆ‘ä»¬æ˜¯æŒ‰ç…§ä¸€è¡Œä¸€è¡Œçš„é¡ºåºæ”¾è¿‡æ¥çš„ï¼Œä¸Šä¸€è¡Œå¿…å®šæœ‰æ£‹å­ï¼Œä¸‹ä¸€è¡Œå¿…å®šæ— æ£‹å­","text":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1219 å…«çš‡å æˆ‘çš„è§£æ³• è‡ªå·±çš„ç¨‹åºå‡ºç°çš„å‡ ä¸ªé—®é¢˜ï¼š å¯¹è§’çº¿è¡¨è¾¾å¼å¤ªè¿‡å¤æ‚ï¼Œå„å±‚ç»å¯¹å€¼éƒ½å¯ä»¥ç®€åŒ–ï¼Œåº”è¯¥ç›¸ä¿¡å¤§éƒ¨åˆ†æƒ…å†µä¸‹å¤æ‚çš„éƒ½æ˜¯é”™è¯¯çš„ ä¸éœ€è¦è®°å½•è¿™ä¸€è¡Œæ”¾æ²¡æ”¾è¿‡æ£‹å­ï¼Œå› ä¸ºæˆ‘ä»¬æ˜¯æŒ‰ç…§ä¸€è¡Œä¸€è¡Œçš„é¡ºåºæ”¾è¿‡æ¥çš„ï¼Œä¸Šä¸€è¡Œå¿…å®šæœ‰æ£‹å­ï¼Œä¸‹ä¸€è¡Œå¿…å®šæ— æ£‹å­ æ³¨æ„åˆå§‹åŒ–çš„éƒ¨åˆ†ï¼Œä¸€å¼€å§‹å°±æ˜¯æŠŠå¾ªç¯è¯­å¥é‡Œå†™æˆäº† NE_SW[i]=true; NE_SW[i+1]=true å¯¼è‡´äº†é”™è¯¯è€Œä¸”ä¸€ç›´æ²¡æ£€æŸ¥å‡ºæ¥ æœ€åé‚£ä¸ªå­˜å‚¨ solution çš„åœ°æ–¹è¿˜æ˜¯æœ‰é—®é¢˜ï¼Œå¦‚æœæ‰¾åˆ°äº†æŸä¸€è¡Œçš„ä¸€ä¸ªè§£å¹¶ä¸”ç»§ç»­å‘ä¸‹æœå¯»è¿™ä¸€è¡Œçš„å…¶ä»–è§£çš„è¯ï¼Œä¼šå‡ºç°ä¸å­˜å‚¨å‰é¢å‡ è¡Œæ£‹å­ä½ç½®çš„é—®é¢˜ï¼Œæ²¡æƒ³åˆ°è§£å†³æ–¹æ³•åªèƒ½åœ¨è¾“å‡ºçš„åœ°æ–¹åšäº†äº›æ“ä½œ å¤§éƒ¨åˆ†æ ‡è§£ä¸­dfsåªæœ‰ä¸€ä¸ªå‚æ•°å°±æ˜¯è¡Œæ•°xç„¶åå¯¹äºæ¯ä¸ªxè¿›è¡Œforå¾ªç¯æšä¸¾çºµåæ ‡yï¼Œæˆ‘è¿™æ ·çš„åšæ³•ä¹Ÿå¯ä»¥ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;cmath&gt;using namespace std;bool board[14][14],col[14],line[14],NE_SW[26],NW_SE[26]; int n,ans,solution[3][15];bool flag(int, int);void dfs(int, int);int main()&#123; cin&gt;&gt;n; for(int i=1;i&lt;=n;i++) &#123;col[i]=true; line[i]=true; NE_SW[i]=true; NW_SE[i]=true; NE_SW[i+n]=true; NW_SE[i+n]=true;&#125;/// è¿™ä¸ªåœ°æ–¹åˆå§‹åŒ–ä¸€å®šè¦æ³¨æ„ dfs(1,1); for(int i=0;i&lt;3;i++)&#123; for(int j=1;j&lt;=n;j++)&#123; if(solution[i][j]==0) solution[i][j]=solution[i-1][j]; cout&lt;&lt;solution[i][j]&lt;&lt;&quot; &quot;; &#125; cout&lt;&lt;endl; &#125; cout&lt;&lt;ans;&#125;bool flag(int x,int y)///åˆ¤å®šè¿™ä¸ªç‚¹èƒ½ä¸èƒ½æ”¾æ£‹å­&#123; if(col[x]&amp;&amp;line[y])&#123;if(NE_SW[x+y-1])&#123; if( y&lt;=x &amp;&amp; NW_SE[n-int(abs(x-y))] ) return true; else if( y&gt;x &amp;&amp; NW_SE[n+int(abs(x-y))] ) return true; //cout&lt;&lt;&quot;æœ€åä¸€ä¸ªå¯¹è§’çº¿å‡ºäº†é—®é¢˜&quot;&lt;&lt;endl; &#125;//cout&lt;&lt;&quot;ç¬¬ä¸€ä¸ªå¯¹è§’çº¿å‡ºäº†é—®é¢˜&quot;&lt;&lt;endl; &#125; //cout&lt;&lt;&quot;x,yæœ‰é—®é¢˜&quot;&lt;&lt;endl; return false;&#125;void dfs(int x,int y)&#123; ///cout&lt;&lt;&quot;function called at&quot;&lt;&lt;x&lt;&lt;&quot; &quot;&lt;&lt;y&lt;&lt;endl; if(flag(x,y))&#123; //if(x==n) ans++; if(ans&lt;=3) solution[ans][x]=y; ///cout&lt;&lt;endl&lt;&lt;&quot;one unit placed at&quot;&lt;&lt;x&lt;&lt;&quot; &quot;&lt;&lt;y&lt;&lt;endl&lt;&lt;endl; col[x]=false; line[y]=false; if(y&lt;=7-x) NE_SW[x+y-1]=false; ///å·¦ä¸Šè§’éƒ¨åˆ†çš„ å³ä¸Š-å·¦ä¸‹å¯¹è§’çº¿ else NE_SW[x+y-1]=false; /// å³ä¸‹è§’éƒ¨åˆ†çš„ å³ä¸Š-å·¦ä¸‹å¯¹è§’çº¿ if(y&lt;=x) NW_SE[n-int(abs(x-y))]=false; ///å³ä¸Šè§’éƒ¨åˆ†çš„ å·¦ä¸Š-å³ä¸‹å¯¹è§’çº¿ else NW_SE[n+int(abs(x-y))]=false; ///å·¦ä¸‹è§’éƒ¨åˆ† å·¦ä¸Š-å³ä¸‹å¯¹è§’çº¿ if(x==n) &#123;ans++;&#125; ///cout&lt;&lt;&quot;-------------&quot;&lt;&lt;endl&lt;&lt;&quot;one solution found, total solution is now &quot;&lt;&lt;ans&lt;&lt;endl&lt;&lt;&quot;-------------&quot;&lt;&lt;endl;&#125; else dfs(x+1,1); col[x]=true; line[y]=true; if(y&lt;=7-x) NE_SW[x+y-1]=true; ///å·¦ä¸Šè§’éƒ¨åˆ†çš„ å³ä¸Š-å·¦ä¸‹å¯¹è§’çº¿ else NE_SW[x+y-1]=true; /// å³ä¸‹è§’éƒ¨åˆ†çš„ å³ä¸Š-å·¦ä¸‹å¯¹è§’çº¿ if(y&lt;=x) NW_SE[n-int(abs(x-y))]=true; ///å³ä¸Šè§’éƒ¨åˆ†çš„ å·¦ä¸Š-å³ä¸‹å¯¹è§’çº¿ else NW_SE[n+int(abs(x-y))]=true; ///å·¦ä¸‹è§’éƒ¨åˆ† å·¦ä¸Š-å³ä¸‹å¯¹è§’çº¿ ///cout&lt;&lt;&quot;value changed back at&quot;&lt;&lt;x&lt;&lt;&quot; &quot;&lt;&lt;y&lt;&lt;endl; &#125; if(y&lt;n) dfs(x,y+1);&#125; æ›´å¯è¯»çš„ä»£ç ä»¥åŠé—®é¢˜ä¼˜åŒ– ä¼˜åŒ–äº†å¯¹è§’çº¿çš„è¡¨è¾¾ ä¼˜åŒ–äº†ç­”æ¡ˆä½ç½®çš„è®°å½• 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;cstring&gt;using namespace std;bool col[14],line[14],NE_SW[26],NW_SE[26]; int n,ans=0,solution[14]; /// col[x] line[y]/// NE_SW å³ä¸Šå‘å·¦ä¸‹æ–¹å‘çš„å¯¹è§’çº¿ï¼Œä»å·¦ä¸Šè§’(1,1)ä¸ºç¬¬ä¸€æ¡ï¼Œç¬¬äºŒæ¡æ˜¯(2,1)-(1,2)/// NW_SE å·¦ä¸Šåˆ°å³ä¸‹æ–¹å‘çš„å¯¹è§’çº¿ï¼Œä»å³ä¸Šè§’(1,n)ä¸ºç¬¬ä¸€æ¡ï¼Œç¬¬äºŒæ¡æ˜¯(n-1,1)-(n,2)void dfs(int,int);bool flag(int,int);int main()&#123; cin&gt;&gt;n; for(int i=1;i&lt;=n;i++) &#123;col[i]=true; line[i]=true; NE_SW[i]=true; NW_SE[i]=true; NE_SW[i+n]=true; NW_SE[i+n]=true;&#125; dfs(1,1); cout&lt;&lt;ans; return 0;&#125;bool flag(int x,int y)&#123; return col[x]&amp;&amp;line[y]&amp;&amp;NE_SW[x+y]&amp;&amp;NW_SE[n+y-x];&#125;void dfs(int x,int y)&#123; if(flag(x,y))&#123; solution[x]=y;///æ³¨æ„è¿™ä¸ªåœ°æ–¹ç‰¹åˆ«ç²¾é«“ï¼Œå› ä¸ºå¦‚æœæˆ‘ä»¬æ¯ä¸ªç­”æ¡ˆéƒ½å¼€æ–°çš„ä¸€è¡Œæ•°ç»„è®°å½•çš„è¯æœ‰å¯èƒ½ä¼šå‡ºç°ä¸Šé¢é—®é¢˜4è¯´çš„æƒ…å†µï¼Œæ‰€ä»¥æˆ‘ä»¬åªéœ€è¦æ¯æ¬¡è¦†ç›–è®°å½•å°±å¥½äº†ï¼Œåæ­£xæ°¸è¿œæ˜¯æŒ‰ä»ä¸Šåˆ°ä¸‹çš„é¡ºåºæ¥çš„ //col[x]=false; line[y]=false; NE_SW[x+y]=false; NW_SE[n+y-x]=false; col[x]=!col[x]; line[y]=!line[y]; NE_SW[x+y]=!NE_SW[x+y]; NW_SE[n+y-x]=!NW_SE[n+y-x]; ///æ³¨æ„ !col[x] åªæ˜¯è¡¨è¾¾ col[x] å–åçš„ä¸€ä¸ªå€¼ï¼Œåªæœ‰ col[x]=!col[x] æ‰èƒ½ç»™åŸæ³¢å°”å€¼èµ‹å€¼ä¸ºå®ƒçš„å if(x==n)&#123;///æœ€åä¸€è¡Œä¹Ÿè¢«å¡«å¥½äº†ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªè§£ ans++; if(ans&lt;=3)&#123; for(int i=1;i&lt;=n;i++) cout&lt;&lt;solution[i]&lt;&lt;&quot; &quot;; cout&lt;&lt;endl; &#125; &#125; else dfs(x+1,1);///è¿˜ä¸åˆ°æœ€åä¸€è¡Œçš„è¯å°±æ¥ç€å»æ‰¾ä¸‹ä¸€è¡Œ ///å›æº¯ï¼šæ‹¿èµ°åˆšåˆšæ”¾ä¸‹çš„æ£‹å­ //col[x]=true; line[y]=true; NE_SW[x+y]=true; NW_SE[n+y-x]=true; col[x]=!col[x]; line[y]=!line[y]; NE_SW[x+y]=!NE_SW[x+y]; NW_SE[n+y-x]=!NW_SE[n+y-x]; &#125; ///å¦‚æœè¿™ä¸ªä½ç½®ä¸ç¬¦åˆæ¡ä»¶(flag(x,y)==false)/è¿™ä¸ªä½ç½®ç¬¦åˆæ¡ä»¶çš„æƒ…å†µå·²ç»è¢«å…¨éƒ¨æšä¸¾äº†(flag(x,y)==true) é‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥å»æ‰¾æœ¬è¡Œçš„ä¸‹ä¸€ä¸ªä½ç½®æ˜¯å¦æ»¡è¶³æ¡ä»¶ if(y&lt;n) dfs(x,y+1);&#125;","categories":[],"tags":[{"name":"NOI","slug":"NOI","permalink":"https://yao-lirong.github.io/blog/tags/NOI/"}]},{"title":"P1031 å‡åˆ†çº¸ç‰Œ","slug":"P1031 å‡åˆ†çº¸ç‰Œ","date":"2019-06-04T04:00:00.000Z","updated":"2019-06-27T12:40:50.000Z","comments":true,"path":"P1031 å‡åˆ†çº¸ç‰Œ/","permalink":"https://yao-lirong.github.io/blog/P1031%20%E5%9D%87%E5%88%86%E7%BA%B8%E7%89%8C/","excerpt":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1031 å‡åˆ†çº¸ç‰Œ æ ‡è§£ æ³¨æ„æœ¬é¢˜ä¸­å¹³å‡æ•°çš„è¿ç”¨ é¦–å…ˆï¼Œä¸€å®šè¦æƒ³åˆ°æ¯å †æ’çš„å¼ æ•°å‡å»å¹³å‡å¼ æ•°ï¼Œè¿™æ ·ï¼Œé¢˜ç›®å°±å˜æˆäº†ç§»åŠ¨æ­£æ•°ï¼ŒåŠ åˆ°è´Ÿæ•°ä¸­ï¼Œæ˜¯å¤§å®¶éƒ½å˜æˆäº†0ï¼Œè¿™å°±æ„å‘³ç€æˆåŠŸäº†60%ï¼ï¼ï¼ï¼ï¼ˆå…³é”®ï¼‰ã€‚ä»¥ä¾‹é¢˜æ¥è¯´ï¼Œå¹³å‡å¼ æ•°ä¸º10ï¼ŒåŸå¼ æ•°å˜ä¸º-1ï¼Œ-2,+7ï¼Œ-4ï¼Œå› ä¸ºæ²¡æœ‰ä¸º0çš„æ•°ï¼Œæ‰€ä»¥ä»æœ€å·¦è¾¹å‡ºå‘ï¼Œå°†-1ç§»åŠ¨åˆ°-2ä¸­ï¼Œå˜ä¸º0ï¼Œ-3ï¼Œ+7,4ï¼Œå†è®²-3å‘å³ç§»åŠ¨â€¦â€¦ä¸€æ¬¡ç±»æ¨ï¼Œç›´åˆ°å…¨ä¸º0ä¸ºæ­¢ã€‚æ²¡ç§»åŠ¨ä¸€æ¬¡ï¼Œæ­¥æ•°ä¾¿åŠ 1ã€‚å…³é”®æ˜¯ï¼Œè´Ÿæ•°æ€ä¹ˆç§»åŠ¨ï¼Œå…¶å®ï¼Œç§»åŠ¨-xå¼ ç‰Œï¼Œå…¶å®å°±æ˜¯ä»å¦ä¸€å †ä¸­ç§»åŠ¨xå¼ ç‰Œï¼Œæ­¥æ•°ç›¸åŒã€‚è¿˜æœ‰å°±æ˜¯è¦è¿‡æ»¤0ï¼Œå¦‚æ’æ•°ä¸º4ï¼Œ4,2,6ï¼Œåˆ™å‡å»å¹³å‡æ•°åä¸º0,0ï¼Œ-2,2ï¼Œå°±è¦ä»ç¬¬ä¸‰å¯¹å¼€å§‹ç§»åŠ¨ã€‚æ³¨æ„æœ‰äº›0æ˜¯ä¸èƒ½è¿‡æ»¤çš„ï¼Œå¦‚1,0,1ï¼Œ-2ä¸­çš„0ã€‚è¿˜æœ‰å°±æ˜¯æ¯æ¬¡ç§»åŠ¨å¥½éƒ½è¦è¿‡æ»¤ã€‚å¦‚-2ï¼Œ2,1,3ï¼Œ-4ï¼Œç¬¬ä¸€æ­¥åå˜ä¸º0,0,1,3ï¼Œ-4ï¼Œå¯ä»¥çœç•¥ç¬¬äºŒå †çš„ç§»åŠ¨ã€‚","text":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1031 å‡åˆ†çº¸ç‰Œ æ ‡è§£ æ³¨æ„æœ¬é¢˜ä¸­å¹³å‡æ•°çš„è¿ç”¨ é¦–å…ˆï¼Œä¸€å®šè¦æƒ³åˆ°æ¯å †æ’çš„å¼ æ•°å‡å»å¹³å‡å¼ æ•°ï¼Œè¿™æ ·ï¼Œé¢˜ç›®å°±å˜æˆäº†ç§»åŠ¨æ­£æ•°ï¼ŒåŠ åˆ°è´Ÿæ•°ä¸­ï¼Œæ˜¯å¤§å®¶éƒ½å˜æˆäº†0ï¼Œè¿™å°±æ„å‘³ç€æˆåŠŸäº†60%ï¼ï¼ï¼ï¼ï¼ˆå…³é”®ï¼‰ã€‚ä»¥ä¾‹é¢˜æ¥è¯´ï¼Œå¹³å‡å¼ æ•°ä¸º10ï¼ŒåŸå¼ æ•°å˜ä¸º-1ï¼Œ-2,+7ï¼Œ-4ï¼Œå› ä¸ºæ²¡æœ‰ä¸º0çš„æ•°ï¼Œæ‰€ä»¥ä»æœ€å·¦è¾¹å‡ºå‘ï¼Œå°†-1ç§»åŠ¨åˆ°-2ä¸­ï¼Œå˜ä¸º0ï¼Œ-3ï¼Œ+7,4ï¼Œå†è®²-3å‘å³ç§»åŠ¨â€¦â€¦ä¸€æ¬¡ç±»æ¨ï¼Œç›´åˆ°å…¨ä¸º0ä¸ºæ­¢ã€‚æ²¡ç§»åŠ¨ä¸€æ¬¡ï¼Œæ­¥æ•°ä¾¿åŠ 1ã€‚å…³é”®æ˜¯ï¼Œè´Ÿæ•°æ€ä¹ˆç§»åŠ¨ï¼Œå…¶å®ï¼Œç§»åŠ¨-xå¼ ç‰Œï¼Œå…¶å®å°±æ˜¯ä»å¦ä¸€å †ä¸­ç§»åŠ¨xå¼ ç‰Œï¼Œæ­¥æ•°ç›¸åŒã€‚è¿˜æœ‰å°±æ˜¯è¦è¿‡æ»¤0ï¼Œå¦‚æ’æ•°ä¸º4ï¼Œ4,2,6ï¼Œåˆ™å‡å»å¹³å‡æ•°åä¸º0,0ï¼Œ-2,2ï¼Œå°±è¦ä»ç¬¬ä¸‰å¯¹å¼€å§‹ç§»åŠ¨ã€‚æ³¨æ„æœ‰äº›0æ˜¯ä¸èƒ½è¿‡æ»¤çš„ï¼Œå¦‚1,0,1ï¼Œ-2ä¸­çš„0ã€‚è¿˜æœ‰å°±æ˜¯æ¯æ¬¡ç§»åŠ¨å¥½éƒ½è¦è¿‡æ»¤ã€‚å¦‚-2ï¼Œ2,1,3ï¼Œ-4ï¼Œç¬¬ä¸€æ­¥åå˜ä¸º0,0,1,3ï¼Œ-4ï¼Œå¯ä»¥çœç•¥ç¬¬äºŒå †çš„ç§»åŠ¨ã€‚ 1234567891011#include &lt;iostream&gt; using namespace std; int main() &#123; int a,p=0,js=0; cin &gt;&gt;a;int q[a]; for (int y=0;y&lt;a;y++)&#123;cin &gt;&gt;q[y]; p+=q[y];&#125; p/=a; for (int y=0;y&lt;a;y++)q[y]-=p; for (int y=0;y&lt;a;y++) &#123;if (q[y]==0)continue; q[y+1]+=q[y]; js++; &#125; cout &lt;&lt;js; return 0;&#125; æˆ‘çš„è§£æ³• 1234567891011121314151617181920212223242526#include&lt;iostream&gt;#include&lt;cstdio&gt;using namespace std;int main()&#123; int sum=0,card[103],num,mean,no_count=0; cin&gt;&gt;num; for(int i=1;i&lt;=num;i++) &#123;cin&gt;&gt;card[i]; sum+=card[i];&#125; mean=sum/num; int pointer=0,local_sum=0; for(int i=1;i&lt;=num;i++)&#123; local_sum+=card[i]; pointer++;///æˆ‘çš„æ€è·¯æ˜¯è®°å½•æœ‰æ²¡æœ‰ä¸€ä¸ª local_max==local_sumï¼Œå¦‚æœæœ‰ local_sumï¼Œå³pointeræ‰€æŒ‡çš„é‚£ä¸€å †ï¼Œä¹‹å‰çš„å°±å…¨éƒ¨æ’å¥½äº†ï¼Œä¸éœ€è¦å†æ“å¿ƒäº† if(pointer==1 &amp;&amp; card[i]==mean) &#123;pointer=1; no_count++;&#125; ///ç›´æ¥ç­‰äºå¹³å‡æ•°çš„å †è¦æ‹¿å‡ºæ¥ç‰¹æ®Šè®¨è®ºï¼Œå› ä¸ºä»–ä»¬åªæœ‰è·Ÿåœ¨å·²ç»æ’å¥½åºçš„å †åé¢çš„æ—¶å€™æ‰ä¸éœ€è¦å†ç»è¿‡ä¸€æ¬¡ç§»åŠ¨ï¼Œè€Œå‰é¢çš„å †å·²ç»æ’å¥½åºçš„æ ‡å¿—å°±æ˜¯ pointer==1ï¼Œè¿™ç§æƒ…å†µä¸‹æˆ‘ä»¬å¯ä»¥å°‘ç§»åŠ¨ä¸€ä¸ªï¼Œå¹¶ä¸”é‡æ–°è®¾ç½® pointer==1 ä»£è¡¨å‰é¢çš„å †éƒ½æœ‰åº if(local_sum==pointer*mean &amp;&amp; pointer!=1)&#123; /// local_sum==pointer*mean æ­¤æ—¶æˆ‘ä»¬æ‰¾åˆ°ä¸€ä¸ªå †ï¼Œå¯ä»¥ä½¿å‰é¢çš„æ‰€æœ‰å †è·å¾—ç¬¦åˆè¦æ±‚çš„è§£ï¼Œå¹¶ä¸”ä»–åªéœ€è¦å‘åˆ«äººè¾“é€ç‰Œï¼Œè‡ªå·±ä¸éœ€è¦æ¥å—ï¼Œæ‰€ä»¥æœ‰ä¸€ä¸ª no_count++ /// pointer!=1 è¿™æ˜¯ local_sum å°±æ˜¯ä»–æœ¬èº«ï¼Œå¿…ç„¶ç›¸ç­‰ no_count++; pointer=0; local_sum=0; &#125; &#125; cout&lt;&lt;num-no_count;&#125;","categories":[],"tags":[{"name":"NOI","slug":"NOI","permalink":"https://yao-lirong.github.io/blog/tags/NOI/"}]},{"title":"P2678 è·³çŸ³å¤´","slug":"P2678 è·³çŸ³å¤´","date":"2019-06-03T04:00:00.000Z","updated":"2019-06-27T12:27:22.000Z","comments":true,"path":"P2678 è·³çŸ³å¤´/","permalink":"https://yao-lirong.github.io/blog/P2678%20%E8%B7%B3%E7%9F%B3%E5%A4%B4/","excerpt":"é¢˜ç›®æ¥æºï¼šæ´›è°·P2678 è·³çŸ³å¤´ è¿™æ˜¯ä¸€é“æ ‡å‡†çš„ â€œæœ€å¤§å€¼æœ€å°â€æˆ–â€œæœ€å°å€¼æœ€å¤§â€œ çš„é¢˜ï¼Œé‡åˆ°è¿™ç§é¢˜ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ è´ªå¿ƒ+äºŒåˆ†æŸ¥æ‰¾ çš„æ–¹æ³•æ¥åš äºŒåˆ†ç­”æ¡ˆ/äºŒåˆ†æŸ¥æ‰¾ æœ‰åºï¼ˆå•è°ƒï¼‰çš„ï¼Œæœ‰ç•Œçš„å°±å¯ä»¥ç”¨äºŒåˆ†æ³•æŸ¥æ‰¾ã€‚","text":"é¢˜ç›®æ¥æºï¼šæ´›è°·P2678 è·³çŸ³å¤´ è¿™æ˜¯ä¸€é“æ ‡å‡†çš„ â€œæœ€å¤§å€¼æœ€å°â€æˆ–â€œæœ€å°å€¼æœ€å¤§â€œ çš„é¢˜ï¼Œé‡åˆ°è¿™ç§é¢˜ï¼Œæˆ‘ä»¬å°±å¯ä»¥ä½¿ç”¨ è´ªå¿ƒ+äºŒåˆ†æŸ¥æ‰¾ çš„æ–¹æ³•æ¥åš äºŒåˆ†ç­”æ¡ˆ/äºŒåˆ†æŸ¥æ‰¾ æœ‰åºï¼ˆå•è°ƒï¼‰çš„ï¼Œæœ‰ç•Œçš„å°±å¯ä»¥ç”¨äºŒåˆ†æ³•æŸ¥æ‰¾ã€‚ æœ‰ç•Œï¼šå¯¹äºæœ¬é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œè¿™ä¸ªæ‰€è°“çš„æœ€çŸ­è·³è·ƒè·ç¦»æ˜¾ç„¶ä¸èƒ½è¶…è¿‡ä¸€ä¸ªèŒƒå›´ï¼ˆè·³ä¸€æ¬¡ä»å¤´è·³åˆ°å°¾ï¼‰ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œç­”æ¡ˆæ˜¯æœ‰ä¸€ä¸ªç¡®å®šçš„èŒƒå›´é™åˆ¶çš„ï¼ˆå¼€å¤´åˆ°ç»“å°¾çš„è·ç¦»å†…ï¼‰ï¼Œæˆ‘ä»¬å°±å¯ä»¥è€ƒè™‘ä¸€ç§å¦å¤–çš„æ–¹æ³•å»è§£å†³â€”â€”æšä¸¾ç­”æ¡ˆï¼Œå¹¶å»éªŒè¯ç­”æ¡ˆæ˜¯å¦å¯è¡Œï¼Œè¿™å®é™…ä¸Šæ˜¯ä¸€ç§å€’æ¨ äºŒåˆ†ï¼šé‚£ä¹ˆå¦‚ä½•ç¡®ä¿æˆ‘ä»¬å¯ä»¥æœ€å¿«çš„æ‰¾åˆ°ç­”æ¡ˆå‘¢ï¼ŸäºŒåˆ†æ˜¯æœ€å¥½é€‰æ‹© å•è°ƒï¼šäºŒåˆ†çš„å‰ææ¡ä»¶æ˜¯ä»€ä¹ˆï¼Ÿæ˜¯ç­”æ¡ˆåŒºé—´æ˜¯æ•´ä½“æœ‰åºçš„ã€‚æˆ‘ä»¬åªè€ƒè™‘åˆæ³•è§£ï¼Œå¹¶ç§°ä¹‹ä¸ºå¯è¡Œè§£ã€‚è€ƒè™‘æ‰€æœ‰å¯è¡Œè§£ï¼Œæˆ‘ä»¬è‚¯å®šæ˜¯è¦ä»è¿™äº›å¯è¡Œè§£ä¸­æ‰¾åˆ°ä¸€ä¸ªæœ€å¥½çš„ä½œä¸ºæˆ‘ä»¬çš„ç­”æ¡ˆï¼Œ è¿™ä¸ªç­”æ¡ˆæˆ‘ä»¬ç§°ä¹‹ä¸ºæœ€ä¼˜è§£ã€‚æœ€ä¼˜è§£ä¸€å®šå¯è¡Œï¼Œä½†å¯è¡Œè§£ä¸ä¸€å®šæœ€ä¼˜ã€‚ æˆ‘ä»¬å‡è®¾æ•´ä¸ªåºåˆ—å…·æœ‰å•è°ƒæ€§ï¼Œä¸”ä¸€ä¸ªæ•°xä¸ºå¯è¡Œè§£ï¼Œé‚£ä¹ˆä¸€èˆ¬çš„ï¼Œæ‰€æœ‰çš„xâ€™(xâ€™&lt;x)éƒ½æ˜¯å¯è¡Œè§£ã€‚ å¹¶ä¸”ï¼Œå¦‚æœæœ‰ä¸€ä¸ªæ•°yæ˜¯éæ³•è§£ï¼Œé‚£ä¹ˆä¸€èˆ¬çš„ï¼Œæ‰€æœ‰çš„yâ€™(yâ€™&gt;y)éƒ½æ˜¯éæ³•è§£ã€‚ æ€»ç»“æ¥è¯´ï¼Œå¯ä»¥ä½¿ç”¨äºŒåˆ†æŸ¥æ‰¾çš„æ¡ä»¶ï¼šè§£çš„ä¸Šä¸‹ç•Œç¡®å®š(l=0,r=L),å¯ä»¥å†™å‡ºåˆ¤æ–­æ¡ä»¶(f(x)&lt;=m),è§£å…·æœ‰åŒºé—´å•è°ƒæ€§(åœ¨æŸä¸ªå€¼ä¹‹å‰æ¡ä»¶éƒ½æˆç«‹ï¼Œä¹‹åéƒ½ä¸æˆç«‹) æœ¬é¢˜å’Œ P2855 River Hopscotch æ˜¯åŒä¸€é“é¢˜ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;algorithm&gt;using namespace std;int rocks[50003],ending,num,removed,result;void finding(int,int);int main()&#123; cin&gt;&gt;ending&gt;&gt;num&gt;&gt;removed; for(int i=1;i&lt;=num;i++) cin&gt;&gt;rocks[i]; rocks[0]=0; rocks[num+1]=ending; sort(rocks+1,rocks+num+1); finding(0,ending); cout&lt;&lt;result; return 0;&#125;void finding(int m, int n)&#123; int mid=(m+n)/2, removing=0; int now=0,pointer=0;///now è¡¨ç¤ºæˆ‘ä»¬ç°åœ¨æ‰€åœ¨çš„ä½ç½®ï¼Œpointer è¡¨ç¤ºä¸‹ä¸€ä¸ªå¯ä»¥è·³åˆ°çš„ä½ç½® while(pointer&lt;num)&#123;///äººå®¶è¿™ä¸ªæ–¹æ³•ç›´æ¥ä¸€æ­¥å­è¿ˆè¿‡å»äº†ï¼Œæ ¹æœ¬ä¸éœ€è¦è®°å½•å“ªä¸ªçŸ³å¤´è¢«æ‹¿æ‰äº†ï¼Œæˆ–è€…åˆ¤å®šä¸€ä¸ªåŸæœ¬æœ‰çŸ³å¤´çš„åœ°æ–¹è¢«æ²¡è¢«æ‹¿æ‰ï¼Œæ¯•ç«Ÿé¢˜ç›®æœ¬èº«å°±å«è·³çŸ³å¤´ï¼Œä¸ºä»€ä¹ˆè¦ä¸€ä¸ªä¸ªçŸ³å¤´çœ‹å‘¢ï¼Œç›´æ¥è·³ä¸å°±å¥½äº† pointer++; if(rocks[pointer]-rocks[now]&lt;mid)///æˆ‘ä»¬è®¤ä¸ºmidæ˜¯æœ€çŸ­è·³è·ƒè·ç¦»ï¼Œå¦‚æœæœ‰æŸç§æƒ…å†µä½¿å¾—è·³è·ƒè·ç¦»æ¯”è¿™ä¸ªæœ€çŸ­çš„è¿˜çŸ­ï¼Œæˆ‘ä»¬å°±éœ€è¦æ‹¿èµ°è¿™å—çŸ³å¤´æ¥å¢å¤§è¿™ä¸ªåœ°æ–¹çš„è·³è·ƒè·ç¦»ï¼Œä½¿å…¶å¤§äºæœ€çŸ­è·³è·ƒè·ç¦» removing++; else//å¦‚æœæ¯”æœ€çŸ­è·ç¦»é•¿çš„è¯ï¼Œæˆ‘ä»¬å°±å¯ä»¥è·³è¿‡å» now=pointer; &#125; if(m&lt;=n)&#123; ///è¿™ä¸ªåœ°æ–¹æˆ‘å†™ m&lt;n æˆ–è€… m&lt;=n æœ‰åŒºåˆ«å—ï¼Ÿæˆ‘çš„måˆ°æœ€åçš„æ—¶å€™åªèƒ½é€šè¿‡mid+1è¿™ä¸€ç§æ–¹å¼æ›´æ–°ï¼Œ+1åˆä¸å½±å“/2ä»¥åmidçš„å€¼ï¼Œæ‰€ä»¥è¿™ä¸¤ä¸ªåˆ¤å®šä¸æ˜¯ä¸€æ ·çš„å—ï¼Ÿ ///ç¡®å®åˆ¤å®šçš„æ—¶å€™æ²¡ä»€ä¹ˆåŒºåˆ«ï¼Œæœ€åéƒ½ä¼šæ›´æ–°åˆ°m=4 n=4 mid=4ï¼Œä½†æ˜¯ m&lt;n è¿è¡Œåˆ° m=4 n=4 mid=4 ä¼šå‘ç° m!&lt;n æ‰€ä»¥ä¸ä¼šæ›´æ–° result if(removing&gt;removed) finding(m,mid-1); ///å¦‚æœæˆ‘ä»¬ä»¥midä¸ºæœ€å°è·ç¦»çš„æƒ…å†µä¸‹ç§»åŠ¨çš„çŸ³å—æ¯”æˆ‘ä»¬æœ¬åº”è¯¥ç§»åŠ¨çš„çŸ³å—å¤šçš„è¯ï¼Œè¯´æ˜è¿™ä¸ªç­”æ¡ˆæ˜¯ä¸åˆæ³•çš„ï¼Œå¹¶ä¸”æ‰€æœ‰å¤§äºmidçš„éƒ½ä¸åˆæ³•ï¼ˆè¶Šå¤§äºmidç§»åŠ¨çš„çŸ³å—åªä¼šè¶Šæ¥è¶Šå¤šï¼‰ï¼Œæ‰€ä»¥å‡å°‘ æœ€å°ç§»åŠ¨è·ç¦» ä½¿å¾—æˆ‘ä»¬ä¸è¦ç§»åŠ¨é‚£ä¹ˆå¤šçŸ³å— else if(removing&lt;=removed) &#123; result=mid; finding(mid+1,n);&#125; ///å¦‚æœä»¥midä¸ºæœ€å°è·ç¦»çš„æƒ…å†µä¸‹ç§»åŠ¨çš„çŸ³å—æ¯”æˆ‘ä»¬æœ¬åº”è¯¥ç§»åŠ¨çš„çŸ³å—å¤šçš„è¯ï¼Œè¯´æ˜è¿™ä¸ªç­”æ¡ˆåˆæ³•ï¼Œä½†æ˜¯å› ä¸ºæˆ‘ä»¬è¦å¯»æ‰¾æœ€å¤§çš„æœ€å°å€¼ï¼Œæ‰€ä»¥å¢å¤§ æœ€å°è·ç¦» çœ‹çœ‹æœ‰æ²¡æœ‰æ›´ä¼˜çš„è§£ &#125;&#125;/*25 5 2 2111417 21*/ äºŒåˆ†æŸ¥æ‰¾æ¨¡æ¿ éé€’å½’å½¢å¼çš„äºŒåˆ†æŸ¥æ‰¾æ¨¡æ¿ 123456789101112int l=1,r=ll;/// 1 æ˜¯ç­”æ¡ˆçš„æœ€å°å€¼ï¼Œllæ˜¯ç­”æ¡ˆçš„æœ€å¤§å€¼ while(l&lt;=r) &#123; ///å½“å·¦å³è¾¹ç•Œé‡åˆçš„æ—¶å€™å°±æ˜¯ç­”æ¡ˆï¼Œé€€å‡ºå¾ªç¯ int mid=(l+r)&gt;&gt;1,q=check(mid);//â€œ&gt;&gt;1â€ç›¸å½“äºâ€œ/2â€ if(check) ///å½“è¯¥è·ç¦»æ»¡è¶³æ¡ä»¶çš„æ—¶å€™ &#123; ///å»å¯»æ‰¾å³åŠéƒ¨åˆ†ï¼Œçœ‹çœ‹è¿˜æœ‰æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ›´å¤§çš„å€¼ ll=mid+1;///llä¸Šmidå³è¾¹ï¼Œæ‰¾å³åŠéƒ¨åˆ† ans=mid;///è®°å½•ç­”æ¡ˆï¼ˆæ›´æ–°ä¸­ï¼‰ &#125; else l=mid+1;///è‹¥è¿™ä¸ªå€¼ä¸æ»¡è¶³ï¼Œå°±æ‰¾å·¦éƒ¨åˆ†&#125; ä¸‹é¢æ˜¯ä¸€ä¸ªäºŒåˆ†æŸ¥æ‰¾çš„æ ·ä¾‹ P1824 Aggressive Cows 12345678910111213141516171819202122232425262728293031#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;algorithm&gt;using namespace std;int stall[100005],cow_num,stall_num,ans;void finding(int,int);int main()&#123; cin&gt;&gt;stall_num&gt;&gt;cow_num; for(int i=1;i&lt;=stall_num;i++) cin&gt;&gt;stall[i]; sort(stall+1,stall+stall_num+1); finding(1,stall[stall_num]); cout&lt;&lt;ans; return 0;&#125;void finding(int m, int n)//çœ‹åˆ°ä¸€ä¸ªç¬¦åˆè¦æ±‚çš„å°±å¡«è¿›å»ï¼Œæœ€åçœ‹å¡«è¿›å»çš„cowå’Œä¸€å…±æœ‰çš„æ˜¯å¤šæ˜¯å°‘&#123; int mid=(m+n)/2,now=1,pointer=1,cow_mid=1;///cow_mid ä»1å¼€å§‹ï¼Œå¦‚æœä»0å¼€å§‹å®é™…ä¸Šç®—çš„æ˜¯é—´è·ï¼Œn+1æ‰æ˜¯ç‰›çš„æ•°é‡ while(pointer&lt;stall_num)&#123; pointer++; if(stall[pointer]-stall[now]&gt;=mid)&#123;///è¿™é‡Œæ³¨æ„æ˜¯ &gt;= åªè¦æ¯”æœ€çŸ­çš„è·ç¦»(mid)å¤§ï¼Œæˆ‘ä»¬å°±å¯ä»¥æ”¾ä¸€å¤´å¥¶ç‰›åœ¨è¿™é‡Œ cow_mid++; now=pointer;&#125; &#125; if(m&lt;=n)&#123; if(cow_mid&gt;=cow_num) &#123;ans=mid; finding(mid+1,n);&#125; ///å¦‚æœè¿™æ¬¡æ”¾çš„æ¯”æˆ‘ä»¬éœ€è¦æ”¾çš„å¤šï¼Œè¯´æ˜æˆ‘ä»¬çš„æœ€çŸ­é—´è·å¤ªå°äº†ï¼Œæ‰€ä»¥è¦å¢å¤§æœ€çŸ­é—´è· else finding(m,mid-1); &#125;&#125;","categories":[],"tags":[{"name":"NOI","slug":"NOI","permalink":"https://yao-lirong.github.io/blog/tags/NOI/"}]},{"title":"P1090 åˆå¹¶æœå­","slug":"P1090 åˆå¹¶æœå­","date":"2019-05-30T04:00:00.000Z","updated":"2019-06-27T12:32:00.000Z","comments":true,"path":"P1090 åˆå¹¶æœå­/","permalink":"https://yao-lirong.github.io/blog/P1090%20%E5%90%88%E5%B9%B6%E6%9E%9C%E5%AD%90/","excerpt":"é¢˜ç›®æ¥æºï¼š æ´›è°·P1090 åˆå¹¶æœå­ ä¸€ç»´æ•°ç»„åšæ³• æœ¬é¢˜æ˜¯ä¸€ä¸ªç®€å•çš„ Huffmanæ ‘ã€‚Huffmanç¼–ç  åœ¨ UTF-8 &amp; Unicode ä¸­éƒ½æœ‰å®ƒæ€æƒ³çš„ä½“ç°ï¼Œå³å‡ºç°é¢‘ç‡é«˜çš„ç¼–ç é•¿åº¦çŸ­ï¼Œå‡ºç°é¢‘ç‡ä½çš„ç¼–ç é•¿åº¦é•¿ï¼Œç”¨ä»¥ç¼©çŸ­æ•´ä½“ç¼–ç é•¿åº¦ è¿™é‡Œæˆ‘ä¹Ÿè¿ç”¨äº†å‰é¢ P1309 çš„æ€æƒ³ï¼šå› ä¸ºæ¯æ¬¡éœ€è¦é‡æ–°æ’åºçš„æ—¶å€™åªæœ‰ä¸€ä¸ªæ•°æ®éœ€è¦è¢«æ’å…¥æ•´ä¸ªæ•°åˆ—å½“ä¸­,æ‰€ä»¥å¹¶ä¸éœ€è¦å‡å®šæ•°æ®æ— åºçš„ quick sortï¼Œåè€Œæ˜¯çº¿æ€§çš„æ’åºæ›´å¿«","text":"é¢˜ç›®æ¥æºï¼š æ´›è°·P1090 åˆå¹¶æœå­ ä¸€ç»´æ•°ç»„åšæ³• æœ¬é¢˜æ˜¯ä¸€ä¸ªç®€å•çš„ Huffmanæ ‘ã€‚Huffmanç¼–ç  åœ¨ UTF-8 &amp; Unicode ä¸­éƒ½æœ‰å®ƒæ€æƒ³çš„ä½“ç°ï¼Œå³å‡ºç°é¢‘ç‡é«˜çš„ç¼–ç é•¿åº¦çŸ­ï¼Œå‡ºç°é¢‘ç‡ä½çš„ç¼–ç é•¿åº¦é•¿ï¼Œç”¨ä»¥ç¼©çŸ­æ•´ä½“ç¼–ç é•¿åº¦ è¿™é‡Œæˆ‘ä¹Ÿè¿ç”¨äº†å‰é¢ P1309 çš„æ€æƒ³ï¼šå› ä¸ºæ¯æ¬¡éœ€è¦é‡æ–°æ’åºçš„æ—¶å€™åªæœ‰ä¸€ä¸ªæ•°æ®éœ€è¦è¢«æ’å…¥æ•´ä¸ªæ•°åˆ—å½“ä¸­,æ‰€ä»¥å¹¶ä¸éœ€è¦å‡å®šæ•°æ®æ— åºçš„ quick sortï¼Œåè€Œæ˜¯çº¿æ€§çš„æ’åºæ›´å¿« 1234567891011121314151617181920212223242526#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;algorithm&gt;using namespace std;int main()&#123; int n,berry[10005];long long ans=0; cin&gt;&gt;n; for(int i=1;i&lt;=n;i++) cin&gt;&gt;berry[i]; sort(berry+1,berry+1+n); for(int i=1;i&lt;=n-1;i++)&#123; berry[i+1]=berry[i]+berry[i+1];///è®¡ç®—æ¯ä¸ªæœå †çš„é‡é‡ ans+=berry[i+1];///ç­”æ¡ˆæ˜¯æ¯æ¬¡æ¬çš„æœå †çš„é‡é‡ä¹‹å’Œ if(berry[i+1]&gt;berry[i+2])&#123;///è§£å†³å‰ä¸¤ä¸ªæ•°ä¹‹å’Œå¤§äºç¬¬ä¸‰/å››ä¸ªæ•°çš„æƒ…å†µï¼ˆæ¯”å¦‚æœ‰ 1 1 1 1ï¼‰æœ€ä¼˜è§£ä¸º4è€Œä¸æ˜¯7 for(int j=i+1;j&lt;=n-1;j++)&#123; if(berry[j]&gt;berry[j+1]) swap(berry[j],berry[j+1]);///çº¿æ€§æ’åº &#125; &#125; &#125; cout&lt;&lt;ans; return 0;&#125; å½’å¹¶åšæ³• æ®è¯´æ˜¯ç¦»æ•£åŒ–ç®—æ³• å°±æ˜¯å…ˆæŠŠåŸæœ¬çš„ä»å°åˆ°å¤§æ’åºæ’å¥½ã€‚ç„¶åç”¨ä¸¤ä¸ªé˜Ÿåˆ—ï¼Œä¸€ä¸ªæ˜¯å­˜å‚¨åŸæœ¬çš„ï¼Œå¦ä¸€ä¸ªæ˜¯å­˜å‚¨åˆæˆçš„ï¼ˆç”±äºåŸæœ¬çš„æ˜¯ä»å°åˆ°å¤§æ‰€æœ‰æ–°å¼€çš„ä¹Ÿæ˜¯ä»å°åˆ°å¤§ï¼‰ã€‚ç„¶ååœ¨ä¸¤ä¸ªé˜Ÿåˆ—çš„å¤´å–æœ€å°çš„ï¼Œæ‰§è¡Œä¸¤æ¬¡ç„¶åæŠŠè¿™ä¸¤ä¸ªåˆå¹¶åŠ å…¥ç¬¬äºŒä¸ªé˜Ÿåˆ—ä¸­ã€‚ ç„¶åç”±äºè¾“å…¥ï¼š (1â‰¤aiâ‰¤20000)(1â‰¤aiâ‰¤20000)(1â‰¤aiâ‰¤20000) ï¼Œæ‰€ä»¥ç”¨æ¡¶æ’åºå°±å¯ä»¥ O(n)O(n)O(n) æ—¶é—´å¤æ‚åº¦ è¦ä¹‰æ˜¯å‚¨å­˜åŸæœ¬æœå †çš„a1æ˜¯æŒ‰é¡ºåºæ’åˆ—çš„ï¼Œæ‰€ä»¥å­˜å‚¨ä¸¤ä¸¤åˆæˆçš„æ–°æœå †çš„a2ä¹Ÿæ˜¯æŒ‰é¡ºåºæ’åˆ—çš„ã€‚å–è¿™ä¸¤ä¸ªæœå †åºåˆ—ä¸­æœ€å°çš„ä¸¤ä¸ªæœå †ï¼Œå¿…å®šè·å¾—è¿™ä¸€æ­¥èƒ½è·å¾—çš„æœ€å°çš„æœå †ã€‚ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include&lt;cstdio&gt;#include&lt;algorithm&gt;#include&lt;cstring&gt;using namespace std;int k,x,num,n1,n2,a1[30001],a2[30001],t[20001],w,sum;int main()&#123; scanf(&quot;%d&quot;,&amp;num); memset(a1,127/3,sizeof(a1)); memset(a2,127/3,sizeof(a2)); for (int i=1;i&lt;=num;i++) &#123; scanf(&quot;%d&quot;,&amp;x); t[x]++;//æ¡¶ &#125; for (int i=1;i&lt;=20000;i++) &#123; while (t[i])//é€šæ’åº &#123; t[i]--; a1[++n1]=i; &#125; &#125; int i=1,j=1; k=1; while (k&lt;num) &#123; if (a1[i]&lt;a2[j])//å–æœ€å°å€¼ &#123; w=a1[i]; i++; &#125; else &#123; w=a2[j]; j++; &#125; if (a1[i]&lt;a2[j])//å–ç¬¬äºŒæ¬¡ &#123; w+=a1[i]; i++; &#125; else &#123; w+=a2[j]; j++; &#125; a2[++n2]=w;//åŠ å…¥ç¬¬äºŒä¸ªé˜Ÿåˆ— k++;//è®¡ç®—åˆå¹¶æ¬¡æ•° sum+=w;//è®¡ç®—ä»·å€¼ &#125; printf(&quot;%d&quot;,sum);&#125; äºŒå‰ï¼ˆå°æ ¹ï¼‰å † s ä»£è¡¨ son, p ä»£è¡¨ parent, size ä»£è¡¨æ•´ä¸ªäºŒå‰å †ä¸­å­˜å‚¨çš„æ•°æ®æ•°é‡ å®Œç¾äºŒå‰æ ‘, å®Œå…¨äºŒå‰æ ‘å’Œå®Œæ»¡äºŒå‰æ ‘çš„åŒºåˆ† 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#include&lt;bits/stdc++.h&gt;using namespace std;const int maxn=10000+10;int n,heap[maxn],size=0;void up(int p) //äºŒå‰å°æ ¹å †å‘ä¸Šè°ƒæ•´ï¼ˆå­èŠ‚ç‚¹å°äºçˆ¶èŠ‚ç‚¹å°±è°ƒæ•´ï¼‰&#123; while(p&gt;1) &#123; if(heap[p]&lt;heap[p/2]) &#123; swap(heap[p],heap[p/2]); p/=2; &#125; else break; &#125;&#125;void insert(int val) //äºŒå‰å †æ’å…¥ï¼Œæ–°å…ƒç´ æ”¾åœ¨å †åº•ï¼Œå‘ä¸Šè°ƒæ•´&#123; heap[++size]=val; up(size);&#125;void down(int p) //äºŒå‰å°æ ¹å †å‘ä¸‹è°ƒæ•´&#123; int s=p*2; while(s&lt;=size) &#123; //ä¸‹é¢è¿™å¥è¯æ˜¯ä»å·¦å³å„¿å­ä¸­é€‰ä¸€ä¸ªæ›´å°çš„åšäº¤æ¢ if(s&lt;size&amp;&amp;heap[s+1]&lt;heap[s]) s++; if(heap[s]&lt;heap[p]) &#123; swap(heap[s],heap[p]); p=s; s=p*2; &#125; else break; &#125;&#125;void extract() //äºŒå‰å †åˆ é™¤å †é¡¶&#123; heap[1]=heap[size--]; //å°†å †åº•ç§»è‡³å †é¡¶ï¼Œå‘ä¸‹è°ƒæ•´ down(1);&#125;int gettop() //è¿”å›å †é¡¶çš„å€¼&#123; return heap[1];&#125;int main()&#123; cin&gt;&gt;n; for(int i=1; i&lt;=n; i++) &#123; int a; cin&gt;&gt;a; insert(a); //å»ºç«‹äºŒå‰å † &#125; long long ans=0; //å…¶å®è¿™é‡Œä¸ä¼šè¶Šç•Œï¼Œä½†å¥½åƒåŸé¢˜æ•°æ®æ˜¯3ä¸‡ while(size&gt;=2) //å¦‚æœè¿˜å¯åˆå¹¶ &#123; int top1=gettop(); //å–å‡ºå †é¡¶ï¼ˆå †ä¸­æœ€å°å€¼ï¼‰ååˆ é™¤å †é¡¶ extract(); int top2=gettop(); //åŒä¸Š extract(); ans+=(top1+top2); insert(top1+top2); //å°†ä¸¤æ•°ä¹‹å’ŒåŠ å…¥äºŒå‰å †ï¼Œé‡å¤è¿ç®— &#125; cout&lt;&lt;ans&lt;&lt;endl; //è¾“å‡ºç­”æ¡ˆ return 0;&#125;","categories":[],"tags":[{"name":"NOI","slug":"NOI","permalink":"https://yao-lirong.github.io/blog/tags/NOI/"}]},{"title":"P1309 ç‘å£«è½®","slug":"P1309 ç‘å£«è½®","date":"2019-05-30T04:00:00.000Z","updated":"2019-06-27T12:26:56.000Z","comments":true,"path":"P1309 ç‘å£«è½®/","permalink":"https://yao-lirong.github.io/blog/P1309%20%E7%91%9E%E5%A3%AB%E8%BD%AE/","excerpt":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1309 ç‘å£«è½® èƒœè€…ç»„å’Œè´¥è€…ç»„åˆ†åˆ«æ˜¯æœ‰åºçš„ï¼Œä½¿ç”¨ mergesort å°†ä¸¤ä¸ªæœ‰åºåŒå‘æ•°ç»„è¿›è¡Œå½’å¹¶ï¼ˆä¸¥æ ¼ä¸Šæ¥è¯´ä¸æ˜¯å½’å¹¶æ’åºï¼‰ï¼Œå¤§å¤§é™ä½äº†æ—¶é—´å¤æ‚åº¦ = O(n)ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨ quicksortï¼Œåˆ™é»˜è®¤æ•´ä¸ªæ•°æ®æ˜¯æ— åºçš„ï¼Œå¯¹æ¯ä¸ªæ•°æ®éƒ½é‡æ–°æ’åºæ‰€ä»¥ä¼šè¶…æ—¶","text":"é¢˜ç›®æ¥æºï¼šæ´›è°·P1309 ç‘å£«è½® èƒœè€…ç»„å’Œè´¥è€…ç»„åˆ†åˆ«æ˜¯æœ‰åºçš„ï¼Œä½¿ç”¨ mergesort å°†ä¸¤ä¸ªæœ‰åºåŒå‘æ•°ç»„è¿›è¡Œå½’å¹¶ï¼ˆä¸¥æ ¼ä¸Šæ¥è¯´ä¸æ˜¯å½’å¹¶æ’åºï¼‰ï¼Œå¤§å¤§é™ä½äº†æ—¶é—´å¤æ‚åº¦ = O(n)ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨ quicksortï¼Œåˆ™é»˜è®¤æ•´ä¸ªæ•°æ®æ˜¯æ— åºçš„ï¼Œå¯¹æ¯ä¸ªæ•°æ®éƒ½é‡æ–°æ’åºæ‰€ä»¥ä¼šè¶…æ—¶ ä¸€ç§å¯ä»¥æ›¿ä»£ç»“æ„ä½“çš„æ–¹æ³•ï¼šæ’åçš„æ—¶å€™æˆ‘ä»¬å¯ä»¥åªå¯¹æ¯ä¸ªé€‰æ‰‹çš„åºå·è¿›è¡Œæ’åºï¼Œè¿™æ ·åšæ—¢å¯ä»¥ä¿è¯æˆ‘ä»¬æœ‰å„ä¸ªäººçš„æ’åºï¼Œåˆå¯ä»¥ä¿è¯ä»–ä»¬çš„æˆç»©å’Œå®åŠ›å¾—åˆ°è®°å½•ï¼ˆåºå·å¯¹åº”ç€æˆç»©å’Œå®åŠ›ï¼Œåœ¨å¯¹åºå·æ ¹æ®å®åŠ›æ’åºçš„åŒæ—¶ï¼Œæ¯ä¸ªåºå·å¯¹åº”çš„æˆç»©å’Œå®åŠ›çš„é¡ºåºæ˜¯ä¸å˜çš„ï¼‰ sort å‡½æ•°ä¸­ cmp çš„ä½¿ç”¨æ–¹æ³• 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;algorithm&gt;using namespace std;int num,round,inquiry,score[200005],power[200005],No[200005],winner[100005],loser[100005];///å…¶ä¸­ï¼ŒNoé‡Œæ¯ä¸ªä¸‹æ ‡ä»£è¡¨é€‰æ‰‹çš„æ’åï¼Œpower &amp; score çš„ä¸‹æ ‡ä»£è¡¨é€‰æ‰‹çš„åºå·bool cmp(int, int);void mergesort();void compete();int main()&#123; cin&gt;&gt;num&gt;&gt;round&gt;&gt;inquiry; for(int i=1;i&lt;=2*num;i++) cin&gt;&gt;score[i]; for(int i=1;i&lt;=2*num;i++) cin&gt;&gt;power[i]; for(int i=1;i&lt;=2*num;i++) No[i]=i; //for(int i=1;i&lt;=2*num;i++) cout&lt;&lt;No[i]&lt;&lt;&quot; &quot;&lt;&lt;score[i]&lt;&lt;endl; sort(No+1,No+1+2*num,cmp); //for(int i=1;i&lt;=2*num;i++) cout&lt;&lt;No[i]&lt;&lt;&quot; &quot;&lt;&lt;score[i]&lt;&lt;endl; for(int i=1;i&lt;=round;i++) &#123; compete(); mergesort(); &#125; cout&lt;&lt;No[inquiry]; //while(true); return 0;&#125;bool cmp(int m, int n)&#123; ///cmpå‡½æ•°ä½¿ç”¨èŒƒä¾‹ if(score[m]==score[n]) return m&lt;n; else return score[m]&gt;score[n];&#125;void compete()&#123; for(int i=1;i&lt;=2*num;i=i+2) &#123; if(power[No[i]]&gt;power[No[i+1]]) &#123; score[No[i]]++; winner[i/2+1]=No[i]; loser[i/2+1]=No[i+1]; &#125; else if(power[No[i]]&lt;power[No[i+1]]) &#123; score[No[i+1]]++; winner[i/2+1]=No[i+1]; loser[i/2+1]=No[i]; &#125; &#125; /*cout&lt;&lt;&quot;compete&quot;&lt;&lt;endl; for(int i=1;i&lt;=num;i++) cout&lt;&lt;winner[i]&lt;&lt;&quot; &quot;&lt;&lt;loser[i]&lt;&lt;endl; cout&lt;&lt;endl;*/&#125;void mergesort()&#123; int i=1,j=1; while(i&lt;=num &amp;&amp; j&lt;=num) &#123; //if(score[winner[i]]&gt;score[loser[j]]) if(cmp(winner[i],loser[j])) ///å®Œå…¨æ— æ³•ç†è§£è¿™ä¸ªåœ°æ–¹åªå†™ä¸€ä¸ªcmpæ˜¯æ€ä¹ˆè¿‡çš„ï¼Œéš¾é“ä¸ä¼šæœ‰ä½äºåé¢çš„ç›¸ç­‰scoreé¡¹å®é™…æ¯”å‰é¢çš„ç›¸ç­‰scoreé¡¹åºå·æ›´å°è¿™ç§æƒ…å†µå— &#123; No[i+j-1]=winner[i]; i++; &#125; //else if(score[loser[j]]&gt;score[winner[i]]) else &#123; No[i+j-1]=loser[j]; j++; &#125; /*else if(score[loser[j]]==score[winner[i]]) &#123; int k=0,temp[200005]; while(score[winner[i]]==score[winner[i+1]]) temp[++k]=winner[i++]; while(score[loser[j]]==score[loser[j]]) temp[++k]=loser[j++]; sort(temp,temp+k); for(int a=1;a&lt;=k;a++) No[a+i+j-1]=temp[a]; &#125;*/ &#125; while(i&lt;=num) &#123; No[i+num]=winner[i]; i++; &#125; while(j&lt;=num) &#123; No[j+num]=loser[j]; j++; &#125; /*cout&lt;&lt;&quot;mergesort&quot;; for(int i=1;i&lt;=num*2;i++) cout&lt;&lt;No[i]&lt;&lt;&quot; &quot;; cout&lt;&lt;endl;*/&#125;/*2 4 17 6 6 710 5 20 15*/","categories":[],"tags":[{"name":"NOI","slug":"NOI","permalink":"https://yao-lirong.github.io/blog/tags/NOI/"}]},{"title":"Introduction to Git Command","slug":"Intro-to-Git-Command","date":"2019-02-10T05:00:00.000Z","updated":"2022-11-02T21:13:14.000Z","comments":true,"path":"Intro-to-Git-Command/","permalink":"https://yao-lirong.github.io/blog/Intro-to-Git-Command/","excerpt":"Creating repository git init: create a repository git add File_Name: add â€œFile_Nameâ€ to repository git add . : add all files git commit -m \"message\": commit changes and tell others what changes have been made git commit -m \"Title\" -m \"Description ..\": commit with a short title then long description","text":"Creating repository git init: create a repository git add File_Name: add â€œFile_Nameâ€ to repository git add . : add all files git commit -m \"message\": commit changes and tell others what changes have been made git commit -m \"Title\" -m \"Description ..\": commit with a short title then long description Way-back Machine git status: tell you which files have been changed git diff: check what content exactly has been changed in each file Time Travelling commitID: git uses commit ID, a hex number calculated by SHA1 to record your commit history HEAD: HEAD is the current version, HEAD^ is the previous, HEAD^^ is the one before the previous, HEAD~100 is the last 100. git log: check the commit history git reflog: check the command history git reset --hard CommitID : Going back to the â€œCommit IDâ€ version (e.g. git reset --hard HEAD^ : going back to the previous version) When you go back, the â€œfuture versionâ€ will no longer appear in â€œgit logâ€. However, you can use â€œgit reflogâ€ to trace â€œcommit IDâ€ from the future Working Directory and Repository Undo Changes messed up with working directory: use git checkout -- File_Name to discard changes in working directory and make â€œFile_Nameâ€ to go back to the latest â€œcommittedâ€ or â€œaddedâ€ version messed up with working directory but donâ€™t want to delete all the changes: git stash saves your local modifications away and reverts the working directory to match the HEAD commit. messed up with working directory and added it to stage: use git reset HEAD File_Name to discard changes in stage but keep â€œFile_Nameâ€ in working directory changed, therefore going back to situation 1 committed the mess to master branch: use the Time Traveling technique in the previous section Deleting Files If you want to delete files that are already committed to the master branch: delete the file in working directory: rm File_Name delete the file from git / restore the file delete the file from git: git rm File_Name &amp; git commit restore the file: git checkout -- File_Name Remote Repository Change Git Remote URL 12git remote set-url &lt;remote_name&gt; &lt;remote_url&gt; # remote name is usually &quot;origin&quot;git remote -v # verbose print info to check changed successfully Change Remote Branch a Local Branch is Tracking 1234git branch &lt;local_branch_name&gt; --set-upstream-to &lt;remote_name&gt;/&lt;remote_branch_name&gt;git branch yao --set-upstream-to=origin/yao# or you can ignore local branch name if you&#x27;re currently on that branchgit branch --set-upstream-to=origin/yao Push to Different Remote Branch 12git push &lt;remote_name&gt; &lt;branch_name&gt;git push origin master Managing Branch Creating and Deleting Branch æŸ¥çœ‹åˆ†æ”¯ï¼šgit branch åˆ›å»ºåˆ†æ”¯ï¼šgit branch &lt;name&gt; åˆ‡æ¢åˆ†æ”¯ï¼šgit checkout &lt;name&gt; åˆå¹¶æŸåˆ†æ”¯åˆ°å½“å‰åˆ†æ”¯ï¼šgit merge &lt;name&gt; åˆ é™¤åˆ†æ”¯ï¼šgit branch -d &lt;name&gt; Configuration show configuration: git config -l --local git config -l --global modify configuration: For this current repo: 12git config user.name &quot;Your Name Here&quot;git config user.email your@email.com For global settings: 12git config --global user.name &quot;Your Name Here&quot;git config --global user.email your@email.com Quick look up a specific attribute: git config user.name If you are using HTTPS remote, it will ask for your username and password each time you push/pull from the remote. You can then cache your credentials with the following command for 7200 seconds (2 hour). If ignore the part in the quote, the credentials will be saved forever. 1git config --global credential.helper &#x27;cache --timeout 7200&#x27; Others Keep a local copy of files, donâ€™t update with server change: git update-index --skip-worktree &lt;path-name&gt; from Stackoverflow When use GitHub, use https to track remote branch. SSH works weird when you have multiple accounts on your local machine. Revert an accidental pull request: the following are 2 equivalent ways 12git reset --mergegit merge --abort","categories":[],"tags":[{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-02-09T05:00:00.000Z","updated":"2022-06-08T19:43:56.000Z","comments":true,"path":"hello-world/","permalink":"https://yao-lirong.github.io/blog/hello-world/","excerpt":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post 1$ hexo new &quot;My New Post&quot; More info: Writing Run server 1$ hexo server More info: Server Generate static files 1$ hexo generate More info: Generating Deploy to remote sites 1$ hexo deploy More info: Deployment Real Start å®é™…ä¸Šä½ åº”è¯¥ä½¿ç”¨ npx hexo &lt;command&gt; æ¥è¿è¡Œ hexo.","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"ML","slug":"ML","permalink":"https://yao-lirong.github.io/blog/tags/ML/"},{"name":"Journal","slug":"Journal","permalink":"https://yao-lirong.github.io/blog/tags/Journal/"},{"name":"Manual","slug":"Manual","permalink":"https://yao-lirong.github.io/blog/tags/Manual/"},{"name":"Logistics","slug":"Logistics","permalink":"https://yao-lirong.github.io/blog/tags/Logistics/"},{"name":"Review","slug":"Review","permalink":"https://yao-lirong.github.io/blog/tags/Review/"},{"name":"Book","slug":"Book","permalink":"https://yao-lirong.github.io/blog/tags/Book/"},{"name":"Tsinghua","slug":"Tsinghua","permalink":"https://yao-lirong.github.io/blog/tags/Tsinghua/"},{"name":"Cornell","slug":"Cornell","permalink":"https://yao-lirong.github.io/blog/tags/Cornell/"},{"name":"Vim","slug":"Vim","permalink":"https://yao-lirong.github.io/blog/tags/Vim/"},{"name":"CS3110","slug":"CS3110","permalink":"https://yao-lirong.github.io/blog/tags/CS3110/"},{"name":"NOI","slug":"NOI","permalink":"https://yao-lirong.github.io/blog/tags/NOI/"}]}