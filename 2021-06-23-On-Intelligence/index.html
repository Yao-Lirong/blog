<!DOCTYPE html>
<html lang="en">
    <!-- title -->


    

<!-- keywords -->



<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="author" content="Yao Lirong">
    <meta name="renderer" content="webkit">
    <meta name="copyright" content="Yao Lirong">
    
        <meta name="keywords" content="Cornell,AI,CS,Computer Science,Artificial Intelligence,Yao,Lirong,姚立嵘,Programming">
    
    <meta name="description" content="姚立嵘 (Yao Lirong)'s Personal Website">
    <meta name="description" content="Complexity is a symptom of confusion, not a cause.">
<meta property="og:type" content="article">
<meta property="og:title" content="On Intelligence">
<meta property="og:url" content="https://yao-lirong.github.io/2021-06-23-On-Intelligence/index.html">
<meta property="og:site_name" content="Yao Lirong&#39;s Blog">
<meta property="og:description" content="Complexity is a symptom of confusion, not a cause.">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-06-23T04:00:00.000Z">
<meta property="article:modified_time" content="2021-08-29T20:52:51.031Z">
<meta property="article:author" content="Yao Lirong">
<meta property="article:tag" content="Reading">
<meta name="twitter:card" content="summary">
    <meta http-equiv="Cache-control" content="no-cache">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <link rel="icon" href="/assets/favicon.ico">
    
    <title>On Intelligence · Yao Lirong&#39;s Blog</title>
    <!-- /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/ -->
<script>
    (function (w) {
        'use strict'
        // rel=preload support test
        if (!w.loadCSS) {
            w.loadCSS = function () {}
        }
        // define on the loadCSS obj
        var rp = (loadCSS.relpreload = {})
        // rel=preload feature support test
        // runs once and returns a function for compat purposes
        rp.support = (function () {
            var ret
            try {
                ret = w.document.createElement('link').relList.supports('preload')
            } catch (e) {
                ret = false
            }
            return function () {
                return ret
            }
        })()

        // if preload isn't supported, get an asynchronous load by using a non-matching media attribute
        // then change that media back to its intended value on load
        rp.bindMediaToggle = function (link) {
            // remember existing media attr for ultimate state, or default to 'all'
            var finalMedia = link.media || 'all'

            function enableStylesheet() {
                link.media = finalMedia
            }

            // bind load handlers to enable media
            if (link.addEventListener) {
                link.addEventListener('load', enableStylesheet)
            } else if (link.attachEvent) {
                link.attachEvent('onload', enableStylesheet)
            }

            // Set rel and non-applicable media type to start an async request
            // note: timeout allows this to happen async to let rendering continue in IE
            setTimeout(function () {
                link.rel = 'stylesheet'
                link.media = 'only x'
            })
            // also enable media after 3 seconds,
            // which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
            setTimeout(enableStylesheet, 3000)
        }

        // loop through link elements in DOM
        rp.poly = function () {
            // double check this to prevent external calls from running
            if (rp.support()) {
                return
            }
            var links = w.document.getElementsByTagName('link')
            for (var i = 0; i < links.length; i++) {
                var link = links[i]
                // qualify links to those with rel=preload and as=style attrs
                if (
                    link.rel === 'preload' &&
                    link.getAttribute('as') === 'style' &&
                    !link.getAttribute('data-loadcss')
                ) {
                    // prevent rerunning on link
                    link.setAttribute('data-loadcss', true)
                    // bind listeners to toggle media back
                    rp.bindMediaToggle(link)
                }
            }
        }

        // if unsupported, run the polyfill
        if (!rp.support()) {
            // run once at least
            rp.poly()

            // rerun poly on an interval until onload
            var run = w.setInterval(rp.poly, 500)
            if (w.addEventListener) {
                w.addEventListener('load', function () {
                    rp.poly()
                    w.clearInterval(run)
                })
            } else if (w.attachEvent) {
                w.attachEvent('onload', function () {
                    rp.poly()
                    w.clearInterval(run)
                })
            }
        }

        // commonjs
        if (typeof exports !== 'undefined') {
            exports.loadCSS = loadCSS
        } else {
            w.loadCSS = loadCSS
        }
    })(typeof global !== 'undefined' ? global : this)
</script>

    <style type="text/css">
    @font-face {
        font-family: 'Oswald-Regular';
        src: url("/font/Oswald-Regular.ttf");
    }

    body {
        margin: 0;
    }

    header,
    footer,
    .back-top,
    .sidebar,
    .container,
    .site-intro-meta,
    .toc-wrapper {
        display: none;
    }

    .site-intro {
        position: relative;
        z-index: 3;
        width: 100%;
        /* height: 50vh; */
        overflow: hidden;
    }

    .site-intro-placeholder {
        position: absolute;
        z-index: -2;
        top: 0;
        left: 0;
        width: calc(100% + 300px);
        height: 100%;
        background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
        background-position: center center;
        transform: translate3d(-226px, 0, 0);
        animation: gradient-move 2.5s ease-out 0s infinite;
    }

    @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }
</style>

    <link rel="preload" href="/css/style.css?v=20210823" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <link rel="preload" href="/css/dark.css?v=20210823" as="style">
    <link rel="stylesheet" href="/css/dark.css" media="(prefers-color-scheme: dark)">
    <link rel="stylesheet" href="/css/mobile.css?v=20210823" media="(max-width: 960px)">
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" as="script">
    <link rel="preload" href="/scripts/main.js?v=20210823" as="script">
    <link rel="preload" href="/scripts/dark.js?v=20210823" as="script">
    <link rel="preload" href="/font/Oswald-Regular.ttf" as="font" crossorigin>
    <link rel="preload" href="https://at.alicdn.com/t/font_327081_1dta1rlogw17zaor.woff" as="font" crossorigin>
    
    <link rel="canonical" href="https://yao-lirong.github.io/2021-06-23-On-Intelligence/">
    <meta name="baidu-site-verification" content="code-JhnBOyJv4Y">
    <!-- algolia -->
    
    <!-- 百度统计  -->
    
    <!-- 谷歌统计  -->
    
        <script>
            (function (i, s, o, g, r, a, m) {
                i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
                }, i[r].l = 1 * new Date(); a = s.createElement(o),
                m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
            })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
            ga('create', 'UA-225410555-1', 'auto');
            ga('send', 'pageview');
        </script>
    
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="Yao Lirong's Blog" type="application/atom+xml">
</head>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js"></script>
    <script type="text/javascript">
        if (typeof window.$ == undefined) {
            console.warn('jquery load from jsdelivr failed, will load local script')
            document.write('<script src="/lib/jquery.min.js" />')
        }
    </script>
    
        <body class="post-body">
    
        <!-- header -->
        <header class="header header-mobile">
    <!-- top read progress line -->
    <div class="header-element">
        <div class="read-progress"></div>
    </div>
    <!-- sidebar menu button -->
    <div class="header-element">
        
            <div class="header-sidebar-menu">
        
            
                <div style="padding-left: 1px;">&#xe775;</div>
            
        </div>
    </div>
    <!-- header actions -->
    <div class="header-actions">
        <!-- theme mode switch button -->
        <span class="header-theme-btn header-element">
            <i class="fas fa-adjust"></i>
        </span>
        <!-- back to home page text -->
        <span class="home-link header-element">
            <a href="/">Yao Lirong's Blog</a>
        </span>
    </div>
    <!-- toggle banner for post layout -->
    
        
            <div class="banner">
        
            <div class="blog-title header-element">
                <a href="/">Yao Lirong&#39;s Blog</a>
            </div>
            <div class="post-title header-element">
                <a href="#" class="post-name">On Intelligence</a>
            </div>
        </div>
    
</header>

        <!-- fixed footer -->
        <footer class="footer-fixed">
    <!-- back to top button -->
    <div class="footer-fixed-element">
        
            <div class="back-top back-top-hidden">
        
        
            <div>&#xe639;</div>
        
        </div>
    </div>
</footer>

        <!-- wrapper -->
        <div class="wrapper">
            <div class="site-intro" style="







    height:50vh;

">
    
    <!-- 主页  -->
    
        
    <!-- 404页  -->
            
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-img" style="background-image: url(/intro/post-bg.jpg)"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
                On Intelligence
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
                
            <!-- 404 -->
            
        </p>
        <!-- 文章页 meta -->
        
            <div class="post-intros">
                <!-- 文章页标签  -->
                
                    <div class="post-intro-tags">
    
    
        <a class="post-tag" href="javascript:void(0);" data-tags="Reading">Reading</a>
    
</div>

                
                
                    <div class="post-intro-read">
                        <span>Word count: <span class="post-count word-count">4.8k</span>Reading time: <span class="post-count reading-time">25 min</span></span>
                    </div>
                
                <div class="post-intro-meta">
                    <!-- 撰写日期 -->
                    <span class="iconfont-archer post-intro-calander">&#xe676;</span>
                    <span class="post-intro-time">2021/06/23</span>
                    <!-- busuanzi -->
                    
                        <span id="busuanzi_container_page_pv" class="busuanzi-pv">
                            <span class="iconfont-archer post-intro-busuanzi">&#xe602;</span>
                            <span id="busuanzi_value_page_pv"></span>
                        </span>
                    
                    <!-- 文章分享 -->
                    <span class="share-wrapper">
                        <span class="iconfont-archer share-icon">&#xe71d;</span>
                        <span class="share-text">Share</span>
                        <ul class="share-list">
                            <li class="iconfont-archer share-qr" data-type="qr">&#xe75b;
                                <div class="share-qrcode"></div>
                            </li>
                            <li class="iconfont-archer" data-type="weibo">&#xe619;</li>
                            <li class="iconfont-archer" data-type="qzone">&#xe62e;</li>
                            <li class="iconfont-archer" data-type="twitter">&#xe634;</li>
                            <li class="iconfont-archer" data-type="facebook">&#xe67a;</li>
                        </ul>
                    </span>
                </div>
            </div>
        
    </div>
</div>

            <script>
  // get user agent
  function getBrowserVersions() {
    var u = window.navigator.userAgent
    return {
      userAgent: u,
      trident: u.indexOf('Trident') > -1, //IE内核
      presto: u.indexOf('Presto') > -1, //opera内核
      webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
      gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
      mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
      ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
      android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
      iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
      iPad: u.indexOf('iPad') > -1, //是否为iPad
      webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
      weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
      uc: u.indexOf('UCBrowser') > -1, //是否为android下的UC浏览器
    }
  }
  var browser = {
    versions: getBrowserVersions(),
  }
  console.log('userAgent: ' + browser.versions.userAgent)

  // callback
  function fontLoaded() {
    console.log('font loaded')
    if (document.getElementsByClassName('site-intro-meta')) {
      document
        .getElementsByClassName('intro-title')[0]
        .classList.add('intro-fade-in')
      document
        .getElementsByClassName('intro-subtitle')[0]
        .classList.add('intro-fade-in')
      var postIntros = document.getElementsByClassName('post-intros')[0]
      if (postIntros) {
        postIntros.classList.add('post-fade-in')
      }
    }
  }

  // UC不支持跨域，所以直接显示
  function asyncCb() {
    if (browser.versions.uc) {
      console.log('UCBrowser')
      fontLoaded()
    } else {
      WebFont.load({
        custom: {
          families: ['Oswald-Regular'],
        },
        loading: function () {
          // 所有字体开始加载
          // console.log('font loading');
        },
        active: function () {
          // 所有字体已渲染
          fontLoaded()
        },
        inactive: function () {
          // 字体预加载失败，无效字体或浏览器不支持加载
          console.log('inactive: timeout')
          fontLoaded()
        },
        timeout: 5000, // Set the timeout to two seconds
      })
    }
  }

  function asyncErr() {
    console.warn('script load from CDN failed, will load local script')
  }

  // load webfont-loader async, and add callback function
  function async(u, cb, err) {
    var d = document,
      t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0]
    o.src = u
    if (cb) {
      o.addEventListener(
        'load',
        function (e) {
          cb(null, e)
        },
        false
      )
    }
    if (err) {
      o.addEventListener(
        'error',
        function (e) {
          err(null, e)
        },
        false
      )
    }
    s.parentNode.insertBefore(o, s)
  }

  var asyncLoadWithFallBack = function (arr, success, reject) {
    var currReject = function () {
      reject()
      arr.shift()
      if (arr.length) async(arr[0], success, currReject)
    }

    async(arr[0], success, currReject)
  }

  asyncLoadWithFallBack(
    [
      'https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js',
      'https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js',
      "/lib/webfontloader.min.js",
    ],
    asyncCb,
    asyncErr
  )
</script>

            <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;">
            <div class="container container-unloaded">
                <main class="main post-page">
    <article class="article-entry">
        <blockquote>
<p>Complexity is a symptom of confusion, not a cause. </p>
</blockquote>
<span id="more"></span>

<h2 id="1-Artificial-Intelligence"><a href="#1-Artificial-Intelligence" class="headerlink" title="1 Artificial Intelligence"></a>1 Artificial Intelligence</h2><ul>
<li>计算机学界的主流观点：不需要学习大脑</li>
<li>此观点的起始：Turing Test，即让人们<strong>认为</strong>它是智能，产生 intelligent behavior 更重要</li>
<li>the Chinese Room: 在中文屋中智能没有产生，作者认为 Understanding cannot be measured by external behavior; it is instead an internal metric of how the brain remembers things and uses its memories to make predictions. 但绝大多数的所谓”AI”和这里的中文屋和这一定义无任何相似之处</li>
</ul>
<h2 id="2-Neural-Networks"><a href="#2-Neural-Networks" class="headerlink" title="2 Neural Networks"></a>2 Neural Networks</h2><p>一些可能已经过时的观点：</p>
<ul>
<li>Neural Network 没有考虑 feedback 和 time changing inputs</li>
<li>Cognitive Scientist 虽然想记录大脑中的 feedback，但是迫于现有技术(fMRI)只能记录脑内活动的位置，无法记录连续的变化</li>
</ul>
<h2 id="3-The-Human-Brain"><a href="#3-The-Human-Brain" class="headerlink" title="3 The Human Brain"></a>3 The Human Brain</h2><blockquote>
<p> Mind is the creation of the cells in the brain. </p>
</blockquote>
<blockquote>
<p> The cortex is extremely flexible and that the inputs to the brain are just patterns. It doesn’t matter where the patterns come from; as long as they correlate over time in consistent ways, the brain can make sense of them.</p>
</blockquote>
<ul>
<li><p>Function Hierarchy: 脑的每个功能部分都被划为 hierarchy，以输入的视觉为例 </p>
<ol>
<li>V1 (primary sensory areas): rawest, most basic level</li>
<li>V2, V4, IT: concerned with more specialized or more abstract aspects</li>
<li>association area: receive inputs from more than one sense </li>
</ol>
<p>虽然是一个 hierarchy，但是实际上当我们从低层走向高层的过程中，information always flows in the opposite direction as well, and with more projections feeding back down the hierarchy than up. </p>
</li>
<li><p><strong>Uniformity of Cortex Parts</strong>: Mountcastle found that parts of cortex performing different function is very similar in appearance and structure. From there, he argues that all regions of the cortex are performing the same operation. The thing that makes the vision area visual and the motor area motoric is how the regions of cortex are connected to each other and to other parts of the central nervous system. </p>
</li>
<li><p>Plasticity of Cortex: 我们发现如果大脑某个部分损坏，另一个部分可以接管它原先的人物，这佐证了 Mountcastle 的观点。另有一个 Thought Experiment：假设我们的大脑并不具有如此的可塑性，那么这就意味着我们的某个大脑部位是专门用来学习中文汉字的，但是对于生物进化来说，汉字进化地太快了，大脑根本不可能适应地这么快（或者外国人也可以迅速学中文亦能佐证这一观点）</p>
</li>
<li><p>Similarity of Inputs into Brain: 不管视觉听觉还是什么输入，真正进了人体都是 Action Potentials. They are all the same - just patterns. 也用来佐证 Mountcastle 的观点。There are spatial and and temporal patterns:</p>
<ul>
<li>Spatial Patterns: coincident patterns in time; they are created when multiple receptors in the same sense organ are stimulated simultaneously</li>
<li>Temporal Patterns: patterns entering your sensory organs are constantly changing over time</li>
</ul>
</li>
<li><p>进一步给出了关于以上两点的例子：认为同时做出反应的假手是自己的手 / 镜头连舌头上的压感接收器，用舌头看东西 </p>
</li>
</ul>
<h2 id="4-Memory"><a href="#4-Memory" class="headerlink" title="4 Memory"></a>4 Memory</h2><ul>
<li><p>驳斥人脑比计算机更快，计算力更高 -&gt; 人脑能做到比计算机快是因为运行原理根本不同 -&gt; 引出本章主旨: the brain doesn’t “compute” the answers to problems; it retrieves the answers from memory.</p>
</li>
<li><p><strong>Four attributes of neocortical memory that are fundamentally different from computer memory</strong>:</p>
<ul>
<li>The neocortex stores sequences of patterns -&gt; predictions of future events</li>
<li>The neocortex recalls patterns auto-associatively -&gt; recall memories appropriate for prediction</li>
<li>The neocortex stores patterns in an invariant form -&gt; apply knowledge of past to new situations that are similar but not identical</li>
<li>The neocortex stores patterns in a hierarchy.</li>
</ul>
<p>接下来我们将详细介绍前三个特征并在第6章介绍最后一个特征 “阶层”</p>
</li>
<li><p>Sequential Pattern: story is stored in your head in a sequential fashion and can only be recalled in the same sequence. You can’t remember the entire story at once. </p>
<p>一个有趣的观点: Truly random thoughts don’t exist. Memory recall almost always follows a pathway of association.</p>
</li>
<li><p>Self-Associativity: The memory system can recall complete patterns when given only partial or distorted inputs. This is a result of Hebbian Learning: Firing together Wires together, so when only a part of the cell is activated, the whole group of cells will be activated. </p>
</li>
<li><p>Invariant Representation: 人脑不是CD或硬盘，we don’t remember or recall things with complete fidelity. Instead, the brain remembers the important relationships in the world, independent of the details. </p>
<p>我们常用视觉来举例子：some set of the cells in the face recognition area remain active as long as your friend’s face is anywhere in your field of vision, regardless of its size, position, orientation, scale, and expression. This <strong>stability of cell firing</strong> is an invariant representation.</p>
</li>
<li><p>小引子导入下一章：下一章的主旨是人脑的主要功能就是 make predictions using memories，but given that the cortex stores invariant information,  how can it make specific predictions? It combines knowledge of the invariant structure with the most recent details.</p>
</li>
</ul>
<h2 id="5-A-New-Framework-of-Intelligence"><a href="#5-A-New-Framework-of-Intelligence" class="headerlink" title="5 A New Framework of Intelligence"></a>5 A New Framework of Intelligence</h2><blockquote>
<p>Prediction is not just one of the things your brain does. It is the primary function of the neocortex, and the foundation of intelligence. The cortex is an organ of prediction.</p>
</blockquote>
<p>这是作者本书中最基本的观点，也就是他所说的新的智能框架 (Memory-Prediction Framework of Intelligence) 。具体地来解释 Prediction 这个概念：Your brain makes low-level sensory predictions about what it expects to see, hear, and feel at every given moment, and it does so in parallel. All regions of your neocortex are simultaneously trying to predict what their next experience will be. “Prediction” means that the neurons involved in sensing your door <strong>become active in advance of them actually receiving sensory input</strong>. When the sensory input does arrive, it is <strong>compared with what was expected</strong>. <strong>Correct predictions result in understanding.</strong>  <strong>Incorrect predictions result in confusion</strong> and prompt you to pay attention. 不局限于 sensory input，motor output 在我们的大脑中也是和 sensory input一样的 pattern, so neocortex can also remembers what behavior (pattern) leads to what sensory input (patter) and we can <strong>direct behavior to satisfy its predictions</strong>. </p>
<p>作者举了很多关于 prediction 的例子（预知乐曲的旋律，朋友的样子，你妈下一句话会说什么…）其中最有意思的例子应该是 “filling in”，即我们原来了解过的人脑的 “自动补全” 功能：人眼虽然有盲点但我们视觉没有盲点，自动将三个角补全成三角形，描绘出被树遮挡的大楼的样子，等等。Your visual cortex is drawing on memories of similar patterns and is making a continuous stream of predictions that fill in for any missing input.</p>
<p>Behavior Cortex Intelligence 之间到底是个什么关系？ 从进化历程来看，cortex 起到什么作用？我们为什么要进化出 Cortex: in the beginning, the cortex served to make more efficient use of existing behaviors, not to create entirely new behaviors. 但是后来在进化过程中有了 new behavior？</p>
<ol>
<li><p>Reptile: Keen senses and well-developed brains endowed them with complex behavior, but relatively rigid </p>
</li>
<li><p>Mammals: Neocortex covering the old brain (reptile brain)</p>
<p>Now sensory patterns are simultaneously fed into the neocortex and the old brain. The recalled memory is compared with the sensory input stream. It both “fills in” the current input and predicts what will be seen next.</p>
</li>
<li><p>Humans: </p>
<ul>
<li>large front part of cortex for high-level planning and thought, so it could store more sophisticated types of memories and make predictions based on complex relationships </li>
<li>motor cortex makes more connections with our muscles so cortex usurps motor control from other parts of the brain (old brain) and now the cortex can direct behavior to satisfy its predictions. </li>
</ul>
</li>
</ol>
<p>本部分也反驳了第一章中所谓的人工智能学者的 behavior determines intelligence 观点：早在 reptile 时期，动物就有了生存本能的 behavior，但是直到 cortex 出现，它们才有了 intelligence。而 cortex 的核心功能就是 prediction. </p>
<p>To make predictions of future events, your neocortex has to store sequences of patterns. To recall the appropriate memories, it has to retrieve patterns by their similarity to past patterns (auto-associative recall). And, finally, memories have to be stored in an invariant form so that the knowledge of past events can be applied to new situations that are similar but not identical to the past. How the physical cortex accomplishes these tasks, plus a fuller exploration of its hierarchy, is the subject of the next chapter.</p>
<h2 id="6-How-the-Cortex-Works"><a href="#6-How-the-Cortex-Works" class="headerlink" title="6 How the Cortex Works"></a>6 How the Cortex Works</h2><ul>
<li><p>invariant representation: </p>
<p>Light receptors in retina concentrate in fovea and sparse out in periphery, so retinal image relayed onto V1 is highly distorted. However, we don’t perceive any retinal pattern change at all. This is a result of invariant representation. </p>
<p>In the course of spanning four cortical stages from retina to IT: cells in retina and V2 are rapidly changing, spatially specific, tiny-feature recognition cells. When we go to IT region, something magical happens and the cells become constantly firing, spatially nonspecific, object recognition cells. (They now fire when seeing a face, no matter it’s on the left or on the right)</p>
</li>
<li><p>Integrating the Senses: 我们到现在为止都是讨论同一类型输入预测同一类型结果，实际上 association area 使得我们也可以预测其他类型的结果，比如视觉输入用来预测听觉，嗅觉等等的结果，亦可以用来指导动作</p>
</li>
<li><p>A New View of V1: 前文的模型有两个问题：仅当到了 IT 这一层时，我们奇迹般地获得了 invariant representation；大脑中大部分区域都是像 association area 一样得到多个输入，但我们的模型中好像 V2 只有 V1 一个输入，V4 只有 V2 一个。</p>
<p>To answer these questions, we propose a new model: V1, V2, V4 are not single cortical regions. Rather, each is a collection of many smaller subregions. V1 has largest number of little cortical areas. V2 has fewer, but larger subregions, each connecting to a number of V1’s subregions. Same for V4 and we have a single IT which has a bird’s eye view of the entire visual world. Now the job of any cortical region is to find out how its inputs are related, to memorize the sequence of correlations between them, and to use this memory to predict how the inputs will behave in the future. We can say <strong>each region of cortex forms invariant representation</strong> drawn from the input areas hierarchically below it. </p>
</li>
<li><p>A Model of the World: 作者认为世界中 Every object is composed of a collection of smaller objects, and most objects are part of larger objects. In an analogous way, memories are stored in the <strong>hierarchical structure</strong> of the cortex. Time really matters and information flowing into the brain arrives as a <strong>sequence of patterns</strong>. 对于每个 cortical region，它识别出来这个 sequence，将其抽象成一个 name - a constant pattern of cell firing，并将这个名字发给他的上级。所以我们也可以说大脑存储的是 Sequence of Sequences. By collapsing predictable sequences into “named objects” at each region in our hierarchy, we achieve more and more stability the higher we go. This creates invariant representations.</p>
</li>
<li><p>Sequences of Sequences: Two processes are at the essence of learning. Assume we are sorting out colored papers.</p>
<ul>
<li>bottom-up classification: deciding what color this paper is</li>
<li>top-down sequence recognition: deciding which sequence are we reading in</li>
</ul>
<p>Notice these two processes help each other. 1. If you know the most likely sequence for this series of inputs, you will use this knowledge to decide how to classify the ambiguous input. 2. recognizing any sequence would be impossible if you hadn’t first classified each piece of paper.</p>
<p>When we have finally recognized a color sequence, say “red red blue green”, we just pass this name to the next higher region; just like the colors to this region, the name is just a pattern to be combined with other inputs, classified, and then put into yet a higher-order sequence. The next higher up region doesn’t have to know what it means. </p>
</li>
<li><p>What a Region of Cortex Looks Like: 我们说过每个 cortical region 有六层 (six layers 从上到下分别为 L1, L2, …, L6 不要跟视觉的 V1 V4 搞混) 但我们一般不把每一层看做人脑的基本单位，而是把 columns running perpendicular to the layer 看做 basic unit of computation in the cortex. 作者认为它是 basic unit of prediction. </p>
<p>我们接下来讨论 How cortical regions communicate with each other 共有三种方法：</p>
<ul>
<li>Upward Flow: Converge inputs from lower regions goes to the input layer of the next region through axons </li>
<li>Downward Flow: Axons in layer 1 spread over long distances, so information flowing down the hierarchy from one column has the potential to activate many columns in the regions below it.</li>
<li>Lateral Flow: L1 给 L4,5 发指令运动，L4,5 收到指令的同时，不仅向下给肌肉发放运动信号，也把这个消息告诉 thalamus，thalamus 过一会后会把这个消息重新传回给 L1。其中 thalamus 收到来自许多不同 L4, L5 的信息，然后再把这些信息一起返回给所有 L1 ，这样本 column 就知道知道周围其他人现在收到的信息。Column not only knows the sequence name (downward flow from above), but also where we are within the sequence (activity from other columns)</li>
</ul>
</li>
<li><p>How a Region of Cortex Works - The Details: </p>
<ul>
<li><p>How does a cortical region classifies inputs? </p>
<p>It’s too complicated, we assume it does</p>
</li>
<li><p>How does it learn sequences of patterns? </p>
<p>Input from lower region -&gt; layer 4 fires -&gt; layers 2,3,5 fire -&gt; layer 1 fires to tell the region up some input has come. Fire together Wire together, so 2,3,5,1 wire together. 2,3,5 now can fire without a layer 4 input, so they learn to “anticipate” when they should fire based on firing of 1. Half of input to layer 1 comes from layer 5 in neighboring columns. This information represents what was happening moments before. It represents columns that were active prior to your column becoming active. The other half of the input to layer 1 comes from layer 6 cells in hierarchically higher regions. This information is more stationary. It represents the name of the sequence you are currently experiencing. Combining these two information, a prediction/sequence is formed. </p>
</li>
<li><p>How does it form a constant “name” for a sequence?</p>
<p>constant names = constant input to the next region during learned sequences = need to turn off the output of the layer 2 and layer 3 cells when a column predicts its activity, or, alternately, to make these cells active when the column can’t predict its activity. Layer 2 cell represent the name of the sequence and they stay on when we are within the sequence. Layer 3b cell represents don’t fire when our column successfully predicts its input but do fire when it doesn’t predict its activity.</p>
</li>
<li><p>How does it make specific predictions? </p>
<p>If you expect a fifth (prediction / invariant representation) and hear a D (specific input). In layer 2 we fire all intervals of fifth. In layer 4 we fire all intervals starting with D. The intersection between the two is our specific prediction. </p>
</li>
</ul>
</li>
<li><p>Flowing Up and Flowing Down: </p>
<ol>
<li>上层给下层 prediction</li>
<li>当下层得到的输入与 prediction 不符 (unexpected)，我们将此特征传导给更上一层，直到 some higher region can interpret it as part of its normal sequence of events. </li>
<li>That higher region generates a new prediction and propagates it down</li>
</ol>
</li>
<li><p>Can Feedback Really Do that? Feedback synapses are all far away from cell’s body, so it’s doubted whether the feedback currents can really make a difference. 但是新研究发现离得远的 synapse 可能有其他特殊的效果（并不确切证实）</p>
</li>
<li><p>How the Cortex Learns: 比如我们有1,2,3层，一开始单个文字在第3层，随着我们持续学习和不断练习单个文字移到了第2层，相对的，我们在第3层习得短语这个 pattern。This ensures that we free up the top for learning more subtle, more complex relationships. 这也是我们变得更熟练的原因。</p>
</li>
<li><p>The Hippocampus: 我们常认为海马体是生成新记忆的中心，在作者的模型中，Hippocampus is the top region of neocortex. 我们刚刚说 unexpected input 被传输给上层，so if something gets to the top of the cortical pyramid, it is the information that can’t be understood by previous experience, the input that is truly new and unexpected. That’s what stored in Hippocampus, but it won’t be stored forever. It’s either transferred down to the cortex (长期记忆) or eventually lost (遗忘) 所谓人在壮中年时对”新事物”的记忆没有那么好实际上是因为这些”新”的东西实际上早已在以前的生活中出现过，所以人对第一次记忆特别深刻，对之后的类似事物就没那么好记性。（它竟然和 How the Cortex Learns 这很扯的一节联起来了）</p>
</li>
<li><p>An Alternative Path up the Hierarchy: 这里要介绍的是从 Layer5 -&gt; thalamus 的路径。这条路径可开可关，它要么被上层激活打开，要么被下层的 unexpected input 激活。我们认为这条路径代表注意力，两种开启方式分别对应主动关注(pay attention)，以及因为奇怪的现象而被动关注 (attention is caught)</p>
</li>
<li><p>Closing Thoughts: 分享了作者从零想结构写代码最后竟然能跑的例子，但是相对的如果别人只给你看一堆代码结构规划，你可能会怀疑这东西到底能不能跑，类比到脑结构中，怀疑的原因是 it is because our intuitive sense of the capacity of the cortex and the power of its hierarchical structure is inadequate.</p>
</li>
</ul>
<h2 id="7-Consciousness-and-Creativity"><a href="#7-Consciousness-and-Creativity" class="headerlink" title="7 Consciousness and Creativity"></a>7 Consciousness and Creativity</h2><ul>
<li>Animals and Human Intelligence: Memory and Prediction are the core of “Intelligence” and they are used by all livings. There is just a continuum of methods and sophistication in how they do it.<ol>
<li>One-cell animal: They used DNA as the medium for memory. Individuals could not learn and adapt within their lifetimes. They could only pass on the DNA-based memory of the world to their offspring through their genes.</li>
<li>Modifiable Nervous System: An individual could now learn about the structure of its world and adapt its behavior accordingly within its lifetime. But an individual still could not communicate this knowledge to its offspring other than by direct observation. Neocortex was also created at this time.</li>
<li>Human Intelligence: It begins with the invention of language and the expansion of our large neocortex. The more important is language. We humans can learn a lot of the structure of the world within our lifetimes, and we can effectively communicate this to many other humans via language.</li>
</ol>
</li>
<li>What is Creativity? Recall that we make predictions by combining the invariant memory recall of what should happen next with the details pertaining to this moment in time. All cortical predictions are predictions by analogy. We are being creative when our memory-prediction system operates at a higher level of abstraction, when it makes uncommon predictions, using uncommon analogies. 注意 GEB 中也提到说 analogy 是智慧的核心</li>
<li>What is Consciousness? 有人认为 consciousness/mind 在身体之外，但是实际上它就在脑中。Your thoughts, which are located in the brain, are physically separate from the body and the rest of the world. Mind is independent of body, but not of brain.</li>
</ul>
<h2 id="8-The-Future-of-Intelligence"><a href="#8-The-Future-of-Intelligence" class="headerlink" title="8 The Future of Intelligence"></a>8 The Future of Intelligence</h2><blockquote>
<p>Because I have been immersed in the neuroscience and computer fields for over two decades, perhaps my brain has built a high-level model of how technological and scientific change occurs, and that model predicts rapid progress. Now is the turning point.</p>
</blockquote>
<ul>
<li>General Direction of Intelligent Machine: Our intelligent machine may have a set of senses that differ from a human’s. attach<br>to these senses a hierarchical memory system that works on the same principles as the cortex. We will then have to train the  memory system much as we teach children. Over repetitive training sessions, our intelligent machine will build a model of its world as seen through its senses. The intelligent machine must learn via observation of its world. Once our intelligent machine has created a model of its world, it can then see analogies to past experiences, make predictions of future events. 这个智能机器的整体运作方法和大脑相同，但是它并不需要与大脑长得相似或得到和大脑相同的输入，它只需要复合结构的，能够用来作“预测”的输入即可。What makes it intelligent is that it can understand and interact with its world via a hierarchical memory model and can think about its world in a way analogous to how you and I think about our world.</li>
<li>Ethical Problems? No. The strongest applications of intelligent machines will be where the human intellect has difficulty, areas in which our senses are inadequate, or in activities we find boring. In general, these activities have little emotional content.</li>
<li>In the following areas, Intelligent Machines will exceed we humans:<ul>
<li>Speed: Transistor switch is much faster than human brain’s electrical signals.</li>
<li>Capacity: we can add capacity to machine’s mind by doing the followings (these are also what we do in DL/ML)<ul>
<li>Adding depth to the hierarchy will lead to deeper understanding: the ability to see higher-order patterns. </li>
<li>Enlarging the capacity within regions will allow the machine to remember more details, or perceive with greater acuity.</li>
<li>Adding new senses and sensory hierarchies permits the device to construct better models of the world</li>
</ul>
</li>
<li>Replicability: we humans learn knowledge and form our own model of the world rather slowly. However, an intelligent machine need not undergo this long learning curve, since chips and other storage can be replicated endlessly and the contents transferred easily.</li>
<li>Sensory Systems: Input patterns to the machine don’t have to be analogous to animal senses, or even to derive from the real world at all. In fact, the author suspects that out inability to tackle issue may be related to a mismatch between the human senses and the physical phenomena we want to understand. Intelligent machines can have custom senses more<br>sensitive than our own, or senses that are distributed, or senses for very small phenomena. They might think in three, four, or more dimensions.</li>
</ul>
</li>
</ul>
<h2 id="Appendix-The-Thousand-Brain-Theory"><a href="#Appendix-The-Thousand-Brain-Theory" class="headerlink" title="Appendix: The Thousand Brain Theory"></a>Appendix: The Thousand Brain Theory</h2><p>Notes from <a target="_blank" rel="external nofollow noopener noreferrer" href="https://www.youtube.com/watch?v=5LFo36g4Lug">Microsoft Research - The Thousand Brains Theory by Jeff Hawkins</a></p>
<h3 id="Local-Cortical-Circuit"><a href="#Local-Cortical-Circuit" class="headerlink" title="Local Cortical Circuit"></a>Local Cortical Circuit</h3><p>Inside a local cortical circuit, neurons are organized in layers. Most connections go vertically across the layers; limited connections go horizontally within layer. Recent find: all layers have a motor output. So it’s always sensorimotor input, no pure sensory input.</p>
<p>Vernon Mountcastle: neocortex is remarkably uniform in appearance and structure because they are actually performing the same basic intrinsic function. A cortical column is the unit of replication. If you understand one of it, you understand the whole brain.</p>
<ul>
<li><p>Layer 2,3 - object </p>
</li>
<li><p>Layer 4 - main input layer</p>
</li>
<li><p>Layer 6 - location relative to the object</p>
</li>
</ul>
<p>L6 sends information to L4, L4 processes these information with its own other input. Over time it forms a representation of what the object itself is in layer L2,3.  On top of that, if we have multiple cortical involved (imagine multiple fingers touching the cup instead of only one), we can instantly build a mental image of the cup by the connections across cortical units happened in L2,3. This is like a voting mechanism where each finger has a guess of its feeling and they settle what the object really is by talking to each other. </p>
<h3 id="Building-a-Reference-Map"><a href="#Building-a-Reference-Map" class="headerlink" title="Building a Reference Map"></a>Building a Reference Map</h3><p>A reference map is the sense of relative location as we are touching the cup</p>
<p>Contrast to the classical view, the vast majority of connections between cortical regions are not hieratical at all. </p>
<p>Hypothesis: the grid cells in entorhinal cortex also exist in every cortical column of every neocortex region. They don’t create reference frames for location but reference frames for the objects we interact (the cup).</p>
<p>In the classical view, we have a hierarchy in our neocortex. The real structure is similar, 但我们并不是 杯柄 -&gt; 杯身 -&gt; 整个杯子 这种真正的阶梯式建模，而是每个“层级”都形成一个自己的杯子模型，这些模型并不相同. This model allows all models to “vote”. Everyone tries to guess what’s going on.</p>

    </article>
    <!-- license -->
    
        <div class="license-wrapper">
            <p>Author：<a href="https://yao-lirong.github.io">Yao Lirong</a>
            </p><p>Link：<a href="https://yao-lirong.github.io/2021-06-23-On-Intelligence/">https://yao-lirong.github.io/2021-06-23-On-Intelligence/</a>
            </p><p>Publish date：<a href="https://yao-lirong.github.io/2021-06-23-On-Intelligence/">June 23rd 2021, 12:00:00 am</a>
            </p><p>Update date：<a href="https://yao-lirong.github.io/2021-06-23-On-Intelligence/">August 29th 2021, 4:52:51 pm</a>
            </p><p>License：本文采用 <a rel="external nofollow noopener noreferrer" target="_blank" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)</a> 进行许可</p>
        </div>
    
    <!-- paginator -->
    <ul class="post-paginator">
        <li class="next">
            
                <div class="nextSlogan">Next Post</div>
                <a href="/2021-06-28-Install-and-Configure-Aria2-on-Linux/" title="Install and Configure Aria2 on WSL">
                    <div class="nextTitle">Install and Configure Aria2 on WSL</div>
                </a>
            
        </li>
        <li class="previous">
            
                <div class="prevSlogan">Previous Post</div>
                <a href="/2021-05-28-Introduction-to-TensorFlow-1.x/" title="Introduction to TensorFlow 1.x">
                    <div class="prevTitle">Introduction to TensorFlow 1.x</div>
                </a>
            
        </li>
    </ul>
    <!-- comment -->
    
        <div class="post-comment">
            <!-- 来必力 City 版安装代码 -->


            

            

            

            <!-- utteranc评论 -->


            <!-- partial('_partial/comment/changyan') -->
            <!--PC版-->


            
            

        </div>
    
    <!-- timeliness note -->
    <!-- idea from: https://hexo.fluid-dev.com/posts/hexo-injector/#%E6%96%87%E7%AB%A0%E6%97%B6%E6%95%88%E6%80%A7%E6%8F%90%E7%A4%BA -->
    
    <!-- Mathjax -->
    
</main>

                <!-- profile -->
                
            </div>
            <footer class="footer footer-unloaded">
    <!-- social  -->
    
        <div class="social">
            
    
        
    
        
            
                <a href="//github.com/Yao-Lirong" class="iconfont-archer github" target="_blank" title="github"></a>
            
        
    
        
            
                <a href="//twitter.com/yao_lirong" class="iconfont-archer twitter" target="_blank" title="twitter"></a>
            
        
    
        
            
                <a href="//www.linkedin.com/in/lirong-yao-cornell/" class="iconfont-archer linkedin" target="_blank" title="linkedin"></a>
            
        
    
        
            
                <a href="/atom.xml" class="iconfont-archer rss" target="_blank" title="rss"></a>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    


        </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank" rel="external nofollow noopener noreferrer">Archer</a></span>
    </div>
    <!-- website approve for Chinese user -->
    
    <!-- 不蒜子  -->
    
        <div class="busuanzi-container">
            
             
                <span id="busuanzi_container_site_pv">PV: <span id="busuanzi_value_site_pv"></span> :)</span>
            
        </div>
    	
</footer>

        </div>
        <!-- toc -->
        
            <div class="toc-wrapper toc-wrapper-loding" style="top:50vh;">
                <div class="toc-catalog">
                    <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
                </div>
                <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Artificial-Intelligence"><span class="toc-number">1.</span> <span class="toc-text">1 Artificial Intelligence</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Neural-Networks"><span class="toc-number">2.</span> <span class="toc-text">2 Neural Networks</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-The-Human-Brain"><span class="toc-number">3.</span> <span class="toc-text">3 The Human Brain</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-Memory"><span class="toc-number">4.</span> <span class="toc-text">4 Memory</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-A-New-Framework-of-Intelligence"><span class="toc-number">5.</span> <span class="toc-text">5 A New Framework of Intelligence</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-How-the-Cortex-Works"><span class="toc-number">6.</span> <span class="toc-text">6 How the Cortex Works</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-Consciousness-and-Creativity"><span class="toc-number">7.</span> <span class="toc-text">7 Consciousness and Creativity</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-The-Future-of-Intelligence"><span class="toc-number">8.</span> <span class="toc-text">8 The Future of Intelligence</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Appendix-The-Thousand-Brain-Theory"><span class="toc-number">9.</span> <span class="toc-text">Appendix: The Thousand Brain Theory</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Local-Cortical-Circuit"><span class="toc-number">9.1.</span> <span class="toc-text">Local Cortical Circuit</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Building-a-Reference-Map"><span class="toc-number">9.2.</span> <span class="toc-text">Building a Reference Map</span></a></li></ol></li></ol>
            </div>
        
        <!-- sidebar -->
        <div class="sidebar sidebar-hide">
    <ul class="sidebar-tabs sidebar-tabs-active-0">
        <li class="sidebar-tab-archives"><span class="iconfont-archer">&#xe67d;</span><span class="tab-name">Archive</span></li>
        <li class="sidebar-tab-tags"><span class="iconfont-archer">&#xe61b;</span><span class="tab-name">Tag</span></li>
        <li class="sidebar-tab-categories"><span class="iconfont-archer">&#xe666;</span><span class="tab-name">Cate</span></li>
    </ul>
    <div class="sidebar-content sidebar-content-show-archive">
        <div class="sidebar-panel-archives">
    <!-- 在 ejs 中将 archive 按照时间排序 -->
    
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
    
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
    
    
    
    
    <div class="total-and-search">
        <div class="total-archive">
        Total : 59
        </div>
        <!-- search  -->
        
    </div>
    
    <div class="post-archive">
    
        
            
            
            <div class="archive-year"> 2022 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">12/31</span>
            <a class="archive-post-title" href="/2022-12-31-2022-%E7%BD%91%E7%BB%9C%E6%97%A5%E5%BF%97/">2022 网络日志</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">04/09</span>
            <a class="archive-post-title" href="/2022-04-09-%E8%A7%86%E9%A2%91%E7%BC%96%E8%BE%91-(FFmpeg-DaVinci)/">视频编辑 (FFmpeg DaVinci)</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> 2021 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">12/31</span>
            <a class="archive-post-title" href="/2021-12-31-2021-%E7%BD%91%E7%BB%9C%E6%97%A5%E5%BF%97/">2021 网络日志</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">09/16</span>
            <a class="archive-post-title" href="/2021-09-16-Intro-to-SQL/">Intro to SQL</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">08/31</span>
            <a class="archive-post-title" href="/2021-08-31-Introduction-to-C/">Introduction to C</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">08/29</span>
            <a class="archive-post-title" href="/2021-08-29-%E6%9B%B4%E6%96%B0archer%E4%B8%BB%E9%A2%98--%E8%BF%81%E7%A7%BBHexo%E5%8D%9A%E5%AE%A2/">更新archer主题 / 迁移Hexo博客</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/28</span>
            <a class="archive-post-title" href="/2021-06-28-Install-and-Configure-Aria2-on-Linux/">Install and Configure Aria2 on WSL</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/23</span>
            <a class="archive-post-title" href="/2021-06-23-On-Intelligence/">On Intelligence</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">05/28</span>
            <a class="archive-post-title" href="/2021-05-28-Introduction-to-TensorFlow-1.x/">Introduction to TensorFlow 1.x</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">02/11</span>
            <a class="archive-post-title" href="/2021-02-11-Tsinghua-DSA-%E4%BD%9C%E4%B8%9A%E6%80%BB%E7%BB%93-(3)/">Tsinghua DSA 作业总结 (3)</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">02/10</span>
            <a class="archive-post-title" href="/2021-02-10-Tsinghua-DSA-%E4%BD%9C%E4%B8%9A%E6%80%BB%E7%BB%93-(2)/">Tsinghua DSA 作业总结 (2)</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">02/09</span>
            <a class="archive-post-title" href="/2021-02-09-Tsinghua-DSA-%E4%BD%9C%E4%B8%9A%E6%80%BB%E7%BB%93-(1)/">Tsinghua DSA 作业总结 (1)</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">01/11</span>
            <a class="archive-post-title" href="/2021-01-11-CornellTsinghua-20FA-%E6%80%BB%E7%BB%93/">Cornell/Tsinghua 20FA 总结</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> 2020 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/29</span>
            <a class="archive-post-title" href="/2020-11-29-Python-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/">Python 常见问题</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/29</span>
            <a class="archive-post-title" href="/2020-11-29-C++-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/">C++ 常见问题</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/23</span>
            <a class="archive-post-title" href="/2020-11-23-Latex-%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7%E6%89%8B%E5%86%8C/">Latex 实用技巧手册</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">10/13</span>
            <a class="archive-post-title" href="/2020-10-13-Algorithm-Design-%E5%8F%8A-CS4820-%E4%B8%80%E8%88%AC%E6%80%A7%E5%86%85%E5%AE%B9%E6%80%BB%E7%BB%93/">Algorithm Design 及 CS4820 一般性内容总结</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">10/02</span>
            <a class="archive-post-title" href="/2020-10-02-INFO1998-Intro-to-Machine-Learning/">INFO1998 Intro to Machine Learning</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">09/29</span>
            <a class="archive-post-title" href="/2020-09-29-Add-Open-with-Windows-Terminalto-Right-Click-Menu/">Add "Open with Windows Terminal" to Right-Click Menu</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">09/07</span>
            <a class="archive-post-title" href="/2020-09-07-CS2024-C++-Programming/">CS2024 C++ Programming</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">09/05</span>
            <a class="archive-post-title" href="/2020-09-05-Windows%E4%B8%8B%E9%85%8D%E7%BD%AEPostgreSQL/">Windows下配置PostgreSQL</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/24</span>
            <a class="archive-post-title" href="/2020-06-24-Kinekt-as-Web-Cam/">Kinect as Web Cam</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/09</span>
            <a class="archive-post-title" href="/2020-06-09-2020-%E7%BD%91%E7%BB%9C%E6%97%A5%E5%BF%97/">2020 网络日志</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">05/27</span>
            <a class="archive-post-title" href="/2020-05-27-Cornell-20SP-%E6%80%BB%E7%BB%93/">Cornell 20SP 总结</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">03/03</span>
            <a class="archive-post-title" href="/2020-03-03-Mutability/">Mutability</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">02/18</span>
            <a class="archive-post-title" href="/2020-02-18-Specifications/">Specifications</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">02/13</span>
            <a class="archive-post-title" href="/2020-02-13-Code-Reuse-with-Modules/">Code Reuse with Modules</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">02/11</span>
            <a class="archive-post-title" href="/2020-02-11-Modules/">Modules</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">02/06</span>
            <a class="archive-post-title" href="/2020-02-06-Higher-Order-Functions/">Higher-Order Functions</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">02/04</span>
            <a class="archive-post-title" href="/2020-02-04-Advanced-Data-Types/">Advanced Data Types</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">01/30</span>
            <a class="archive-post-title" href="/2020-01-30-Standard-Data-Types/">Standard Data Types</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">01/28</span>
            <a class="archive-post-title" href="/2020-01-28-Functions/">Functions</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">01/24</span>
            <a class="archive-post-title" href="/2020-01-24-CS2043-Unix-Tools-and-Scripting/">CS2043 Unix Tools and Scripting</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">01/20</span>
            <a class="archive-post-title" href="/2020-01-20-Installing-Ocaml-on-Linux/">Installing and Configuring Ocaml on Linux</a>
        </li>
    
        
            
            
                
                </ul>
            
            <div class="archive-year"> 2019 </div>
            <ul class="year-list">
            
        
        <li class="archive-post-item">
            <span class="archive-post-date">12/22</span>
            <a class="archive-post-title" href="/2019-12-22-Cornell-19FA-%E6%80%BB%E7%BB%93/">Cornell 19FA 总结</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">12/17</span>
            <a class="archive-post-title" href="/2019-12-17-add-pdf-file-to-hexo/">Add pdf file to hexo</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">12/05</span>
            <a class="archive-post-title" href="/2019-12-05-Problem-Analysis/">Problem Analysis</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/26</span>
            <a class="archive-post-title" href="/2019-11-26-Priority-Queue-and-Heap/">Priority Queue and Heap</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/23</span>
            <a class="archive-post-title" href="/2019-11-23-Android-Basics-User-Interface/">Udacity: Android Basics</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/21</span>
            <a class="archive-post-title" href="/2019-11-21-shortest-path-algorithm/">Shortest path algorithm</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/21</span>
            <a class="archive-post-title" href="/2019-11-21-import-Junit-and-JavaFx-into-VSCode/">Import Junit and JavaFx into VSCode</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/20</span>
            <a class="archive-post-title" href="/2019-11-20-Graph-(Recitation)/">Graph (Recitation)</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/19</span>
            <a class="archive-post-title" href="/2019-11-19-Graph-Traversal/">Graph Traversal</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/12</span>
            <a class="archive-post-title" href="/2019-11-12-synchronization/">Synchronization</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">11/07</span>
            <a class="archive-post-title" href="/2019-11-07-Concurrency/">Concurrency</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">10/17</span>
            <a class="archive-post-title" href="/2019-10-17-Designing-and-documenting-interfaces-and-implementations/">Designing and documenting interfaces and implementations</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">09/30</span>
            <a class="archive-post-title" href="/2019-09-30-Value-Representation,-Hashing,-and-Generics/">Value Representation, Hashing, and Generics</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">07/07</span>
            <a class="archive-post-title" href="/2019-07-07-P1162-%E5%A1%AB%E6%B6%82%E9%A2%9C%E8%89%B2/">P1162 填涂颜色</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">07/04</span>
            <a class="archive-post-title" href="/2019-07-04-P1141-01%E8%BF%B7%E5%AE%AB/">P1141 01迷宫</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">07/02</span>
            <a class="archive-post-title" href="/2019-07-02-P1118-Backward-Digital-Sums/">P1118 Backward Digital Sums</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/26</span>
            <a class="archive-post-title" href="/P1019%20%E5%8D%95%E8%AF%8D%E6%8E%A5%E9%BE%99/">P1019 单词接龙</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/17</span>
            <a class="archive-post-title" href="/P1101%20%E5%8D%95%E8%AF%8D%E6%96%B9%E9%98%B5/">P1101 单词方阵</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/16</span>
            <a class="archive-post-title" href="/P1219%20%E5%85%AB%E7%9A%87%E5%90%8E/">P1219 八皇后</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/04</span>
            <a class="archive-post-title" href="/P1031%20%E5%9D%87%E5%88%86%E7%BA%B8%E7%89%8C/">P1031 均分纸牌</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">06/03</span>
            <a class="archive-post-title" href="/P2678%20%E8%B7%B3%E7%9F%B3%E5%A4%B4/">P2678 跳石头</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">05/30</span>
            <a class="archive-post-title" href="/P1090%20%E5%90%88%E5%B9%B6%E6%9E%9C%E5%AD%90/">P1090 合并果子</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">05/30</span>
            <a class="archive-post-title" href="/P1309%20%E7%91%9E%E5%A3%AB%E8%BD%AE/">P1309 瑞士轮</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">02/10</span>
            <a class="archive-post-title" href="/Intro-to-Git-Command/">Introduction to Git Command</a>
        </li>
    
        
        <li class="archive-post-item">
            <span class="archive-post-date">02/09</span>
            <a class="archive-post-title" href="/hello-world/">Hello World</a>
        </li>
    
    </ul></div>
</div>

        <div class="sidebar-panel-tags">
    <div class="sidebar-tags-name">
        
            <span class="sidebar-tag-name" data-tags="NOI">
                <span class="iconfont-archer">&#xe606;</span>
                NOI
            </span>
        
            <span class="sidebar-tag-name" data-tags="Cornell">
                <span class="iconfont-archer">&#xe606;</span>
                Cornell
            </span>
        
            <span class="sidebar-tag-name" data-tags="19FA">
                <span class="iconfont-archer">&#xe606;</span>
                19FA
            </span>
        
            <span class="sidebar-tag-name" data-tags="CS2112">
                <span class="iconfont-archer">&#xe606;</span>
                CS2112
            </span>
        
            <span class="sidebar-tag-name" data-tags="Logistics">
                <span class="iconfont-archer">&#xe606;</span>
                Logistics
            </span>
        
            <span class="sidebar-tag-name" data-tags="Java">
                <span class="iconfont-archer">&#xe606;</span>
                Java
            </span>
        
            <span class="sidebar-tag-name" data-tags="Android">
                <span class="iconfont-archer">&#xe606;</span>
                Android
            </span>
        
            <span class="sidebar-tag-name" data-tags="Hexo">
                <span class="iconfont-archer">&#xe606;</span>
                Hexo
            </span>
        
            <span class="sidebar-tag-name" data-tags="20SP">
                <span class="iconfont-archer">&#xe606;</span>
                20SP
            </span>
        
            <span class="sidebar-tag-name" data-tags="CS2043">
                <span class="iconfont-archer">&#xe606;</span>
                CS2043
            </span>
        
            <span class="sidebar-tag-name" data-tags="CS3110">
                <span class="iconfont-archer">&#xe606;</span>
                CS3110
            </span>
        
            <span class="sidebar-tag-name" data-tags="网络日志">
                <span class="iconfont-archer">&#xe606;</span>
                网络日志
            </span>
        
            <span class="sidebar-tag-name" data-tags="CS4320">
                <span class="iconfont-archer">&#xe606;</span>
                CS4320
            </span>
        
            <span class="sidebar-tag-name" data-tags="20FA">
                <span class="iconfont-archer">&#xe606;</span>
                20FA
            </span>
        
            <span class="sidebar-tag-name" data-tags="Python">
                <span class="iconfont-archer">&#xe606;</span>
                Python
            </span>
        
            <span class="sidebar-tag-name" data-tags="Tsinghua">
                <span class="iconfont-archer">&#xe606;</span>
                Tsinghua
            </span>
        
            <span class="sidebar-tag-name" data-tags="C++">
                <span class="iconfont-archer">&#xe606;</span>
                C++
            </span>
        
            <span class="sidebar-tag-name" data-tags="Latex">
                <span class="iconfont-archer">&#xe606;</span>
                Latex
            </span>
        
            <span class="sidebar-tag-name" data-tags="CS4820">
                <span class="iconfont-archer">&#xe606;</span>
                CS4820
            </span>
        
            <span class="sidebar-tag-name" data-tags="Linux">
                <span class="iconfont-archer">&#xe606;</span>
                Linux
            </span>
        
            <span class="sidebar-tag-name" data-tags="Git">
                <span class="iconfont-archer">&#xe606;</span>
                Git
            </span>
        
            <span class="sidebar-tag-name" data-tags="Reading">
                <span class="iconfont-archer">&#xe606;</span>
                Reading
            </span>
        
            <span class="sidebar-tag-name" data-tags="CS2024">
                <span class="iconfont-archer">&#xe606;</span>
                CS2024
            </span>
        
    </div>
    <div class="iconfont-archer sidebar-tags-empty">&#xe678;</div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
        缺失模块，请参考主题文档进行安装配置：https://github.com/fi3ework/hexo-theme-archer#%E5%AE%89%E8%A3%85%E4%B8%BB%E9%A2%98
    </div> 
    <div class="sidebar-tags-list"></div>
</div>

        <div class="sidebar-panel-categories">
    <div class="sidebar-categories-name">
    
    </div>
    <div class="iconfont-archer sidebar-categories-empty">&#xe678;</div>
    <div class="sidebar-categories-list"></div>
</div>

    </div>
</div>

        <!-- site-meta -->
        <script>
    var siteMeta = {
        root: "/",
        author: "Yao Lirong"
    }
</script>

        <!-- import experimental options here -->
        <!-- main func -->
        <script src="/scripts/main.js?v=20210823"></script>
        <!-- dark mode -->
        <script src="/scripts/dark.js?v=20210823"></script>
        <!-- fancybox -->
        <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" defer></script>
        <!-- algolia -->
        
        <!-- busuanzi -->
        
            <script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>
        
        <!-- CNZZ -->
        
        <!-- async load share.js -->
        
            <script src="/scripts/share.js?v=20210823" async></script>
        
        <!-- mermaid -->
        
    </body>
</html>
